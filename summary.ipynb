{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Sihui Huang\n",
    "### Uni: sh3573\n",
    "### Email: sh3573@columbia.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: All code should be in Python3. Keras version should be 2.0.4. The directory structure on the bitbucket repo should be exactly same as the hw4.zip provided to you (with the exception of data directory. Do not upload it). To push the code to remote repo, use the same instructions as given in HW0. **Double check you remote repo for correct directory structure. We won't consider any regrade requests based on wrong directory structure penalty. Again, do not upload data to your bitbucket repo ** <br>\n",
    "**The data provided to you should not be used for any other purpose than this course. You must not distribute it or upload it to any public platform.**\n",
    "\n",
    "In this assignment, we are going to solve the problem of summarization using a sequence to sequence model. In a sequence to sequence problem, we have an encoder and a decoder. We feed the sequence of word embeddings to an encoder and train decoder to learn the summaries. We will be seeing 2 types of encoder decoder architectures in this assignment\n",
    "\n",
    "# Preparing Inputs\n",
    "The first part of the assignment is to prepare data. You are given training data in train_article.txt, in which each line is the first sentence from an article, and training summary sentences in train_title.txt, which are the corresponding titles of the article. You will be training the model to predict the title of an article given the first sentence of that article, where title generation is a summarization task. Let us limit the maximum vocabulary size to 20000 and maximum length of article to 200 (These are just initial params to get you started and we recommend experimenting, to improve your scores after you are done with your first implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "MAX_LEN = 200\n",
    "VOCAB_SIZE = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes article file, summary file, maximum length of sentence and vocabulary size and does the following\n",
    "* Create vocabulary: Take most frequent VOCAB_SIZE number of words from article file. Add two special symbols ZERO at start and UNK at end to finally have VOCAB_SIZE + 2 words. Use this array as idx2word. Repeat the process for summary data to create another idx2word corresponding to it. \n",
    "* Using the above idx2word for both article and summary data, create word2idx, which will map every word to its index in idx2word array. \n",
    "* Convert the words in the article and summary data to their corresponding index from word2idx. If a word is not present in the vocab, use the index of UNK. \n",
    "* After the above preprocessing, each sentence in article and summary data should be a list of indices\n",
    "* Now find the max length of a sentence (which is basically number of indices in a sentence) in article data. Pad every sentence in article data to that length, so that all sentences are of same length. You may use pad_sequences function provided by keras. Do the same for title data.\n",
    "* return the following outputs transformed article data, vocab size of article data, idx2word(articledata), word2idx(articledata),transformed summary data, vocab size of summary data, idx2word(summarydata), word2idx(summarydata)\n",
    "\n",
    "reference: https://github.com/ChunML/seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(source, dist, max_len, vocab_size):\n",
    "\n",
    "    # Reading raw text from source and destination files\n",
    "    f = open(source, 'r')\n",
    "    X_data = f.read()\n",
    "    f.close()\n",
    "    f = open(dist, 'r')\n",
    "    y_data = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Splitting raw text into array of sequences\n",
    "    X = [text_to_word_sequence(x, filters='')[::-1] for x, y in zip(X_data.split('\\n'), y_data.split('\\n')) if len(x) > 0 and len(y) > 0 and len(x) <= max_len and len(y) <= max_len]\n",
    "    y = [text_to_word_sequence(y, filters='') for x, y in zip(X_data.split('\\n'), y_data.split('\\n')) if len(x) > 0 and len(y) > 0 and len(x) <= max_len and len(y) <= max_len]\n",
    "\n",
    "    # Creating the vocabulary set with the most common words\n",
    "    dist = FreqDist(np.hstack(X))\n",
    "    X_vocab = dist.most_common(vocab_size)\n",
    "    dist = FreqDist(np.hstack(y))\n",
    "    y_vocab = dist.most_common(vocab_size)\n",
    "\n",
    "    # Creating an array of words from the vocabulary set, we will use this array as index-to-word dictionary\n",
    "    X_ix_to_word = [word[0] for word in X_vocab]\n",
    "    # Adding the word \"ZERO\" to the beginning of the array\n",
    "    X_ix_to_word.insert(0, 'ZERO')\n",
    "    # Adding the word 'UNK' to the end of the array (stands for UNKNOWN words)\n",
    "    X_ix_to_word.append('UNK')\n",
    "\n",
    "    # Creating the word-to-index dictionary from the array created above\n",
    "    X_word_to_ix = {word:ix for ix, word in enumerate(X_ix_to_word)}\n",
    "\n",
    "    # Converting each word to its index value\n",
    "    for i, sentence in enumerate(X):\n",
    "        for j, word in enumerate(sentence):\n",
    "            if word in X_word_to_ix:\n",
    "                X[i][j] = X_word_to_ix[word]\n",
    "            else:\n",
    "                X[i][j] = X_word_to_ix['UNK']\n",
    "\n",
    "    y_ix_to_word = [word[0] for word in y_vocab]\n",
    "    y_ix_to_word.insert(0, 'ZERO')\n",
    "    y_ix_to_word.append('UNK')\n",
    "    y_word_to_ix = {word:ix for ix, word in enumerate(y_ix_to_word)}\n",
    "    for i, sentence in enumerate(y):\n",
    "        for j, word in enumerate(sentence):\n",
    "            if word in y_word_to_ix:\n",
    "                y[i][j] = y_word_to_ix[word]\n",
    "            else:\n",
    "                y[i][j] = y_word_to_ix['UNK']\n",
    "    return (X, len(X_vocab)+2, X_word_to_ix, X_ix_to_word, y, len(y_vocab)+2, y_word_to_ix, y_ix_to_word)\n",
    "\n",
    "def load_test_data(source, X_word_to_ix, max_len):\n",
    "    f = open(source, 'r')\n",
    "    X_data = f.read()\n",
    "    f.close()\n",
    "\n",
    "    X = [text_to_word_sequence(x, filters='')[::-1] for x in X_data.split('\\n') if len(x) > 0 and len(x) <= max_len]\n",
    "    for i, sentence in enumerate(X):\n",
    "        for j, word in enumerate(sentence):\n",
    "            if word in X_word_to_ix:\n",
    "                X[i][j] = X_word_to_ix[word]\n",
    "            else:\n",
    "                X[i][j] = X_word_to_ix['UNK']\n",
    "    return X\n",
    "\n",
    "def process_data(word_sentences, max_len, word_to_ix):\n",
    "    # Vectorizing each element in each sequence\n",
    "    sequences = np.zeros((len(word_sentences), max_len, len(word_to_ix)))\n",
    "    for i, sentence in enumerate(word_sentences):\n",
    "        for j, word in enumerate(sentence):\n",
    "            sequences[i, j, word] = 1.\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the above function to load the training data from article and summary (i.e. title) files. Do note that, based on your model architecture, you may need to further one-hot vectorize your input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n",
      "[INFO] Zero padding...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Loading data...')\n",
    "X, X_vocab_len, X_word_to_ix, X_ix_to_word, y, y_vocab_len, y_word_to_ix, y_ix_to_word = load_data('data/train_article.txt', 'data/train_title.txt', MAX_LEN, VOCAB_SIZE)\n",
    "\n",
    "# Finding the length of the longest sequence\n",
    "X_max_len = max([len(sentence) for sentence in X])\n",
    "y_max_len = max([len(sentence) for sentence in y])\n",
    "\n",
    "# Padding zeros to make all sequences have a same length with the longest one\n",
    "print('[INFO] Zero padding...')\n",
    "X = pad_sequences(X, maxlen=X_max_len, dtype='int32', padding='post')\n",
    "y = pad_sequences(y, maxlen=y_max_len, dtype='int32', padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24)\n",
      "(50000, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidirectional LSTM Encoder Decoder\n",
    "Define the parameters for your LSTM encoder decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LAYER_NUM = 4\n",
    "HIDDEN_DIM = 512\n",
    "NB_EPOCH = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Unidirectional encoder decoder LSTM model in create_model function. The model should have a LSTM Unidirectional layer as encoder and a LSTM decoder. Use categorical_cross_entropy loss and experiment with different optimizers to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_UniLSTM(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Creating encoder network\n",
    "    model.add(Embedding(X_vocab_len, hidden_size, input_length=X_max_len, mask_zero=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(RepeatVector(y_max_len))\n",
    "\n",
    "    # Creating decoder network\n",
    "    for _ in range(num_layers):\n",
    "        model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(y_vocab_len)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create_UniLSTMwithAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling model...\n"
     ]
    }
   ],
   "source": [
    "# Creating the network model\n",
    "print('[INFO] Compiling model...')\n",
    "model = create_UniLSTM(X_vocab_len, X_max_len, y_vocab_len, y_max_len, HIDDEN_DIM, LAYER_NUM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Now that we have everything in place, we can run our model. We recommend training the model in batches instead of training on all 50,000 article-title pairs at once, if you encounter memory contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 1th 0/50000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 14s - loss: 8.8177 - acc: 0.5246 - val_loss: 2.8536 - val_acc: 0.7686\n",
      "[INFO] Training model: epoch 1th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5546 - acc: 0.7676 - val_loss: 2.3277 - val_acc: 0.7697\n",
      "[INFO] Training model: epoch 1th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3265 - acc: 0.7689 - val_loss: 2.2440 - val_acc: 0.7720\n",
      "[INFO] Training model: epoch 1th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2901 - acc: 0.7678 - val_loss: 2.2782 - val_acc: 0.7605\n",
      "[INFO] Training model: epoch 1th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3058 - acc: 0.7659 - val_loss: 2.1638 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 1th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2078 - acc: 0.7714 - val_loss: 2.3497 - val_acc: 0.7645\n",
      "[INFO] Training model: epoch 1th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2275 - acc: 0.7693 - val_loss: 2.1692 - val_acc: 0.7713\n",
      "[INFO] Training model: epoch 1th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2285 - acc: 0.7629 - val_loss: 2.3589 - val_acc: 0.7613\n",
      "[INFO] Training model: epoch 1th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1669 - acc: 0.7726 - val_loss: 2.0064 - val_acc: 0.7741\n",
      "[INFO] Training model: epoch 1th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1281 - acc: 0.7701 - val_loss: 2.1446 - val_acc: 0.7675\n",
      "[INFO] Training model: epoch 1th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0974 - acc: 0.7682 - val_loss: 2.1716 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 1th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2704 - acc: 0.7658 - val_loss: 2.0668 - val_acc: 0.7722\n",
      "[INFO] Training model: epoch 1th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 2.0050 - acc: 0.7722 - val_loss: 2.0208 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 1th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0175 - acc: 0.7693 - val_loss: 2.0897 - val_acc: 0.7608\n",
      "[INFO] Training model: epoch 1th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1155 - acc: 0.7676 - val_loss: 1.9266 - val_acc: 0.7752\n",
      "[INFO] Training model: epoch 1th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0054 - acc: 0.7675 - val_loss: 1.9896 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 1th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9994 - acc: 0.7679 - val_loss: 1.8733 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 1th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9388 - acc: 0.7707 - val_loss: 1.8438 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 1th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0074 - acc: 0.7709 - val_loss: 1.9844 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 1th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9610 - acc: 0.7677 - val_loss: 2.0551 - val_acc: 0.7722\n",
      "[INFO] Training model: epoch 1th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0514 - acc: 0.7711 - val_loss: 1.9560 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9503 - acc: 0.7741 - val_loss: 1.9363 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9594 - acc: 0.7710 - val_loss: 1.9415 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 1th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0049 - acc: 0.7659 - val_loss: 1.9288 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 1th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9210 - acc: 0.7743 - val_loss: 2.0082 - val_acc: 0.7661\n",
      "[INFO] Training model: epoch 1th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9993 - acc: 0.7660 - val_loss: 1.9635 - val_acc: 0.7681\n",
      "[INFO] Training model: epoch 1th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9208 - acc: 0.7724 - val_loss: 1.9078 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 1th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9537 - acc: 0.7701 - val_loss: 2.0493 - val_acc: 0.7723\n",
      "[INFO] Training model: epoch 1th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9253 - acc: 0.7752 - val_loss: 1.9603 - val_acc: 0.7723\n",
      "[INFO] Training model: epoch 1th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9433 - acc: 0.7721 - val_loss: 2.0291 - val_acc: 0.7608\n",
      "[INFO] Training model: epoch 1th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9475 - acc: 0.7712 - val_loss: 1.8657 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 1th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9677 - acc: 0.7718 - val_loss: 1.9655 - val_acc: 0.7725\n",
      "[INFO] Training model: epoch 1th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9682 - acc: 0.7721 - val_loss: 1.9256 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9355 - acc: 0.7729 - val_loss: 1.9574 - val_acc: 0.7669\n",
      "[INFO] Training model: epoch 1th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9370 - acc: 0.7706 - val_loss: 1.9184 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 1th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9425 - acc: 0.7711 - val_loss: 1.9254 - val_acc: 0.7736\n",
      "[INFO] Training model: epoch 1th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9839 - acc: 0.7697 - val_loss: 1.8774 - val_acc: 0.7783\n",
      "[INFO] Training model: epoch 1th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.9325 - acc: 0.7722 - val_loss: 1.8689 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 1th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9319 - acc: 0.7725 - val_loss: 1.8949 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 1th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9314 - acc: 0.7732 - val_loss: 1.9021 - val_acc: 0.7706\n",
      "[INFO] Training model: epoch 1th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9378 - acc: 0.7718 - val_loss: 1.9747 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 1th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9448 - acc: 0.7730 - val_loss: 1.8997 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.8778 - acc: 0.7776 - val_loss: 1.8946 - val_acc: 0.7761\n",
      "[INFO] Training model: epoch 1th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9821 - acc: 0.7662 - val_loss: 1.9377 - val_acc: 0.7713\n",
      "[INFO] Training model: epoch 1th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8846 - acc: 0.7764 - val_loss: 1.9071 - val_acc: 0.7725\n",
      "[INFO] Training model: epoch 1th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9564 - acc: 0.7696 - val_loss: 1.9502 - val_acc: 0.7702\n",
      "[INFO] Training model: epoch 1th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8852 - acc: 0.7759 - val_loss: 1.9769 - val_acc: 0.7684\n",
      "[INFO] Training model: epoch 1th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.9622 - acc: 0.7702 - val_loss: 4.8185 - val_acc: 0.7636\n",
      "[INFO] Training model: epoch 1th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9617 - acc: 0.7687 - val_loss: 1.9923 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8851 - acc: 0.7774 - val_loss: 1.8930 - val_acc: 0.7752\n",
      "[INFO] Training model: epoch 2th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8589 - acc: 0.7762 - val_loss: 1.9395 - val_acc: 0.7733\n",
      "[INFO] Training model: epoch 2th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8899 - acc: 0.7738 - val_loss: 1.9465 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 2th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9196 - acc: 0.7704 - val_loss: 1.8048 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 2th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8818 - acc: 0.7724 - val_loss: 1.8962 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 2th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9152 - acc: 0.7718 - val_loss: 1.8417 - val_acc: 0.7761\n",
      "[INFO] Training model: epoch 2th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8960 - acc: 0.7726 - val_loss: 1.9338 - val_acc: 0.7705\n",
      "[INFO] Training model: epoch 2th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9165 - acc: 0.7709 - val_loss: 1.8841 - val_acc: 0.7747\n",
      "[INFO] Training model: epoch 2th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9080 - acc: 0.7714 - val_loss: 1.8980 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 2th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8906 - acc: 0.7721 - val_loss: 1.9573 - val_acc: 0.7666\n",
      "[INFO] Training model: epoch 2th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8938 - acc: 0.7726 - val_loss: 1.8162 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 2th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8812 - acc: 0.7739 - val_loss: 1.9264 - val_acc: 0.7736\n",
      "[INFO] Training model: epoch 2th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9471 - acc: 0.7696 - val_loss: 1.9369 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 2th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9141 - acc: 0.7687 - val_loss: 1.8640 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 2th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8974 - acc: 0.7722 - val_loss: 1.8172 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 2th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9060 - acc: 0.7729 - val_loss: 2.0259 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 2th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9441 - acc: 0.7728 - val_loss: 1.8930 - val_acc: 0.7752\n",
      "[INFO] Training model: epoch 2th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8848 - acc: 0.7727 - val_loss: 1.8909 - val_acc: 0.7753\n",
      "[INFO] Training model: epoch 2th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8954 - acc: 0.7723 - val_loss: 1.9277 - val_acc: 0.7723\n",
      "[INFO] Training model: epoch 2th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8583 - acc: 0.7756 - val_loss: 1.8366 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 2th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8695 - acc: 0.7772 - val_loss: 1.9323 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 2th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8616 - acc: 0.7759 - val_loss: 1.9290 - val_acc: 0.7667\n",
      "[INFO] Training model: epoch 2th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.8435 - acc: 0.7768 - val_loss: 1.9290 - val_acc: 0.7705\n",
      "[INFO] Training model: epoch 2th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9042 - acc: 0.7731 - val_loss: 1.7885 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8777 - acc: 0.7760 - val_loss: 1.8343 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 2th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8570 - acc: 0.7787 - val_loss: 1.8980 - val_acc: 0.7739\n",
      "[INFO] Training model: epoch 2th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9357 - acc: 0.7716 - val_loss: 1.8946 - val_acc: 0.7714\n",
      "[INFO] Training model: epoch 2th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8958 - acc: 0.7745 - val_loss: 1.8994 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 2th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8627 - acc: 0.7766 - val_loss: 1.8389 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 2th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.8373 - acc: 0.7772 - val_loss: 1.7760 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 2th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8467 - acc: 0.7772 - val_loss: 1.7824 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 2th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8773 - acc: 0.7735 - val_loss: 1.9307 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 2th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9326 - acc: 0.7713 - val_loss: 1.8501 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 2th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8836 - acc: 0.7745 - val_loss: 1.8969 - val_acc: 0.7698\n",
      "[INFO] Training model: epoch 2th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8820 - acc: 0.7708 - val_loss: 1.9161 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 2th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8349 - acc: 0.7768 - val_loss: 1.9082 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 2th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8423 - acc: 0.7757 - val_loss: 1.7875 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 2th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8783 - acc: 0.7720 - val_loss: 1.9097 - val_acc: 0.7709\n",
      "[INFO] Training model: epoch 2th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8625 - acc: 0.7753 - val_loss: 1.9307 - val_acc: 0.7691\n",
      "[INFO] Training model: epoch 2th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8637 - acc: 0.7750 - val_loss: 1.8798 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8527 - acc: 0.7732 - val_loss: 1.9030 - val_acc: 0.7786\n",
      "[INFO] Training model: epoch 2th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8948 - acc: 0.7748 - val_loss: 1.9202 - val_acc: 0.7702\n",
      "[INFO] Training model: epoch 2th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8505 - acc: 0.7759 - val_loss: 1.8499 - val_acc: 0.7723\n",
      "[INFO] Training model: epoch 2th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8513 - acc: 0.7743 - val_loss: 1.7886 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 2th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9189 - acc: 0.7675 - val_loss: 1.8850 - val_acc: 0.7705\n",
      "[INFO] Training model: epoch 2th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8148 - acc: 0.7780 - val_loss: 1.9005 - val_acc: 0.7691\n",
      "[INFO] Training model: epoch 2th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8552 - acc: 0.7749 - val_loss: 1.8895 - val_acc: 0.7723\n",
      "[INFO] Training model: epoch 2th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9202 - acc: 0.7690 - val_loss: 1.8987 - val_acc: 0.7700\n",
      "[INFO] Training model: epoch 2th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8999 - acc: 0.7696 - val_loss: 1.8449 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 2th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8667 - acc: 0.7748 - val_loss: 1.9462 - val_acc: 0.7603\n",
      "[INFO] Training model: epoch 2th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8848 - acc: 0.7732 - val_loss: 1.7958 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 3th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8153 - acc: 0.7759 - val_loss: 1.7938 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 3th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8215 - acc: 0.7761 - val_loss: 1.8622 - val_acc: 0.7730\n",
      "[INFO] Training model: epoch 3th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8459 - acc: 0.7732 - val_loss: 1.8559 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 3th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7992 - acc: 0.7790 - val_loss: 1.8616 - val_acc: 0.7738\n",
      "[INFO] Training model: epoch 3th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8216 - acc: 0.7774 - val_loss: 1.9078 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 3th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8316 - acc: 0.7740 - val_loss: 1.8579 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7954 - acc: 0.7783 - val_loss: 1.8806 - val_acc: 0.7678\n",
      "[INFO] Training model: epoch 3th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8581 - acc: 0.7720 - val_loss: 1.7786 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 3th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8719 - acc: 0.7700 - val_loss: 1.7449 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 3th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8815 - acc: 0.7716 - val_loss: 1.8557 - val_acc: 0.7705\n",
      "[INFO] Training model: epoch 3th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8635 - acc: 0.7727 - val_loss: 1.8603 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 3th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.8110 - acc: 0.7754 - val_loss: 1.8601 - val_acc: 0.7745\n",
      "[INFO] Training model: epoch 3th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8748 - acc: 0.7718 - val_loss: 1.7414 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 3th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8232 - acc: 0.7758 - val_loss: 1.9247 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 3th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8541 - acc: 0.7733 - val_loss: 1.8116 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 3th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8417 - acc: 0.7750 - val_loss: 1.7498 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 3th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8347 - acc: 0.7763 - val_loss: 1.8232 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 3th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8130 - acc: 0.7768 - val_loss: 1.8389 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7888 - acc: 0.7795 - val_loss: 1.8308 - val_acc: 0.7767\n",
      "[INFO] Training model: epoch 3th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8393 - acc: 0.7740 - val_loss: 1.8183 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 3th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8147 - acc: 0.7774 - val_loss: 1.8000 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 3th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8266 - acc: 0.7755 - val_loss: 1.7629 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 3th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8288 - acc: 0.7754 - val_loss: 1.8143 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 3th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8239 - acc: 0.7761 - val_loss: 1.8105 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 3th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8423 - acc: 0.7725 - val_loss: 1.8922 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 3th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8118 - acc: 0.7771 - val_loss: 1.8595 - val_acc: 0.7730\n",
      "[INFO] Training model: epoch 3th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8098 - acc: 0.7771 - val_loss: 1.8518 - val_acc: 0.7739\n",
      "[INFO] Training model: epoch 3th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8453 - acc: 0.7779 - val_loss: 1.8071 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 3th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8795 - acc: 0.7728 - val_loss: 1.8299 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 3th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8549 - acc: 0.7740 - val_loss: 1.8203 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8019 - acc: 0.7788 - val_loss: 1.8017 - val_acc: 0.7761\n",
      "[INFO] Training model: epoch 3th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8334 - acc: 0.7752 - val_loss: 1.9137 - val_acc: 0.7722\n",
      "[INFO] Training model: epoch 3th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8421 - acc: 0.7759 - val_loss: 1.8611 - val_acc: 0.7714\n",
      "[INFO] Training model: epoch 3th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8513 - acc: 0.7719 - val_loss: 1.7871 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8055 - acc: 0.7752 - val_loss: 1.9418 - val_acc: 0.7669\n",
      "[INFO] Training model: epoch 3th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8551 - acc: 0.7732 - val_loss: 1.8672 - val_acc: 0.7716\n",
      "[INFO] Training model: epoch 3th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7787 - acc: 0.7797 - val_loss: 1.7732 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 3th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8603 - acc: 0.7731 - val_loss: 1.8174 - val_acc: 0.7763\n",
      "[INFO] Training model: epoch 3th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8296 - acc: 0.7760 - val_loss: 1.7439 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 3th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7986 - acc: 0.7778 - val_loss: 1.8287 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8222 - acc: 0.7786 - val_loss: 1.8434 - val_acc: 0.7725\n",
      "[INFO] Training model: epoch 3th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7782 - acc: 0.7799 - val_loss: 1.7727 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 3th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8077 - acc: 0.7778 - val_loss: 1.8189 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 3th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7788 - acc: 0.7825 - val_loss: 1.8356 - val_acc: 0.7736\n",
      "[INFO] Training model: epoch 3th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8007 - acc: 0.7789 - val_loss: 1.7084 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 3th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8372 - acc: 0.7744 - val_loss: 1.8373 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 3th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8049 - acc: 0.7769 - val_loss: 1.8528 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8280 - acc: 0.7755 - val_loss: 1.8860 - val_acc: 0.7677\n",
      "[INFO] Training model: epoch 3th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8517 - acc: 0.7734 - val_loss: 1.8075 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 3th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7927 - acc: 0.7787 - val_loss: 1.9051 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 4th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8401 - acc: 0.7727 - val_loss: 1.8618 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 4th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8167 - acc: 0.7741 - val_loss: 1.7131 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 4th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7587 - acc: 0.7790 - val_loss: 1.7712 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 4th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8126 - acc: 0.7747 - val_loss: 1.8097 - val_acc: 0.7755\n",
      "[INFO] Training model: epoch 4th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8042 - acc: 0.7758 - val_loss: 1.8214 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 4th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7962 - acc: 0.7746 - val_loss: 1.9389 - val_acc: 0.7572\n",
      "[INFO] Training model: epoch 4th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7751 - acc: 0.7785 - val_loss: 1.7652 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 4th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8333 - acc: 0.7732 - val_loss: 1.7410 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 4th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8072 - acc: 0.7758 - val_loss: 1.7947 - val_acc: 0.7759\n",
      "[INFO] Training model: epoch 4th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7941 - acc: 0.7755 - val_loss: 1.8752 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 4th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7803 - acc: 0.7777 - val_loss: 1.8356 - val_acc: 0.7714\n",
      "[INFO] Training model: epoch 4th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7811 - acc: 0.7788 - val_loss: 1.7785 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 4th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8252 - acc: 0.7709 - val_loss: 1.8050 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 4th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7592 - acc: 0.7796 - val_loss: 1.8381 - val_acc: 0.7741\n",
      "[INFO] Training model: epoch 4th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7856 - acc: 0.7771 - val_loss: 1.8207 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 4th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7769 - acc: 0.7783 - val_loss: 1.8585 - val_acc: 0.7669\n",
      "[INFO] Training model: epoch 4th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7888 - acc: 0.7790 - val_loss: 1.8341 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 4th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7717 - acc: 0.7816 - val_loss: 1.8610 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 4th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7885 - acc: 0.7790 - val_loss: 1.8219 - val_acc: 0.7761\n",
      "[INFO] Training model: epoch 4th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8023 - acc: 0.7770 - val_loss: 1.8143 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 4th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7919 - acc: 0.7766 - val_loss: 1.7863 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 4th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7853 - acc: 0.7788 - val_loss: 1.8377 - val_acc: 0.7761\n",
      "[INFO] Training model: epoch 4th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7963 - acc: 0.7768 - val_loss: 1.8022 - val_acc: 0.7767\n",
      "[INFO] Training model: epoch 4th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7676 - acc: 0.7793 - val_loss: 1.7781 - val_acc: 0.7833\n",
      "[INFO] Training model: epoch 4th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8290 - acc: 0.7725 - val_loss: 1.8274 - val_acc: 0.7753\n",
      "[INFO] Training model: epoch 4th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8006 - acc: 0.7782 - val_loss: 1.7691 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 4th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7929 - acc: 0.7765 - val_loss: 1.7701 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 4th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8073 - acc: 0.7742 - val_loss: 1.7735 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 4th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7954 - acc: 0.7778 - val_loss: 1.8081 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 4th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7785 - acc: 0.7799 - val_loss: 1.8799 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 4th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7802 - acc: 0.7785 - val_loss: 1.7986 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 4th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8146 - acc: 0.7756 - val_loss: 1.7694 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 4th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8046 - acc: 0.7751 - val_loss: 1.8449 - val_acc: 0.7763\n",
      "[INFO] Training model: epoch 4th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7772 - acc: 0.7802 - val_loss: 1.9459 - val_acc: 0.7636\n",
      "[INFO] Training model: epoch 4th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7961 - acc: 0.7774 - val_loss: 1.7888 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 4th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.7911 - acc: 0.7770 - val_loss: 1.7698 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 4th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8216 - acc: 0.7741 - val_loss: 1.7879 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 4th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8436 - acc: 0.7738 - val_loss: 1.7852 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 4th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8086 - acc: 0.7770 - val_loss: 1.7255 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7900 - acc: 0.7777 - val_loss: 1.8628 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 4th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8591 - acc: 0.7697 - val_loss: 1.8182 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 4th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8547 - acc: 0.7699 - val_loss: 1.7667 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8074 - acc: 0.7771 - val_loss: 1.8409 - val_acc: 0.7669\n",
      "[INFO] Training model: epoch 4th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8169 - acc: 0.7755 - val_loss: 1.7721 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 4th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7730 - acc: 0.7765 - val_loss: 1.8215 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 4th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7994 - acc: 0.7737 - val_loss: 1.8274 - val_acc: 0.7739\n",
      "[INFO] Training model: epoch 4th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7649 - acc: 0.7814 - val_loss: 1.7919 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 4th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7579 - acc: 0.7814 - val_loss: 1.8869 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 4th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8089 - acc: 0.7763 - val_loss: 1.7258 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 4th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7737 - acc: 0.7795 - val_loss: 1.7569 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7811 - acc: 0.7775 - val_loss: 1.7534 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 5th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7605 - acc: 0.7754 - val_loss: 1.6995 - val_acc: 0.7833\n",
      "[INFO] Training model: epoch 5th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7685 - acc: 0.7776 - val_loss: 1.7508 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 5th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8210 - acc: 0.7723 - val_loss: 1.7486 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 5th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7838 - acc: 0.7752 - val_loss: 1.7539 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6974 - acc: 0.7842 - val_loss: 1.7739 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 5th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7347 - acc: 0.7816 - val_loss: 1.7449 - val_acc: 0.7763\n",
      "[INFO] Training model: epoch 5th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7909 - acc: 0.7745 - val_loss: 1.7458 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 5th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7382 - acc: 0.7800 - val_loss: 1.8128 - val_acc: 0.7697\n",
      "[INFO] Training model: epoch 5th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7930 - acc: 0.7748 - val_loss: 1.7281 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 5th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8023 - acc: 0.7732 - val_loss: 1.6784 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 5th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7961 - acc: 0.7762 - val_loss: 1.7699 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 5th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8275 - acc: 0.7725 - val_loss: 1.7023 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 5th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7951 - acc: 0.7766 - val_loss: 1.7345 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 5th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7481 - acc: 0.7800 - val_loss: 1.8301 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 5th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7524 - acc: 0.7785 - val_loss: 1.8474 - val_acc: 0.7709\n",
      "[INFO] Training model: epoch 5th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7856 - acc: 0.7757 - val_loss: 1.8358 - val_acc: 0.7702\n",
      "[INFO] Training model: epoch 5th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7494 - acc: 0.7796 - val_loss: 1.7855 - val_acc: 0.7753\n",
      "[INFO] Training model: epoch 5th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7587 - acc: 0.7780 - val_loss: 1.8288 - val_acc: 0.7694\n",
      "[INFO] Training model: epoch 5th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7784 - acc: 0.7771 - val_loss: 1.7840 - val_acc: 0.7733\n",
      "[INFO] Training model: epoch 5th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7320 - acc: 0.7814 - val_loss: 1.7636 - val_acc: 0.7761\n",
      "[INFO] Training model: epoch 5th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7591 - acc: 0.7791 - val_loss: 1.7641 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 5th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7401 - acc: 0.7814 - val_loss: 1.7310 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 5th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8096 - acc: 0.7731 - val_loss: 1.7638 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 5th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7840 - acc: 0.7771 - val_loss: 1.7902 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 5th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7645 - acc: 0.7781 - val_loss: 1.8441 - val_acc: 0.7702\n",
      "[INFO] Training model: epoch 5th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7560 - acc: 0.7782 - val_loss: 1.7793 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 5th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7590 - acc: 0.7792 - val_loss: 1.6560 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 5th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7283 - acc: 0.7821 - val_loss: 1.7976 - val_acc: 0.7733\n",
      "[INFO] Training model: epoch 5th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7811 - acc: 0.7773 - val_loss: 1.8140 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 5th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7635 - acc: 0.7783 - val_loss: 1.6964 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 5th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7661 - acc: 0.7782 - val_loss: 1.7519 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 5th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7879 - acc: 0.7776 - val_loss: 1.7310 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 5th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7510 - acc: 0.7784 - val_loss: 1.7512 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 5th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7900 - acc: 0.7759 - val_loss: 1.8281 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 5th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7673 - acc: 0.7787 - val_loss: 1.7749 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 5th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7782 - acc: 0.7779 - val_loss: 1.7414 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 5th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7807 - acc: 0.7759 - val_loss: 1.7774 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 5th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8041 - acc: 0.7725 - val_loss: 1.7592 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 5th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7397 - acc: 0.7790 - val_loss: 1.7983 - val_acc: 0.7759\n",
      "[INFO] Training model: epoch 5th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7835 - acc: 0.7737 - val_loss: 1.8322 - val_acc: 0.7714\n",
      "[INFO] Training model: epoch 5th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7454 - acc: 0.7786 - val_loss: 1.7524 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 5th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7707 - acc: 0.7774 - val_loss: 1.7143 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 5th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8149 - acc: 0.7736 - val_loss: 1.7681 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 5th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7275 - acc: 0.7801 - val_loss: 1.7479 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 5th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7927 - acc: 0.7752 - val_loss: 1.8244 - val_acc: 0.7697\n",
      "[INFO] Training model: epoch 5th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8025 - acc: 0.7745 - val_loss: 1.8942 - val_acc: 0.7634\n",
      "[INFO] Training model: epoch 5th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8058 - acc: 0.7714 - val_loss: 1.7883 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 5th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7956 - acc: 0.7745 - val_loss: 1.6998 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 5th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8078 - acc: 0.7716 - val_loss: 1.7085 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 6th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7738 - acc: 0.7732 - val_loss: 1.7953 - val_acc: 0.7713\n",
      "[INFO] Training model: epoch 6th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7513 - acc: 0.7750 - val_loss: 1.7931 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 6th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7717 - acc: 0.7748 - val_loss: 1.7264 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 6th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7461 - acc: 0.7760 - val_loss: 1.7429 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 6th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7576 - acc: 0.7754 - val_loss: 1.7691 - val_acc: 0.7759\n",
      "[INFO] Training model: epoch 6th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7432 - acc: 0.7785 - val_loss: 1.6762 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 6th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7390 - acc: 0.7773 - val_loss: 1.7213 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7299 - acc: 0.7798 - val_loss: 1.7779 - val_acc: 0.7752\n",
      "[INFO] Training model: epoch 6th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7541 - acc: 0.7775 - val_loss: 1.7812 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 6th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.7566 - acc: 0.7766 - val_loss: 1.7961 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 6th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7469 - acc: 0.7764 - val_loss: 1.7571 - val_acc: 0.7786\n",
      "[INFO] Training model: epoch 6th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7365 - acc: 0.7782 - val_loss: 1.7216 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 6th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7100 - acc: 0.7787 - val_loss: 1.8003 - val_acc: 0.7700\n",
      "[INFO] Training model: epoch 6th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7386 - acc: 0.7764 - val_loss: 1.7212 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 6th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7319 - acc: 0.7761 - val_loss: 1.6832 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 6th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7559 - acc: 0.7773 - val_loss: 1.7973 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 6th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7533 - acc: 0.7806 - val_loss: 1.7221 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 6th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7247 - acc: 0.7796 - val_loss: 1.7819 - val_acc: 0.7725\n",
      "[INFO] Training model: epoch 6th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7770 - acc: 0.7752 - val_loss: 1.7594 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 6th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7712 - acc: 0.7753 - val_loss: 1.8445 - val_acc: 0.7686\n",
      "[INFO] Training model: epoch 6th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7585 - acc: 0.7794 - val_loss: 1.8096 - val_acc: 0.7667\n",
      "[INFO] Training model: epoch 6th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7150 - acc: 0.7825 - val_loss: 1.7276 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 6th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7439 - acc: 0.7770 - val_loss: 1.7224 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 6th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7455 - acc: 0.7802 - val_loss: 1.6691 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8073 - acc: 0.7707 - val_loss: 1.7715 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 6th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7386 - acc: 0.7801 - val_loss: 1.7788 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 6th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7700 - acc: 0.7748 - val_loss: 1.7055 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 6th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7024 - acc: 0.7810 - val_loss: 1.8432 - val_acc: 0.7653\n",
      "[INFO] Training model: epoch 6th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7717 - acc: 0.7744 - val_loss: 1.8180 - val_acc: 0.7705\n",
      "[INFO] Training model: epoch 6th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7679 - acc: 0.7760 - val_loss: 1.8299 - val_acc: 0.7706\n",
      "[INFO] Training model: epoch 6th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7104 - acc: 0.7808 - val_loss: 1.7695 - val_acc: 0.7741\n",
      "[INFO] Training model: epoch 6th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7213 - acc: 0.7798 - val_loss: 1.7907 - val_acc: 0.7730\n",
      "[INFO] Training model: epoch 6th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7675 - acc: 0.7749 - val_loss: 1.7846 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 6th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7336 - acc: 0.7804 - val_loss: 1.7268 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 6th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7336 - acc: 0.7790 - val_loss: 1.6454 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 6th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7383 - acc: 0.7802 - val_loss: 1.8523 - val_acc: 0.7706\n",
      "[INFO] Training model: epoch 6th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7317 - acc: 0.7780 - val_loss: 1.8068 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 6th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.7447 - acc: 0.7793 - val_loss: 1.7028 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 6th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7215 - acc: 0.7784 - val_loss: 1.7270 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 6th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7775 - acc: 0.7749 - val_loss: 1.6823 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 6th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7288 - acc: 0.7788 - val_loss: 1.7312 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 6th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7512 - acc: 0.7767 - val_loss: 1.7349 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 6th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7464 - acc: 0.7799 - val_loss: 1.7698 - val_acc: 0.7759\n",
      "[INFO] Training model: epoch 6th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7105 - acc: 0.7804 - val_loss: 1.7142 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 6th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6707 - acc: 0.7848 - val_loss: 1.7544 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 6th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7485 - acc: 0.7788 - val_loss: 1.7544 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 6th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7460 - acc: 0.7799 - val_loss: 1.7732 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 6th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7206 - acc: 0.7810 - val_loss: 1.7463 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 6th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7517 - acc: 0.7778 - val_loss: 1.7792 - val_acc: 0.7730\n",
      "[INFO] Training model: epoch 6th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6879 - acc: 0.7830 - val_loss: 1.7077 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 7th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7147 - acc: 0.7784 - val_loss: 1.7006 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 7th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7250 - acc: 0.7775 - val_loss: 1.6688 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 7th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6966 - acc: 0.7783 - val_loss: 1.7249 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 7th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7020 - acc: 0.7809 - val_loss: 1.8490 - val_acc: 0.7659\n",
      "[INFO] Training model: epoch 7th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6842 - acc: 0.7825 - val_loss: 1.8533 - val_acc: 0.7598\n",
      "[INFO] Training model: epoch 7th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7279 - acc: 0.7788 - val_loss: 1.7130 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 7th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7319 - acc: 0.7760 - val_loss: 1.6712 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 7th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7383 - acc: 0.7763 - val_loss: 1.7176 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 7th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7839 - acc: 0.7718 - val_loss: 1.7630 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 7th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6829 - acc: 0.7812 - val_loss: 1.7250 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 7th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7697 - acc: 0.7706 - val_loss: 1.7051 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 7th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7430 - acc: 0.7756 - val_loss: 1.6480 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 7th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6956 - acc: 0.7806 - val_loss: 1.6779 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 7th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7270 - acc: 0.7767 - val_loss: 1.7469 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 7th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7004 - acc: 0.7833 - val_loss: 1.7830 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 7th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7070 - acc: 0.7813 - val_loss: 1.7196 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 7th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6589 - acc: 0.7844 - val_loss: 1.7780 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 7th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6781 - acc: 0.7836 - val_loss: 1.7418 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 7th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7060 - acc: 0.7804 - val_loss: 1.7068 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 7th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7342 - acc: 0.7800 - val_loss: 1.6937 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 7th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7258 - acc: 0.7788 - val_loss: 1.7895 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 7th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6810 - acc: 0.7828 - val_loss: 1.7818 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 7th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7279 - acc: 0.7792 - val_loss: 1.8235 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 7th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7227 - acc: 0.7769 - val_loss: 1.6899 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 7th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6814 - acc: 0.7813 - val_loss: 1.7024 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 7th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7213 - acc: 0.7778 - val_loss: 1.9286 - val_acc: 0.7592\n",
      "[INFO] Training model: epoch 7th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7200 - acc: 0.7792 - val_loss: 1.6885 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 7th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7130 - acc: 0.7797 - val_loss: 1.7597 - val_acc: 0.7770\n",
      "[INFO] Training model: epoch 7th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8048 - acc: 0.7707 - val_loss: 1.6685 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 7th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6807 - acc: 0.7820 - val_loss: 1.7122 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7410 - acc: 0.7775 - val_loss: 1.7608 - val_acc: 0.7738\n",
      "[INFO] Training model: epoch 7th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7159 - acc: 0.7824 - val_loss: 1.7346 - val_acc: 0.7767\n",
      "[INFO] Training model: epoch 7th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6850 - acc: 0.7821 - val_loss: 1.7073 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 7th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.7112 - acc: 0.7799 - val_loss: 1.7540 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 7th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7696 - acc: 0.7774 - val_loss: 1.8147 - val_acc: 0.7700\n",
      "[INFO] Training model: epoch 7th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7004 - acc: 0.7825 - val_loss: 1.6954 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 7th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7079 - acc: 0.7812 - val_loss: 1.6440 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 7th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7313 - acc: 0.7784 - val_loss: 1.8032 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 7th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7233 - acc: 0.7797 - val_loss: 1.6513 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 7th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6980 - acc: 0.7806 - val_loss: 1.6455 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 7th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7328 - acc: 0.7773 - val_loss: 1.7213 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 7th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7142 - acc: 0.7814 - val_loss: 1.7413 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 7th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7308 - acc: 0.7799 - val_loss: 1.7057 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 7th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7360 - acc: 0.7757 - val_loss: 1.7441 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 7th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7379 - acc: 0.7776 - val_loss: 1.7231 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 7th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7365 - acc: 0.7806 - val_loss: 1.7303 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 7th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7304 - acc: 0.7802 - val_loss: 1.7025 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 7th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7029 - acc: 0.7813 - val_loss: 1.8342 - val_acc: 0.7678\n",
      "[INFO] Training model: epoch 7th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7558 - acc: 0.7767 - val_loss: 1.7435 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 7th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6900 - acc: 0.7843 - val_loss: 1.7845 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7077 - acc: 0.7775 - val_loss: 1.6902 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 8th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6324 - acc: 0.7852 - val_loss: 1.6583 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 8th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6909 - acc: 0.7795 - val_loss: 1.7096 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 8th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6966 - acc: 0.7798 - val_loss: 1.6900 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 8th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6812 - acc: 0.7804 - val_loss: 1.7432 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 8th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7485 - acc: 0.7749 - val_loss: 1.7377 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 8th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7009 - acc: 0.7762 - val_loss: 1.8024 - val_acc: 0.7706\n",
      "[INFO] Training model: epoch 8th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6987 - acc: 0.7815 - val_loss: 1.7283 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 8th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7077 - acc: 0.7771 - val_loss: 1.6908 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 8th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6538 - acc: 0.7841 - val_loss: 1.6818 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 8th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6363 - acc: 0.7871 - val_loss: 1.6814 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 8th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6772 - acc: 0.7820 - val_loss: 1.6547 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 8th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6755 - acc: 0.7819 - val_loss: 1.6933 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 8th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7095 - acc: 0.7791 - val_loss: 1.7070 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 8th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6976 - acc: 0.7801 - val_loss: 1.6194 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 8th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6792 - acc: 0.7792 - val_loss: 1.6575 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 8th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7123 - acc: 0.7794 - val_loss: 1.7265 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7305 - acc: 0.7761 - val_loss: 1.7128 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 8th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6725 - acc: 0.7818 - val_loss: 1.7056 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 8th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6901 - acc: 0.7844 - val_loss: 1.7841 - val_acc: 0.7725\n",
      "[INFO] Training model: epoch 8th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6847 - acc: 0.7808 - val_loss: 1.7545 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 8th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6786 - acc: 0.7812 - val_loss: 1.7484 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 8th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7034 - acc: 0.7802 - val_loss: 1.6304 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 8th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7086 - acc: 0.7796 - val_loss: 1.6919 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 8th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7033 - acc: 0.7797 - val_loss: 1.7644 - val_acc: 0.7741\n",
      "[INFO] Training model: epoch 8th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7055 - acc: 0.7813 - val_loss: 1.7662 - val_acc: 0.7745\n",
      "[INFO] Training model: epoch 8th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7382 - acc: 0.7748 - val_loss: 1.7768 - val_acc: 0.7739\n",
      "[INFO] Training model: epoch 8th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7132 - acc: 0.7797 - val_loss: 1.6765 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 8th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7085 - acc: 0.7800 - val_loss: 1.7159 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 8th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6741 - acc: 0.7824 - val_loss: 1.7272 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 8th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6881 - acc: 0.7785 - val_loss: 1.7572 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 8th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7071 - acc: 0.7806 - val_loss: 1.6743 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 8th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6887 - acc: 0.7815 - val_loss: 1.7537 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 8th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7708 - acc: 0.7755 - val_loss: 1.6409 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 8th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6949 - acc: 0.7789 - val_loss: 1.6801 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 8th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7270 - acc: 0.7777 - val_loss: 1.7627 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7179 - acc: 0.7760 - val_loss: 1.7499 - val_acc: 0.7770\n",
      "[INFO] Training model: epoch 8th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7331 - acc: 0.7774 - val_loss: 1.7041 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 8th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7526 - acc: 0.7768 - val_loss: 1.7448 - val_acc: 0.7733\n",
      "[INFO] Training model: epoch 8th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6769 - acc: 0.7826 - val_loss: 1.7554 - val_acc: 0.7738\n",
      "[INFO] Training model: epoch 8th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6425 - acc: 0.7851 - val_loss: 1.5691 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 8th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7119 - acc: 0.7785 - val_loss: 1.7935 - val_acc: 0.7767\n",
      "[INFO] Training model: epoch 8th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7209 - acc: 0.7786 - val_loss: 1.7238 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 8th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6254 - acc: 0.7871 - val_loss: 1.6308 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 8th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6787 - acc: 0.7830 - val_loss: 1.7327 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 8th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6987 - acc: 0.7826 - val_loss: 1.6014 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 8th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7272 - acc: 0.7807 - val_loss: 1.6071 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 8th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7263 - acc: 0.7777 - val_loss: 1.7002 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 8th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6847 - acc: 0.7833 - val_loss: 1.6585 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 8th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7195 - acc: 0.7777 - val_loss: 1.7077 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 9th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6398 - acc: 0.7843 - val_loss: 1.6797 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 9th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6703 - acc: 0.7798 - val_loss: 1.6889 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 9th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7043 - acc: 0.7761 - val_loss: 1.7024 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 9th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6142 - acc: 0.7869 - val_loss: 1.6479 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 9th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7017 - acc: 0.7768 - val_loss: 1.7415 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 9th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6339 - acc: 0.7837 - val_loss: 1.7077 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 9th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6940 - acc: 0.7775 - val_loss: 1.7000 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 9th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.7105 - acc: 0.7757 - val_loss: 1.6545 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 9th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6403 - acc: 0.7846 - val_loss: 1.6080 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 9th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7040 - acc: 0.7786 - val_loss: 1.6793 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 9th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7037 - acc: 0.7774 - val_loss: 1.6514 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 9th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6715 - acc: 0.7813 - val_loss: 1.7627 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 9th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6668 - acc: 0.7829 - val_loss: 1.7138 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 9th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7009 - acc: 0.7794 - val_loss: 1.7203 - val_acc: 0.7739\n",
      "[INFO] Training model: epoch 9th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7148 - acc: 0.7752 - val_loss: 1.7075 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 9th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6632 - acc: 0.7812 - val_loss: 1.6610 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 9th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6813 - acc: 0.7821 - val_loss: 1.6855 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 9th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6906 - acc: 0.7778 - val_loss: 1.6897 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 9th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6952 - acc: 0.7805 - val_loss: 1.6379 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 9th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6978 - acc: 0.7795 - val_loss: 1.7280 - val_acc: 0.7752\n",
      "[INFO] Training model: epoch 9th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6369 - acc: 0.7853 - val_loss: 1.6503 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7061 - acc: 0.7755 - val_loss: 1.7057 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 9th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6565 - acc: 0.7829 - val_loss: 1.6840 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 9th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6973 - acc: 0.7780 - val_loss: 1.6534 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 9th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6951 - acc: 0.7769 - val_loss: 1.5826 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 9th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6783 - acc: 0.7816 - val_loss: 1.6493 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 9th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6265 - acc: 0.7863 - val_loss: 1.7173 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 9th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6411 - acc: 0.7853 - val_loss: 1.7607 - val_acc: 0.7741\n",
      "[INFO] Training model: epoch 9th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6967 - acc: 0.7798 - val_loss: 1.7632 - val_acc: 0.7716\n",
      "[INFO] Training model: epoch 9th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7199 - acc: 0.7779 - val_loss: 1.6784 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 9th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6651 - acc: 0.7838 - val_loss: 1.6030 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 9th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6755 - acc: 0.7807 - val_loss: 1.7026 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 9th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6643 - acc: 0.7823 - val_loss: 1.7733 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 9th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6808 - acc: 0.7814 - val_loss: 1.6596 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 9th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6607 - acc: 0.7825 - val_loss: 1.6152 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 9th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7221 - acc: 0.7766 - val_loss: 1.5813 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 9th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6982 - acc: 0.7768 - val_loss: 1.6942 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 9th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7121 - acc: 0.7782 - val_loss: 1.7045 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 9th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6715 - acc: 0.7822 - val_loss: 1.6381 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 9th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6824 - acc: 0.7827 - val_loss: 1.6378 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 9th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6830 - acc: 0.7821 - val_loss: 1.6780 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 9th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6987 - acc: 0.7806 - val_loss: 1.7376 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 9th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6745 - acc: 0.7821 - val_loss: 1.6426 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 9th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7117 - acc: 0.7787 - val_loss: 1.7244 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 9th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6549 - acc: 0.7856 - val_loss: 1.7294 - val_acc: 0.7763\n",
      "[INFO] Training model: epoch 9th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6828 - acc: 0.7820 - val_loss: 1.5782 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 9th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6697 - acc: 0.7848 - val_loss: 1.6372 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 9th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6643 - acc: 0.7824 - val_loss: 1.6620 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7317 - acc: 0.7797 - val_loss: 1.5883 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 9th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7131 - acc: 0.7796 - val_loss: 1.6595 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 10th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6210 - acc: 0.7832 - val_loss: 1.6922 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 10th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7119 - acc: 0.7761 - val_loss: 1.6640 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 10th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6592 - acc: 0.7806 - val_loss: 1.5659 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 10th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6712 - acc: 0.7802 - val_loss: 1.6541 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 10th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6794 - acc: 0.7790 - val_loss: 1.6329 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 10th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6536 - acc: 0.7809 - val_loss: 1.5997 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 10th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6328 - acc: 0.7822 - val_loss: 1.6211 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 10th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6558 - acc: 0.7827 - val_loss: 1.7416 - val_acc: 0.7763\n",
      "[INFO] Training model: epoch 10th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6660 - acc: 0.7809 - val_loss: 1.6789 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 10th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6724 - acc: 0.7796 - val_loss: 1.6019 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 10th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6394 - acc: 0.7825 - val_loss: 1.7206 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 10th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6518 - acc: 0.7798 - val_loss: 1.5940 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 10th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6337 - acc: 0.7839 - val_loss: 1.6452 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 10th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5999 - acc: 0.7863 - val_loss: 1.6907 - val_acc: 0.7770\n",
      "[INFO] Training model: epoch 10th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6655 - acc: 0.7819 - val_loss: 1.7049 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 10th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6488 - acc: 0.7826 - val_loss: 1.7554 - val_acc: 0.7706\n",
      "[INFO] Training model: epoch 10th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6329 - acc: 0.7848 - val_loss: 1.6216 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 10th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6833 - acc: 0.7775 - val_loss: 1.6496 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 10th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6783 - acc: 0.7809 - val_loss: 1.6874 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 10th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6091 - acc: 0.7875 - val_loss: 1.6470 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 10th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6466 - acc: 0.7814 - val_loss: 1.7397 - val_acc: 0.7675\n",
      "[INFO] Training model: epoch 10th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6846 - acc: 0.7782 - val_loss: 1.6197 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 10th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6883 - acc: 0.7791 - val_loss: 1.6013 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 10th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6429 - acc: 0.7848 - val_loss: 1.6811 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 10th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6620 - acc: 0.7805 - val_loss: 1.6740 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 10th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6792 - acc: 0.7812 - val_loss: 1.7474 - val_acc: 0.7702\n",
      "[INFO] Training model: epoch 10th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6766 - acc: 0.7819 - val_loss: 1.7000 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 10th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6879 - acc: 0.7779 - val_loss: 1.6192 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 10th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6507 - acc: 0.7832 - val_loss: 1.7736 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 10th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6508 - acc: 0.7823 - val_loss: 1.6479 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 10th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6701 - acc: 0.7815 - val_loss: 1.7097 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 10th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.6515 - acc: 0.7817 - val_loss: 1.6173 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 10th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6959 - acc: 0.7788 - val_loss: 1.7179 - val_acc: 0.7759\n",
      "[INFO] Training model: epoch 10th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6122 - acc: 0.7886 - val_loss: 1.6143 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 10th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6072 - acc: 0.7883 - val_loss: 1.6917 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 10th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6902 - acc: 0.7796 - val_loss: 1.6221 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 10th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6713 - acc: 0.7830 - val_loss: 1.7634 - val_acc: 0.7733\n",
      "[INFO] Training model: epoch 10th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7051 - acc: 0.7771 - val_loss: 1.6613 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 10th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6977 - acc: 0.7775 - val_loss: 1.6246 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 10th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6347 - acc: 0.7857 - val_loss: 1.6391 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 10th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6956 - acc: 0.7794 - val_loss: 1.8141 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 10th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6375 - acc: 0.7829 - val_loss: 1.7027 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 10th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6655 - acc: 0.7808 - val_loss: 1.6797 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 10th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6645 - acc: 0.7818 - val_loss: 1.6633 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 10th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6242 - acc: 0.7865 - val_loss: 1.6127 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 10th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6568 - acc: 0.7820 - val_loss: 1.6315 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 10th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6791 - acc: 0.7809 - val_loss: 1.6714 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 10th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6847 - acc: 0.7812 - val_loss: 1.6548 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 10th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6562 - acc: 0.7810 - val_loss: 1.6350 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 10th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6780 - acc: 0.7812 - val_loss: 1.6507 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 11th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5969 - acc: 0.7851 - val_loss: 1.6552 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 11th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5840 - acc: 0.7871 - val_loss: 1.6044 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 11th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6348 - acc: 0.7818 - val_loss: 1.5256 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 11th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5770 - acc: 0.7884 - val_loss: 1.6709 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 11th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5990 - acc: 0.7856 - val_loss: 1.5579 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 11th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5996 - acc: 0.7869 - val_loss: 1.6458 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 11th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6036 - acc: 0.7827 - val_loss: 1.6409 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 11th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6151 - acc: 0.7834 - val_loss: 1.6237 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 11th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5867 - acc: 0.7878 - val_loss: 1.6334 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 11th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6056 - acc: 0.7843 - val_loss: 1.7404 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 11th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6089 - acc: 0.7837 - val_loss: 1.6431 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 11th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6691 - acc: 0.7779 - val_loss: 1.6944 - val_acc: 0.7708\n",
      "[INFO] Training model: epoch 11th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6388 - acc: 0.7785 - val_loss: 1.6318 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 11th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6933 - acc: 0.7786 - val_loss: 1.6498 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 11th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6543 - acc: 0.7825 - val_loss: 1.6756 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 11th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6379 - acc: 0.7829 - val_loss: 1.6585 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 11th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6618 - acc: 0.7778 - val_loss: 1.6107 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 11th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6311 - acc: 0.7836 - val_loss: 1.5746 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 11th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.6597 - acc: 0.7795 - val_loss: 1.7357 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 11th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6235 - acc: 0.7827 - val_loss: 1.6572 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 11th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6370 - acc: 0.7815 - val_loss: 1.6873 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 11th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6424 - acc: 0.7827 - val_loss: 1.6390 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 11th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6343 - acc: 0.7841 - val_loss: 1.6743 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 11th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6262 - acc: 0.7866 - val_loss: 1.6491 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 11th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6456 - acc: 0.7812 - val_loss: 1.6249 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 11th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6542 - acc: 0.7797 - val_loss: 1.8488 - val_acc: 0.7661\n",
      "[INFO] Training model: epoch 11th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6698 - acc: 0.7806 - val_loss: 1.7028 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 11th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6778 - acc: 0.7793 - val_loss: 1.7744 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 11th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6422 - acc: 0.7830 - val_loss: 1.6750 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 11th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6898 - acc: 0.7752 - val_loss: 1.5463 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 11th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6367 - acc: 0.7841 - val_loss: 1.7144 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 11th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6279 - acc: 0.7843 - val_loss: 1.6657 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 11th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6262 - acc: 0.7856 - val_loss: 1.6940 - val_acc: 0.7763\n",
      "[INFO] Training model: epoch 11th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6654 - acc: 0.7817 - val_loss: 1.7171 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 11th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6185 - acc: 0.7838 - val_loss: 1.6509 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 11th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6471 - acc: 0.7827 - val_loss: 1.5455 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 11th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6262 - acc: 0.7843 - val_loss: 1.6062 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 11th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6508 - acc: 0.7805 - val_loss: 1.6654 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 11th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6896 - acc: 0.7764 - val_loss: 1.6307 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 11th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6711 - acc: 0.7814 - val_loss: 1.7169 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 11th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6488 - acc: 0.7838 - val_loss: 1.6500 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 11th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6488 - acc: 0.7824 - val_loss: 1.6573 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 11th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6348 - acc: 0.7849 - val_loss: 1.5734 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 11th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6478 - acc: 0.7844 - val_loss: 1.6792 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 11th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7223 - acc: 0.7741 - val_loss: 1.6762 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 11th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6613 - acc: 0.7815 - val_loss: 1.6015 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 11th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6460 - acc: 0.7818 - val_loss: 1.6086 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6547 - acc: 0.7820 - val_loss: 1.5767 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 11th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6621 - acc: 0.7817 - val_loss: 1.6125 - val_acc: 0.7833\n",
      "[INFO] Training model: epoch 11th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6311 - acc: 0.7867 - val_loss: 1.6767 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 12th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5664 - acc: 0.7894 - val_loss: 1.6151 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 12th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6143 - acc: 0.7821 - val_loss: 1.5756 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 12th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6182 - acc: 0.7824 - val_loss: 1.5917 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 12th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6370 - acc: 0.7806 - val_loss: 1.6570 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 12th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6489 - acc: 0.7822 - val_loss: 1.6098 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 12th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5978 - acc: 0.7838 - val_loss: 1.5385 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 12th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6195 - acc: 0.7821 - val_loss: 1.5473 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 12th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6451 - acc: 0.7805 - val_loss: 1.6466 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 12th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5874 - acc: 0.7823 - val_loss: 1.6411 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 12th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6290 - acc: 0.7818 - val_loss: 1.6848 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 12th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5837 - acc: 0.7859 - val_loss: 1.6039 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 12th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6058 - acc: 0.7854 - val_loss: 1.7512 - val_acc: 0.7684\n",
      "[INFO] Training model: epoch 12th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6230 - acc: 0.7828 - val_loss: 1.6415 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 12th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5648 - acc: 0.7871 - val_loss: 1.6482 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 12th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6097 - acc: 0.7838 - val_loss: 1.5957 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 12th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5940 - acc: 0.7879 - val_loss: 1.6074 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 12th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6245 - acc: 0.7812 - val_loss: 1.5872 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 12th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6503 - acc: 0.7802 - val_loss: 1.6733 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 12th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5749 - acc: 0.7867 - val_loss: 1.6487 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 12th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6459 - acc: 0.7800 - val_loss: 1.5872 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 12th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6255 - acc: 0.7838 - val_loss: 1.6303 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 12th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6579 - acc: 0.7818 - val_loss: 1.6343 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 12th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5882 - acc: 0.7870 - val_loss: 1.7534 - val_acc: 0.7673\n",
      "[INFO] Training model: epoch 12th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5994 - acc: 0.7850 - val_loss: 1.6081 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 12th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5891 - acc: 0.7846 - val_loss: 1.6109 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 12th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6445 - acc: 0.7778 - val_loss: 1.6680 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 12th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5987 - acc: 0.7871 - val_loss: 1.6506 - val_acc: 0.7783\n",
      "[INFO] Training model: epoch 12th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5927 - acc: 0.7846 - val_loss: 1.6652 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 12th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6056 - acc: 0.7855 - val_loss: 1.7215 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 12th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6343 - acc: 0.7841 - val_loss: 1.6072 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 12th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6419 - acc: 0.7805 - val_loss: 1.6565 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 12th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6494 - acc: 0.7818 - val_loss: 1.6333 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 12th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6345 - acc: 0.7843 - val_loss: 1.6193 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 12th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6576 - acc: 0.7794 - val_loss: 1.6083 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6684 - acc: 0.7798 - val_loss: 1.6675 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 12th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6123 - acc: 0.7848 - val_loss: 1.7007 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 12th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6365 - acc: 0.7795 - val_loss: 1.6967 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 12th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6075 - acc: 0.7853 - val_loss: 1.7089 - val_acc: 0.7770\n",
      "[INFO] Training model: epoch 12th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6403 - acc: 0.7816 - val_loss: 1.6377 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6480 - acc: 0.7816 - val_loss: 1.6292 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 12th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5918 - acc: 0.7881 - val_loss: 1.7202 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 12th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6013 - acc: 0.7846 - val_loss: 1.5777 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 12th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.6312 - acc: 0.7829 - val_loss: 1.6125 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 12th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6101 - acc: 0.7863 - val_loss: 1.6270 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 12th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6455 - acc: 0.7808 - val_loss: 1.6488 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 12th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6394 - acc: 0.7822 - val_loss: 1.6537 - val_acc: 0.7833\n",
      "[INFO] Training model: epoch 12th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6390 - acc: 0.7805 - val_loss: 1.6431 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 12th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6021 - acc: 0.7853 - val_loss: 1.6065 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6067 - acc: 0.7848 - val_loss: 1.6827 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 12th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6053 - acc: 0.7870 - val_loss: 1.6528 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5986 - acc: 0.7819 - val_loss: 1.5410 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5216 - acc: 0.7887 - val_loss: 1.6531 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 13th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5835 - acc: 0.7857 - val_loss: 1.6325 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 13th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6100 - acc: 0.7805 - val_loss: 1.5351 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 13th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5661 - acc: 0.7841 - val_loss: 1.6159 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 13th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5946 - acc: 0.7825 - val_loss: 1.5847 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 13th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5683 - acc: 0.7864 - val_loss: 1.5554 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 13th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6347 - acc: 0.7786 - val_loss: 1.5834 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 13th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6005 - acc: 0.7826 - val_loss: 1.5839 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 13th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6037 - acc: 0.7823 - val_loss: 1.6019 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 13th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5925 - acc: 0.7827 - val_loss: 1.6298 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 13th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6164 - acc: 0.7814 - val_loss: 1.6991 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 13th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5893 - acc: 0.7841 - val_loss: 1.6403 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 13th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6295 - acc: 0.7816 - val_loss: 1.6203 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 13th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5625 - acc: 0.7894 - val_loss: 1.5705 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5686 - acc: 0.7859 - val_loss: 1.6212 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5932 - acc: 0.7868 - val_loss: 1.5096 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 13th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5571 - acc: 0.7871 - val_loss: 1.5373 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 13th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6258 - acc: 0.7796 - val_loss: 1.6076 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 13th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6392 - acc: 0.7805 - val_loss: 1.7008 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 13th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5917 - acc: 0.7859 - val_loss: 1.6374 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 13th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6136 - acc: 0.7829 - val_loss: 1.5066 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 13th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5958 - acc: 0.7853 - val_loss: 1.6679 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 13th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5884 - acc: 0.7848 - val_loss: 1.6423 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 13th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5925 - acc: 0.7857 - val_loss: 1.6034 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 13th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6192 - acc: 0.7814 - val_loss: 1.6186 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 13th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5666 - acc: 0.7880 - val_loss: 1.6276 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 13th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6271 - acc: 0.7799 - val_loss: 1.4824 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 13th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6130 - acc: 0.7838 - val_loss: 1.5436 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 13th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.6079 - acc: 0.7833 - val_loss: 1.7520 - val_acc: 0.7731\n",
      "[INFO] Training model: epoch 13th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6118 - acc: 0.7835 - val_loss: 1.6403 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 13th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.6047 - acc: 0.7820 - val_loss: 1.6453 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 13th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6039 - acc: 0.7837 - val_loss: 1.5615 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 13th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5526 - acc: 0.7904 - val_loss: 1.5580 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 13th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6296 - acc: 0.7823 - val_loss: 1.6473 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 13th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6266 - acc: 0.7842 - val_loss: 1.6442 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 13th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6457 - acc: 0.7804 - val_loss: 1.6352 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 13th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5825 - acc: 0.7894 - val_loss: 1.6314 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 13th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6233 - acc: 0.7816 - val_loss: 1.6622 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 13th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5939 - acc: 0.7841 - val_loss: 1.6520 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 13th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5972 - acc: 0.7855 - val_loss: 1.6292 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 13th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6185 - acc: 0.7828 - val_loss: 1.6259 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 13th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6555 - acc: 0.7806 - val_loss: 1.6180 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 13th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5963 - acc: 0.7861 - val_loss: 1.5992 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 13th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6220 - acc: 0.7836 - val_loss: 1.6681 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 13th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6412 - acc: 0.7773 - val_loss: 1.6027 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 13th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6073 - acc: 0.7836 - val_loss: 1.6876 - val_acc: 0.7725\n",
      "[INFO] Training model: epoch 13th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5908 - acc: 0.7870 - val_loss: 1.5684 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 13th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6034 - acc: 0.7863 - val_loss: 1.5874 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 13th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6137 - acc: 0.7841 - val_loss: 1.6130 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 14th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5995 - acc: 0.7824 - val_loss: 1.5408 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 14th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5446 - acc: 0.7866 - val_loss: 1.6138 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 14th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5448 - acc: 0.7887 - val_loss: 1.5280 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 14th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5941 - acc: 0.7819 - val_loss: 1.5609 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 14th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5387 - acc: 0.7872 - val_loss: 1.5536 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 14th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5639 - acc: 0.7850 - val_loss: 1.6271 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 14th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5422 - acc: 0.7870 - val_loss: 1.6540 - val_acc: 0.7770\n",
      "[INFO] Training model: epoch 14th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5844 - acc: 0.7804 - val_loss: 1.6046 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 14th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5560 - acc: 0.7871 - val_loss: 1.5594 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 14th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5556 - acc: 0.7866 - val_loss: 1.4963 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 14th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5762 - acc: 0.7837 - val_loss: 1.4848 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 14th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5828 - acc: 0.7855 - val_loss: 1.5413 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 14th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5724 - acc: 0.7853 - val_loss: 1.6193 - val_acc: 0.7778\n",
      "[INFO] Training model: epoch 14th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5839 - acc: 0.7839 - val_loss: 1.5987 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 14th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5711 - acc: 0.7864 - val_loss: 1.4822 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 14th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5784 - acc: 0.7851 - val_loss: 1.5233 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 14th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5725 - acc: 0.7848 - val_loss: 1.5846 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 14th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5674 - acc: 0.7858 - val_loss: 1.6433 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 14th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6135 - acc: 0.7813 - val_loss: 1.6382 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 14th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5858 - acc: 0.7827 - val_loss: 1.6853 - val_acc: 0.7744\n",
      "[INFO] Training model: epoch 14th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5866 - acc: 0.7839 - val_loss: 1.6354 - val_acc: 0.7784\n",
      "[INFO] Training model: epoch 14th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6155 - acc: 0.7817 - val_loss: 1.6438 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 14th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5807 - acc: 0.7854 - val_loss: 1.6766 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 14th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5961 - acc: 0.7836 - val_loss: 1.5795 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 14th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5604 - acc: 0.7860 - val_loss: 1.5544 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 14th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5959 - acc: 0.7826 - val_loss: 1.6174 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 14th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6040 - acc: 0.7816 - val_loss: 1.5665 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 14th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6093 - acc: 0.7836 - val_loss: 1.5928 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 14th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6014 - acc: 0.7832 - val_loss: 1.6893 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 14th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5707 - acc: 0.7872 - val_loss: 1.5641 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 14th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6007 - acc: 0.7833 - val_loss: 1.6204 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 14th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5879 - acc: 0.7855 - val_loss: 1.6853 - val_acc: 0.7684\n",
      "[INFO] Training model: epoch 14th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5450 - acc: 0.7883 - val_loss: 1.6814 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 14th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5517 - acc: 0.7887 - val_loss: 1.5715 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 14th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6081 - acc: 0.7851 - val_loss: 1.5931 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 14th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6114 - acc: 0.7834 - val_loss: 1.5524 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 14th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5798 - acc: 0.7854 - val_loss: 1.5947 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 14th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5517 - acc: 0.7904 - val_loss: 1.6730 - val_acc: 0.7723\n",
      "[INFO] Training model: epoch 14th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5696 - acc: 0.7862 - val_loss: 1.5918 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 14th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5989 - acc: 0.7852 - val_loss: 1.5396 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 14th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5839 - acc: 0.7869 - val_loss: 1.6332 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 14th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5845 - acc: 0.7856 - val_loss: 1.5853 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5987 - acc: 0.7823 - val_loss: 1.6419 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 14th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6031 - acc: 0.7836 - val_loss: 1.5909 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 14th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5553 - acc: 0.7898 - val_loss: 1.6188 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 14th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6545 - acc: 0.7795 - val_loss: 1.5741 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 14th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5829 - acc: 0.7852 - val_loss: 1.5973 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 14th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6088 - acc: 0.7846 - val_loss: 1.5985 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 14th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5873 - acc: 0.7855 - val_loss: 1.6293 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 14th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6288 - acc: 0.7824 - val_loss: 1.6029 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 15th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5666 - acc: 0.7830 - val_loss: 1.4458 - val_acc: 0.7973\n",
      "[INFO] Training model: epoch 15th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5536 - acc: 0.7839 - val_loss: 1.5490 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 15th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5385 - acc: 0.7851 - val_loss: 1.6371 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 15th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5373 - acc: 0.7889 - val_loss: 1.6188 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 15th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5168 - acc: 0.7895 - val_loss: 1.5480 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5522 - acc: 0.7855 - val_loss: 1.5729 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 15th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5356 - acc: 0.7888 - val_loss: 1.5936 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 15th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5535 - acc: 0.7860 - val_loss: 1.5132 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 15th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5873 - acc: 0.7822 - val_loss: 1.5970 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 15th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5556 - acc: 0.7852 - val_loss: 1.6238 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 15th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5756 - acc: 0.7835 - val_loss: 1.5948 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5516 - acc: 0.7878 - val_loss: 1.5814 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 15th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5508 - acc: 0.7848 - val_loss: 1.5418 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 15th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5616 - acc: 0.7841 - val_loss: 1.5574 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 15th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5846 - acc: 0.7809 - val_loss: 1.5016 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 15th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5755 - acc: 0.7827 - val_loss: 1.6211 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 15th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5423 - acc: 0.7863 - val_loss: 1.5334 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 15th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5583 - acc: 0.7853 - val_loss: 1.5519 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 15th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5253 - acc: 0.7887 - val_loss: 1.6075 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 15th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5531 - acc: 0.7891 - val_loss: 1.6847 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 15th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5344 - acc: 0.7880 - val_loss: 1.4965 - val_acc: 0.7956\n",
      "[INFO] Training model: epoch 15th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5791 - acc: 0.7832 - val_loss: 1.5963 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5452 - acc: 0.7895 - val_loss: 1.5799 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 15th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5650 - acc: 0.7876 - val_loss: 1.6783 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 15th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5691 - acc: 0.7856 - val_loss: 1.5556 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 15th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6220 - acc: 0.7793 - val_loss: 1.4931 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 15th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5583 - acc: 0.7865 - val_loss: 1.6032 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 15th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5714 - acc: 0.7832 - val_loss: 1.5952 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 15th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6171 - acc: 0.7806 - val_loss: 1.6927 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 15th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5797 - acc: 0.7845 - val_loss: 1.5316 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 15th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5409 - acc: 0.7871 - val_loss: 1.5506 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 15th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6151 - acc: 0.7816 - val_loss: 1.6004 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5714 - acc: 0.7861 - val_loss: 1.5939 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 15th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5295 - acc: 0.7931 - val_loss: 1.4865 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 15th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5427 - acc: 0.7896 - val_loss: 1.6318 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 15th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5746 - acc: 0.7853 - val_loss: 1.6756 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 15th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5640 - acc: 0.7851 - val_loss: 1.6383 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 15th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5589 - acc: 0.7874 - val_loss: 1.5898 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 15th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5911 - acc: 0.7859 - val_loss: 1.6086 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 15th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5347 - acc: 0.7890 - val_loss: 1.5547 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 15th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5801 - acc: 0.7855 - val_loss: 1.5729 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 15th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5753 - acc: 0.7836 - val_loss: 1.6110 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 15th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5739 - acc: 0.7859 - val_loss: 1.6060 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 15th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5808 - acc: 0.7838 - val_loss: 1.4881 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 15th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6025 - acc: 0.7834 - val_loss: 1.5918 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 15th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6044 - acc: 0.7827 - val_loss: 1.5156 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 15th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5636 - acc: 0.7875 - val_loss: 1.6015 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 15th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5558 - acc: 0.7884 - val_loss: 1.6659 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 15th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5859 - acc: 0.7834 - val_loss: 1.6605 - val_acc: 0.7786\n",
      "[INFO] Training model: epoch 15th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6169 - acc: 0.7825 - val_loss: 1.5237 - val_acc: 0.7989\n",
      "[INFO] Training model: epoch 16th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5560 - acc: 0.7836 - val_loss: 1.5757 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 16th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5326 - acc: 0.7859 - val_loss: 1.4418 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 16th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4978 - acc: 0.7908 - val_loss: 1.5483 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 16th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5432 - acc: 0.7840 - val_loss: 1.5088 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5079 - acc: 0.7904 - val_loss: 1.5358 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 16th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5460 - acc: 0.7856 - val_loss: 1.4571 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 16th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5393 - acc: 0.7865 - val_loss: 1.5381 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 16th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5528 - acc: 0.7830 - val_loss: 1.5919 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 16th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5604 - acc: 0.7818 - val_loss: 1.5916 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 16th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5485 - acc: 0.7838 - val_loss: 1.4920 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 16th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5576 - acc: 0.7838 - val_loss: 1.5732 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 16th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5268 - acc: 0.7891 - val_loss: 1.5553 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 16th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5520 - acc: 0.7868 - val_loss: 1.6523 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 16th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5462 - acc: 0.7848 - val_loss: 1.5770 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 16th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5646 - acc: 0.7863 - val_loss: 1.5455 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 16th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4923 - acc: 0.7912 - val_loss: 1.5428 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 16th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5431 - acc: 0.7843 - val_loss: 1.5291 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 16th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5366 - acc: 0.7861 - val_loss: 1.5182 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 16th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5798 - acc: 0.7825 - val_loss: 1.4931 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 16th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5354 - acc: 0.7875 - val_loss: 1.4902 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 16th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5810 - acc: 0.7820 - val_loss: 1.6503 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 16th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5310 - acc: 0.7875 - val_loss: 1.5335 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5875 - acc: 0.7813 - val_loss: 1.5934 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 16th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5462 - acc: 0.7859 - val_loss: 1.5474 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 16th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5869 - acc: 0.7823 - val_loss: 1.5753 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 16th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5623 - acc: 0.7857 - val_loss: 1.5614 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 16th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5816 - acc: 0.7806 - val_loss: 1.6384 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 16th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5737 - acc: 0.7850 - val_loss: 1.5690 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 16th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5292 - acc: 0.7898 - val_loss: 1.5264 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 16th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5417 - acc: 0.7861 - val_loss: 1.5948 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 16th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5597 - acc: 0.7855 - val_loss: 1.5314 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 16th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5619 - acc: 0.7838 - val_loss: 1.5517 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5354 - acc: 0.7877 - val_loss: 1.4660 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 16th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5598 - acc: 0.7844 - val_loss: 1.5465 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 16th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5859 - acc: 0.7835 - val_loss: 1.5812 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 16th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5491 - acc: 0.7872 - val_loss: 1.5735 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 16th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5408 - acc: 0.7898 - val_loss: 1.5607 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 16th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5507 - acc: 0.7870 - val_loss: 1.6014 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 16th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5436 - acc: 0.7844 - val_loss: 1.6633 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 16th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5447 - acc: 0.7870 - val_loss: 1.6941 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 16th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5655 - acc: 0.7862 - val_loss: 1.6144 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 16th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5572 - acc: 0.7843 - val_loss: 1.6535 - val_acc: 0.7756\n",
      "[INFO] Training model: epoch 16th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5517 - acc: 0.7862 - val_loss: 1.6462 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 16th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5473 - acc: 0.7868 - val_loss: 1.5456 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 16th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5502 - acc: 0.7876 - val_loss: 1.5596 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 16th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5448 - acc: 0.7892 - val_loss: 1.4951 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 16th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5358 - acc: 0.7898 - val_loss: 1.5190 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 16th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5815 - acc: 0.7834 - val_loss: 1.6477 - val_acc: 0.7755\n",
      "[INFO] Training model: epoch 16th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5944 - acc: 0.7828 - val_loss: 1.5676 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 16th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5072 - acc: 0.7928 - val_loss: 1.5728 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 17th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4849 - acc: 0.7901 - val_loss: 1.5317 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 17th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5357 - acc: 0.7857 - val_loss: 1.4677 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 17th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5037 - acc: 0.7864 - val_loss: 1.5031 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 17th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5207 - acc: 0.7856 - val_loss: 1.5427 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 17th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5038 - acc: 0.7888 - val_loss: 1.5753 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 17th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4965 - acc: 0.7898 - val_loss: 1.5677 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 17th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4996 - acc: 0.7886 - val_loss: 1.4884 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 17th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5471 - acc: 0.7832 - val_loss: 1.5604 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 17th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5060 - acc: 0.7882 - val_loss: 1.6530 - val_acc: 0.7698\n",
      "[INFO] Training model: epoch 17th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4831 - acc: 0.7928 - val_loss: 1.5656 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 17th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5396 - acc: 0.7841 - val_loss: 1.5490 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 17th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5038 - acc: 0.7876 - val_loss: 1.5487 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 17th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5568 - acc: 0.7850 - val_loss: 1.5454 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 17th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5147 - acc: 0.7878 - val_loss: 1.5603 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 17th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.4852 - acc: 0.7921 - val_loss: 1.5319 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 17th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5370 - acc: 0.7841 - val_loss: 1.6128 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 17th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5438 - acc: 0.7854 - val_loss: 1.5727 - val_acc: 0.7752\n",
      "[INFO] Training model: epoch 17th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5291 - acc: 0.7881 - val_loss: 1.6249 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 17th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4790 - acc: 0.7946 - val_loss: 1.5159 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 17th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5555 - acc: 0.7830 - val_loss: 1.5304 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 17th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5482 - acc: 0.7859 - val_loss: 1.5332 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 17th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5300 - acc: 0.7868 - val_loss: 1.5496 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 17th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4965 - acc: 0.7915 - val_loss: 1.5490 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 17th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5516 - acc: 0.7857 - val_loss: 1.5522 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 17th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5636 - acc: 0.7823 - val_loss: 1.6194 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 17th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5418 - acc: 0.7878 - val_loss: 1.4689 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 17th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5280 - acc: 0.7868 - val_loss: 1.5350 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 17th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4890 - acc: 0.7912 - val_loss: 1.6045 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 17th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5148 - acc: 0.7903 - val_loss: 1.5334 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 17th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5452 - acc: 0.7852 - val_loss: 1.6351 - val_acc: 0.7753\n",
      "[INFO] Training model: epoch 17th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5944 - acc: 0.7827 - val_loss: 1.5575 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 17th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5580 - acc: 0.7831 - val_loss: 1.4160 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 17th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5832 - acc: 0.7820 - val_loss: 1.5430 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 17th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5663 - acc: 0.7821 - val_loss: 1.5298 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 17th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5213 - acc: 0.7889 - val_loss: 1.4731 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 17th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5427 - acc: 0.7862 - val_loss: 1.6003 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 17th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5646 - acc: 0.7869 - val_loss: 1.5960 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 17th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5690 - acc: 0.7861 - val_loss: 1.5269 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 17th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5246 - acc: 0.7892 - val_loss: 1.5763 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 17th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5357 - acc: 0.7895 - val_loss: 1.4628 - val_acc: 0.7998\n",
      "[INFO] Training model: epoch 17th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5430 - acc: 0.7877 - val_loss: 1.5938 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 17th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5598 - acc: 0.7838 - val_loss: 1.5974 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 17th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5457 - acc: 0.7864 - val_loss: 1.5849 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 17th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5944 - acc: 0.7820 - val_loss: 1.5723 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 17th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5197 - acc: 0.7910 - val_loss: 1.5666 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 17th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5685 - acc: 0.7867 - val_loss: 1.5751 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 17th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5462 - acc: 0.7879 - val_loss: 1.5619 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 17th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5884 - acc: 0.7841 - val_loss: 1.5324 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 17th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5775 - acc: 0.7848 - val_loss: 1.6345 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 17th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5213 - acc: 0.7907 - val_loss: 1.6285 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 18th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4633 - acc: 0.7914 - val_loss: 1.5026 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 18th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5187 - acc: 0.7838 - val_loss: 1.4542 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 18th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5191 - acc: 0.7847 - val_loss: 1.5462 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 18th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5198 - acc: 0.7855 - val_loss: 1.5534 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 18th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5351 - acc: 0.7855 - val_loss: 1.5205 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 18th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5312 - acc: 0.7856 - val_loss: 1.5643 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 18th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4827 - acc: 0.7895 - val_loss: 1.5752 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 18th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4800 - acc: 0.7905 - val_loss: 1.5292 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 18th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4884 - acc: 0.7894 - val_loss: 1.5788 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 18th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4881 - acc: 0.7875 - val_loss: 1.5180 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 18th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5298 - acc: 0.7857 - val_loss: 1.5352 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 18th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5206 - acc: 0.7878 - val_loss: 1.5444 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 18th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4839 - acc: 0.7896 - val_loss: 1.4914 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 18th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5249 - acc: 0.7857 - val_loss: 1.4721 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 18th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5156 - acc: 0.7860 - val_loss: 1.5276 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 18th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4912 - acc: 0.7896 - val_loss: 1.4679 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 18th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4765 - acc: 0.7912 - val_loss: 1.4753 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 18th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5528 - acc: 0.7845 - val_loss: 1.5329 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 18th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5133 - acc: 0.7905 - val_loss: 1.5285 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 18th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5305 - acc: 0.7875 - val_loss: 1.5996 - val_acc: 0.7783\n",
      "[INFO] Training model: epoch 18th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5371 - acc: 0.7867 - val_loss: 1.5278 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 18th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5111 - acc: 0.7888 - val_loss: 1.5100 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 18th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4899 - acc: 0.7893 - val_loss: 1.5268 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 18th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5758 - acc: 0.7818 - val_loss: 1.5212 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 18th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5305 - acc: 0.7864 - val_loss: 1.5112 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 18th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5800 - acc: 0.7805 - val_loss: 1.5143 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 18th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5604 - acc: 0.7825 - val_loss: 1.5071 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 18th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5215 - acc: 0.7875 - val_loss: 1.5192 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 18th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4817 - acc: 0.7936 - val_loss: 1.5981 - val_acc: 0.7767\n",
      "[INFO] Training model: epoch 18th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5118 - acc: 0.7896 - val_loss: 1.5564 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 18th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5344 - acc: 0.7857 - val_loss: 1.5719 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 18th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5636 - acc: 0.7829 - val_loss: 1.4145 - val_acc: 0.8009\n",
      "[INFO] Training model: epoch 18th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5481 - acc: 0.7842 - val_loss: 1.4487 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 18th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5132 - acc: 0.7898 - val_loss: 1.5251 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 18th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5461 - acc: 0.7837 - val_loss: 1.4253 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 18th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4921 - acc: 0.7910 - val_loss: 1.5377 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 18th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5033 - acc: 0.7895 - val_loss: 1.6593 - val_acc: 0.7728\n",
      "[INFO] Training model: epoch 18th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5610 - acc: 0.7844 - val_loss: 1.5107 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 18th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.5464 - acc: 0.7848 - val_loss: 1.5417 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 18th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5350 - acc: 0.7853 - val_loss: 1.4708 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5432 - acc: 0.7879 - val_loss: 1.5501 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 18th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5075 - acc: 0.7904 - val_loss: 1.5801 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 18th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5261 - acc: 0.7882 - val_loss: 1.5651 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 18th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5626 - acc: 0.7840 - val_loss: 1.4595 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 18th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5507 - acc: 0.7844 - val_loss: 1.5584 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 18th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5214 - acc: 0.7874 - val_loss: 1.5609 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 18th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5272 - acc: 0.7895 - val_loss: 1.5875 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 18th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5194 - acc: 0.7868 - val_loss: 1.5426 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 18th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5325 - acc: 0.7884 - val_loss: 1.5267 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 18th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5247 - acc: 0.7882 - val_loss: 1.4945 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 19th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4930 - acc: 0.7867 - val_loss: 1.5014 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 19th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4788 - acc: 0.7863 - val_loss: 1.5514 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 19th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4918 - acc: 0.7891 - val_loss: 1.5687 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 19th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4854 - acc: 0.7885 - val_loss: 1.5783 - val_acc: 0.7738\n",
      "[INFO] Training model: epoch 19th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4464 - acc: 0.7927 - val_loss: 1.5313 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 19th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4717 - acc: 0.7900 - val_loss: 1.4477 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 19th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4607 - acc: 0.7900 - val_loss: 1.5306 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 19th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4666 - acc: 0.7905 - val_loss: 1.4773 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 19th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4644 - acc: 0.7880 - val_loss: 1.4893 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 19th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4852 - acc: 0.7897 - val_loss: 1.6166 - val_acc: 0.7777\n",
      "[INFO] Training model: epoch 19th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5541 - acc: 0.7842 - val_loss: 1.4887 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 19th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4752 - acc: 0.7902 - val_loss: 1.5064 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 19th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5103 - acc: 0.7853 - val_loss: 1.6448 - val_acc: 0.7691\n",
      "[INFO] Training model: epoch 19th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5010 - acc: 0.7857 - val_loss: 1.4477 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 19th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4730 - acc: 0.7895 - val_loss: 1.5350 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 19th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4758 - acc: 0.7905 - val_loss: 1.4816 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 19th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4838 - acc: 0.7899 - val_loss: 1.5657 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 19th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5159 - acc: 0.7869 - val_loss: 1.5708 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 19th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5138 - acc: 0.7864 - val_loss: 1.4226 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 19th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5125 - acc: 0.7880 - val_loss: 1.5425 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 19th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5477 - acc: 0.7838 - val_loss: 1.5022 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 19th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4565 - acc: 0.7914 - val_loss: 1.4916 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 19th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5466 - acc: 0.7842 - val_loss: 1.6016 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 19th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4956 - acc: 0.7901 - val_loss: 1.4688 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 19th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4870 - acc: 0.7896 - val_loss: 1.4910 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 19th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.5165 - acc: 0.7854 - val_loss: 1.4207 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 19th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5098 - acc: 0.7898 - val_loss: 1.5446 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 19th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5050 - acc: 0.7905 - val_loss: 1.5738 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 19th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4922 - acc: 0.7901 - val_loss: 1.4653 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 19th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4847 - acc: 0.7901 - val_loss: 1.5321 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 19th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5254 - acc: 0.7839 - val_loss: 1.4588 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 19th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5330 - acc: 0.7845 - val_loss: 1.5332 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 19th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5175 - acc: 0.7894 - val_loss: 1.4269 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 19th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5130 - acc: 0.7869 - val_loss: 1.6279 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 19th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5491 - acc: 0.7843 - val_loss: 1.5799 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 19th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5387 - acc: 0.7853 - val_loss: 1.5470 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 19th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4824 - acc: 0.7918 - val_loss: 1.4751 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 19th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4998 - acc: 0.7895 - val_loss: 1.5358 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 19th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5203 - acc: 0.7877 - val_loss: 1.5686 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 19th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5303 - acc: 0.7882 - val_loss: 1.5281 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 19th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5463 - acc: 0.7850 - val_loss: 1.5316 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 19th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5341 - acc: 0.7858 - val_loss: 1.5030 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 19th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5679 - acc: 0.7810 - val_loss: 1.5416 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 19th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4969 - acc: 0.7909 - val_loss: 1.5370 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 19th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4864 - acc: 0.7907 - val_loss: 1.5132 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 19th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5084 - acc: 0.7883 - val_loss: 1.4743 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 19th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5100 - acc: 0.7874 - val_loss: 1.5799 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 19th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5228 - acc: 0.7864 - val_loss: 1.4696 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 19th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4888 - acc: 0.7928 - val_loss: 1.5916 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 19th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5530 - acc: 0.7841 - val_loss: 1.5028 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 20th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4498 - acc: 0.7911 - val_loss: 1.4179 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 20th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4592 - acc: 0.7893 - val_loss: 1.4878 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 20th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4980 - acc: 0.7855 - val_loss: 1.4863 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 20th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4381 - acc: 0.7914 - val_loss: 1.4611 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 20th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4854 - acc: 0.7870 - val_loss: 1.4037 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 20th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4905 - acc: 0.7861 - val_loss: 1.4296 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4781 - acc: 0.7884 - val_loss: 1.4016 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 20th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4640 - acc: 0.7894 - val_loss: 1.4247 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 20th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4759 - acc: 0.7873 - val_loss: 1.5336 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 20th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4843 - acc: 0.7842 - val_loss: 1.4890 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 20th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5158 - acc: 0.7838 - val_loss: 1.5615 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 20th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4448 - acc: 0.7943 - val_loss: 1.5263 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 20th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4792 - acc: 0.7920 - val_loss: 1.4721 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 20th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4843 - acc: 0.7901 - val_loss: 1.5111 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 20th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4675 - acc: 0.7883 - val_loss: 1.5022 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 20th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4597 - acc: 0.7913 - val_loss: 1.4644 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 20th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4593 - acc: 0.7917 - val_loss: 1.5452 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 20th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5154 - acc: 0.7841 - val_loss: 1.4850 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 20th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5063 - acc: 0.7860 - val_loss: 1.4470 - val_acc: 0.7944\n",
      "[INFO] Training model: epoch 20th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5155 - acc: 0.7845 - val_loss: 1.5040 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 20th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4631 - acc: 0.7906 - val_loss: 1.5111 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 20th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5342 - acc: 0.7844 - val_loss: 1.4635 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 20th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4999 - acc: 0.7881 - val_loss: 1.4931 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 20th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5252 - acc: 0.7860 - val_loss: 1.5273 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 20th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4774 - acc: 0.7906 - val_loss: 1.4788 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 20th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4728 - acc: 0.7925 - val_loss: 1.4651 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 20th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4685 - acc: 0.7909 - val_loss: 1.5027 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 20th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4974 - acc: 0.7897 - val_loss: 1.5313 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 20th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4723 - acc: 0.7899 - val_loss: 1.5728 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 20th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5299 - acc: 0.7856 - val_loss: 1.4487 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 20th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5225 - acc: 0.7869 - val_loss: 1.5010 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 20th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4853 - acc: 0.7901 - val_loss: 1.5112 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 20th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5068 - acc: 0.7870 - val_loss: 1.5227 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 20th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5126 - acc: 0.7872 - val_loss: 1.5981 - val_acc: 0.7788\n",
      "[INFO] Training model: epoch 20th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4966 - acc: 0.7891 - val_loss: 1.4982 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 20th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4507 - acc: 0.7934 - val_loss: 1.5877 - val_acc: 0.7759\n",
      "[INFO] Training model: epoch 20th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5023 - acc: 0.7893 - val_loss: 1.4905 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 20th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5016 - acc: 0.7896 - val_loss: 1.4395 - val_acc: 0.7991\n",
      "[INFO] Training model: epoch 20th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5230 - acc: 0.7841 - val_loss: 1.6071 - val_acc: 0.7745\n",
      "[INFO] Training model: epoch 20th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5155 - acc: 0.7884 - val_loss: 1.4968 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 20th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5180 - acc: 0.7857 - val_loss: 1.5572 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 20th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5472 - acc: 0.7835 - val_loss: 1.5254 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 20th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5041 - acc: 0.7877 - val_loss: 1.4772 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 20th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4605 - acc: 0.7947 - val_loss: 1.5226 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 20th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4930 - acc: 0.7893 - val_loss: 1.5778 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 20th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5107 - acc: 0.7890 - val_loss: 1.4792 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 20th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5203 - acc: 0.7865 - val_loss: 1.6310 - val_acc: 0.7736\n",
      "[INFO] Training model: epoch 20th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5139 - acc: 0.7886 - val_loss: 1.5462 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 20th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5130 - acc: 0.7867 - val_loss: 1.5722 - val_acc: 0.7833\n",
      "[INFO] Training model: epoch 20th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4778 - acc: 0.7932 - val_loss: 1.5607 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 21th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4348 - acc: 0.7922 - val_loss: 1.3844 - val_acc: 0.7997\n",
      "[INFO] Training model: epoch 21th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4760 - acc: 0.7882 - val_loss: 1.4184 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 21th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4611 - acc: 0.7862 - val_loss: 1.4694 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 21th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4691 - acc: 0.7865 - val_loss: 1.4190 - val_acc: 0.7994\n",
      "[INFO] Training model: epoch 21th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4664 - acc: 0.7872 - val_loss: 1.4200 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4503 - acc: 0.7890 - val_loss: 1.4399 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 21th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5040 - acc: 0.7834 - val_loss: 1.5381 - val_acc: 0.7772\n",
      "[INFO] Training model: epoch 21th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4802 - acc: 0.7860 - val_loss: 1.5022 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 21th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4387 - acc: 0.7930 - val_loss: 1.4900 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 21th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4011 - acc: 0.7978 - val_loss: 1.4893 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 21th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4338 - acc: 0.7926 - val_loss: 1.5198 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 21th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5058 - acc: 0.7831 - val_loss: 1.4493 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 21th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4196 - acc: 0.7928 - val_loss: 1.5649 - val_acc: 0.7802\n",
      "[INFO] Training model: epoch 21th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4287 - acc: 0.7914 - val_loss: 1.4920 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 21th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4441 - acc: 0.7919 - val_loss: 1.5613 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 21th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4849 - acc: 0.7878 - val_loss: 1.5424 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 21th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4777 - acc: 0.7868 - val_loss: 1.3995 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 21th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4677 - acc: 0.7908 - val_loss: 1.4696 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 21th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4828 - acc: 0.7874 - val_loss: 1.5665 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 21th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4840 - acc: 0.7888 - val_loss: 1.4785 - val_acc: 0.7817\n",
      "[INFO] Training model: epoch 21th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4570 - acc: 0.7920 - val_loss: 1.4318 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 21th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5292 - acc: 0.7843 - val_loss: 1.4066 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5039 - acc: 0.7880 - val_loss: 1.5312 - val_acc: 0.7769\n",
      "[INFO] Training model: epoch 21th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4619 - acc: 0.7882 - val_loss: 1.5053 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 21th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4877 - acc: 0.7898 - val_loss: 1.4931 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 21th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4821 - acc: 0.7883 - val_loss: 1.4674 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 21th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4873 - acc: 0.7889 - val_loss: 1.4896 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 21th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4991 - acc: 0.7873 - val_loss: 1.4547 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 21th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4977 - acc: 0.7869 - val_loss: 1.4885 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 21th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5066 - acc: 0.7870 - val_loss: 1.4650 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 21th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4573 - acc: 0.7917 - val_loss: 1.4451 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4462 - acc: 0.7926 - val_loss: 1.4984 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 21th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5036 - acc: 0.7862 - val_loss: 1.5919 - val_acc: 0.7794\n",
      "[INFO] Training model: epoch 21th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4785 - acc: 0.7901 - val_loss: 1.4804 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 21th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4795 - acc: 0.7905 - val_loss: 1.5004 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 21th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5298 - acc: 0.7832 - val_loss: 1.4890 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 21th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4782 - acc: 0.7909 - val_loss: 1.5325 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 21th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4809 - acc: 0.7904 - val_loss: 1.5482 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 21th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4913 - acc: 0.7882 - val_loss: 1.4799 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 21th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4950 - acc: 0.7903 - val_loss: 1.4858 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 21th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5031 - acc: 0.7869 - val_loss: 1.5009 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 21th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5107 - acc: 0.7852 - val_loss: 1.5075 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 21th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4906 - acc: 0.7896 - val_loss: 1.4922 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 21th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5001 - acc: 0.7884 - val_loss: 1.4721 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 21th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5079 - acc: 0.7873 - val_loss: 1.5272 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 21th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4661 - acc: 0.7911 - val_loss: 1.4685 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5109 - acc: 0.7863 - val_loss: 1.5867 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 21th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4981 - acc: 0.7893 - val_loss: 1.5261 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 21th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4715 - acc: 0.7900 - val_loss: 1.5375 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 21th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4641 - acc: 0.7933 - val_loss: 1.4975 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 22th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4349 - acc: 0.7916 - val_loss: 1.4007 - val_acc: 0.7956\n",
      "[INFO] Training model: epoch 22th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4401 - acc: 0.7913 - val_loss: 1.4411 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 22th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4298 - acc: 0.7901 - val_loss: 1.4408 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4388 - acc: 0.7920 - val_loss: 1.5454 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 22th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4934 - acc: 0.7856 - val_loss: 1.5467 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 22th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4620 - acc: 0.7859 - val_loss: 1.5037 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 22th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4828 - acc: 0.7852 - val_loss: 1.4755 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 22th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4672 - acc: 0.7877 - val_loss: 1.4032 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 22th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4194 - acc: 0.7937 - val_loss: 1.5199 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 22th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4512 - acc: 0.7875 - val_loss: 1.4040 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 22th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4498 - acc: 0.7896 - val_loss: 1.4841 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 22th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4449 - acc: 0.7892 - val_loss: 1.4886 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 22th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4759 - acc: 0.7886 - val_loss: 1.4903 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 22th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4524 - acc: 0.7886 - val_loss: 1.4274 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 22th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4505 - acc: 0.7890 - val_loss: 1.3814 - val_acc: 0.8012\n",
      "[INFO] Training model: epoch 22th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4517 - acc: 0.7914 - val_loss: 1.5394 - val_acc: 0.7809\n",
      "[INFO] Training model: epoch 22th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4597 - acc: 0.7900 - val_loss: 1.5259 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 22th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4583 - acc: 0.7880 - val_loss: 1.4590 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 22th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4852 - acc: 0.7873 - val_loss: 1.4385 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 22th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4572 - acc: 0.7908 - val_loss: 1.4536 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 22th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4612 - acc: 0.7917 - val_loss: 1.4074 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 22th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4746 - acc: 0.7881 - val_loss: 1.4258 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 22th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4256 - acc: 0.7939 - val_loss: 1.4464 - val_acc: 0.7956\n",
      "[INFO] Training model: epoch 22th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.4553 - acc: 0.7928 - val_loss: 1.4835 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 22th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4436 - acc: 0.7959 - val_loss: 1.4520 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 22th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4781 - acc: 0.7881 - val_loss: 1.4066 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 22th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4880 - acc: 0.7882 - val_loss: 1.4098 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 22th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4485 - acc: 0.7916 - val_loss: 1.5249 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 22th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4365 - acc: 0.7931 - val_loss: 1.5082 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 22th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4466 - acc: 0.7916 - val_loss: 1.4658 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 22th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4668 - acc: 0.7900 - val_loss: 1.5259 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 22th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4677 - acc: 0.7898 - val_loss: 1.4083 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4910 - acc: 0.7860 - val_loss: 1.5171 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 22th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5068 - acc: 0.7859 - val_loss: 1.5050 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 22th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4544 - acc: 0.7909 - val_loss: 1.4719 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 22th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4307 - acc: 0.7936 - val_loss: 1.4602 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 22th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5111 - acc: 0.7847 - val_loss: 1.5293 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 22th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5199 - acc: 0.7850 - val_loss: 1.5219 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 22th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5051 - acc: 0.7868 - val_loss: 1.4244 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 22th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4926 - acc: 0.7882 - val_loss: 1.4888 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 22th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4753 - acc: 0.7889 - val_loss: 1.4973 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 22th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4909 - acc: 0.7893 - val_loss: 1.5045 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 22th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4980 - acc: 0.7873 - val_loss: 1.4634 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 22th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4945 - acc: 0.7866 - val_loss: 1.4437 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 22th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4829 - acc: 0.7877 - val_loss: 1.5453 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 22th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5049 - acc: 0.7855 - val_loss: 1.5260 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 22th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4797 - acc: 0.7878 - val_loss: 1.4715 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 22th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4608 - acc: 0.7909 - val_loss: 1.4825 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 22th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4823 - acc: 0.7886 - val_loss: 1.4939 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 22th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4788 - acc: 0.7903 - val_loss: 1.4615 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 23th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4604 - acc: 0.7856 - val_loss: 1.3545 - val_acc: 0.7973\n",
      "[INFO] Training model: epoch 23th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3855 - acc: 0.7967 - val_loss: 1.4417 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 23th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4582 - acc: 0.7871 - val_loss: 1.3764 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 23th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4415 - acc: 0.7900 - val_loss: 1.4366 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 23th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4131 - acc: 0.7919 - val_loss: 1.4261 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 23th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4735 - acc: 0.7885 - val_loss: 1.4653 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 23th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4030 - acc: 0.7918 - val_loss: 1.4969 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 23th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4416 - acc: 0.7895 - val_loss: 1.4318 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 23th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4353 - acc: 0.7884 - val_loss: 1.4169 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 23th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4518 - acc: 0.7877 - val_loss: 1.4411 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 23th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.4105 - acc: 0.7945 - val_loss: 1.4230 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 23th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4502 - acc: 0.7894 - val_loss: 1.4756 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 23th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4686 - acc: 0.7848 - val_loss: 1.5034 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 23th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4533 - acc: 0.7885 - val_loss: 1.4925 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 23th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4512 - acc: 0.7913 - val_loss: 1.4635 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 23th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.4677 - acc: 0.7900 - val_loss: 1.4842 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 23th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3972 - acc: 0.7973 - val_loss: 1.5287 - val_acc: 0.7764\n",
      "[INFO] Training model: epoch 23th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4903 - acc: 0.7817 - val_loss: 1.6398 - val_acc: 0.7730\n",
      "[INFO] Training model: epoch 23th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4485 - acc: 0.7924 - val_loss: 1.3809 - val_acc: 0.7994\n",
      "[INFO] Training model: epoch 23th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3916 - acc: 0.7977 - val_loss: 1.5009 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 23th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4656 - acc: 0.7896 - val_loss: 1.5858 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 23th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4691 - acc: 0.7880 - val_loss: 1.3650 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 23th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4369 - acc: 0.7918 - val_loss: 1.4868 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 23th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4429 - acc: 0.7908 - val_loss: 1.5034 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 23th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4401 - acc: 0.7937 - val_loss: 1.4388 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 23th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4508 - acc: 0.7901 - val_loss: 1.4957 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 23th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4142 - acc: 0.7945 - val_loss: 1.4930 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 23th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4270 - acc: 0.7934 - val_loss: 1.4120 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 23th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4325 - acc: 0.7919 - val_loss: 1.5533 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 23th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4254 - acc: 0.7939 - val_loss: 1.4713 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 23th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4808 - acc: 0.7859 - val_loss: 1.4682 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 23th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5256 - acc: 0.7825 - val_loss: 1.4309 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 23th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4805 - acc: 0.7884 - val_loss: 1.4404 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 23th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.4346 - acc: 0.7934 - val_loss: 1.4338 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 23th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4761 - acc: 0.7874 - val_loss: 1.4795 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 23th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4674 - acc: 0.7887 - val_loss: 1.4068 - val_acc: 0.7994\n",
      "[INFO] Training model: epoch 23th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4757 - acc: 0.7892 - val_loss: 1.4675 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 23th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4704 - acc: 0.7896 - val_loss: 1.4750 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 23th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4848 - acc: 0.7888 - val_loss: 1.4650 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 23th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4518 - acc: 0.7929 - val_loss: 1.4948 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 23th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4573 - acc: 0.7891 - val_loss: 1.4168 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 23th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4464 - acc: 0.7921 - val_loss: 1.5744 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 23th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4625 - acc: 0.7909 - val_loss: 1.5013 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 23th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4880 - acc: 0.7882 - val_loss: 1.4798 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 23th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4846 - acc: 0.7871 - val_loss: 1.5081 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 23th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4960 - acc: 0.7864 - val_loss: 1.4492 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 23th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4706 - acc: 0.7889 - val_loss: 1.5238 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 23th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.4976 - acc: 0.7884 - val_loss: 1.4487 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 23th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4472 - acc: 0.7930 - val_loss: 1.4539 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 23th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4486 - acc: 0.7929 - val_loss: 1.4855 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 24th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4374 - acc: 0.7877 - val_loss: 1.4967 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 24th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3975 - acc: 0.7943 - val_loss: 1.3562 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 24th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3890 - acc: 0.7954 - val_loss: 1.3460 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 24th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4104 - acc: 0.7911 - val_loss: 1.4515 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 24th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3998 - acc: 0.7943 - val_loss: 1.3980 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 24th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4433 - acc: 0.7863 - val_loss: 1.3756 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4608 - acc: 0.7858 - val_loss: 1.4692 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 24th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4462 - acc: 0.7868 - val_loss: 1.3663 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 24th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4653 - acc: 0.7871 - val_loss: 1.4085 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 24th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4100 - acc: 0.7927 - val_loss: 1.4726 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 24th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4484 - acc: 0.7884 - val_loss: 1.3551 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3656 - acc: 0.7973 - val_loss: 1.3856 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 24th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4014 - acc: 0.7922 - val_loss: 1.4466 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 24th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3806 - acc: 0.7947 - val_loss: 1.4677 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 24th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4675 - acc: 0.7860 - val_loss: 1.4546 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 24th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4245 - acc: 0.7907 - val_loss: 1.4555 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 24th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4864 - acc: 0.7857 - val_loss: 1.4001 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 24th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4093 - acc: 0.7966 - val_loss: 1.5017 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 24th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4483 - acc: 0.7904 - val_loss: 1.4771 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 24th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4267 - acc: 0.7881 - val_loss: 1.3878 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 24th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4688 - acc: 0.7857 - val_loss: 1.4675 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 24th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4174 - acc: 0.7911 - val_loss: 1.4163 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 24th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4644 - acc: 0.7880 - val_loss: 1.4248 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 24th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4232 - acc: 0.7937 - val_loss: 1.3883 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 24th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4218 - acc: 0.7945 - val_loss: 1.4657 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 24th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4353 - acc: 0.7913 - val_loss: 1.4055 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 24th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4537 - acc: 0.7886 - val_loss: 1.4562 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 24th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4570 - acc: 0.7889 - val_loss: 1.5255 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 24th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5271 - acc: 0.7814 - val_loss: 1.4355 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 24th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4155 - acc: 0.7931 - val_loss: 1.5081 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 24th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4268 - acc: 0.7932 - val_loss: 1.4342 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 24th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4294 - acc: 0.7936 - val_loss: 1.4868 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 24th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4164 - acc: 0.7942 - val_loss: 1.5320 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 24th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4458 - acc: 0.7908 - val_loss: 1.4941 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 24th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.4947 - acc: 0.7855 - val_loss: 1.4469 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 24th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4326 - acc: 0.7930 - val_loss: 1.4566 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 24th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4978 - acc: 0.7853 - val_loss: 1.4581 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 24th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.5251 - acc: 0.7815 - val_loss: 1.3685 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 24th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4518 - acc: 0.7886 - val_loss: 1.4814 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 24th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4383 - acc: 0.7923 - val_loss: 1.4101 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 24th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4775 - acc: 0.7885 - val_loss: 1.4677 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 24th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4470 - acc: 0.7925 - val_loss: 1.4355 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 24th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4770 - acc: 0.7887 - val_loss: 1.4694 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 24th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4428 - acc: 0.7894 - val_loss: 1.4473 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 24th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4721 - acc: 0.7885 - val_loss: 1.5043 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 24th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4931 - acc: 0.7851 - val_loss: 1.4765 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 24th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4229 - acc: 0.7952 - val_loss: 1.5002 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 24th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4873 - acc: 0.7874 - val_loss: 1.4278 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 24th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4675 - acc: 0.7929 - val_loss: 1.4724 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 24th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4985 - acc: 0.7870 - val_loss: 1.5088 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 25th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3781 - acc: 0.7938 - val_loss: 1.4107 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 25th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4441 - acc: 0.7870 - val_loss: 1.3827 - val_acc: 0.7944\n",
      "[INFO] Training model: epoch 25th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4074 - acc: 0.7900 - val_loss: 1.3100 - val_acc: 0.8034\n",
      "[INFO] Training model: epoch 25th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3531 - acc: 0.7980 - val_loss: 1.4716 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 25th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3642 - acc: 0.7973 - val_loss: 1.4575 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4242 - acc: 0.7897 - val_loss: 1.3814 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 25th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4073 - acc: 0.7905 - val_loss: 1.3422 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 25th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3889 - acc: 0.7925 - val_loss: 1.4744 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 25th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4286 - acc: 0.7896 - val_loss: 1.3731 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 25th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3990 - acc: 0.7911 - val_loss: 1.4259 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 25th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4500 - acc: 0.7870 - val_loss: 1.3887 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 25th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4100 - acc: 0.7921 - val_loss: 1.4350 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 25th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4075 - acc: 0.7934 - val_loss: 1.3831 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 25th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4082 - acc: 0.7908 - val_loss: 1.4668 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 25th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4036 - acc: 0.7955 - val_loss: 1.4771 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 25th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3504 - acc: 0.7989 - val_loss: 1.4205 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 25th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4770 - acc: 0.7845 - val_loss: 1.3781 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4473 - acc: 0.7873 - val_loss: 1.3850 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 25th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3970 - acc: 0.7945 - val_loss: 1.4554 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 25th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4205 - acc: 0.7937 - val_loss: 1.4859 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 25th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4332 - acc: 0.7906 - val_loss: 1.4372 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 25th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4351 - acc: 0.7900 - val_loss: 1.4169 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 25th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4444 - acc: 0.7881 - val_loss: 1.4307 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 25th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4766 - acc: 0.7856 - val_loss: 1.4395 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 25th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4547 - acc: 0.7871 - val_loss: 1.4535 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 25th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4567 - acc: 0.7900 - val_loss: 1.4148 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 25th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4460 - acc: 0.7889 - val_loss: 1.4668 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 25th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4393 - acc: 0.7886 - val_loss: 1.4838 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 25th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4297 - acc: 0.7914 - val_loss: 1.4952 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4131 - acc: 0.7924 - val_loss: 1.3689 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 25th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4779 - acc: 0.7878 - val_loss: 1.4246 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 25th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4247 - acc: 0.7918 - val_loss: 1.5031 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 25th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3957 - acc: 0.7949 - val_loss: 1.4817 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 25th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4274 - acc: 0.7912 - val_loss: 1.4803 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 25th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4498 - acc: 0.7907 - val_loss: 1.4365 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 25th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4602 - acc: 0.7907 - val_loss: 1.4755 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 25th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4294 - acc: 0.7905 - val_loss: 1.4157 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 25th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3823 - acc: 0.7975 - val_loss: 1.4893 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 25th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4408 - acc: 0.7908 - val_loss: 1.4846 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4805 - acc: 0.7863 - val_loss: 1.4776 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 25th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4785 - acc: 0.7883 - val_loss: 1.4560 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 25th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4385 - acc: 0.7910 - val_loss: 1.4646 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 25th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4562 - acc: 0.7921 - val_loss: 1.5274 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 25th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4552 - acc: 0.7909 - val_loss: 1.4854 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 25th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4362 - acc: 0.7940 - val_loss: 1.3582 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 25th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4902 - acc: 0.7860 - val_loss: 1.4969 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 25th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4633 - acc: 0.7883 - val_loss: 1.4363 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 25th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4644 - acc: 0.7898 - val_loss: 1.4654 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 25th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5098 - acc: 0.7838 - val_loss: 1.4953 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 25th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4216 - acc: 0.7948 - val_loss: 1.4291 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 26th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4086 - acc: 0.7899 - val_loss: 1.4036 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 26th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3888 - acc: 0.7918 - val_loss: 1.4453 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 26th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3801 - acc: 0.7929 - val_loss: 1.3651 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 26th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3835 - acc: 0.7930 - val_loss: 1.3771 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 26th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3927 - acc: 0.7936 - val_loss: 1.4563 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 26th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3860 - acc: 0.7945 - val_loss: 1.4077 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 26th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4179 - acc: 0.7906 - val_loss: 1.4145 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 26th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4023 - acc: 0.7930 - val_loss: 1.3728 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 26th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3764 - acc: 0.7950 - val_loss: 1.4828 - val_acc: 0.7816\n",
      "[INFO] Training model: epoch 26th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3869 - acc: 0.7928 - val_loss: 1.4970 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 26th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4376 - acc: 0.7868 - val_loss: 1.4418 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 26th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4178 - acc: 0.7904 - val_loss: 1.4800 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 26th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3710 - acc: 0.7936 - val_loss: 1.4355 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 26th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4054 - acc: 0.7963 - val_loss: 1.4404 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 26th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3784 - acc: 0.7945 - val_loss: 1.3865 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 26th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4178 - acc: 0.7926 - val_loss: 1.3824 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 26th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4066 - acc: 0.7920 - val_loss: 1.4526 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 26th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3943 - acc: 0.7938 - val_loss: 1.4350 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 26th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3732 - acc: 0.7963 - val_loss: 1.4678 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 26th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4262 - acc: 0.7920 - val_loss: 1.5091 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 26th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4512 - acc: 0.7877 - val_loss: 1.4595 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 26th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4130 - acc: 0.7911 - val_loss: 1.5078 - val_acc: 0.7780\n",
      "[INFO] Training model: epoch 26th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4259 - acc: 0.7921 - val_loss: 1.4839 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 26th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4302 - acc: 0.7925 - val_loss: 1.3889 - val_acc: 0.7989\n",
      "[INFO] Training model: epoch 26th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4412 - acc: 0.7910 - val_loss: 1.4727 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 26th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4044 - acc: 0.7921 - val_loss: 1.3916 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 26th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4202 - acc: 0.7929 - val_loss: 1.4111 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 26th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4165 - acc: 0.7929 - val_loss: 1.4018 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 26th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4441 - acc: 0.7898 - val_loss: 1.4455 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 26th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3977 - acc: 0.7934 - val_loss: 1.3891 - val_acc: 0.7973\n",
      "[INFO] Training model: epoch 26th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4293 - acc: 0.7894 - val_loss: 1.4586 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 26th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4176 - acc: 0.7945 - val_loss: 1.4877 - val_acc: 0.7808\n",
      "[INFO] Training model: epoch 26th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4074 - acc: 0.7940 - val_loss: 1.3959 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 26th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3916 - acc: 0.7931 - val_loss: 1.5517 - val_acc: 0.7791\n",
      "[INFO] Training model: epoch 26th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4351 - acc: 0.7916 - val_loss: 1.4348 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 26th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4612 - acc: 0.7892 - val_loss: 1.4422 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 26th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4070 - acc: 0.7933 - val_loss: 1.4790 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 26th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4571 - acc: 0.7886 - val_loss: 1.4350 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 26th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3875 - acc: 0.7958 - val_loss: 1.4433 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 26th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4102 - acc: 0.7938 - val_loss: 1.4305 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 26th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4581 - acc: 0.7900 - val_loss: 1.4886 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 26th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4275 - acc: 0.7917 - val_loss: 1.4110 - val_acc: 0.7956\n",
      "[INFO] Training model: epoch 26th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4427 - acc: 0.7912 - val_loss: 1.5151 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 26th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4814 - acc: 0.7856 - val_loss: 1.3925 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 26th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4731 - acc: 0.7891 - val_loss: 1.4626 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 26th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4097 - acc: 0.7949 - val_loss: 1.3707 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 26th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4489 - acc: 0.7913 - val_loss: 1.4242 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 26th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4285 - acc: 0.7909 - val_loss: 1.4538 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 26th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4907 - acc: 0.7839 - val_loss: 1.4296 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 26th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4523 - acc: 0.7893 - val_loss: 1.4386 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 27th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4205 - acc: 0.7884 - val_loss: 1.4754 - val_acc: 0.7847\n",
      "[INFO] Training model: epoch 27th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3941 - acc: 0.7915 - val_loss: 1.4626 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 27th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3823 - acc: 0.7944 - val_loss: 1.3918 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 27th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3664 - acc: 0.7946 - val_loss: 1.4292 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 27th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3465 - acc: 0.7970 - val_loss: 1.4127 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 27th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3775 - acc: 0.7920 - val_loss: 1.3901 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 27th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3540 - acc: 0.7950 - val_loss: 1.3847 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 27th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3567 - acc: 0.7954 - val_loss: 1.4677 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 27th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3858 - acc: 0.7930 - val_loss: 1.4291 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 27th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3847 - acc: 0.7959 - val_loss: 1.3716 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 27th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3949 - acc: 0.7897 - val_loss: 1.3209 - val_acc: 0.8041\n",
      "[INFO] Training model: epoch 27th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4040 - acc: 0.7902 - val_loss: 1.4289 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 27th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4154 - acc: 0.7903 - val_loss: 1.4138 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 27th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3633 - acc: 0.7958 - val_loss: 1.3237 - val_acc: 0.7970\n",
      "[INFO] Training model: epoch 27th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4107 - acc: 0.7914 - val_loss: 1.4245 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 27th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4022 - acc: 0.7923 - val_loss: 1.3698 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 27th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4091 - acc: 0.7900 - val_loss: 1.3844 - val_acc: 0.7944\n",
      "[INFO] Training model: epoch 27th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4091 - acc: 0.7909 - val_loss: 1.5100 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 27th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4000 - acc: 0.7920 - val_loss: 1.3374 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 27th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3694 - acc: 0.7936 - val_loss: 1.5443 - val_acc: 0.7748\n",
      "[INFO] Training model: epoch 27th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4117 - acc: 0.7920 - val_loss: 1.3831 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 27th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3707 - acc: 0.7976 - val_loss: 1.4245 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 27th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3582 - acc: 0.7953 - val_loss: 1.4259 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 27th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4129 - acc: 0.7921 - val_loss: 1.4107 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 27th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4239 - acc: 0.7892 - val_loss: 1.4548 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 27th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4018 - acc: 0.7921 - val_loss: 1.4680 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 27th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4042 - acc: 0.7935 - val_loss: 1.5087 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 27th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4289 - acc: 0.7911 - val_loss: 1.4336 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 27th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4014 - acc: 0.7941 - val_loss: 1.3882 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 27th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4050 - acc: 0.7949 - val_loss: 1.4201 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 27th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3792 - acc: 0.7959 - val_loss: 1.3755 - val_acc: 0.7967\n",
      "[INFO] Training model: epoch 27th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3893 - acc: 0.7949 - val_loss: 1.4926 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 27th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3902 - acc: 0.7947 - val_loss: 1.4700 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 27th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4754 - acc: 0.7851 - val_loss: 1.4166 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 27th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4390 - acc: 0.7892 - val_loss: 1.4595 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 27th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4220 - acc: 0.7925 - val_loss: 1.4201 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 27th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4638 - acc: 0.7877 - val_loss: 1.3520 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 27th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4822 - acc: 0.7864 - val_loss: 1.4240 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 27th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4441 - acc: 0.7881 - val_loss: 1.4280 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 27th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4099 - acc: 0.7903 - val_loss: 1.4001 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 27th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4267 - acc: 0.7929 - val_loss: 1.3661 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 27th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4124 - acc: 0.7934 - val_loss: 1.4934 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 27th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4500 - acc: 0.7898 - val_loss: 1.4423 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 27th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4635 - acc: 0.7880 - val_loss: 1.4202 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 27th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4376 - acc: 0.7909 - val_loss: 1.4578 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 27th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4150 - acc: 0.7931 - val_loss: 1.2826 - val_acc: 0.8092\n",
      "[INFO] Training model: epoch 27th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4291 - acc: 0.7893 - val_loss: 1.4591 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 27th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4230 - acc: 0.7911 - val_loss: 1.4254 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 27th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4647 - acc: 0.7883 - val_loss: 1.4594 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 27th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3810 - acc: 0.7983 - val_loss: 1.4034 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 28th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3710 - acc: 0.7969 - val_loss: 1.4720 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 28th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3786 - acc: 0.7940 - val_loss: 1.3929 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 28th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3950 - acc: 0.7930 - val_loss: 1.3352 - val_acc: 0.7997\n",
      "[INFO] Training model: epoch 28th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3692 - acc: 0.7938 - val_loss: 1.4120 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 28th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3810 - acc: 0.7932 - val_loss: 1.3855 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 28th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4129 - acc: 0.7894 - val_loss: 1.4117 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 28th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4159 - acc: 0.7879 - val_loss: 1.3634 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 28th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3548 - acc: 0.7925 - val_loss: 1.4061 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 28th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3951 - acc: 0.7920 - val_loss: 1.4372 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 28th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3567 - acc: 0.7963 - val_loss: 1.4474 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 28th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4046 - acc: 0.7877 - val_loss: 1.4323 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 28th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3713 - acc: 0.7962 - val_loss: 1.4012 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 28th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3909 - acc: 0.7913 - val_loss: 1.4740 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 28th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3758 - acc: 0.7929 - val_loss: 1.3927 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 28th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3631 - acc: 0.7950 - val_loss: 1.3871 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 28th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4032 - acc: 0.7909 - val_loss: 1.4232 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 28th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3825 - acc: 0.7927 - val_loss: 1.3591 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 28th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3712 - acc: 0.7948 - val_loss: 1.4185 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 28th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4140 - acc: 0.7889 - val_loss: 1.4384 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 28th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3876 - acc: 0.7929 - val_loss: 1.3130 - val_acc: 0.8012\n",
      "[INFO] Training model: epoch 28th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3840 - acc: 0.7937 - val_loss: 1.4084 - val_acc: 0.7967\n",
      "[INFO] Training model: epoch 28th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4375 - acc: 0.7883 - val_loss: 1.3891 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 28th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4147 - acc: 0.7897 - val_loss: 1.3905 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 28th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4053 - acc: 0.7923 - val_loss: 1.4177 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 28th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3542 - acc: 0.7964 - val_loss: 1.3676 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 28th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4345 - acc: 0.7900 - val_loss: 1.4884 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 28th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4199 - acc: 0.7916 - val_loss: 1.4713 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 28th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3956 - acc: 0.7945 - val_loss: 1.4884 - val_acc: 0.7800\n",
      "[INFO] Training model: epoch 28th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3707 - acc: 0.7968 - val_loss: 1.4229 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 28th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3646 - acc: 0.7963 - val_loss: 1.4149 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 28th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3882 - acc: 0.7950 - val_loss: 1.4901 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 28th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3838 - acc: 0.7955 - val_loss: 1.3425 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 28th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3893 - acc: 0.7952 - val_loss: 1.4453 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 28th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4054 - acc: 0.7914 - val_loss: 1.4057 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 28th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3847 - acc: 0.7954 - val_loss: 1.4230 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 28th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3977 - acc: 0.7924 - val_loss: 1.4745 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 28th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4145 - acc: 0.7922 - val_loss: 1.5184 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 28th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3945 - acc: 0.7948 - val_loss: 1.5010 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 28th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3918 - acc: 0.7928 - val_loss: 1.4013 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 28th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4159 - acc: 0.7911 - val_loss: 1.4290 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 28th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4316 - acc: 0.7889 - val_loss: 1.4548 - val_acc: 0.7822\n",
      "[INFO] Training model: epoch 28th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4252 - acc: 0.7907 - val_loss: 1.4420 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 28th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3921 - acc: 0.7945 - val_loss: 1.4534 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 28th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3912 - acc: 0.7931 - val_loss: 1.3801 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 28th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4239 - acc: 0.7930 - val_loss: 1.3929 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 28th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4262 - acc: 0.7898 - val_loss: 1.4196 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 28th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4233 - acc: 0.7920 - val_loss: 1.4514 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 28th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4012 - acc: 0.7949 - val_loss: 1.4644 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 28th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4343 - acc: 0.7909 - val_loss: 1.4310 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 28th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4280 - acc: 0.7900 - val_loss: 1.2896 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 29th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3512 - acc: 0.7924 - val_loss: 1.3952 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 29th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3794 - acc: 0.7904 - val_loss: 1.2707 - val_acc: 0.8056\n",
      "[INFO] Training model: epoch 29th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3548 - acc: 0.7946 - val_loss: 1.3264 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 29th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3403 - acc: 0.7975 - val_loss: 1.3572 - val_acc: 0.7989\n",
      "[INFO] Training model: epoch 29th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4238 - acc: 0.7873 - val_loss: 1.3936 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 29th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3488 - acc: 0.7948 - val_loss: 1.3755 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 29th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3875 - acc: 0.7924 - val_loss: 1.3709 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 29th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3443 - acc: 0.7950 - val_loss: 1.3358 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 29th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3543 - acc: 0.7964 - val_loss: 1.3930 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 29th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3957 - acc: 0.7904 - val_loss: 1.4533 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 29th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3748 - acc: 0.7937 - val_loss: 1.3677 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 29th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4105 - acc: 0.7884 - val_loss: 1.3462 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 29th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3635 - acc: 0.7942 - val_loss: 1.3943 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 29th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3553 - acc: 0.7966 - val_loss: 1.2863 - val_acc: 0.8037\n",
      "[INFO] Training model: epoch 29th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4246 - acc: 0.7877 - val_loss: 1.3329 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 29th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3879 - acc: 0.7924 - val_loss: 1.3475 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 29th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4092 - acc: 0.7869 - val_loss: 1.3688 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 29th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3871 - acc: 0.7914 - val_loss: 1.4215 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 29th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3621 - acc: 0.7946 - val_loss: 1.3584 - val_acc: 0.7991\n",
      "[INFO] Training model: epoch 29th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4093 - acc: 0.7898 - val_loss: 1.4079 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 29th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3809 - acc: 0.7936 - val_loss: 1.3377 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 29th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3866 - acc: 0.7948 - val_loss: 1.4169 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 29th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3590 - acc: 0.7971 - val_loss: 1.3873 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 29th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4070 - acc: 0.7921 - val_loss: 1.3324 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 29th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4035 - acc: 0.7884 - val_loss: 1.3685 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 29th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3709 - acc: 0.7954 - val_loss: 1.4113 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 29th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3754 - acc: 0.7979 - val_loss: 1.4495 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 29th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4099 - acc: 0.7897 - val_loss: 1.4649 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 29th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4210 - acc: 0.7899 - val_loss: 1.4048 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 29th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4205 - acc: 0.7879 - val_loss: 1.4686 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 29th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4360 - acc: 0.7878 - val_loss: 1.4019 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 29th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3596 - acc: 0.7980 - val_loss: 1.4149 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 29th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3796 - acc: 0.7940 - val_loss: 1.4347 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 29th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4086 - acc: 0.7921 - val_loss: 1.3911 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 29th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4193 - acc: 0.7904 - val_loss: 1.3123 - val_acc: 0.8022\n",
      "[INFO] Training model: epoch 29th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4260 - acc: 0.7900 - val_loss: 1.3895 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 29th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4084 - acc: 0.7935 - val_loss: 1.4210 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 29th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3614 - acc: 0.7979 - val_loss: 1.3869 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 29th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4179 - acc: 0.7891 - val_loss: 1.5275 - val_acc: 0.7795\n",
      "[INFO] Training model: epoch 29th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3962 - acc: 0.7934 - val_loss: 1.3674 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 29th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3805 - acc: 0.7961 - val_loss: 1.4021 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 29th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3726 - acc: 0.7984 - val_loss: 1.3883 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 29th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4274 - acc: 0.7905 - val_loss: 1.3868 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 29th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4172 - acc: 0.7917 - val_loss: 1.4292 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 29th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3670 - acc: 0.7995 - val_loss: 1.4309 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 29th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4178 - acc: 0.7927 - val_loss: 1.3494 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 29th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3788 - acc: 0.7967 - val_loss: 1.4799 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 29th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4213 - acc: 0.7916 - val_loss: 1.4555 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 29th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3554 - acc: 0.7988 - val_loss: 1.4005 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 29th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4270 - acc: 0.7907 - val_loss: 1.3698 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 30th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3326 - acc: 0.7956 - val_loss: 1.3992 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 30th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3665 - acc: 0.7932 - val_loss: 1.3237 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 30th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3419 - acc: 0.7966 - val_loss: 1.4381 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 30th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3296 - acc: 0.7957 - val_loss: 1.4142 - val_acc: 0.7823\n",
      "[INFO] Training model: epoch 30th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3544 - acc: 0.7923 - val_loss: 1.3343 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 30th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3852 - acc: 0.7908 - val_loss: 1.3274 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 30th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3569 - acc: 0.7963 - val_loss: 1.3400 - val_acc: 0.7997\n",
      "[INFO] Training model: epoch 30th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3466 - acc: 0.7963 - val_loss: 1.3747 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 30th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3574 - acc: 0.7929 - val_loss: 1.3216 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 30th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3419 - acc: 0.7935 - val_loss: 1.3806 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 30th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3856 - acc: 0.7896 - val_loss: 1.3466 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 30th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3145 - acc: 0.8008 - val_loss: 1.4059 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 30th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4067 - acc: 0.7887 - val_loss: 1.3870 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 30th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3672 - acc: 0.7939 - val_loss: 1.4177 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 30th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3689 - acc: 0.7918 - val_loss: 1.3864 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 30th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3587 - acc: 0.7949 - val_loss: 1.4150 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 30th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2987 - acc: 0.8024 - val_loss: 1.4050 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 30th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4304 - acc: 0.7862 - val_loss: 1.3317 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 30th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3132 - acc: 0.8004 - val_loss: 1.3828 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 30th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3962 - acc: 0.7892 - val_loss: 1.4173 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 30th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3364 - acc: 0.7969 - val_loss: 1.3720 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 30th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4128 - acc: 0.7893 - val_loss: 1.3909 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 30th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3481 - acc: 0.7971 - val_loss: 1.3932 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 30th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3980 - acc: 0.7929 - val_loss: 1.3905 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 30th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3502 - acc: 0.7973 - val_loss: 1.4285 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 30th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3701 - acc: 0.7921 - val_loss: 1.3815 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 30th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3731 - acc: 0.7950 - val_loss: 1.4261 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 30th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3734 - acc: 0.7968 - val_loss: 1.3872 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 30th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4113 - acc: 0.7892 - val_loss: 1.3681 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 30th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3693 - acc: 0.7968 - val_loss: 1.4640 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 30th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3854 - acc: 0.7921 - val_loss: 1.3164 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 30th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4024 - acc: 0.7909 - val_loss: 1.4114 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 30th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4024 - acc: 0.7919 - val_loss: 1.4120 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 30th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3662 - acc: 0.7938 - val_loss: 1.3830 - val_acc: 0.7970\n",
      "[INFO] Training model: epoch 30th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3872 - acc: 0.7949 - val_loss: 1.4792 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 30th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4055 - acc: 0.7910 - val_loss: 1.4926 - val_acc: 0.7798\n",
      "[INFO] Training model: epoch 30th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4123 - acc: 0.7915 - val_loss: 1.3566 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 30th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4028 - acc: 0.7911 - val_loss: 1.4449 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 30th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4031 - acc: 0.7926 - val_loss: 1.4481 - val_acc: 0.7850\n",
      "[INFO] Training model: epoch 30th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3982 - acc: 0.7927 - val_loss: 1.3951 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 30th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4113 - acc: 0.7897 - val_loss: 1.3666 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 30th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3810 - acc: 0.7970 - val_loss: 1.3806 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 30th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4017 - acc: 0.7907 - val_loss: 1.3766 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 30th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4237 - acc: 0.7923 - val_loss: 1.4757 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 30th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3900 - acc: 0.7919 - val_loss: 1.3837 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 30th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4018 - acc: 0.7938 - val_loss: 1.4537 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 30th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3745 - acc: 0.7965 - val_loss: 1.4655 - val_acc: 0.7855\n",
      "[INFO] Training model: epoch 30th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.4120 - acc: 0.7925 - val_loss: 1.4474 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 30th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.4027 - acc: 0.7958 - val_loss: 1.3718 - val_acc: 0.8009\n",
      "[INFO] Training model: epoch 30th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4094 - acc: 0.7935 - val_loss: 1.3265 - val_acc: 0.8002\n",
      "[INFO] Training model: epoch 31th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3395 - acc: 0.7965 - val_loss: 1.3771 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 31th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3353 - acc: 0.7962 - val_loss: 1.3508 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 31th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3146 - acc: 0.7985 - val_loss: 1.3864 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 31th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3600 - acc: 0.7925 - val_loss: 1.3557 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 31th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3536 - acc: 0.7930 - val_loss: 1.2880 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 31th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3263 - acc: 0.7943 - val_loss: 1.4330 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 31th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3225 - acc: 0.7961 - val_loss: 1.4134 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 31th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3796 - acc: 0.7870 - val_loss: 1.3341 - val_acc: 0.7997\n",
      "[INFO] Training model: epoch 31th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3309 - acc: 0.7956 - val_loss: 1.3531 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 31th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3697 - acc: 0.7928 - val_loss: 1.3160 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 31th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.3599 - acc: 0.7928 - val_loss: 1.3656 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 31th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3612 - acc: 0.7932 - val_loss: 1.3661 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 31th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3598 - acc: 0.7952 - val_loss: 1.3828 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 31th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3205 - acc: 0.7971 - val_loss: 1.3259 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 31th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3783 - acc: 0.7919 - val_loss: 1.4206 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 31th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3403 - acc: 0.7951 - val_loss: 1.3559 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 31th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3547 - acc: 0.7952 - val_loss: 1.3555 - val_acc: 0.7991\n",
      "[INFO] Training model: epoch 31th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.3899 - acc: 0.7918 - val_loss: 1.4181 - val_acc: 0.7858\n",
      "[INFO] Training model: epoch 31th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3489 - acc: 0.7948 - val_loss: 1.3787 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 31th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3902 - acc: 0.7902 - val_loss: 1.3630 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 31th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3616 - acc: 0.7953 - val_loss: 1.3572 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 31th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3398 - acc: 0.7965 - val_loss: 1.3756 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 31th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3581 - acc: 0.7967 - val_loss: 1.3784 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 31th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3731 - acc: 0.7957 - val_loss: 1.4282 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 31th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3642 - acc: 0.7951 - val_loss: 1.4149 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 31th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3353 - acc: 0.7980 - val_loss: 1.3814 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 31th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.4030 - acc: 0.7898 - val_loss: 1.4696 - val_acc: 0.7819\n",
      "[INFO] Training model: epoch 31th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3497 - acc: 0.7968 - val_loss: 1.3635 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 31th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3592 - acc: 0.7972 - val_loss: 1.4276 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 31th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s - loss: 1.4253 - acc: 0.7892 - val_loss: 1.3842 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 31th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4002 - acc: 0.7898 - val_loss: 1.3649 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 31th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3765 - acc: 0.7934 - val_loss: 1.4626 - val_acc: 0.7841\n",
      "[INFO] Training model: epoch 31th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3906 - acc: 0.7915 - val_loss: 1.3735 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 31th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4084 - acc: 0.7908 - val_loss: 1.3924 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 31th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3642 - acc: 0.7985 - val_loss: 1.4593 - val_acc: 0.7834\n",
      "[INFO] Training model: epoch 31th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3923 - acc: 0.7920 - val_loss: 1.4747 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 31th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3746 - acc: 0.7926 - val_loss: 1.3954 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 31th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3640 - acc: 0.7983 - val_loss: 1.4384 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 31th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4126 - acc: 0.7894 - val_loss: 1.3664 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 31th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3530 - acc: 0.7972 - val_loss: 1.3828 - val_acc: 0.7991\n",
      "[INFO] Training model: epoch 31th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3616 - acc: 0.7959 - val_loss: 1.2887 - val_acc: 0.8041\n",
      "[INFO] Training model: epoch 31th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3429 - acc: 0.7981 - val_loss: 1.4233 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 31th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3730 - acc: 0.7958 - val_loss: 1.4235 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 31th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4383 - acc: 0.7896 - val_loss: 1.4405 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 31th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4188 - acc: 0.7907 - val_loss: 1.3952 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 31th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3600 - acc: 0.7963 - val_loss: 1.3417 - val_acc: 0.8002\n",
      "[INFO] Training model: epoch 31th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3308 - acc: 0.8002 - val_loss: 1.4865 - val_acc: 0.7839\n",
      "[INFO] Training model: epoch 31th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3665 - acc: 0.7972 - val_loss: 1.3829 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 31th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3772 - acc: 0.7955 - val_loss: 1.3676 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 31th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4084 - acc: 0.7927 - val_loss: 1.4239 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 32th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3572 - acc: 0.7915 - val_loss: 1.3784 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 32th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3513 - acc: 0.7932 - val_loss: 1.2766 - val_acc: 0.8030\n",
      "[INFO] Training model: epoch 32th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3461 - acc: 0.7916 - val_loss: 1.3562 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 32th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3571 - acc: 0.7943 - val_loss: 1.4283 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 32th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3114 - acc: 0.7977 - val_loss: 1.4171 - val_acc: 0.7905\n",
      "[INFO] Training model: epoch 32th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3364 - acc: 0.7935 - val_loss: 1.3877 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 32th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3573 - acc: 0.7936 - val_loss: 1.3808 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 32th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3023 - acc: 0.8013 - val_loss: 1.3397 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 32th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3530 - acc: 0.7944 - val_loss: 1.3618 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 32th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3444 - acc: 0.7957 - val_loss: 1.3716 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 32th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3076 - acc: 0.7974 - val_loss: 1.3216 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 32th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3772 - acc: 0.7905 - val_loss: 1.2359 - val_acc: 0.8111\n",
      "[INFO] Training model: epoch 32th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3602 - acc: 0.7912 - val_loss: 1.3527 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 32th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3460 - acc: 0.7958 - val_loss: 1.2969 - val_acc: 0.8028\n",
      "[INFO] Training model: epoch 32th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3292 - acc: 0.7970 - val_loss: 1.4101 - val_acc: 0.7845\n",
      "[INFO] Training model: epoch 32th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3289 - acc: 0.7975 - val_loss: 1.3309 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 32th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3466 - acc: 0.7973 - val_loss: 1.3165 - val_acc: 0.8030\n",
      "[INFO] Training model: epoch 32th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3272 - acc: 0.7986 - val_loss: 1.2626 - val_acc: 0.8077\n",
      "[INFO] Training model: epoch 32th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3359 - acc: 0.7947 - val_loss: 1.3201 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 32th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3670 - acc: 0.7913 - val_loss: 1.3409 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 32th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3470 - acc: 0.7937 - val_loss: 1.3402 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 32th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3338 - acc: 0.7987 - val_loss: 1.3657 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 32th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3269 - acc: 0.7966 - val_loss: 1.4009 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 32th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3451 - acc: 0.7945 - val_loss: 1.2879 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 32th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3453 - acc: 0.7971 - val_loss: 1.3644 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 32th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3826 - acc: 0.7907 - val_loss: 1.4280 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 32th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3684 - acc: 0.7932 - val_loss: 1.3454 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 32th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3464 - acc: 0.7960 - val_loss: 1.3107 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 32th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3514 - acc: 0.7951 - val_loss: 1.2732 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 32th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3453 - acc: 0.7978 - val_loss: 1.3595 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 32th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3494 - acc: 0.7954 - val_loss: 1.3561 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 32th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4073 - acc: 0.7893 - val_loss: 1.3247 - val_acc: 0.8005\n",
      "[INFO] Training model: epoch 32th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3442 - acc: 0.7976 - val_loss: 1.3365 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 32th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3718 - acc: 0.7950 - val_loss: 1.3924 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 32th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3722 - acc: 0.7942 - val_loss: 1.4098 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 32th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3867 - acc: 0.7929 - val_loss: 1.4067 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 32th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3887 - acc: 0.7919 - val_loss: 1.3578 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 32th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3728 - acc: 0.7944 - val_loss: 1.3205 - val_acc: 0.8017\n",
      "[INFO] Training model: epoch 32th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3649 - acc: 0.7978 - val_loss: 1.3461 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 32th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3871 - acc: 0.7931 - val_loss: 1.4224 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 32th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3739 - acc: 0.7939 - val_loss: 1.3773 - val_acc: 0.7970\n",
      "[INFO] Training model: epoch 32th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3867 - acc: 0.7944 - val_loss: 1.4350 - val_acc: 0.7861\n",
      "[INFO] Training model: epoch 32th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4314 - acc: 0.7890 - val_loss: 1.4066 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 32th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3925 - acc: 0.7911 - val_loss: 1.4293 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 32th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3799 - acc: 0.7942 - val_loss: 1.3615 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 32th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3753 - acc: 0.7957 - val_loss: 1.4965 - val_acc: 0.7775\n",
      "[INFO] Training model: epoch 32th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3590 - acc: 0.7958 - val_loss: 1.4789 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 32th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3972 - acc: 0.7922 - val_loss: 1.3672 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 32th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3874 - acc: 0.7915 - val_loss: 1.4605 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 32th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3745 - acc: 0.7939 - val_loss: 1.4970 - val_acc: 0.7827\n",
      "[INFO] Training model: epoch 33th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3286 - acc: 0.7966 - val_loss: 1.4196 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 33th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3833 - acc: 0.7887 - val_loss: 1.3433 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 33th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3086 - acc: 0.7975 - val_loss: 1.3699 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 33th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3119 - acc: 0.7960 - val_loss: 1.3878 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 33th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2869 - acc: 0.7986 - val_loss: 1.4054 - val_acc: 0.7848\n",
      "[INFO] Training model: epoch 33th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3090 - acc: 0.7985 - val_loss: 1.3523 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 33th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3228 - acc: 0.8000 - val_loss: 1.3486 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 33th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3276 - acc: 0.7946 - val_loss: 1.2991 - val_acc: 0.7980\n",
      "[INFO] Training model: epoch 33th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3538 - acc: 0.7922 - val_loss: 1.3255 - val_acc: 0.7973\n",
      "[INFO] Training model: epoch 33th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3465 - acc: 0.7928 - val_loss: 1.2380 - val_acc: 0.8059\n",
      "[INFO] Training model: epoch 33th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3033 - acc: 0.7995 - val_loss: 1.3646 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 33th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3198 - acc: 0.7966 - val_loss: 1.3166 - val_acc: 0.7995\n",
      "[INFO] Training model: epoch 33th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3616 - acc: 0.7934 - val_loss: 1.3315 - val_acc: 0.7995\n",
      "[INFO] Training model: epoch 33th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3673 - acc: 0.7911 - val_loss: 1.2609 - val_acc: 0.8034\n",
      "[INFO] Training model: epoch 33th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3465 - acc: 0.7934 - val_loss: 1.2957 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 33th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3382 - acc: 0.7963 - val_loss: 1.3230 - val_acc: 0.7989\n",
      "[INFO] Training model: epoch 33th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3248 - acc: 0.7969 - val_loss: 1.3746 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 33th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3227 - acc: 0.7968 - val_loss: 1.2980 - val_acc: 0.8042\n",
      "[INFO] Training model: epoch 33th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3523 - acc: 0.7968 - val_loss: 1.3049 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 33th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3430 - acc: 0.7942 - val_loss: 1.3696 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 33th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2831 - acc: 0.8034 - val_loss: 1.3463 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 33th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3507 - acc: 0.7939 - val_loss: 1.3568 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 33th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3874 - acc: 0.7888 - val_loss: 1.3051 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 33th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3369 - acc: 0.7946 - val_loss: 1.3673 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 33th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3369 - acc: 0.7958 - val_loss: 1.3349 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 33th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3416 - acc: 0.7971 - val_loss: 1.3603 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 33th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3945 - acc: 0.7880 - val_loss: 1.3647 - val_acc: 0.8002\n",
      "[INFO] Training model: epoch 33th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3542 - acc: 0.7950 - val_loss: 1.3093 - val_acc: 0.8036\n",
      "[INFO] Training model: epoch 33th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3554 - acc: 0.7950 - val_loss: 1.4326 - val_acc: 0.7803\n",
      "[INFO] Training model: epoch 33th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3301 - acc: 0.7998 - val_loss: 1.3222 - val_acc: 0.8009\n",
      "[INFO] Training model: epoch 33th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3819 - acc: 0.7907 - val_loss: 1.3662 - val_acc: 0.7950\n",
      "[INFO] Training model: epoch 33th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3719 - acc: 0.7939 - val_loss: 1.3753 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 33th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3374 - acc: 0.7995 - val_loss: 1.4337 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 33th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3445 - acc: 0.7975 - val_loss: 1.3932 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 33th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3376 - acc: 0.7973 - val_loss: 1.3869 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 33th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3634 - acc: 0.7924 - val_loss: 1.3173 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 33th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3726 - acc: 0.7942 - val_loss: 1.3146 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 33th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3502 - acc: 0.7955 - val_loss: 1.3672 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 33th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3886 - acc: 0.7894 - val_loss: 1.4455 - val_acc: 0.7831\n",
      "[INFO] Training model: epoch 33th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3490 - acc: 0.7968 - val_loss: 1.4532 - val_acc: 0.7837\n",
      "[INFO] Training model: epoch 33th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3569 - acc: 0.7966 - val_loss: 1.3695 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 33th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3677 - acc: 0.7939 - val_loss: 1.4981 - val_acc: 0.7814\n",
      "[INFO] Training model: epoch 33th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3744 - acc: 0.7966 - val_loss: 1.3302 - val_acc: 0.8002\n",
      "[INFO] Training model: epoch 33th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3640 - acc: 0.7943 - val_loss: 1.3019 - val_acc: 0.8025\n",
      "[INFO] Training model: epoch 33th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3560 - acc: 0.7960 - val_loss: 1.4161 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 33th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.4039 - acc: 0.7925 - val_loss: 1.4281 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 33th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4123 - acc: 0.7891 - val_loss: 1.4035 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 33th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3514 - acc: 0.7955 - val_loss: 1.4554 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 33th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3743 - acc: 0.7950 - val_loss: 1.4161 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 33th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3765 - acc: 0.7959 - val_loss: 1.3646 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 34th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3262 - acc: 0.7942 - val_loss: 1.3766 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 34th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2889 - acc: 0.7979 - val_loss: 1.2922 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 34th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3194 - acc: 0.7940 - val_loss: 1.3896 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 34th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2633 - acc: 0.8014 - val_loss: 1.3690 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 34th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3297 - acc: 0.7933 - val_loss: 1.3780 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 34th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2993 - acc: 0.7997 - val_loss: 1.3371 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 34th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3104 - acc: 0.7961 - val_loss: 1.3663 - val_acc: 0.7916\n",
      "[INFO] Training model: epoch 34th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3017 - acc: 0.7963 - val_loss: 1.3410 - val_acc: 0.7895\n",
      "[INFO] Training model: epoch 34th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3283 - acc: 0.7954 - val_loss: 1.3839 - val_acc: 0.7866\n",
      "[INFO] Training model: epoch 34th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3464 - acc: 0.7923 - val_loss: 1.3285 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 34th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3187 - acc: 0.7966 - val_loss: 1.3309 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 34th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3255 - acc: 0.7953 - val_loss: 1.3861 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 34th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2929 - acc: 0.7995 - val_loss: 1.3393 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 34th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3886 - acc: 0.7876 - val_loss: 1.3104 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 34th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3356 - acc: 0.7955 - val_loss: 1.2484 - val_acc: 0.8084\n",
      "[INFO] Training model: epoch 34th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3354 - acc: 0.7968 - val_loss: 1.3055 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 34th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3835 - acc: 0.7895 - val_loss: 1.4198 - val_acc: 0.7869\n",
      "[INFO] Training model: epoch 34th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3668 - acc: 0.7896 - val_loss: 1.2949 - val_acc: 0.8009\n",
      "[INFO] Training model: epoch 34th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3621 - acc: 0.7929 - val_loss: 1.3351 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 34th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3429 - acc: 0.7951 - val_loss: 1.4172 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 34th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2952 - acc: 0.8008 - val_loss: 1.3110 - val_acc: 0.7997\n",
      "[INFO] Training model: epoch 34th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3330 - acc: 0.7972 - val_loss: 1.3074 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 34th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3327 - acc: 0.7954 - val_loss: 1.3700 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 34th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3109 - acc: 0.7999 - val_loss: 1.3797 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 34th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3264 - acc: 0.7966 - val_loss: 1.2610 - val_acc: 0.8080\n",
      "[INFO] Training model: epoch 34th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3336 - acc: 0.7960 - val_loss: 1.3629 - val_acc: 0.7923\n",
      "[INFO] Training model: epoch 34th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3640 - acc: 0.7934 - val_loss: 1.3474 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 34th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3485 - acc: 0.7952 - val_loss: 1.2880 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 34th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3440 - acc: 0.7953 - val_loss: 1.3675 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 34th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3435 - acc: 0.7954 - val_loss: 1.3546 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 34th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3398 - acc: 0.7956 - val_loss: 1.3832 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 34th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3441 - acc: 0.7963 - val_loss: 1.3773 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 34th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3434 - acc: 0.7958 - val_loss: 1.3787 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 34th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3466 - acc: 0.7944 - val_loss: 1.3545 - val_acc: 0.7956\n",
      "[INFO] Training model: epoch 34th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3449 - acc: 0.7978 - val_loss: 1.3388 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 34th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3584 - acc: 0.7931 - val_loss: 1.2756 - val_acc: 0.8052\n",
      "[INFO] Training model: epoch 34th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3390 - acc: 0.7950 - val_loss: 1.3906 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 34th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3486 - acc: 0.7945 - val_loss: 1.3521 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 34th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3680 - acc: 0.7938 - val_loss: 1.3540 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 34th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3487 - acc: 0.7971 - val_loss: 1.3122 - val_acc: 0.8019\n",
      "[INFO] Training model: epoch 34th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3693 - acc: 0.7938 - val_loss: 1.3758 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 34th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3940 - acc: 0.7909 - val_loss: 1.4257 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 34th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3641 - acc: 0.7949 - val_loss: 1.4386 - val_acc: 0.7862\n",
      "[INFO] Training model: epoch 34th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3612 - acc: 0.7981 - val_loss: 1.3643 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 34th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3767 - acc: 0.7927 - val_loss: 1.2631 - val_acc: 0.8092\n",
      "[INFO] Training model: epoch 34th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3490 - acc: 0.7947 - val_loss: 1.3964 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 34th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3784 - acc: 0.7928 - val_loss: 1.2950 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 34th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3604 - acc: 0.7970 - val_loss: 1.2980 - val_acc: 0.8075\n",
      "[INFO] Training model: epoch 34th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3485 - acc: 0.7964 - val_loss: 1.3276 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 34th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3516 - acc: 0.7981 - val_loss: 1.4575 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 35th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3147 - acc: 0.7959 - val_loss: 1.3075 - val_acc: 0.8003\n",
      "[INFO] Training model: epoch 35th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3039 - acc: 0.7960 - val_loss: 1.2327 - val_acc: 0.8081\n",
      "[INFO] Training model: epoch 35th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3182 - acc: 0.7936 - val_loss: 1.2211 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 35th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2907 - acc: 0.7989 - val_loss: 1.3353 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 35th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3441 - acc: 0.7898 - val_loss: 1.3078 - val_acc: 0.7928\n",
      "[INFO] Training model: epoch 35th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2822 - acc: 0.7988 - val_loss: 1.3067 - val_acc: 0.7986\n",
      "[INFO] Training model: epoch 35th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2739 - acc: 0.8009 - val_loss: 1.2784 - val_acc: 0.8025\n",
      "[INFO] Training model: epoch 35th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3665 - acc: 0.7893 - val_loss: 1.3054 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 35th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3110 - acc: 0.7964 - val_loss: 1.4136 - val_acc: 0.7842\n",
      "[INFO] Training model: epoch 35th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3034 - acc: 0.7956 - val_loss: 1.3397 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 35th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3320 - acc: 0.7964 - val_loss: 1.3194 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 35th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2749 - acc: 0.8001 - val_loss: 1.2892 - val_acc: 0.8009\n",
      "[INFO] Training model: epoch 35th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3225 - acc: 0.7938 - val_loss: 1.2611 - val_acc: 0.8044\n",
      "[INFO] Training model: epoch 35th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3127 - acc: 0.7947 - val_loss: 1.2899 - val_acc: 0.8002\n",
      "[INFO] Training model: epoch 35th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3520 - acc: 0.7927 - val_loss: 1.4080 - val_acc: 0.7877\n",
      "[INFO] Training model: epoch 35th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3025 - acc: 0.7986 - val_loss: 1.3905 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 35th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3100 - acc: 0.7978 - val_loss: 1.3348 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 35th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3783 - acc: 0.7918 - val_loss: 1.2936 - val_acc: 0.7989\n",
      "[INFO] Training model: epoch 35th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3153 - acc: 0.7972 - val_loss: 1.3225 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 35th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3420 - acc: 0.7957 - val_loss: 1.2674 - val_acc: 0.8044\n",
      "[INFO] Training model: epoch 35th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2800 - acc: 0.8024 - val_loss: 1.3086 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 35th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3160 - acc: 0.7959 - val_loss: 1.2575 - val_acc: 0.8056\n",
      "[INFO] Training model: epoch 35th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3411 - acc: 0.7948 - val_loss: 1.3806 - val_acc: 0.7900\n",
      "[INFO] Training model: epoch 35th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3382 - acc: 0.7955 - val_loss: 1.4198 - val_acc: 0.7892\n",
      "[INFO] Training model: epoch 35th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3287 - acc: 0.7973 - val_loss: 1.4007 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 35th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3429 - acc: 0.7966 - val_loss: 1.3790 - val_acc: 0.7902\n",
      "[INFO] Training model: epoch 35th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3513 - acc: 0.7956 - val_loss: 1.3186 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 35th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3415 - acc: 0.7955 - val_loss: 1.3656 - val_acc: 0.7967\n",
      "[INFO] Training model: epoch 35th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3226 - acc: 0.7969 - val_loss: 1.4641 - val_acc: 0.7811\n",
      "[INFO] Training model: epoch 35th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3829 - acc: 0.7916 - val_loss: 1.3337 - val_acc: 0.7959\n",
      "[INFO] Training model: epoch 35th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3471 - acc: 0.7963 - val_loss: 1.3946 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 35th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3683 - acc: 0.7929 - val_loss: 1.2824 - val_acc: 0.8072\n",
      "[INFO] Training model: epoch 35th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3278 - acc: 0.7973 - val_loss: 1.3838 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 35th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3454 - acc: 0.7934 - val_loss: 1.3481 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 35th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3313 - acc: 0.7971 - val_loss: 1.3528 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 35th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3227 - acc: 0.7973 - val_loss: 1.2705 - val_acc: 0.8019\n",
      "[INFO] Training model: epoch 35th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3896 - acc: 0.7893 - val_loss: 1.3831 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 35th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3480 - acc: 0.7945 - val_loss: 1.3156 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 35th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3356 - acc: 0.7966 - val_loss: 1.3919 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 35th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3282 - acc: 0.7996 - val_loss: 1.3328 - val_acc: 0.8002\n",
      "[INFO] Training model: epoch 35th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3643 - acc: 0.7913 - val_loss: 1.3694 - val_acc: 0.7944\n",
      "[INFO] Training model: epoch 35th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3410 - acc: 0.7964 - val_loss: 1.4521 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 35th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3396 - acc: 0.8000 - val_loss: 1.4141 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 35th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3255 - acc: 0.7989 - val_loss: 1.3465 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 35th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3488 - acc: 0.7944 - val_loss: 1.3591 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 35th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3778 - acc: 0.7932 - val_loss: 1.3310 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 35th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3365 - acc: 0.7991 - val_loss: 1.3333 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 35th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3563 - acc: 0.7963 - val_loss: 1.4117 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 35th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3363 - acc: 0.7999 - val_loss: 1.4655 - val_acc: 0.7825\n",
      "[INFO] Training model: epoch 35th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3838 - acc: 0.7913 - val_loss: 1.3458 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 36th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2870 - acc: 0.7987 - val_loss: 1.2859 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 36th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2839 - acc: 0.7995 - val_loss: 1.3425 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 36th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3120 - acc: 0.7946 - val_loss: 1.3324 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 36th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2774 - acc: 0.7990 - val_loss: 1.3603 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 36th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2962 - acc: 0.7961 - val_loss: 1.3001 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 36th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2704 - acc: 0.8000 - val_loss: 1.3082 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 36th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2808 - acc: 0.7996 - val_loss: 1.4083 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 36th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3210 - acc: 0.7941 - val_loss: 1.3703 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 36th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3288 - acc: 0.7938 - val_loss: 1.4281 - val_acc: 0.7806\n",
      "[INFO] Training model: epoch 36th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3074 - acc: 0.7986 - val_loss: 1.3992 - val_acc: 0.7830\n",
      "[INFO] Training model: epoch 36th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3301 - acc: 0.7935 - val_loss: 1.3019 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 36th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2957 - acc: 0.7962 - val_loss: 1.3348 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 36th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2970 - acc: 0.7987 - val_loss: 1.3777 - val_acc: 0.7894\n",
      "[INFO] Training model: epoch 36th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3065 - acc: 0.7968 - val_loss: 1.3007 - val_acc: 0.8025\n",
      "[INFO] Training model: epoch 36th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3465 - acc: 0.7914 - val_loss: 1.3598 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 36th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2824 - acc: 0.7992 - val_loss: 1.3843 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 36th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2876 - acc: 0.8031 - val_loss: 1.2834 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 36th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2980 - acc: 0.7983 - val_loss: 1.3765 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 36th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3396 - acc: 0.7943 - val_loss: 1.2928 - val_acc: 0.8012\n",
      "[INFO] Training model: epoch 36th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3370 - acc: 0.7946 - val_loss: 1.3802 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 36th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3297 - acc: 0.7952 - val_loss: 1.3267 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 36th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2856 - acc: 0.8008 - val_loss: 1.2689 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 36th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2975 - acc: 0.7996 - val_loss: 1.3695 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 36th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3715 - acc: 0.7907 - val_loss: 1.3782 - val_acc: 0.7864\n",
      "[INFO] Training model: epoch 36th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3075 - acc: 0.7983 - val_loss: 1.2496 - val_acc: 0.8041\n",
      "[INFO] Training model: epoch 36th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3351 - acc: 0.7951 - val_loss: 1.3247 - val_acc: 0.7991\n",
      "[INFO] Training model: epoch 36th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.2988 - acc: 0.8006 - val_loss: 1.3003 - val_acc: 0.8033\n",
      "[INFO] Training model: epoch 36th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3444 - acc: 0.7936 - val_loss: 1.2935 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 36th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3048 - acc: 0.7975 - val_loss: 1.3448 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 36th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3417 - acc: 0.7949 - val_loss: 1.3824 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 36th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3162 - acc: 0.7966 - val_loss: 1.3739 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 36th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3866 - acc: 0.7893 - val_loss: 1.3194 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 36th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3290 - acc: 0.7968 - val_loss: 1.3572 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 36th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3121 - acc: 0.7992 - val_loss: 1.3542 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 36th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3415 - acc: 0.7937 - val_loss: 1.3789 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 36th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3444 - acc: 0.7970 - val_loss: 1.3050 - val_acc: 0.8022\n",
      "[INFO] Training model: epoch 36th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3997 - acc: 0.7897 - val_loss: 1.3772 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 36th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3425 - acc: 0.7935 - val_loss: 1.2679 - val_acc: 0.8067\n",
      "[INFO] Training model: epoch 36th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2927 - acc: 0.8002 - val_loss: 1.3715 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 36th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3502 - acc: 0.7958 - val_loss: 1.3666 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 36th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3384 - acc: 0.7961 - val_loss: 1.3328 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 36th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3111 - acc: 0.8005 - val_loss: 1.3634 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 36th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3609 - acc: 0.7930 - val_loss: 1.3430 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 36th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2964 - acc: 0.8010 - val_loss: 1.3014 - val_acc: 0.8012\n",
      "[INFO] Training model: epoch 36th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3303 - acc: 0.7971 - val_loss: 1.4185 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 36th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3501 - acc: 0.7941 - val_loss: 1.3390 - val_acc: 0.7944\n",
      "[INFO] Training model: epoch 36th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3272 - acc: 0.7977 - val_loss: 1.3086 - val_acc: 0.7994\n",
      "[INFO] Training model: epoch 36th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3688 - acc: 0.7916 - val_loss: 1.3780 - val_acc: 0.7912\n",
      "[INFO] Training model: epoch 36th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3349 - acc: 0.7975 - val_loss: 1.3753 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 36th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3178 - acc: 0.7994 - val_loss: 1.4210 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 37th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2947 - acc: 0.7970 - val_loss: 1.2401 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 37th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2502 - acc: 0.8029 - val_loss: 1.3180 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 37th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2991 - acc: 0.7962 - val_loss: 1.2675 - val_acc: 0.8022\n",
      "[INFO] Training model: epoch 37th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2333 - acc: 0.8055 - val_loss: 1.2135 - val_acc: 0.8067\n",
      "[INFO] Training model: epoch 37th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3127 - acc: 0.7934 - val_loss: 1.2599 - val_acc: 0.8052\n",
      "[INFO] Training model: epoch 37th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3142 - acc: 0.7948 - val_loss: 1.2434 - val_acc: 0.8067\n",
      "[INFO] Training model: epoch 37th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3172 - acc: 0.7918 - val_loss: 1.1915 - val_acc: 0.8108\n",
      "[INFO] Training model: epoch 37th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3138 - acc: 0.7945 - val_loss: 1.3304 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 37th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2760 - acc: 0.8002 - val_loss: 1.3602 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 37th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3176 - acc: 0.7936 - val_loss: 1.2950 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 37th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2842 - acc: 0.7987 - val_loss: 1.3569 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 37th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2735 - acc: 0.7996 - val_loss: 1.2822 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 37th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3412 - acc: 0.7922 - val_loss: 1.2967 - val_acc: 0.7995\n",
      "[INFO] Training model: epoch 37th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 1.2867 - acc: 0.7990 - val_loss: 1.3285 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 37th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2802 - acc: 0.7994 - val_loss: 1.2630 - val_acc: 0.8098\n",
      "[INFO] Training model: epoch 37th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3274 - acc: 0.7958 - val_loss: 1.3073 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 37th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3303 - acc: 0.7941 - val_loss: 1.3484 - val_acc: 0.7887\n",
      "[INFO] Training model: epoch 37th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2808 - acc: 0.8004 - val_loss: 1.4045 - val_acc: 0.7884\n",
      "[INFO] Training model: epoch 37th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3255 - acc: 0.7939 - val_loss: 1.3778 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 37th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2994 - acc: 0.7984 - val_loss: 1.2673 - val_acc: 0.8052\n",
      "[INFO] Training model: epoch 37th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3043 - acc: 0.7981 - val_loss: 1.2658 - val_acc: 0.8056\n",
      "[INFO] Training model: epoch 37th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3266 - acc: 0.7955 - val_loss: 1.2864 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 37th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3151 - acc: 0.7965 - val_loss: 1.3068 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 37th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3032 - acc: 0.7970 - val_loss: 1.3520 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 37th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3052 - acc: 0.7966 - val_loss: 1.3078 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 37th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3330 - acc: 0.7953 - val_loss: 1.2848 - val_acc: 0.8036\n",
      "[INFO] Training model: epoch 37th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2810 - acc: 0.8013 - val_loss: 1.2696 - val_acc: 0.8061\n",
      "[INFO] Training model: epoch 37th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3274 - acc: 0.7953 - val_loss: 1.3632 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 37th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3127 - acc: 0.7945 - val_loss: 1.3229 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 37th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3222 - acc: 0.7976 - val_loss: 1.3458 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 37th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3746 - acc: 0.7902 - val_loss: 1.2723 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 37th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3550 - acc: 0.7909 - val_loss: 1.3801 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 37th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3267 - acc: 0.7923 - val_loss: 1.3018 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 37th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3015 - acc: 0.7993 - val_loss: 1.3486 - val_acc: 0.7934\n",
      "[INFO] Training model: epoch 37th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3664 - acc: 0.7911 - val_loss: 1.2772 - val_acc: 0.7997\n",
      "[INFO] Training model: epoch 37th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2827 - acc: 0.8014 - val_loss: 1.3566 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 37th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2904 - acc: 0.7997 - val_loss: 1.2923 - val_acc: 0.8027\n",
      "[INFO] Training model: epoch 37th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3121 - acc: 0.7991 - val_loss: 1.3459 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 37th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3208 - acc: 0.8004 - val_loss: 1.3674 - val_acc: 0.7948\n",
      "[INFO] Training model: epoch 37th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3400 - acc: 0.7946 - val_loss: 1.2742 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 37th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3483 - acc: 0.7937 - val_loss: 1.3919 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 37th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3342 - acc: 0.7963 - val_loss: 1.3694 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 37th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3334 - acc: 0.7972 - val_loss: 1.4341 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 37th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3013 - acc: 0.7999 - val_loss: 1.3089 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 37th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3406 - acc: 0.7949 - val_loss: 1.4722 - val_acc: 0.7792\n",
      "[INFO] Training model: epoch 37th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3792 - acc: 0.7914 - val_loss: 1.3121 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 37th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3251 - acc: 0.7996 - val_loss: 1.3641 - val_acc: 0.7903\n",
      "[INFO] Training model: epoch 37th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2783 - acc: 0.8016 - val_loss: 1.3448 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 37th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3615 - acc: 0.7917 - val_loss: 1.3377 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 37th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3235 - acc: 0.7978 - val_loss: 1.2096 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 38th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.2566 - acc: 0.8010 - val_loss: 1.2549 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 38th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2752 - acc: 0.7984 - val_loss: 1.3004 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 38th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2619 - acc: 0.8003 - val_loss: 1.2644 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 38th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2724 - acc: 0.8007 - val_loss: 1.2755 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 38th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2579 - acc: 0.8018 - val_loss: 1.1962 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 38th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2559 - acc: 0.8002 - val_loss: 1.2990 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 38th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3014 - acc: 0.7936 - val_loss: 1.3581 - val_acc: 0.7872\n",
      "[INFO] Training model: epoch 38th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3017 - acc: 0.7940 - val_loss: 1.3193 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 38th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2760 - acc: 0.7999 - val_loss: 1.3117 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 38th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3029 - acc: 0.7943 - val_loss: 1.2952 - val_acc: 0.7970\n",
      "[INFO] Training model: epoch 38th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3216 - acc: 0.7931 - val_loss: 1.3178 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 38th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3107 - acc: 0.7936 - val_loss: 1.3117 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 38th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2771 - acc: 0.7997 - val_loss: 1.2556 - val_acc: 0.8048\n",
      "[INFO] Training model: epoch 38th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3257 - acc: 0.7934 - val_loss: 1.2843 - val_acc: 0.7987\n",
      "[INFO] Training model: epoch 38th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2908 - acc: 0.7973 - val_loss: 1.2313 - val_acc: 0.8048\n",
      "[INFO] Training model: epoch 38th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2879 - acc: 0.7964 - val_loss: 1.2002 - val_acc: 0.8111\n",
      "[INFO] Training model: epoch 38th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2650 - acc: 0.8007 - val_loss: 1.3256 - val_acc: 0.7973\n",
      "[INFO] Training model: epoch 38th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2863 - acc: 0.7998 - val_loss: 1.3812 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 38th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2830 - acc: 0.7980 - val_loss: 1.2681 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 38th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2787 - acc: 0.7992 - val_loss: 1.2869 - val_acc: 0.8017\n",
      "[INFO] Training model: epoch 38th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2863 - acc: 0.7994 - val_loss: 1.2865 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 38th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3174 - acc: 0.7945 - val_loss: 1.3692 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 38th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2895 - acc: 0.7982 - val_loss: 1.3436 - val_acc: 0.7889\n",
      "[INFO] Training model: epoch 38th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3262 - acc: 0.7944 - val_loss: 1.3463 - val_acc: 0.7886\n",
      "[INFO] Training model: epoch 38th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2688 - acc: 0.8021 - val_loss: 1.3281 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 38th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2999 - acc: 0.7986 - val_loss: 1.3295 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 38th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3133 - acc: 0.7952 - val_loss: 1.3132 - val_acc: 0.7966\n",
      "[INFO] Training model: epoch 38th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3373 - acc: 0.7929 - val_loss: 1.2483 - val_acc: 0.8042\n",
      "[INFO] Training model: epoch 38th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3237 - acc: 0.7957 - val_loss: 1.2486 - val_acc: 0.8123\n",
      "[INFO] Training model: epoch 38th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3138 - acc: 0.7962 - val_loss: 1.3492 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 38th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3067 - acc: 0.7979 - val_loss: 1.2911 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 38th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3422 - acc: 0.7941 - val_loss: 1.2498 - val_acc: 0.8073\n",
      "[INFO] Training model: epoch 38th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2929 - acc: 0.7997 - val_loss: 1.3361 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 38th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3071 - acc: 0.7992 - val_loss: 1.3356 - val_acc: 0.7973\n",
      "[INFO] Training model: epoch 38th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3056 - acc: 0.7973 - val_loss: 1.3987 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 38th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3438 - acc: 0.7918 - val_loss: 1.2959 - val_acc: 0.8028\n",
      "[INFO] Training model: epoch 38th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3198 - acc: 0.7951 - val_loss: 1.3605 - val_acc: 0.7911\n",
      "[INFO] Training model: epoch 38th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3298 - acc: 0.7954 - val_loss: 1.2552 - val_acc: 0.8017\n",
      "[INFO] Training model: epoch 38th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2983 - acc: 0.7982 - val_loss: 1.4220 - val_acc: 0.7853\n",
      "[INFO] Training model: epoch 38th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3196 - acc: 0.7973 - val_loss: 1.2943 - val_acc: 0.7975\n",
      "[INFO] Training model: epoch 38th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2836 - acc: 0.8008 - val_loss: 1.3714 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 38th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3003 - acc: 0.7966 - val_loss: 1.2822 - val_acc: 0.8027\n",
      "[INFO] Training model: epoch 38th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3227 - acc: 0.7969 - val_loss: 1.3227 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 38th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3181 - acc: 0.7993 - val_loss: 1.3007 - val_acc: 0.8052\n",
      "[INFO] Training model: epoch 38th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3109 - acc: 0.7987 - val_loss: 1.3492 - val_acc: 0.7908\n",
      "[INFO] Training model: epoch 38th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3130 - acc: 0.7977 - val_loss: 1.3287 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 38th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3604 - acc: 0.7920 - val_loss: 1.2713 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 38th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3283 - acc: 0.7966 - val_loss: 1.3981 - val_acc: 0.7917\n",
      "[INFO] Training model: epoch 38th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3128 - acc: 0.7982 - val_loss: 1.3184 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 38th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3492 - acc: 0.7955 - val_loss: 1.3444 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 39th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2744 - acc: 0.7987 - val_loss: 1.2981 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 39th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2722 - acc: 0.7976 - val_loss: 1.3692 - val_acc: 0.7873\n",
      "[INFO] Training model: epoch 39th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2624 - acc: 0.8009 - val_loss: 1.2788 - val_acc: 0.7978\n",
      "[INFO] Training model: epoch 39th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2617 - acc: 0.7997 - val_loss: 1.2751 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 39th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2695 - acc: 0.7985 - val_loss: 1.2970 - val_acc: 0.7955\n",
      "[INFO] Training model: epoch 39th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2648 - acc: 0.7991 - val_loss: 1.3235 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 39th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2574 - acc: 0.7985 - val_loss: 1.2913 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 39th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2663 - acc: 0.8020 - val_loss: 1.1582 - val_acc: 0.8095\n",
      "[INFO] Training model: epoch 39th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2340 - acc: 0.8028 - val_loss: 1.2733 - val_acc: 0.8033\n",
      "[INFO] Training model: epoch 39th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3045 - acc: 0.7942 - val_loss: 1.2621 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 39th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2802 - acc: 0.7977 - val_loss: 1.2648 - val_acc: 0.8033\n",
      "[INFO] Training model: epoch 39th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2616 - acc: 0.7995 - val_loss: 1.3416 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 39th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2537 - acc: 0.8004 - val_loss: 1.2891 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 39th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3031 - acc: 0.7982 - val_loss: 1.3068 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 39th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3006 - acc: 0.7969 - val_loss: 1.3322 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 39th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2700 - acc: 0.8009 - val_loss: 1.3082 - val_acc: 0.7981\n",
      "[INFO] Training model: epoch 39th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2656 - acc: 0.8016 - val_loss: 1.2904 - val_acc: 0.7972\n",
      "[INFO] Training model: epoch 39th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3132 - acc: 0.7957 - val_loss: 1.3486 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 39th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2653 - acc: 0.8012 - val_loss: 1.3087 - val_acc: 0.7970\n",
      "[INFO] Training model: epoch 39th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2924 - acc: 0.7972 - val_loss: 1.2041 - val_acc: 0.8103\n",
      "[INFO] Training model: epoch 39th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3044 - acc: 0.7986 - val_loss: 1.2804 - val_acc: 0.8022\n",
      "[INFO] Training model: epoch 39th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3421 - acc: 0.7904 - val_loss: 1.2940 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 39th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2671 - acc: 0.8006 - val_loss: 1.3081 - val_acc: 0.7927\n",
      "[INFO] Training model: epoch 39th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2795 - acc: 0.7975 - val_loss: 1.3865 - val_acc: 0.7881\n",
      "[INFO] Training model: epoch 39th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.2935 - acc: 0.7968 - val_loss: 1.2825 - val_acc: 0.7952\n",
      "[INFO] Training model: epoch 39th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2761 - acc: 0.7993 - val_loss: 1.3569 - val_acc: 0.7878\n",
      "[INFO] Training model: epoch 39th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2501 - acc: 0.8044 - val_loss: 1.2876 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 39th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2941 - acc: 0.7995 - val_loss: 1.3201 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 39th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3086 - acc: 0.7977 - val_loss: 1.2976 - val_acc: 0.7964\n",
      "[INFO] Training model: epoch 39th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3067 - acc: 0.7961 - val_loss: 1.3482 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 39th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2614 - acc: 0.8026 - val_loss: 1.2908 - val_acc: 0.8033\n",
      "[INFO] Training model: epoch 39th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3501 - acc: 0.7926 - val_loss: 1.3799 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 39th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2858 - acc: 0.8006 - val_loss: 1.2642 - val_acc: 0.8020\n",
      "[INFO] Training model: epoch 39th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3347 - acc: 0.7939 - val_loss: 1.3459 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 39th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2961 - acc: 0.7998 - val_loss: 1.3621 - val_acc: 0.7939\n",
      "[INFO] Training model: epoch 39th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2785 - acc: 0.8006 - val_loss: 1.2687 - val_acc: 0.8012\n",
      "[INFO] Training model: epoch 39th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3126 - acc: 0.7956 - val_loss: 1.3377 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 39th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3174 - acc: 0.7965 - val_loss: 1.3209 - val_acc: 0.7936\n",
      "[INFO] Training model: epoch 39th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2938 - acc: 0.7989 - val_loss: 1.4106 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 39th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3149 - acc: 0.7976 - val_loss: 1.2186 - val_acc: 0.8120\n",
      "[INFO] Training model: epoch 39th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3388 - acc: 0.7963 - val_loss: 1.2488 - val_acc: 0.8064\n",
      "[INFO] Training model: epoch 39th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3092 - acc: 0.7990 - val_loss: 1.3645 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 39th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3187 - acc: 0.7968 - val_loss: 1.3397 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 39th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3361 - acc: 0.7941 - val_loss: 1.3503 - val_acc: 0.7870\n",
      "[INFO] Training model: epoch 39th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3257 - acc: 0.7980 - val_loss: 1.3426 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 39th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3301 - acc: 0.7942 - val_loss: 1.2109 - val_acc: 0.8064\n",
      "[INFO] Training model: epoch 39th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2900 - acc: 0.7992 - val_loss: 1.3241 - val_acc: 0.7942\n",
      "[INFO] Training model: epoch 39th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3259 - acc: 0.7977 - val_loss: 1.3552 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 39th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3095 - acc: 0.7983 - val_loss: 1.3727 - val_acc: 0.7897\n",
      "[INFO] Training model: epoch 39th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3114 - acc: 0.7961 - val_loss: 1.3000 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 40th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2447 - acc: 0.8002 - val_loss: 1.2547 - val_acc: 0.8006\n",
      "[INFO] Training model: epoch 40th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2209 - acc: 0.8009 - val_loss: 1.2616 - val_acc: 0.7941\n",
      "[INFO] Training model: epoch 40th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2645 - acc: 0.7991 - val_loss: 1.2767 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 40th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2652 - acc: 0.8006 - val_loss: 1.2665 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 40th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2164 - acc: 0.8043 - val_loss: 1.2672 - val_acc: 0.8003\n",
      "[INFO] Training model: epoch 40th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2760 - acc: 0.7959 - val_loss: 1.3200 - val_acc: 0.7962\n",
      "[INFO] Training model: epoch 40th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2603 - acc: 0.7980 - val_loss: 1.2928 - val_acc: 0.7947\n",
      "[INFO] Training model: epoch 40th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2589 - acc: 0.7991 - val_loss: 1.2627 - val_acc: 0.8003\n",
      "[INFO] Training model: epoch 40th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2770 - acc: 0.7962 - val_loss: 1.2579 - val_acc: 0.7994\n",
      "[INFO] Training model: epoch 40th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2862 - acc: 0.7964 - val_loss: 1.3139 - val_acc: 0.7958\n",
      "[INFO] Training model: epoch 40th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2752 - acc: 0.7994 - val_loss: 1.2252 - val_acc: 0.8052\n",
      "[INFO] Training model: epoch 40th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.2156 - acc: 0.8066 - val_loss: 1.3012 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 40th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2102 - acc: 0.8065 - val_loss: 1.3111 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 40th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2658 - acc: 0.7980 - val_loss: 1.2267 - val_acc: 0.8042\n",
      "[INFO] Training model: epoch 40th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2611 - acc: 0.8006 - val_loss: 1.2263 - val_acc: 0.8075\n",
      "[INFO] Training model: epoch 40th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2651 - acc: 0.8016 - val_loss: 1.2797 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 40th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2856 - acc: 0.7959 - val_loss: 1.2871 - val_acc: 0.8033\n",
      "[INFO] Training model: epoch 40th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2794 - acc: 0.7973 - val_loss: 1.2801 - val_acc: 0.7989\n",
      "[INFO] Training model: epoch 40th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2909 - acc: 0.7964 - val_loss: 1.2969 - val_acc: 0.8022\n",
      "[INFO] Training model: epoch 40th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3044 - acc: 0.7945 - val_loss: 1.1529 - val_acc: 0.8169\n",
      "[INFO] Training model: epoch 40th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2948 - acc: 0.7981 - val_loss: 1.2934 - val_acc: 0.7983\n",
      "[INFO] Training model: epoch 40th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3098 - acc: 0.7938 - val_loss: 1.3108 - val_acc: 0.7944\n",
      "[INFO] Training model: epoch 40th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2697 - acc: 0.7990 - val_loss: 1.2858 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 40th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3327 - acc: 0.7945 - val_loss: 1.2867 - val_acc: 0.8011\n",
      "[INFO] Training model: epoch 40th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3023 - acc: 0.7965 - val_loss: 1.2417 - val_acc: 0.8050\n",
      "[INFO] Training model: epoch 40th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.2671 - acc: 0.8010 - val_loss: 1.2551 - val_acc: 0.8045\n",
      "[INFO] Training model: epoch 40th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3265 - acc: 0.7943 - val_loss: 1.3270 - val_acc: 0.7931\n",
      "[INFO] Training model: epoch 40th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3220 - acc: 0.7934 - val_loss: 1.2937 - val_acc: 0.8022\n",
      "[INFO] Training model: epoch 40th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3297 - acc: 0.7940 - val_loss: 1.2682 - val_acc: 0.8014\n",
      "[INFO] Training model: epoch 40th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2557 - acc: 0.8041 - val_loss: 1.1801 - val_acc: 0.8131\n",
      "[INFO] Training model: epoch 40th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3076 - acc: 0.7983 - val_loss: 1.3910 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 40th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3293 - acc: 0.7945 - val_loss: 1.2753 - val_acc: 0.7994\n",
      "[INFO] Training model: epoch 40th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2853 - acc: 0.7973 - val_loss: 1.2576 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 40th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3034 - acc: 0.7968 - val_loss: 1.2636 - val_acc: 0.8041\n",
      "[INFO] Training model: epoch 40th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2996 - acc: 0.7987 - val_loss: 1.3683 - val_acc: 0.7909\n",
      "[INFO] Training model: epoch 40th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3086 - acc: 0.7958 - val_loss: 1.3408 - val_acc: 0.7919\n",
      "[INFO] Training model: epoch 40th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2958 - acc: 0.7974 - val_loss: 1.3726 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 40th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2886 - acc: 0.7983 - val_loss: 1.3542 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 40th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2899 - acc: 0.8002 - val_loss: 1.3146 - val_acc: 0.7970\n",
      "[INFO] Training model: epoch 40th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2977 - acc: 0.7985 - val_loss: 1.3153 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 40th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3135 - acc: 0.7964 - val_loss: 1.3386 - val_acc: 0.7925\n",
      "[INFO] Training model: epoch 40th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3184 - acc: 0.7973 - val_loss: 1.3412 - val_acc: 0.7920\n",
      "[INFO] Training model: epoch 40th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3033 - acc: 0.7981 - val_loss: 1.2350 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 40th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2858 - acc: 0.8002 - val_loss: 1.2676 - val_acc: 0.8067\n",
      "[INFO] Training model: epoch 40th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3053 - acc: 0.7973 - val_loss: 1.3886 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 40th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 1.3094 - acc: 0.7959 - val_loss: 1.3864 - val_acc: 0.7880\n",
      "[INFO] Training model: epoch 40th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2787 - acc: 0.8008 - val_loss: 1.4093 - val_acc: 0.7856\n",
      "[INFO] Training model: epoch 40th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.3254 - acc: 0.7943 - val_loss: 1.3330 - val_acc: 0.7933\n",
      "[INFO] Training model: epoch 40th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.3071 - acc: 0.7987 - val_loss: 1.2976 - val_acc: 0.8025\n",
      "[INFO] Training model: epoch 40th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.2846 - acc: 0.8020 - val_loss: 1.2951 - val_acc: 0.8044\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "#tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./weight/without_attention_weight.hdf5', \n",
    "                             save_weights_only=True, save_best_only=True, monitor='loss')\n",
    "\n",
    "k_start = 1\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # Training 1000 sequences at a time\n",
    "    for i in range(0, len(X), 1000):\n",
    "        if i + 1000 >= len(X):\n",
    "            i_end = len(X)\n",
    "        else:\n",
    "            i_end = i + 1000\n",
    "        y_sequences = process_data(y[i:i_end], y_max_len, y_word_to_ix)\n",
    "\n",
    "        print('[INFO] Training model: epoch {}th {}/{} samples'.format(k, i, len(X)))\n",
    "        #model.fit(X[i:i_end], y_sequences, batch_size=BATCH_SIZE, nb_epoch=1, validation_split=0.1, callbacks=[tensorboard])\n",
    "        model.fit(X[i:i_end], y_sequences, batch_size=BATCH_SIZE, nb_epoch=1, validation_split=0.2, callbacks=[checkpoint])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using Rouge score\n",
    "Now that you have trained the model, load the test data i.e. test_article.txt and corresponding reference titles test_title.txt. Process test_article.txt in the same way as you did your train_article.txt. Then use your model to predict the titles. When you have your model predicted titles, and the reference titles (test_title.txt) calculate the Rouge score corresponding to your predictions. \n",
    "You should install rouge by executing \"pip3 install rouge\". Refer https://pypi.python.org/pypi/rouge/0.2.1 for documentation on how to use the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london stock exchange up at midday\n",
      "london stock exchange up at midday\n",
      "barack robson he to for for\n",
      "rugby of for world\n",
      "UNK 's UNK to to to in in\n",
      "sampras named named with player\n",
      "stocks down in mexico brazil argentina\n",
      "kevin 's to to to to to in in\n",
      "the the of of in\n",
      "armstrong armstrong s pleads to in\n",
      "new to to to to to in in\n",
      "routs voted to to to at the\n",
      "rain team doping for for for\n",
      "<unk> <unk> wins at at at\n",
      "holyfield lewis to in\n",
      "jennifer s to to to\n",
      "UNK 's to to in\n",
      "UNK fires UNK to to for for\n",
      "discounts 's a a for for\n",
      "<unk> 's named as coach as 's coach\n",
      "study of in to to to to in in\n",
      "ronaldo says to to milan milan\n",
      "matthew <unk> wins wins wins receive in at of\n",
      "<unk> 's chief to to to in in\n",
      "olympic of of of of in in in in\n",
      "some care should to to on\n",
      "un court to to to to\n",
      "UNK UNK a can a the\n",
      "UNK ponders the\n",
      "UNK 's UNK to <unk>\n",
      "colts ## cardinals ##\n",
      "boeing to to to to in in\n",
      "dodge 's for for\n",
      "ucla knight to for\n",
      "intel 's to to to of\n",
      "devils 's to to in in\n",
      "britney co-founder to to for for\n",
      "UNK 's UNK to UNK\n",
      "deschamps fires leaves to to\n",
      "audi bancshares buy buy for $\n",
      "<unk> <unk> <unk> <unk> <unk> <unk>\n",
      "UNK 's UNK to for\n",
      "webb wins for at\n",
      "lemieux defenseman named out to to weeks weeks\n",
      "UNK cyclist to to to to to in\n",
      "shields 's a for for\n",
      "UNK UNK wins wins wins award award\n",
      "knicks and nets to to to to\n",
      "UNK 's UNK to to in\n",
      "london 's ftse-### index up\n",
      "devils scores loves in in\n",
      "UNK 's to to in in world cup\n",
      "## kills in in in in in\n",
      "UNK <unk> <unk> <unk> <unk> for\n",
      "<unk> the the the of UNK\n",
      "alicia housewives to to to of of\n",
      "stocks up in mexico brazil argentina ; in\n",
      "UNK of of UNK to in in in\n",
      "armstrong williams to hoya at award award\n",
      "<unk> 's UNK UNK of UNK\n",
      "UNK named as of of coach\n",
      "UNK signs joins UNK loan from\n",
      "panthers sign defenseman <unk>\n",
      "klitschko 's to to in him\n",
      "UNK 's for for\n",
      "<unk> 's is the the the <unk>\n",
      "experts 's in to to to to to to for\n",
      "london stock exchange up at midday\n",
      "UNK to for <unk>\n",
      "woods woods to woods to at\n",
      "knicks 's is is is the the\n",
      "<unk> the the the of the\n",
      "<unk> named named as as coach coach coach\n",
      "ruiz 's to to but to the\n",
      "UNK 's UNK to to in in\n",
      "boeing airlines says # # boeing to\n",
      "lebron says to to to to\n",
      "UNK UNK UNK in in in\n",
      "former court to guilty to for for\n",
      "nissan 's to to for for\n",
      "webb UNK UNK receive at\n",
      "UNK wins wins at at\n",
      "sundance of UNK UNK in\n",
      "canucks duncan named selanne named to to coach\n",
      "strong earthquake hits southern\n",
      "us inflation rate falls in\n",
      "gold prices fall as as dollar dollar\n",
      "delta 's to to to in in in\n",
      "pepperdine gets to to the\n",
      "matthew s wife wife mtv birth to in\n",
      "commonwealth wins rhythmic gymnastics\n",
      "results wins gold gold at at\n",
      "UNK s to to to in in at at at\n",
      "woods woods to to at\n",
      "making the can for the the\n",
      "commonwealth to to host for host olympics\n",
      "exhibit of of to to to to of\n",
      "nasa spacecraft files nasa launch for for\n",
      "china 's lawmakers meets 's to to to\n",
      "explosion explosion in injures\n",
      "jazz actor actor UNK dies dies at ##\n",
      "gordon 's to to to in\n",
      "former soviet minister dies dies\n",
      "australia to to for world world cup cup\n",
      "india to to to to to in\n",
      "clinton democrats to in republicans republicans a a to to a\n",
      "a 's of a a a to of of\n",
      "UNK wins out out at at open\n",
      "results cup championship results\n",
      "kuznetsova to to to in at at at at at\n",
      "us troops in in of in in\n",
      "china beats oman #-# at world cup qualifier\n",
      "UNK of workers in in in in\n",
      "olympic torch to to to to to to beijing\n",
      "mourinho says he to to to next\n",
      "UNK 's to to to in\n",
      "the funds for business\n",
      "roddick withdraws withdraws from open\n",
      "evidence wants to sue for in\n",
      "ronaldo to play out in in in\n",
      "tokyo stocks higher dollar higher against yen\n",
      "springsteen 's to to to UNK\n",
      "olympic president president president to to to in in president president\n",
      "france 's to to on world world world world world\n",
      "lemieux scores to to to to to to over\n",
      "rob 's to to the the the the the the\n",
      "els wins to to the at at at at at\n",
      "canada 's central rates rates\n",
      "UNK 's UNK in in\n",
      "tokyo stocks slip dollar higher against yen\n",
      "nbc 's a to to the the\n",
      "phelps 's hoya to to to to to to at\n",
      "UNK 's UNK to to to to of\n",
      "mccain house to to on on\n",
      "UNK to to to to to in in\n",
      "UNK of of in in in\n",
      "UNK suspends doping positive for\n",
      "new reports flu in in\n",
      "twilight 's to chosen to UNK\n",
      "author of of to to to to UNK\n",
      "police police to fights in in\n",
      "phillips 's for the\n",
      "phelps waits to to to in in\n",
      "london stock exchange up at midday\n",
      "us of would to to to in in\n",
      "flamengo hires as coach for for\n",
      "<unk> 's the the of of the the\n",
      "UNK 's the at\n",
      "sao defends to of of in\n",
      "cuba to host for #### ####\n",
      "what the is a a a the\n",
      "ucla trojans for ucla\n",
      "tokyo stocks higher dollar higher against yen\n",
      "UNK 's to in\n",
      "london 's exchange up up midday\n",
      "mauresmo withdraws for wimbledon wimbledon\n",
      "former president president president to run in\n",
      "new senate passes sites in in in\n",
      "jennifer sues to simpson on\n",
      "<unk> named named as to with team\n",
      "safin says to to to at for the\n",
      "london 's prices index up\n",
      "beijing president leaves leaves visit to\n",
      "gore to to to to china\n",
      "shuttle to to space for space\n",
      "phelps 's to to to to to to to world cup\n",
      "beijing to to to to to to\n",
      "UNK cultures to to to in in in\n",
      "UNK of novelist in in in in\n",
      "wall street on as as as as\n",
      "woods woods to woods to at\n",
      "grizzlies ## cardinals #\n",
      "israeli police kill in in in\n",
      "<unk> night UNK in UNK\n",
      "brazil to play for in in\n",
      "flamengo hires as as coach coach\n",
      "police ship UNK strike in in\n",
      "china 's new UNK\n",
      "former singer says birth to birth birth to in\n",
      "us jersey to to to on\n",
      "pope 's for to to to to to to for\n",
      "UNK 's is the the the the the\n",
      "armstrong says to hoya to to in at\n",
      "bush 's clinton to to bush to to to\n",
      "agassi williams to to in wimbledon\n",
      "springsteen shines for graf\n",
      "UNK the the the the\n",
      "u.s. s to to to for for for to in\n",
      "UNK 's a to to in\n",
      "us says to to to to to in\n",
      "england players to to euro euro to in in world\n",
      "UNK 's the the the the the the\n",
      "rob stewart to to a to to the the\n",
      "perry bacon to to in at in\n",
      "bush 's to to to in\n",
      "a the the the the the the the\n",
      "janet 's to to to on\n",
      "UNK 's UNK for in\n",
      "UNK 's to to to in in\n",
      "larsson to to to to to with\n",
      "south africa to to to to to in in in\n",
      "founder 's of to to to to of\n",
      "london 's exchange index up ##.##\n",
      "dolphins recall <unk> <unk>\n",
      "pamela mcconaughey says he to iphone in\n",
      "sao shines to on in cup cup\n",
      "couple born of to to in UNK\n",
      "bayern robson he to to for next\n",
      "ajax beats valencia #-# #-# in league\n",
      "UNK 's UNK to to the\n",
      "<unk> the the the of of UNK\n",
      "kobe hernandez to to for\n",
      "UNK UNK UNK to to\n",
      "singh overcomes to to to for at at\n",
      "UNK wins to at at at title\n",
      "singh wins daytona to at cup title\n",
      "euro slide on dollar dollar dollar\n",
      "thai pm minister says he to to\n",
      "simpson 's says to to to to to to\n",
      "obama 's to to to for obama\n",
      "key parties to to to in in\n",
      "<unk> of of of 's 's\n",
      "sao named as as coach\n",
      "a the of of of of the the\n",
      "spain to to to in world cup cup\n",
      "world organizers to to for #### ####\n",
      "treasury prices in in\n",
      "united to to to to to in in\n",
      "UNK hilton to to to to baby\n",
      "bayern davies to to to to to the\n",
      "australia ## england ##-##\n",
      "london 's exchange up up points\n",
      "israeli army to to to in in\n",
      "fossett 's 's to his to to to in in\n",
      "UNK <unk> <unk> writer at at\n",
      "twilight 's to on fame fame fame\n",
      "UNK of at to to in in\n",
      "schumacher says one-year to to to\n",
      "woods woods to woods to at the\n",
      "northridge 's to play in in in\n",
      "UNK 's to ### in in in\n",
      "UNK wins wins marathon at sprint\n",
      "rain suspends retirement in in\n",
      "patrick williams to receive receive in\n",
      "german inflation rate rate\n",
      "albania and #-# #-# #-# in\n",
      "cowboys is for cowboys\n",
      "england beats england #\n",
      "lindsay lohan released to jail for\n",
      "nasa sues to simpson for for in\n",
      "judge court in in in in\n",
      "sampras murray to to open masters injury\n",
      "<unk> <unk> <unk> to to to in\n",
      "london 's ftse-### index up ## points at at close\n",
      "safin says to to wimbledon wimbledon wimbledon wimbledon\n",
      "UNK 's to to to to for the\n",
      "india to to to to nuclear\n",
      "ajax beats #-# #-# #-# in #-#\n",
      "tips cooking for the\n",
      "former parliament chief to resign to\n",
      "bush 's for 's to in in\n",
      "UNK 's for at in\n",
      "lyon to manchester to on in in to cup cup\n",
      "former <unk> <unk> <unk> <unk> <unk> dies dies at ##\n",
      "hbo 's to to to <unk>\n",
      "former <unk> <unk> <unk> dies at ##\n",
      "former gibson former wife UNK divorce divorce in in\n",
      "UNK wins nordic combined\n",
      "eritrea government to to to to\n",
      "results wins biathlon cup biathlon\n",
      "UNK <unk> ## wins awards\n",
      "UNK wins to for at at at classic\n",
      "chrysler 's to to to for in\n",
      "ohio tech ray to to to in in\n",
      "ronaldo says schumacher to to\n",
      "#-##-## 's in to to to in in in\n",
      "greece to deficit for\n",
      "UNK 's UNK to in\n",
      "former cyclist champ banned for for\n",
      "UNK signs <unk> joins contract for\n",
      "recession to to to for for chrysler\n",
      "UNK UNK a a in in in\n",
      "UNK 's UNK for for\n",
      "UNK bull to box-office for for ####\n",
      "no. 's coach to to # #\n",
      "stocks down in mexico brazil argentina\n",
      "brazil coach hoya to cup for in\n",
      "moderate earthquake shakes tokyo turkey\n",
      "rhodes 's to to to on\n",
      "no. # notre ## ## ##\n",
      "mets re-sign re-sign <unk> <unk> injured\n",
      "mcgwire 's to to in\n",
      "thousands of on to to in in in\n",
      "yankees and yankees to to\n",
      "us s to to to for to for in\n",
      "judge of s to to to to in\n",
      "knicks sox to to to to the\n",
      "<unk> 's 's of of UNK\n",
      "<unk> bowl for <unk>\n",
      "duval wins to at at at\n",
      "bucs shines for\n",
      "cowboys release release\n",
      "UNK 's for ##-##\n",
      "forgiving grown-ups for halloween\n",
      "bush 's of bush bush bush to to to to\n",
      "mavericks ## chargers #\n",
      "the 's game to to to to to to the\n",
      "in 's in to to in to in in in\n",
      "no. state to to in state\n",
      "bush 's on on\n",
      "yankees and to to to to in\n",
      "UNK to UNK for for\n",
      "UNK 's UNK the at <unk>\n",
      "britney says to to to for to ##m\n",
      "holyfield sent for for\n",
      "it broncos a a to for for for\n",
      "giants mets to to to to\n",
      "devils hope to to to in in in\n",
      "agassi wants for for\n",
      "a your for the the\n",
      "film <unk> UNK to to UNK\n",
      "explosion explosion in in in in\n",
      "<unk> recipe for the\n",
      "agassi davies to for at\n",
      "perry pulling to to to in\n",
      "a 's a a is of of UNK\n",
      "simpson sues simpson simpson simpson to to UNK\n",
      "mccain mccain mccain mccain to on on mccain\n",
      "ayala wants for to wimbledon\n",
      "world of of of in in in in\n",
      "braves ## UNK\n",
      "devils 's to to to in in\n",
      "a the the the the the the the the the the\n",
      "london 's prices in\n",
      "london share prices lower\n",
      "o'neal o'neal to to for for\n",
      "sonics 's to to to\n",
      "maddux sanders to to to\n",
      "gordon gets to to in\n",
      "panthers hire hire hire as coach coach\n",
      "dodgers sign for ##-##\n",
      "astros sanders to to to to to\n",
      "raiders lifts for angels\n",
      "devils sox yankees to to in in in\n",
      "columnist 's UNK the\n",
      "flower is for the\n",
      "a 's in to to to to to to for\n",
      "analysts chairman to to to to in in in\n",
      "f# to to to to in in\n",
      "nadal williams to at open open\n",
      "a olympics the of of of\n",
      "shuttle shuttle shuttle space for space\n",
      "UNK paulo named at of of\n",
      "lemieux says to to to to to season season\n",
      "pearl of to to to in\n",
      "angels smoltz angels for\n",
      "new of of halloween in\n",
      "UNK 's for at\n",
      "ripken 's to to for\n",
      "klitschko 's to to to to to to to\n",
      "devils beat to to to in in\n",
      "boeing airlines orders boeing to to to\n",
      "hbo 's UNK to to to the\n",
      "UNK 's UNK on the\n",
      "clemens williams yankees to to in\n",
      "court serbs to to to to to to to\n",
      "a 's the the the the the the the the the the the\n",
      "woods mets to to to to\n",
      "astronauts banned to to for\n",
      "agassi williams for\n",
      "webb williams for at at\n",
      "<unk> <unk> <unk> en <unk> film\n",
      "malone delivers for for\n",
      "broncos are to to to to\n",
      "no. state to to to in\n",
      "chiefs have to to for\n",
      "UNK wins sbc at\n",
      "buchanan bacon to to to to the\n",
      "angels fargas angels for for\n",
      "how to to for\n",
      "webb wins for at\n",
      "panthers hire hire to\n",
      "couples 's to at at\n",
      "ripken 's to to to on\n",
      "youtube to to stake for\n",
      "cowboys is to to in\n",
      "usc 's UNK to to to <unk>\n",
      "ucla jackets to to to game\n",
      "explosion explosion in in\n",
      "jimenez wins wins at at\n",
      "UNK wins wins world at title\n",
      "south to play south in in in\n",
      "it 's a to to the the the\n",
      "UNK 's UNK to to in in\n",
      "UNK <unk> <unk> poet dies at\n",
      "UNK 's 's a the the the the of of\n",
      "a 's a a a a a a in\n",
      "crist 's to to to for\n",
      "olmert 's to to to to to to\n",
      "tanzanian president visit parliament\n",
      "jimenez wins pole at title\n",
      "gremio beats armenia #-# in in league\n",
      "when 's a a a a a the the\n",
      "judge judge to to to in in\n",
      "giambi sinatra a a but for\n",
      "in is of museum a a of the\n",
      "sao paulo UNK as of in\n",
      "world to cup to world world in\n",
      "UNK hilton hoya receive to for\n",
      "tottenham signs brazilian UNK UNK\n",
      "former playwright player dies dies at\n",
      "england to to to to for to world cup\n",
      "safin to to out at at\n",
      "johnson 's to to to in\n",
      "UNK koeman <unk> named to as new coach\n",
      "UNK 's sure at at at\n",
      "rain banned to banned for for doping\n",
      "mickelson busch to to the at at\n",
      "agassi williams to to at\n",
      "rockies bowl a for for for\n",
      "bush 's bush\n",
      "dole 's to to to on\n",
      "UNK wins for at at classic\n",
      "former president president president to to to in term\n",
      "norstrom 's UNK <unk>\n",
      "california of of in in in in in in\n",
      "german 's interest rates interest\n",
      "share prices close higher\n",
      "sorenstam 's to in in\n",
      "corn corn corn corn\n",
      "michael stewart to to to to the the\n",
      "UNK to to to in ## to million million million\n",
      "parcells hire coach to\n",
      "dodgers lose to to in\n",
      "UNK <unk> <unk> poet at at\n",
      "former president president <unk> dies at\n",
      "a to can the\n",
      "tokyo stocks lower midday dollar against against yen\n",
      "former <unk> <unk> <unk> <unk> dies at ##\n",
      "arsenal united to to to to to to arsenal\n",
      "euro trades against dollar #.#### in\n",
      "a the of of of the of\n",
      "london 's ftse-### index up ## points at at close close\n",
      "judge fraud to gun of UNK\n",
      "tottenham signs UNK three-year three-year on from\n",
      "small plane crashes in in in\n",
      "tottenham signs brazilian UNK from from\n",
      "ac milan sign from\n",
      "barcelona signs to to to to to on\n",
      "UNK 's the the the the\n",
      "turin marks UNK in\n",
      "coyotes sign forward UNK\n",
      "germans 's to to to world world cup\n",
      "a york of the a a a a in in\n",
      "UNK says to to to to in in\n",
      "<unk> 's of as as in in in of\n",
      "# to to to dollars in\n",
      "mourinho says he to to for everton\n",
      "australian developments ratings\n",
      "usc 's to to to to\n",
      "author 's of a of of of UNK\n",
      "crude oil prices fall\n",
      "<unk> the the the the the\n",
      "UNK bowl a for for\n",
      "<unk> <unk> the the of the <unk>\n",
      "UNK ivy to to of the the\n",
      "kings beat ducks to\n",
      "UNK 's is is but the the the\n",
      "ripken all-star for all-star\n",
      "holyfield roberts to accuses for\n",
      "devils devils devils to in\n",
      "mets 's to to to to to the\n",
      "london share prices lower at\n",
      "kevin bacon he to to to to to in in\n",
      "britney spears he he to for for\n",
      "sao names UNK in cup cup\n",
      "fossett 's to to to to to in\n",
      "police police of tons in in in\n",
      "real madrid sign joins\n",
      "roma sign joins on\n",
      "buchanan starr to to to to in in\n",
      "microsoft may to to for for UNK\n",
      "<unk> 's the the of UNK\n",
      "bruins 's to to to to\n",
      "UNK companies to to to for for\n",
      "robin williams to receive expecting divorce\n",
      "bush senate passes on on\n",
      "deschamps replaces named to of\n",
      "clinton 's in to to to to in 's with\n",
      "denise leads wins to to to to\n",
      "man to to to to\n",
      "midfielder striker to to to to to to loan\n",
      "sarah jackson harvey to to to in in\n",
      "chelsea signs signs striker striker loan on from loan loan loan\n",
      "bush 's on UNK\n",
      "# killed killed in in\n",
      "spain to to for to in in\n",
      "armstrong armstrong hoya hoya for tour for at\n",
      "world of world in at\n",
      "us senate to to on in\n",
      "UNK is to all for\n",
      "the 's to in in in in\n",
      "UNK gets to to to to in world cup\n",
      "vikings release hire on\n",
      "red sox UNK to\n",
      "ford earns to cut in in\n",
      "mets sign mets to\n",
      "brazilian economy deficit record in\n",
      "UNK <unk> gop presidential\n",
      "lakers sign lakers #-#\n",
      "braves release UNK to\n",
      "yankees ca yankees to to\n",
      "willie is for for\n",
      "willie sinatra is is the\n",
      "knicks and yankees to to to to the\n",
      "galaxy hire hire as as as coach\n",
      "a the of a of of the\n",
      "police police find bodies at in in in\n",
      "UNK 's to to to at at ryder\n",
      "timeline of of zoo of in\n",
      "the women the of the of of of\n",
      "china coach hoya to for for for\n",
      "UNK carolina the 's of to in in\n",
      "draw to to world cup cup cup\n",
      "share prices close higher\n",
      "larsson says to play to play the in\n",
      "pepperdine 's UNK to in\n",
      "the of of of of\n",
      "UNK of of to to to 's 's\n",
      "UNK UNK UNK in of in\n",
      "kuwait stock exchange index\n",
      "thai stock exchange ends\n",
      "shenzhen stock exchange index\n",
      "thai stock exchange #.##\n",
      "international hosts opens opens opens in\n",
      "thai stock exchange #.##\n",
      "UNK 's to in in in\n",
      "UNK 's UNK to in in in\n",
      "UNK hosts of solar to to in\n",
      "new tree UNK to to in\n",
      "australian dollar ends to\n",
      "google to to to for for for\n",
      "kerry is a to to to in in\n",
      "bush 's to to to to to\n",
      "UNK 's UNK to to to to of\n",
      "dole should on on in\n",
      "police police UNK UNK in in\n",
      "jennifer singer singer article in in\n",
      "UNK UNK the the\n",
      "UNK 's the the the\n",
      "UNK schools UNK UNK\n",
      "<unk> your for for the\n",
      "northridge says to to to to to in\n",
      "UNK of of of in in\n",
      "UNK to to to to to to to to in\n",
      "selig 's for for for\n",
      "microsoft to to carry for for to\n",
      "a of a the of of\n",
      "beijing to urged protect to in in\n",
      "UNK 's to to to for for\n",
      "ventura 's UNK for UNK\n",
      "doctors to to to to on\n",
      "how your of of the the the\n",
      "the <unk> of of the\n",
      "us says surging to to to to to\n",
      "UNK 's a to the the the\n",
      "<unk> the the the the the\n",
      "how the for for the the\n",
      "UNK 's for for for\n",
      "the 's of of the the to to to in the\n",
      "UNK 's UNK to to\n",
      "study 's to to for for for for\n",
      "paint salad to n't the for the\n",
      "bush bush to bush bush bush to bush\n",
      "simpsons 's the the\n",
      "the the of of the the of\n",
      "the your for the UNK\n",
      "u.s. campaign to to to to in\n",
      "UNK 's 's to to to to in in\n",
      "UNK 's UNK UNK to UNK\n",
      "google to to is on\n",
      "the the of of the\n",
      "toyota s to to for for for for in\n",
      "UNK night for the the\n",
      "the the of of the the\n",
      "us senate on on to on on\n",
      "gore chinese of of a a to in\n",
      "UNK <unk> <unk> to to in in\n",
      "us says to import to to\n",
      "UNK chief to to to in in\n",
      "UNK 's the the the\n",
      "arafat of UNK to in\n",
      "clinton clinton clinton to to in in in\n",
      "UNK magazines for the\n",
      "chrysler s $ $ $ $ $ $ $\n",
      "study UNK UNK emerge in in\n",
      "parents is iphone a to of children\n",
      "UNK the for the\n",
      "it 's a a to for for\n",
      "seeing of to to in in in\n",
      "experts treasure to to to to to to to\n",
      "the the of the the the the the\n",
      "when to to to to to the\n",
      "UNK 's to to to the the the\n",
      "UNK musician of b. in\n",
      "johnson 's to to to to to to the\n",
      "new york in to to to in the\n",
      "us to new to\n",
      "<unk> 's <unk> <unk>\n",
      "it the the the the the to the the\n",
      "UNK UNK UNK a of in of\n",
      "<unk> 's is the the the of the\n",
      "a UNK of of of\n",
      "un calls to to to to\n",
      "<unk> me is for for for\n",
      "the the of of the the the\n",
      "study is a to to in in UNK\n",
      "obama 's to to to to to\n",
      "UNK UNK UNK in in UNK\n",
      "the me of the the\n",
      "in of in to to to to of of\n",
      "UNK 's a the the UNK\n",
      "we 's to to to to to of of\n",
      "delta 's to to in in in\n",
      "brazil stocks fall to in\n",
      "UNK funds prices on on\n",
      "gators 's to to to in for\n",
      "UNK 's of to to to to to 's\n",
      "dole house clinton on on on\n",
      "there 's a a a a a a a the\n",
      "simpsons 's a the the\n",
      "the the for in the\n",
      "UNK the for the the\n",
      "UNK 's toned the the\n",
      "UNK remake UNK for UNK\n",
      "UNK 's UNK to to the UNK\n",
      "a the the to to the the\n",
      "how to to to in in\n",
      "a 's a a a a to the the\n",
      "the me of the UNK\n",
      "jimmy 's UNK to for\n",
      "us 's times to in in in\n",
      "<unk> your for for\n",
      "bruins recall <unk> <unk>\n",
      "barbecue is is a the the\n",
      "study of of of of of in in in\n",
      "contains 's to to to the of of of\n",
      "springsteen shines UNK UNK\n",
      "the the traveling for the\n",
      "safin says to to to to in at\n",
      "the the of of of UNK\n",
      "it 's a a for for for\n",
      "bush 's to to in in in in\n",
      "UNK 's UNK to to of\n",
      "bush 's obama <unk>\n",
      "it should to be for\n",
      "a 's crowd to to a in in in\n",
      "a the can for the the\n",
      "UNK of UNK in in in\n",
      "new of on on on in in\n",
      "willie 's a to for for\n",
      "boeing to urged to to in\n",
      "mccain mccain to to to on on on\n",
      "the the the the the the the\n",
      "writer-director sinatra is to to\n",
      "the the the of of the\n",
      "glenn 's a the for the\n",
      "the <unk> of the\n",
      "writer-director sinatra 's the to the UNK\n",
      "deer is for for\n",
      "how salad is for for for UNK\n",
      "<unk> <unk> <unk> of of UNK\n",
      "<unk> 's 's the to the the\n",
      "UNK UNK to to in in\n",
      "UNK the a the the the\n",
      "how to can for the the\n",
      "nissan to to to for for\n",
      "mccain mccain mccain to to to to for\n",
      "whiff of of to to in in in in in\n",
      "study finds to to to in in\n",
      "obama obama obama obama to to obama\n",
      "microsoft to to to as on #q\n",
      "boeing 's to to to in in in in\n",
      "UNK 's 's UNK to to to in of in\n",
      "UNK has has surgery surgery surgery\n",
      "UNK of of gun in in in\n",
      "elderly is of UNK in in\n",
      "a the of a the to the\n",
      "UNK UNK to in\n",
      "a 's a a of to of of\n",
      "analysts 's to to to in\n",
      "bush 's obama obama for obama\n",
      "hollywood jovi in in in in in in in in in in\n",
      "new senate passes to in in\n",
      "dole says she she a a a a a\n",
      "UNK 's to to at at\n",
      "fossett 's 's to to to to in in the the the\n",
      "the your for the\n",
      "former says says says to to to in in in\n",
      "UNK the for the the\n",
      "nissan 's to for for\n",
      "betty the recipe\n",
      "UNK gets to at at at at at\n",
      "microsoft &amp; to for for for for for\n",
      "cowboys mets to to cowboys\n",
      "the the of of of the\n",
      "dodgers lose to to to for\n",
      "a the of a a a a the\n",
      "UNK <unk> UNK UNK\n",
      "barbecue is is a the to the\n",
      "recession of of in in in in\n",
      "brazil shifts gave to to for\n",
      "springsteen settles UNK to UNK\n",
      "the the of the the the the\n",
      "UNK your the\n",
      "obama 's obama obama to to to for\n",
      "<unk> me is the the UNK\n",
      "springsteen UNK in UNK\n",
      "UNK 's the the the the\n",
      "UNK says to to to to to to to\n",
      "california 's UNK in in in\n",
      "divac 's to to for\n",
      "cowboys 's to to to for\n",
      "<unk> 's for for the the\n",
      "dodgers ca to to in in\n",
      "celtics get celtics to to\n",
      "UNK is to to to to to\n",
      "the 's 's to to to to to to to to\n",
      "<unk> me is the the the the\n",
      "UNK 's is the the the the\n",
      "bruins named named as coach\n",
      "UNK 's the is to the the\n",
      "patriots is to for for\n",
      "astronauts to to to to to to to\n",
      "<unk> 's for the\n",
      "mets mets mets to to\n",
      "dodgers need to to to to\n",
      "mavericks ## mavericks #\n",
      "UNK 's of birth of birth to of\n",
      "when is is a but in the UNK\n",
      "nissan foods to for for\n",
      "cowboys smith to to to to\n",
      "a 's 's the on UNK\n",
      "UNK <unk> UNK to to in UNK\n",
      "usc nelson a to to for the\n",
      "holocaust of of of UNK in of\n",
      "UNK to to to to for in in\n",
      "new funds to to to for for\n",
      "<unk> <unk> to the the the at at\n",
      "the <unk> for the the\n",
      "michael jackson to receive expecting nominees awards\n",
      "how UNK for for UNK\n",
      "new of of to in in\n",
      "nbc 's is a for for\n",
      "duval overcomes to for at\n",
      "how to can can a to the\n",
      "chinese to to to to to in\n",
      "it 's the the the the is the the the the\n",
      "knicks hope to to to to to\n",
      "boeing to to to to to to in\n",
      "UNK owners to to to in in\n",
      "glenn 's to to to on\n",
      "california of oks in in\n",
      "toledo 's to to to to to to\n",
      "<unk> 's of a the the <unk>\n",
      "phelps wins aim at at at\n",
      "olympiakos killed killed during car\n",
      "grammy UNK 's receive to to in\n",
      "in york in to to to in in\n",
      "a 's is the\n",
      "UNK 's a for for\n",
      "UNK UNK UNK for in\n",
      "nbc 's to to to to to to in\n",
      "webb renews to to\n",
      "UNK UNK for the UNK\n",
      "UNK of on a in in\n",
      "it 's a a you to for\n",
      "UNK UNK in in in\n",
      "UNK 's a to for for\n",
      "barkley says to to to for\n",
      "UNK 's UNK to in in\n",
      "UNK 's <unk> UNK UNK\n",
      "webb wins wins to at at at giro\n",
      "UNK UNK UNK in in UNK\n",
      "<unk> the the the the the the\n",
      "the is of of of UNK\n",
      "aging 's 's to to to to in\n",
      "bruins have to for\n",
      "ucla 's to to to in\n",
      "holyfield 's to to to in\n",
      "a 's UNK to to to of\n",
      "how to can can a the\n",
      "<unk> 's the the the UNK\n",
      "judge lawyers of to of of in in\n",
      "if 's is a the the a the the\n",
      "mavericks sox yankees to to\n",
      "UNK 's to to UNK\n",
      "a the of of of the the the\n",
      "jets manning to for\n",
      "the the of <unk>\n",
      "billy 's is to to the to the in\n",
      "sonics agree to to to deal\n",
      "a of of of of in\n",
      "UNK 's UNK to the the\n",
      "a a a a a a a in\n",
      "willie accepts <unk>\n",
      "ucla 's to to to to in\n",
      "UNK UNK UNK in in in the\n",
      "UNK 's for in\n",
      "some to can to to to\n",
      "<unk> 's to to the the\n",
      "UNK of of to to in in\n",
      "UNK 's the the the the the the the\n",
      "how to a a to to a\n",
      "it 's a a the the the the the the\n",
      "gebrselassie sherpa to to to in in in\n",
      "experts 's to to to in in in\n",
      "holyfield sticking to to in\n",
      "selig 's for for for\n",
      "UNK 's UNK to to the\n",
      "northridge 's to to to to in in\n",
      "hbo 's to to to to the\n",
      "johnson wins for for at at\n",
      "helicopters of ruins in in in in in\n",
      "UNK 's UNK to to the UNK\n",
      "UNK UNK the\n",
      "UNK of UNK gun in in\n",
      "the bowl a a the the the\n",
      "dodgers rout dodgers dodgers\n",
      "UNK mount to to in\n",
      "UNK UNK sue in\n",
      "UNK 's for for in\n",
      "when 's is the the the the the\n",
      "i to to for\n",
      "clinton 's to on\n",
      "a the the the the the the the the\n",
      "UNK 's to to to to to to a the\n",
      "cox news service service budget\n",
      "braves have for for\n",
      "ankiel 's to to to game\n",
      "UNK state to to in in\n",
      "a s doping <unk> <unk> <unk> to in in <unk>\n",
      "a UNK of of of UNK\n",
      "<unk> 's is the the the the the\n",
      "safin says to to to at at at\n",
      "kings devils to to in in\n",
      "broncos broncos aikman to to to\n",
      "scientists of UNK UNK of in in UNK\n",
      "p &amp; to to to to to to to\n",
      "a the the the the the the the the\n",
      "malone 's to to for\n",
      "holyfield is to in\n",
      "dolphins ## seahawks ##\n",
      "UNK s says says to to to to in\n",
      "france cup to to world world world world cup\n",
      "beijing of beijing to to to to in china\n",
      "UNK 's UNK to the\n",
      "UNK 's to to to in\n",
      "oh betty is a the the\n",
      "northridge 's to to to to in\n",
      "selig 's to to in the\n",
      "bucs is a to to the\n",
      "weighing your for <unk>\n",
      "yankees lose to to to to\n",
      "a york of the of a a the of\n",
      "key of of of of in in\n",
      "the the for for the the\n",
      "celtics sox to to to to\n",
      "bulls 's to to to to to to to for the\n",
      "mets mets mets to\n",
      "goldman 's to to for for for for\n",
      "ramadan 's UNK to to in in UNK\n",
      "why 's for for for\n",
      "twa celebrates names for in\n",
      "UNK reigns for for\n",
      "study 's UNK UNK in in\n",
      "UNK 's the the the\n",
      "UNK the a to to in in\n",
      "parton nearing a to for for\n",
      "bush 's obama obama to to to to\n",
      "when is is a the the the\n",
      "ucla 's for in\n",
      "UNK 's UNK UNK\n",
      "mavericks sox to to to to to\n",
      "a 's of a a of of the\n",
      "a 's 's a a a a of of\n",
      "pepperdine 's for in\n",
      "#-##-## schools UNK to to in UNK\n",
      "<unk> of of the of the the\n",
      "UNK recipe for for the\n",
      "UNK 's a to to to the\n",
      "for 's the the the the the the the the the the\n",
      "cowboys jets to cowboys\n",
      "UNK 's UNK to to in in in\n",
      "UNK <unk> UNK UNK to to of UNK\n",
      "<unk> 's 's <unk>\n",
      "UNK 's on to to for\n",
      "clinton clinton on on on on\n",
      "us stock stock ### in for in in in in\n",
      "how to is on\n",
      "UNK 's to to to the the the\n",
      "mcgwire yanks to for\n",
      "ripken says to to to for for\n",
      "bruins 's to to to in in\n",
      "woods woods to to woods\n",
      "UNK 's 's to the the the at\n",
      "cowboys 's to to to to to\n",
      "UNK 's <unk> <unk>\n",
      "tips recipe for the\n",
      "no. need to to to in\n",
      "ucla ivy to to in\n",
      "a for a a a a a a a of the\n",
      "bush 's on bush\n",
      "nbc 's to to to for\n",
      "the the of of the\n",
      "UNK 's to to to of\n",
      "UNK 's 's 's to of of\n",
      "it 's a the the the the the the the\n",
      "UNK 's 's to to to the\n",
      "UNK shines for <unk>\n",
      "UNK 's UNK to to of\n",
      "UNK looms UNK to to in\n",
      "UNK night for the\n",
      "stewart smoltz offense in\n",
      "UNK the the the the\n",
      "UNK fargas to to to in\n",
      "it 's is to the the to in in in\n",
      "UNK 's a to in the\n",
      "china kong of 's 's 's 's 's\n",
      "tips to to to for for\n",
      "mets mets mets to to to to\n",
      "the <unk> of of the\n",
      "UNK baylor for to\n",
      "a the of the of the the\n",
      "UNK UNK UNK for of <unk>\n",
      "UNK to to to UNK\n",
      "gore of of to to in in\n",
      "UNK 's UNK to to in in the\n",
      "bruins hope to to to in to\n",
      "clippers ## aikman\n",
      "satellite 's to to in in in\n",
      "for 's a a to for for\n",
      "cowboys tries to to for for\n",
      "how 's is on\n",
      "tips to for\n",
      "microsoft to buy profit #q #q\n",
      "kings sox to to to to\n",
      "willie 's a the for\n",
      "celtics stop celtics ###-##\n",
      "UNK 's UNK to to to in in\n",
      "rangers 's to to in in to in\n",
      "<unk> 's the the the\n",
      "a 's is to to is to in in\n",
      "UNK 's UNK at in at\n",
      "no. ## oklahoma ##\n",
      "the 's is the the UNK\n",
      "angels bats for angels\n",
      "a the to a a a the\n",
      "UNK UNK UNK UNK\n",
      "<unk> 's 's to to to to in of <unk>\n",
      "wall street stock n't a of\n",
      "safety is your\n",
      "roberts kicker for n.y.\n",
      "a the of of of the the the\n",
      "california 's UNK UNK in in\n",
      "weir 's to to to to to to to to the\n",
      "UNK 's for ryder in ryder cup cup\n",
      "grizzlies sox to to to for\n",
      "UNK 's to to to in\n",
      "UNK born of of of in in\n",
      "woods woods to woods to woods\n",
      "coyotes sign defenseman <unk> <unk>\n",
      "UNK 's to to to to to to in\n",
      "ventura 's to for\n",
      "a of of a in in\n",
      "new #,###.## UNK battle of in in\n",
      "new york to to in in in\n",
      "clinton 's to on on\n",
      "UNK UNK on for in in\n",
      "new of of in in in\n",
      "a the to a a a the\n",
      "it 's is is for for for\n",
      "wallace says to to to to to to\n",
      "UNK 's UNK the the UNK\n",
      "the the of of to\n",
      "giants giants to to to to to to\n",
      "a of a a of in in in\n",
      "stocks 's of in in in\n",
      "dole democrats to to republicans to in in\n",
      "advance for a to of a a a a for of\n",
      "mavericks beat to to\n",
      "the the for for the the\n",
      "UNK of UNK in in in\n",
      "a follows picasso bush on bush on\n",
      "tips your for chocolate\n",
      "UNK generation UNK to to in\n",
      "giants giants to of of\n",
      "how to can for the\n",
      "duval overcomes to to to at the\n",
      "hbo 's <unk> the with for the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ducks 's to to to\n",
      "man man in of of of of of in\n",
      "UNK <unk> skating at at\n",
      "lemieux hire named to to player\n",
      "grizzlies forward selanne named to to to for\n",
      "smoltz 's to to to for\n",
      "knoblauch has to in\n",
      "rep. simpson to to to to to to of\n",
      "UNK takes UNK tour award\n",
      "a the to to to\n",
      "UNK bowl a for for\n",
      "baseball owners to to to in in\n",
      "cowboys cowboys to to on to\n",
      "us fraud of of of of to in in\n",
      "some companies to to on\n",
      "taiwan korea find on on\n",
      "police police seize in in\n",
      "the the the the\n",
      "study may UNK pose to in in\n",
      "study 's a to to to to of of\n",
      "webb voted UNK at at\n",
      "a 's the the the the the the the the\n",
      "nbc 's ratings ratings\n",
      "karl qb to to to to for\n",
      "singh overcomes to to to in in\n",
      "a agreements in in of a in in\n",
      "UNK of of UNK to in in in\n",
      "UNK 's on on on\n",
      "the the the the of the\n",
      "glenn 's the the <unk>\n",
      "mavericks 's to to to to to\n",
      "UNK 's to to to in in in\n",
      "buchanan 's to to for\n",
      "woman of of of of of in\n",
      "loud delays salaries\n",
      "baseball owners to to to to in\n",
      "mickelson 's to but but to for\n",
      "the <unk> of of the\n",
      "us says to on on on in\n",
      "UNK 's 's <unk>\n",
      "giants giants to giants to\n",
      "UNK the for the\n",
      "google to to for for\n",
      "UNK UNK predict UNK\n",
      "pets 's a a of of of of\n",
      "UNK 's UNK to in <unk>\n",
      "UNK 's to to to to to to the the\n",
      "holyfield 's a for\n",
      "broncos broncos to to to to to to to\n",
      "nissan to to for UNK\n",
      "bucs fargas to to for\n",
      "how to for for the the\n",
      "holyfield 's to to to the\n",
      "<unk> the the the the\n",
      "a years of a a a a in\n",
      "us to to to to to to to to of of\n",
      "a 's 's a of a to of of\n",
      "bush 's to on on on on\n",
      "study sopranos a to to a to to in\n",
      "UNK wins wins to to to to in in at\n",
      "selanne gets to to to in\n",
      "a york in in in a a the a the the\n",
      "dodgers mets dodgers dodgers dodgers\n",
      "finding of a UNK in in UNK\n",
      "UNK wins for at at\n",
      "sonics # to to to\n",
      "UNK 're the to to the the\n",
      "ucla smoltz offense for\n",
      "scientists 's UNK to to in of\n",
      "UNK UNK UNK UNK in\n",
      "woods rockies to for for\n",
      "norstrom 's to in\n",
      "raiders is angels for bucs\n",
      "the budget to the on\n",
      "no. ## no. st. ## ## ##\n",
      "reba stewart is is to on\n",
      "UNK UNK UNK to in in in\n",
      "UNK 's in to to in in the of\n",
      "UNK 's to to to in cup\n",
      "forgiving grown-ups for for\n",
      "how to for a the the\n",
      "the the of of of UNK\n",
      "census to on for for\n",
      "school of of gun in in\n",
      "it 's a the the the the the the\n",
      "residents workers develops in in\n",
      "a of of of 's 's 's 's 's <unk>\n",
      "no. 's gets to\n",
      "obama 's obama to to for in\n",
      "UNK UNK UNK for in\n",
      "clinton says clinton on to to in in\n",
      "dodgers sox dodgers to rangers\n",
      "sarah jovi says to to to to to in\n",
      "UNK 's UNK on to UNK\n",
      "a 're in the the a the the\n",
      "UNK <unk> UNK to in in\n",
      "yankees get n't to to to\n",
      "UNK of of of of in in in\n",
      "UNK the the\n",
      "<unk> your for for\n",
      "<unk> 's a of of of UNK\n",
      "former <unk> <unk> <unk> dies at at ##\n",
      "the recipe of the\n",
      "UNK discover UNK to to to in UNK\n",
      "schilling 's to to to for\n",
      "study to a to to to for\n",
      "UNK schools for the\n",
      "us nations to to to to to to to in\n",
      "devils devils notre ##\n",
      "sonics bruins to to\n",
      "selig 's a a for for\n",
      "UNK 's the the UNK\n",
      "oprah says jay-z to to to in in\n",
      "UNK 's a to to to of UNK\n",
      "els 's to to to the to to the the\n",
      "UNK <unk> UNK for in <unk>\n",
      "anderson relishes a a for the\n",
      "hurricanes scores to to to to to to in\n",
      "the the of the the the the the\n",
      "UNK UNK UNK to in\n",
      "<unk> 's the the the <unk>\n",
      "microsoft to for for\n",
      "<unk> <unk> <unk> of <unk>\n",
      "my chocolate is is is but the the\n",
      "a the to to to to to the\n",
      "cowboys cowboys aikman to to to to\n",
      "judge of UNK in in in in\n",
      "UNK a&amp;m to to to to in in\n",
      "the the for the the\n",
      "giants giants to to to to\n",
      "glenn 's UNK the for UNK\n",
      "northridge ## notre ##\n",
      "heisman 's <unk> at\n",
      "selanne hire named to with\n",
      "in years in to to a to to in for\n",
      "cowboys cowboys cowboys for\n",
      "gold 's #q as as as as oil oil\n",
      "henin hingis he to to for\n",
      "sonics agree to to to to to\n",
      "UNK UNK UNK the in the\n",
      "mets sign mets to to\n",
      "UNK UNK UNK UNK in in\n",
      "celtics get to to\n",
      "france 's to to world world world world world world cup\n",
      "holyfield is to to in\n",
      "harvard 's 's to to to to in in\n",
      "some 's is a a a the\n",
      "kings need to to to to\n",
      "aikman shines for his\n",
      "a york of the the the the\n",
      "<unk> finds to to to to to\n",
      "glenn 's to to to the\n",
      "hbo 's 's to to <unk>\n",
      "a of of of a of of UNK\n",
      "janet 's is to of of UNK\n",
      "UNK 's a the the the the\n",
      "us 's defend to to for in for\n",
      "how to a to in in UNK\n",
      "UNK trojans for for\n",
      "klitschko 's to to to to the\n",
      "judge of UNK to in in UNK\n",
      "bruins fires hire coach\n",
      "mets 's to to to in\n",
      "the the fascinating for the the\n",
      "no. st. 's to to ## st.\n",
      "boeing to to to to to to\n",
      "a is of of of UNK of of of\n",
      "after 's crowd to to to to in in\n",
      "study finds to pose to for UNK\n",
      "pepperdine 's to to to game\n",
      "jennifer grown-ups iphone for\n",
      "UNK switches in at in\n",
      "yankees ## yankees to\n",
      "we 's to to to in of the\n",
      "stocks street in reflects to as in in\n",
      "UNK 's a to to to for\n",
      "ucla 's for to to game\n",
      "census UNK transplants\n",
      "exhibit UNK UNK UNK UNK\n",
      "revolution owners to to to\n",
      "UNK 's UNK the to\n",
      "<unk> <unk> of of UNK\n",
      "the UNK is the the UNK\n",
      "ethics wars secrets id in in\n",
      "UNK 's UNK to in the\n",
      "a 's of in in a in the the\n",
      "a the of for the the\n",
      "UNK lies UNK UNK\n",
      "giants mets to to for\n",
      "galaxy says he to to to to for\n",
      "UNK 's is the the the the the\n",
      "parcells fargas to to for for\n",
      "UNK UNK UNK in in\n",
      "the <unk> <unk> <unk>\n",
      "<unk> <unk> <unk> <unk> to to to in\n",
      "selanne 's to to to to in\n",
      "UNK state to to\n",
      "UNK is for for\n",
      "<unk> of ### marathon short-course\n",
      "no. ## no. ## ## ##\n",
      "study finds to to to to to for\n",
      "a the of the the the\n",
      "if 's a the the the the the the\n",
      "UNK 's to to for\n",
      "UNK ponders\n",
      "it 's the the the the the the\n",
      "the season\n",
      "riley ewing ewing to he to to to to for\n",
      "hugh <unk> <unk> star of birth at at\n",
      "armstrong s de de de de de tour tour tour tour france\n",
      "giuliani of laborers of of in in in\n",
      "UNK is for the\n",
      "toyota 's to to to for in\n",
      "tips the wear\n",
      "a <unk> <unk> 's of\n",
      "in york of in in in in of of of\n",
      "how to can for to\n",
      "dolphins fires hire as arbitration\n",
      "mickelson gets to at at classic\n",
      "<unk> 's the for the the\n",
      "UNK 's UNK for in\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "microsoft &amp; to to to for to for for\n",
      "o.j. clooney to to to to of UNK\n",
      "in years in a a a a a a a\n",
      "malone sent to for for\n",
      "UNK wins win gold at at at\n",
      "mets mets mets to to to\n",
      "mavericks sox to to to to\n",
      "lemieux says to to to to to in\n",
      "<unk> bowl a for for\n",
      "delta 's to to to in in in\n",
      "mary 's 's the to for UNK\n",
      "ucla 's on for in\n",
      "UNK 's UNK the the UNK\n",
      "this finals for for for\n",
      "crist 's to for for\n",
      "how companies is column of of\n",
      "intel 's on in in\n",
      "UNK UNK UNK the UNK\n",
      "england cup to to to cup to cup cup cup\n",
      "the attraction of <unk>\n",
      "no. ## no. ## ##\n",
      "new of would fields in in in\n",
      "it 's a the the the the the the\n",
      "webb UNK UNK receive to at in\n",
      "it 's a a for for for\n",
      "making the wines for the\n",
      "a of of to of a in in\n",
      "in power in in in in in in in with with\n",
      "UNK 's for UNK\n",
      "no. state for to\n",
      "UNK of UNK UNK UNK in UNK\n",
      "<unk> watching of to of UNK\n",
      "UNK assistant UNK UNK in in\n",
      "cowboys proves to to to to the\n",
      "us prices fall in ##\n",
      "UNK stewart UNK to to the the the\n",
      "UNK 's on to in\n",
      "ventura 's UNK to to in the\n",
      "raiders is for for\n",
      "rockies 's a the for for\n",
      "a the a a to a of the\n",
      "how the can for the the\n",
      "UNK 's 's the with UNK\n",
      "UNK 's to to to in\n",
      "ripken says to to to to in\n",
      "ucla 's for in ##-##\n",
      "ucla 's to to in the\n",
      "actor 's UNK to to in\n",
      "woods mets to to to to\n",
      "the UNK for of in\n",
      "author 's of to to to to of in\n",
      "a 's of the the the the\n",
      "after 's to to to to to to in\n",
      "UNK finds uses UNK in in UNK\n",
      "china 's chinese to to to to in\n",
      "a ethics of a a a in of\n",
      "bonds defense to to to\n",
      "bruins defense to to\n",
      "i 's is to to the the the\n",
      "hillary 's of to to to to 's 's UNK\n",
      "knicks have nets to to\n",
      "gators 's to to to in\n",
      "holyfield is for in\n",
      "mls UNK to to for for\n",
      "mavericks sox mavericks to\n",
      "how UNK is for UNK\n",
      "the the of the the the\n",
      "a 's the 's the the the the the\n",
      "saddam of of of of of in in\n",
      "the the the the the the the the the\n",
      "UNK 's to to to for\n",
      "<unk> 's 's to to to to in of\n",
      "chronology of to UNK\n",
      "mcenroe 's to in in\n",
      "<unk> the for for the\n",
      "mavericks rout to to to\n",
      "kings beat kings kings\n",
      "canadian inflation inflation #.# percent in\n",
      "mccain campaign mccain to on\n",
      "panel of sue in in in\n",
      "some the to to to a a the\n",
      "some the a to to a a the\n",
      "UNK of of of of in in in\n",
      "mavericks sox to to to to in\n",
      "yankees yanks to to in\n",
      "new of method in in in in\n",
      "bush 's to to to in\n",
      "revolution need to for for\n",
      "cowboys mets mets cowboys\n",
      "a 's of of of a to the\n",
      "UNK 's UNK to to the the\n",
      "UNK gets to to at at\n",
      "UNK UNK player player for in\n",
      "a 's a a a a a a a\n",
      "UNK of a UNK of in\n",
      "after <unk> her to to to to in\n",
      "<unk> the tops to the the\n",
      "klitschko 's to to to in in\n",
      "jets broncos to to to to to to to\n",
      "rangers beat rangers #-#\n",
      "ucla 's a to to to in the\n",
      "anderson is for in\n",
      "UNK schools UNK for in in\n",
      "<unk> <unk> the the of the of UNK\n",
      "a a a in in in\n",
      "dow stocks stocks as as in prices\n",
      "mickelson 's to to of the the at\n",
      "bruins need to for\n",
      "wimbledon to formula to to f#\n",
      "a 's a a of of of UNK\n",
      "bush of on bush bush bush\n",
      "the the of of the the\n",
      "how your for the\n",
      "UNK the to the the\n",
      "gingrich steal ruins to to in in in\n",
      "mets sign to to\n",
      "mavericks # ducks to\n",
      "mickelson 's to but to to for the\n",
      "UNK is a giants\n",
      "wall the stock a the of the\n",
      "UNK ivy UNK to to in in\n",
      "a 's a a a a to to in the\n",
      "twitter ratings ratings profits\n",
      "UNK 's the to of <unk>\n",
      "UNK 's aim to to at at\n",
      "o.j. of in to in in in\n",
      "celtics sign agree to terms\n",
      "clinton clinton to to clinton of in\n",
      "pepperdine robinson to in UNK\n",
      "toyota 's to crisis in for in in\n",
      "mickelson gets to to to to the\n",
      "UNK 's UNK the in\n",
      "UNK agreements to to to in in\n",
      "i should to all for for\n",
      "UNK <unk> UNK for in\n",
      "angels mets dodgers to to in\n",
      "UNK 's a for for\n",
      "UNK emerges UNK to in in\n",
      "mets mets mets to to to to\n",
      "the the can a the the\n",
      "UNK of of to of of in\n",
      "a 's the the of the the the the\n",
      "michigan 's to in in\n",
      "<unk> the the the the\n",
      "dodgers 's to for for\n",
      "kings sox to ###-### to\n",
      "ripken says he to to to to in\n",
      "UNK 's to to to in in in in\n",
      "sometimes 's is a the the\n",
      "celtics lose to to to to to to\n",
      "UNK of would to to in in in\n",
      "study to a a a a a UNK\n",
      "google to to to for for for\n",
      "brazil 's to to to for in in in\n",
      "UNK manning to to for for for\n",
      "i 's is the the the\n",
      "a years in in in a in in in in in\n",
      "mavericks 's to to to in\n",
      "<unk> <unk> <unk> <unk> <unk> dies\n",
      "the the of of of UNK\n",
      "bucs fargas a to for\n",
      "gore 's to to to to to in in\n",
      "<unk> recipe of the UNK\n",
      "UNK your to to\n",
      "a 's a a a the a the of\n",
      "how the for for the UNK\n",
      "recession of to to in in in\n",
      "UNK the the\n",
      "judge of crime to in in in\n",
      "mcgwire 's to to to to in\n",
      "klitschko 's he to to to in in\n",
      "yankees proves yankees yankees to to the\n",
      "a the a the the the the the\n",
      "a is of a in UNK\n",
      "safin safin to at wimbledon\n",
      "prime-time ratings ratings for\n",
      "it 's a a to for for for\n",
      "a is of a of in in in\n",
      "tips 's to to be for the\n",
      "treasury prices fall as stocks of\n",
      "UNK 's a to for for\n",
      "UNK 's for ##\n",
      "a 's 's the to to to the\n",
      "<unk> 's for the\n",
      "scientists to to to to to in in\n",
      "ucla 's to to state\n",
      "judge 's of to to to to in\n",
      "UNK need to be for for\n",
      "rangers need to to in in\n",
      "UNK 's a to for for\n",
      "why 's for for the <unk>\n",
      "tyson 's to to to to to for\n",
      "hbo 's UNK to to to of of\n",
      "patriots need to a for for\n",
      "UNK the the of of the\n",
      "alicia hefner 's to to to to the\n",
      "list of emerges UNK of in in\n",
      "a women the to of the the\n",
      "how to for for the the\n",
      "UNK 's to to in in\n",
      "cowboys need cowboys cowboys\n",
      "dodgers bats for dodgers\n",
      "study to to column to to to in\n",
      "holyfield 's to to to in\n",
      "UNK bowl a a for\n",
      "a 's 's the the the the the the\n",
      "hbo 's UNK to to new\n",
      "tour banned to banned to to for\n",
      "raiders fargas angels for cowboys\n",
      "a 's the to to to to in in in\n",
      "dow stock market stock in early\n",
      "if 's is to to be be to to the\n",
      "rodriguez fargas on for for\n",
      "sprewell 's to to to to\n",
      "china 's to to to for in\n",
      "if 's a to to to to to the\n",
      "a UNK for in the\n",
      "phelps 's to receive to at in\n",
      "study victim of gun in in UNK\n",
      "former coach to to to to to to to\n",
      "UNK 's to to in in\n",
      "the the of for the for\n",
      "intel 's stock a a on\n",
      "dodgers mets dodgers dodgers\n",
      "california 's oks in in in\n",
      "a the of the the the the the\n",
      "former 's to to to to to in in\n",
      "UNK 's the the the cup\n",
      "serena williams williams williams to biscayne\n",
      "UNK 's a a for for\n",
      "a UNK in in in\n",
      "it 's is the is the the the the the\n",
      "the the of for the\n",
      "woods manning to to for\n",
      "UNK 's a for for\n",
      "anderson 's a to to for\n",
      "how companies to can to the\n",
      "u.s. 's to to to to to in in in\n",
      "we salad to for for for\n",
      "UNK owners is to to the\n",
      "UNK of of of in in\n",
      "a the of of of of\n",
      "pearl UNK madoff macy\n",
      "weighing the is is of the\n",
      "parton bacon to to for\n",
      "janet bacon to to on\n",
      "angels ca n't to to the\n",
      "a the of the of the the the\n",
      "UNK companies to to in in\n",
      "toyota to spend to for for for in\n",
      "holyfield stewart to to the the\n",
      "when is is the is the the\n",
      "UNK of a a to in in\n",
      "angels sign dodgers for\n",
      "los angeles daily news\n",
      "sorenstam 's to to in\n",
      "it 's the the the the the the the\n",
      "UNK dame to to to in cup\n",
      "a 's 's the the the UNK\n",
      "lemieux says to to to to in\n",
      "a the of of of of\n",
      "UNK 's for at\n",
      "UNK 's UNK the UNK\n",
      "us to to to to to\n",
      "UNK 's is the UNK UNK\n",
      "the <unk> of of of\n",
      "rockies bowl a for\n",
      "UNK is to for for\n",
      "lakers beat lakers to to\n",
      "<unk> 's is is the the the\n",
      "a band of a a a a a a\n",
      "in UNK UNK to in in\n",
      "UNK 's to to for for\n",
      "<unk> 's the the the UNK\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "gore discover UNK in in\n",
      "how your is a the the UNK\n",
      "ford to to strike #q\n",
      "china of of to to in for in\n",
      "a 's is on UNK UNK\n",
      "alternative 's a to for UNK\n",
      "UNK health to to to to for\n",
      "UNK tips for for\n",
      "UNK 's of of of in in in\n",
      "UNK 's UNK in in\n",
      "UNK ivy a to to\n",
      "#-##-## 's UNK to to the\n",
      "UNK schools UNK in in in\n",
      "UNK 's for UNK\n",
      "yankees hernandez yankees to to\n",
      "the bowl a the to to the\n",
      "bigger wins pa.\n",
      "dodgers mets mets #-#\n",
      "<unk> ## 's to to to to in in\n",
      "UNK 's to to to in the\n",
      "nbc 's a to to the the the\n",
      "oprah 's to to to to in\n",
      "UNK 's UNK to to to in in\n",
      "shrek 's UNK to to <unk>\n",
      "thousands of of of of in in\n",
      "the the of of\n",
      "UNK 's to to of at at\n",
      "advance 's in to to to to in to for contributed\n",
      "ucla 's hat to in game\n",
      "UNK <unk> 's his to to to the\n",
      "duval overcomes to to to at the\n",
      "a the the the the for\n",
      "a 's a the the the the the\n",
      "<unk> funds vow to to to to\n",
      "usc 's to to to for the\n",
      "knicks 's to to to in in\n",
      "palin s harvey to to to to of\n",
      "UNK says says says to to\n",
      "notre dame to to in in\n",
      "usc 's to to to to for\n",
      "woods woods to woods\n",
      "UNK gets to at at at hall\n",
      "willie hernandez UNK to to to the\n",
      "paint salad is is the to the\n",
      "sorenstam 's to to to in in\n",
      "world cup world world\n",
      "a players to to to be in in in\n",
      "<unk> 's is the for for\n",
      "mcgwire 's to to in\n",
      "mets mets mets to to to the\n",
      "<unk> <unk> of <unk>\n",
      "knicks 's knicks to to to to in\n",
      "UNK ponders for the\n",
      "#-##-## 's a to to the the UNK\n",
      "selig 's a for for\n",
      "us gas to to a as as for wall\n",
      "devils 's notre to in\n",
      "UNK of of of the\n",
      "sabatini named with sean\n",
      "the 's is the the UNK\n",
      "andretti 's to to to to in in\n",
      "ramadan 's a to to of of in\n",
      "UNK 's of to to to to UNK\n",
      "intel 's on a the\n",
      "advance 's a to to a a a in for\n",
      "cowboys have cowboys to to to to\n",
      "UNK 's UNK to to the\n",
      "UNK fargas to for in in\n",
      "a is of a of of of UNK\n",
      "UNK 's UNK <unk>\n",
      "for 's a a to to to\n",
      "a UNK of of of in of\n",
      "UNK 's UNK in in in\n",
      "<unk> the UNK UNK of in\n",
      "mets mets mets to to to to\n",
      "<unk> <unk> <unk> receive <unk> in in in of of\n",
      "UNK a the a a a to the the\n",
      "giants mets to to to to to\n",
      "a the of to the the the\n",
      "a 's sunday the the the a a a a the\n",
      "a the the the the the the the\n",
      "china to to to to for in\n",
      "brazil 's to to to to to in in in\n",
      "nissan 's to to in for\n",
      "the the the the of the the the\n",
      "UNK 's UNK the UNK\n",
      "the the of of of UNK\n",
      "the 's the of the the the the the\n",
      "UNK of to of of in\n",
      "UNK 's for at\n",
      "a is of a a a in of of\n",
      "<unk> 's president to to to to to <unk> <unk>\n",
      "UNK to to to to to to to world\n",
      "UNK 's to to to in in in\n",
      "holyfield 's to to in in\n",
      "cowboys fargas to to to to the\n",
      "a the of a of of of\n",
      "UNK 's UNK in in in\n",
      "ucla 's for in ucla\n",
      "UNK the UNK the the UNK\n",
      "kings ## cardinals ##\n",
      "rockies 's a to to to for\n",
      "<unk> the the the <unk>\n",
      "ucla fits to to to in\n",
      "harvick gets to at at at\n",
      "hbo 's 's to to to in UNK\n",
      "ethiopia workers to to in\n",
      "a clinton of in of bush a the in the\n",
      "usc 's a to to for\n",
      "UNK upholds UNK in in in in\n",
      "the 's the of the the the the the the\n",
      "sorenstam 's to in in derby\n",
      "hbo 's to to to to in in\n",
      "gore of on to to in in\n",
      "in practices a a in in the\n",
      "a the the the of the the the\n",
      "in york of to a of in in\n",
      "UNK 's for <unk>\n",
      "how to on UNK\n",
      "chrysler says buy ### to for to for\n",
      "the the of of the the\n",
      "UNK 's 's to to to to in\n",
      "german stock exchange exchange\n",
      "australian stock market rises\n",
      "international becomes development in in\n",
      "## kill ore in in china china\n",
      "china 's president vice-premier workshop\n",
      "russia 's to UNK\n",
      "un 's new talks to\n",
      "england lead #-# #-# in\n",
      "beijing of on of opens in in in\n",
      "australian dollar closes higher\n",
      "chinext index opens lower monday\n",
      "south korea to to to to\n",
      "chinext index opens lower lower\n",
      "chinext index opens lower lower\n",
      "dollar trades at mid-### yen in\n",
      "dollar trades narrowly to yen yen tokyo\n",
      "dollar trades at lower ## in tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "crude futures futures on\n",
      "dollar trades at lower yen yen in tokyo\n",
      "#-##-## 's a to to to of UNK\n",
      "beijing to to to to to in in\n",
      "kuala lumpur stocks close lower\n",
      "bulgarian stock market ends higher\n",
      "german stocks open higher\n",
      "german stocks open higher\n",
      "german stocks open higher\n",
      "nikkei closes #.## pct higher\n",
      "dollar trades at mid-### yen in tokyo\n",
      "tanzanian president leaves visit for for\n",
      "london stock exchange london stock\n",
      "international conference on opens opens in\n",
      "china 's of 's 's 's 's 's\n",
      "new expressway in in guangdong\n",
      "UNK of summit in\n",
      "new zealand sharemarket closes new\n",
      "crude prices decline on u.s.\n",
      "jakarta stocks close close\n",
      "london stock exchange closed for\n",
      "UNK 's to on in\n",
      "kuala lumpur stocks close lower\n",
      "beijing UNK province railway\n",
      "china developments related to swine strikes\n",
      "beijing hosts national meeting opens in\n",
      "united 's to to to to in world\n",
      "china <unk> on in in in in\n",
      "sri lankan says # in\n",
      "gold industry in in in in in\n",
      "china stock market closed for for\n",
      "ecb main reference exchange rates\n",
      "dollar trades at lower yen yen in tokyo\n",
      "german stocks exchange higher\n",
      "us reports prices #.# percent in in\n",
      "dollar trades at lower yen yen in\n",
      "dollar trades at lower yen in tokyo\n",
      "australian stock market rises\n",
      "australian dollar closes higher\n",
      "brazil to to to to to to cup cup cup\n",
      "court court to to of\n",
      "u.s. stocks end mixed\n",
      "beijing to to to to in in games\n",
      "dollar down in upper ## yen range tokyo\n",
      "german stocks open higher\n",
      "china shares open #.## on on on\n",
      "bulgarian stock market ends higher higher\n",
      "dollar down to upper yen yen in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "beijing to to on on\n",
      "wall street stocks end mixed\n",
      "dollar trades mid-### mid-### yen in\n",
      "xinhua home news advisory march\n",
      "oil futures fall fall\n",
      "dollar trades at lower yen in in\n",
      "dollar trades at ## yen in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "european stocks end #.##\n",
      "## killed in in in in\n",
      "dollar trades lower lower ## in tokyo\n",
      "s. korean shares close flat\n",
      "u.s. stocks trade mixed\n",
      "kuala lumpur stocks close lower\n",
      "bush 's of 's bush bush bush bush\n",
      "german stock reference exchange rates\n",
      "flamengo named as coach coach\n",
      "uganda 's UNK parliament\n",
      "china 's to to to for in china\n",
      "dollar down in upper ## yen in tokyo\n",
      "dollar trades at lower ## yen in\n",
      "dollar remains at lower ## yen in\n",
      "dollar trades lower lower yen in tokyo\n",
      "chinese shares close up on on on\n",
      "dollar remains at lower ## yen range\n",
      "dollar trades at lower ## in tokyo\n",
      "iran leads china #-# in women soccer soccer\n",
      "china 's to coal to 's 's in\n",
      "south africa to UNK to in\n",
      "sri prime minister minister\n",
      "australian dollar closes higher\n",
      "ecb main reference exchange rates\n",
      "chinese chinese leaves for arrives in\n",
      "malaysian 's president to to to to\n",
      "australian dollar closes higher\n",
      "chinese photo photo fair in in\n",
      "international international fair opens opens in\n",
      "the <unk> of the the\n",
      "dollar trades at ## yen in tokyo\n",
      "five killed in in in\n",
      "yankees release chargers to\n",
      "s. korean stocks bourse\n",
      "u.s. stocks open lower\n",
      "u.s. stocks fall as as on\n",
      "dollar remains at lower ## yen range\n",
      "dollar trades lower lower yen in tokyo\n",
      "stocks close higher in mexico brazil\n",
      "dollar trades lower ## yen in tokyo\n",
      "bulgarian stock market ends higher higher\n",
      "pope to to cooperate cooperation cooperation\n",
      "new senate in war in in in\n",
      "us military secretary in in iraq\n",
      "wall street stocks end mixed\n",
      "us stocks stocks end mixed\n",
      "ecb main exchange exchange rates\n",
      "johannesburg stocks close to\n",
      "# killed in in in in\n",
      "UNK goal UNK easy serie serie\n",
      "dollar at at upper yen yen in tokyo\n",
      "chinext index opens lower wednesday\n",
      "dollar trades in upper ## yen in tokyo\n",
      "beijing to to to to in in\n",
      "flamengo withdraws from in soccer soccer\n",
      "UNK of at in of in in in\n",
      "strong earthquake hits southern\n",
      "international conference film opens opens in in\n",
      "myanmar to hold talks on\n",
      "a of of 's in in in\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar trades at lower yen in tokyo\n",
      "dollar remains at lower ## yen range\n",
      "ronaldo to to for for\n",
      "dollar trades at mid-### yen in tokyo\n",
      "brazil to to in\n",
      "china promotes first UNK\n",
      "world of for ####\n",
      "australian dollar closes higher\n",
      "spain holds #-# #-# #-# in\n",
      "australian dollar closes higher\n",
      "pakistan to to to to to\n",
      "mexico lead mexico #-#\n",
      "kuala lumpur stocks close lower\n",
      "a women the women the the cup\n",
      "johannesburg stock exchange index\n",
      "dollar trades at lower ## yen in\n",
      "nikkei opens #.## higher\n",
      "bulgarian stock market ends higher higher\n",
      "malaysian 's to UNK\n",
      "two kill lawmaker killed in\n",
      "world cup cup #### to world for in cup\n",
      "dollar trades at lower yen yen in\n",
      "taiwan stocks fall lower on\n",
      "un secretary military in\n",
      "chinese chinese to to to to to in\n",
      "china to to for for cup\n",
      "iran beats china #-# in\n",
      "s. korean shares close higher\n",
      "chinext index opens lower friday\n",
      "chinext index opens lower friday\n",
      "beijing 's build to for in\n",
      "china 's first of of in\n",
      "jakarta stocks close lower\n",
      "u.s. stocks trade higher\n",
      "greece front in in\n",
      "former former and <unk> dies at ##\n",
      "china beats china 's 's 's 's\n",
      "germany wins biathlon jump team\n",
      "china wins wins women 's #x###m #x###m gold\n",
      "ucla 's to to in in\n",
      "u.s. stocks end mixed\n",
      "dollar trades at lower yen yen in tokyo\n",
      "italy israel sign sign agreement agreement\n",
      "china 's to market securities\n",
      "beijing 's build railway to in in\n",
      "dollar down in upper ## yen in tokyo\n",
      "brazil stocks end #.##\n",
      "dollar remains at lower ## yen in tokyo\n",
      "foreign exchange rates in new\n",
      "hong kong shares close #.## percent\n",
      "hong kong shares close #.## percent\n",
      "hong kong close close close percent\n",
      "china 's china of in in in\n",
      "bulgarian stock market ends higher higher\n",
      "u.s. stocks end mixed\n",
      "chinext index opens lower friday\n",
      "chinext index opens lower friday\n",
      "corn 's treasury bond\n",
      "beijing to on to held held in\n",
      "UNK 's UNK UNK in\n",
      "hong kong share prices close kong\n",
      "malaysia korean sign trade agreements agreements\n",
      "dollar trades at mid-### yen in tokyo\n",
      "china 's boost reform\n",
      "cuba to to to to #### ####\n",
      "jakarta stocks end lower\n",
      "shenzhen b-share market down at wednesday close\n",
      "dollar trades at mid-### yen in\n",
      "dollar remains in lower ## yen range\n",
      "stocks close higher in brazil brazil\n",
      "dollar trades at ## yen in tokyo\n",
      "dollar remains at lower ## yen range tokyo\n",
      "dollar trades at lower yen in tokyo\n",
      "dollar trades at mid-### yen in\n",
      "china 's market market for\n",
      "stocks close higher in brazil brazil\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar trades in upper ## yen in tokyo\n",
      "nikkei opens #.## lower pct\n",
      "dollar down in upper ## yen range tokyo\n",
      "hong kong stocks close #.## pct\n",
      "johannesburg stock exchange rates\n",
      "australian stock market closes higher\n",
      "giuliani 's decides to to to to to 's in\n",
      "south korea sign agreement agreements\n",
      "dollar trades at upper yen yen in tokyo\n",
      "two kill kill killed in in\n",
      "stocks mixed in early trading\n",
      "cameroon beats colombia #-# in world cup qualifier\n",
      "palestinians police UNK in in\n",
      "australian dollar closes higher\n",
      "UNK powers for for\n",
      "seminar on on economic on\n",
      "chinese shares close #.## pct on trade trade\n",
      "dollar remains in lower ## yen range\n",
      "dollar trades at lower yen in in\n",
      "australian dollar closes higher\n",
      "australia to to to to in in\n",
      "new zealand stocks close higher\n",
      "pope president to visit for\n",
      "bangladesh 's hold parliament\n",
      "UNK to about in in\n",
      "dollar down in upper ## yen range tokyo\n",
      "UNK festival opens opens opens\n",
      "hong kong shares fall hong percent\n",
      "court court UNK to to to\n",
      "beijing process of to to at in in\n",
      "australian dollar closes higher\n",
      "australian stock market closes\n",
      "police stabbed found in in in\n",
      "chinese trade fair opens in\n",
      "russia 's stock markets buick #.# percent\n",
      "tunisia beats armenia #-# in cup\n",
      "us military crashes in in\n",
      "factbox wins wins motorcycle cycle\n",
      "dollar trades at mid-### yen in\n",
      "UNK UNK UNK in in in\n",
      "real draws #-# #-# #-#\n",
      "s. korean main bourse down on\n",
      "devils sox notre #\n",
      "german stocks open higher\n",
      "crude prices decline on\n",
      "dollar trades at to yen in tokyo\n",
      "london stock exchange up stock midday\n",
      "german stocks exchange higher\n",
      "s. korean stock markets\n",
      "stocks close higher in mexico brazil\n",
      "london stock exchange ends higher\n",
      "us senate to to\n",
      "chinese shares open #.## pct on on\n",
      "german stocks open higher\n",
      "german stock exchange exchange\n",
      "chrysler s schedule bank #.# $ in billion\n",
      "nigeria to to host #### host games\n",
      "ajax beats to #-# #-# in\n",
      "police police seize tons in in in\n",
      "dollar trades at lower ## yen in\n",
      "dollar trades at lower ## yen in tokyo\n",
      "china china china operational guangdong\n",
      "wall street opens lower on\n",
      "dollar trades vs. to yen in\n",
      "dollar falls lower lower lower yen yen\n",
      "<unk> wins wins women 's ###m gold gold\n",
      "german stocks open higher\n",
      "crude futures futures on\n",
      "dollar trades to upper yen yen in tokyo\n",
      "stocks close higher in mexico brazil\n",
      "dollar trades at upper yen yen in tokyo\n",
      "johannesburg stock market stock to\n",
      "beijing to to to #### #### #### games\n",
      "dollar trades at upper yen yen in tokyo\n",
      "germany beats spain #-# #-# in world cup\n",
      "german stock markets close higher\n",
      "australian dollar ends higher\n",
      "taiwan stock end lower\n",
      "results of # # division soccer\n",
      "dollar down in upper ## yen range tokyo\n",
      "china confirms new case flu flu\n",
      "malaysia to to to to\n",
      "german stocks exchange higher\n",
      "new zealand stocks closes higher\n",
      "beijing to host international to to\n",
      "explosion in in in in\n",
      "rubber futures close higher on smaller volumes\n",
      "china 's to to to in in\n",
      "rubber futures close higher on smaller volumes\n",
      "UNK wins wins wins at at marathon\n",
      "UNK ivy to to in in\n",
      "rubber futures close on on volumes volumes\n",
      "u.s. senate in on\n",
      "rubber futures close higher on smaller volumes\n",
      "midfielder striker <unk> to to to to for for\n",
      "two u.s. soldiers killed in iraq\n",
      "UNK wins wins stage stage stage motorcycle\n",
      "spain to host for world in\n",
      "rubber futures close higher on smaller volumes\n",
      "pakistan to to aid aid\n",
      "gold closes unchanged in hong kong\n",
      "hong kong markets closed closed kong\n",
      "thailand financial markets closed\n",
      "china financial markets closed\n",
      "UNK wins biathlon cup world cup\n",
      "hong kong stocks close #.## percent lower\n",
      "pakistan beats for africa\n",
      "holyfield 's a on for\n",
      "malaysian shares close #.## percent lower\n",
      "u.s. condemns embassy in in\n",
      "woods woods to woods to woods\n",
      "taiwan financial markets closed\n",
      "northridge 's to at at at\n",
      "russia wins women 's biathlon relay title\n",
      "obama s to obama obama to to obama\n",
      "hong kong markets closed for for for holiday\n",
      "chinese 's of 's 's 's 's in\n",
      "philippine shares close #.## percent lower\n",
      "us jobless sales in in in\n",
      "UNK named from coach\n",
      "galaxy robson to as as as 's 's\n",
      "roddick wins ###cc at gp prix\n",
      "schumacher schumacher wins grand grand prix\n",
      "UNK vote to in in\n",
      "oil prices in asian\n",
      "european 's financial markets\n",
      "rubber futures prices steady on volumes volumes\n",
      "ucla 's nets to in\n",
      "hong kong wen kong kong 's in\n",
      "commonwealth games podium 's 's 's 's at\n",
      "commonwealth games the 's 's 's podium\n",
      "UNK of take in in in\n",
      "rubber futures close higher on smaller volumes\n",
      "ethiopia to to to on\n",
      "key marks of s s s\n",
      "taiwan financial markets closed\n",
      "new of of of in in\n",
      "french stocks fall universiade on\n",
      "klitschko 's to to in in\n",
      "drought around for the\n",
      "israeli militants two more in in\n",
      "hong kong markets closed closed for\n",
      "chinese develops on medicine\n",
      "pope calls for urges to to to in\n",
      "chrysler 's to to to for for for\n",
      "hong kong markets closed for for\n",
      "hong stock markets closed for for holiday\n",
      "u.s. senate to oil oil\n",
      "world marks to international in\n",
      "australian bourse prices up\n",
      "saddam of of of of of to of of of\n",
      "hollywood 's of to of to to to of for\n",
      "rubber futures close higher on smaller volumes\n",
      "australian storm tour of\n",
      "<unk> <unk> <unk> cub <unk> <unk>\n",
      "celtic scores to to cup cup cup\n",
      "UNK wins wins stage downhill\n",
      "ronaldo to to to in in in\n",
      "israeli 's UNK to to to in in\n",
      "oil prices in in\n",
      "selig is for for\n",
      "taiwan financial markets closed\n",
      "skorean shares close #.## percent percent\n",
      "malaysian shares close #.## percent lower\n",
      "results cup badminton results results\n",
      "## injured in in in in in\n",
      "broadway 's 's on on of\n",
      "the the to the the the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 's the the of the of the\n",
      "UNK joins <unk> <unk> to from\n",
      "UNK 's UNK the the UNK\n",
      "jennifer simpson to to for for for\n",
      "serena williams withdraws of at biscayne\n",
      "serena williams to to at semifinals\n",
      "london stock exchange up at midday\n",
      "gators 's to to to to in in\n",
      "UNK than of in in in in\n",
      "UNK UNK to receive at at at\n",
      "<unk> trials the of of\n",
      "london stock exchange up at midday\n",
      "<unk> <unk> UNK UNK UNK <unk>\n",
      "citigroup #q #q profit profit profit on\n",
      "UNK wins world world of of of race\n",
      "judge channel to to to in in\n",
      "mary <unk> <unk> <unk> <unk> <unk> at at at <unk>\n",
      "intel 's to in in\n",
      "former olympic champion poet dies at ##\n",
      "# killed in in in in in in\n",
      "jagr to he to to for nhl\n",
      "a of the the the the the the the\n",
      "manchester to to to to to to for\n",
      "UNK 's to to in in\n",
      "asian stock markets close mostly higher\n",
      "united states to to team in\n",
      "ucla 's for to in\n",
      "european stock end close\n",
      "UNK 's the the\n",
      "UNK 's to to to to in in\n",
      "china flu flu swine in in in flu\n",
      "stocks edge after after after of\n",
      "judge 's of to to to to in\n",
      "canada to to protect\n",
      "thailand calls to to cooperation in\n",
      "UNK UNK the UNK\n",
      "UNK 's to to to to to the\n",
      "armstrong armstrong to for tour tour tour tour\n",
      "actor of of birth to\n",
      "leeds signs UNK to to loan loan\n",
      "panthers hire named named to to of\n",
      "study 's a to in UNK\n",
      "# killed in in in in\n",
      "UNK 's for at\n",
      "UNK UNK wins receive at at nominees\n",
      "venus williams beats on masters biscayne\n",
      "latest developments to to in in\n",
      "holmes slumdog <unk> girlfriend dies dies\n",
      "lemieux williams to to to game\n",
      "buchanan says to to to on cd\n",
      "singh grabs to for at at\n",
      "stock markets mixed in\n",
      "<unk> the the the the\n",
      "u.s. house policy u.s. to to to to of\n",
      "rob UNK star receive to receive in in of\n",
      "UNK champion to to to to to in world\n",
      "UNK 's UNK to for\n",
      "dolphins re-sign forward <unk> <unk> <unk>\n",
      "UNK 's to to to to to to s\n",
      "stocks mixed in early trading\n",
      "<unk> 's at race\n",
      "no. defense for in\n",
      "london share prices lower\n",
      "yankees keep suns to to\n",
      "no. ## duke ## ## ## ##\n",
      "rep. 's to to in in\n",
      "bruins coach toledo to northwestern\n",
      "UNK 's a to to the the\n",
      "pepperdine 's in in\n",
      "UNK taste for UNK\n",
      "<unk> 's 's 's to to of 's\n",
      "UNK learned a for UNK\n",
      "police police crime tons in in in\n",
      "world 's of of to to to in 's\n",
      "yankees lose yankees to\n",
      "sorenstam wins for for at at at\n",
      "israel government aid to in in\n",
      "endangered 's to to to to in in\n",
      "UNK 's <unk> the of the UNK\n",
      "dragila wins wins at\n",
      "stars sign sign to <unk>\n",
      "UNK of UNK UNK of in in UNK\n",
      "oprah potter UNK to to for\n",
      "<unk> of presidential\n",
      "police police find tons in in in\n",
      "tyson wants he for tyson\n",
      "world cup downhill downhill canceled to\n",
      "scotland squad squad for\n",
      "study to requires to to to for UNK\n",
      "grizzlies 's to to to to\n",
      "gore of of to to to to in 's\n",
      "phillips is a for UNK\n",
      "former president sworn sworn in in president\n",
      "woods woods to woods to to at at at\n",
      "astronauts serbs to to to to to\n",
      "valentin 's for for\n",
      "spain to brazil #-# in\n",
      "els grabs to to the at at at\n",
      "laura 's 's to to to to 's UNK\n",
      "UNK 's UNK the the\n",
      "the the of of of the the the\n",
      "dow stock stock stock to for in\n",
      "london 's ftse-### index up ## points at at close\n",
      "london 's ftse-### index up ## points at at close\n",
      "bush house on on on on to to\n",
      "it 's is a the the the the the\n",
      "holocaust <unk> UNK heir UNK UNK UNK\n",
      "judge pleads UNK to to\n",
      "UNK 's UNK UNK UNK\n",
      "#-##-## 's to to to in in in\n",
      "cholera killed kills UNK\n",
      "microsoft UNK UNK UNK\n",
      "giants mets to to to to\n",
      "former playwright poet <unk> dies at ##\n",
      "a of of in to to to in of\n",
      "federer wins wins grand\n",
      "former striker eto alan to to for for\n",
      "UNK to to coach to for coach\n",
      "ac milan milan milan milan milan surgery\n",
      "brothers 's to to to to to in in\n",
      "a 's the to the the to at to the\n",
      "ferguson says to to to to england england cup\n",
      "barbecue is a UNK of of UNK\n",
      "UNK to to to for for\n",
      "eu 's to to to on\n",
      "in is of of a a of of of\n",
      "UNK named as as coach coach\n",
      "UNK 's UNK the the UNK\n",
      "treasury prices fall as stocks of\n",
      "treasury prices mixed as stocks of\n",
      "favre says to to to to to to\n",
      "nissan 's to to for for\n",
      "red sign to to to\n",
      "stars sign sign to\n",
      "mavericks ## mavericks #\n",
      "goldman 's to to to to to of\n",
      "it 's a a to to the the the\n",
      "judge workers to to to for for\n",
      "police police in in in in in of in\n",
      "london 's exchange closes up\n",
      "world of biathlon cup biathlon biathlon\n",
      "london 's prices in\n",
      "pope s pm to to to to\n",
      "police police seize in in in in\n",
      "police village of wear UNK in UNK\n",
      "vanderbilt stock above above in low\n",
      "intel 's stock a a for prices\n",
      "pope calls to to\n",
      "irish pm minister to to amid\n",
      "nasa to repairs space for space\n",
      "UNK 's 's to to to to in\n",
      "devils ## rangers ## ##\n",
      "cowboys mets mets for\n",
      "california 's oks in in\n",
      "UNK owners to to to for\n",
      "nadal nadal to to in semifinals\n",
      "former <unk> <unk> dies at ##\n",
      "hingis withdraws withdraws french open open\n",
      "pope king minister visits\n",
      "# killed in explosion in\n",
      "intel 's to to to for in\n",
      "us 's deficit to #### in in in in\n",
      "judge of of to to to to in\n",
      "zaccheroni davies for at\n",
      "chris alan pleads pleads to to in\n",
      "eu to to strike to in\n",
      "cage sues sue to in in in\n",
      "seoul stocks end markets\n",
      "german 's interest rate rates\n",
      "mickelson gets to to the the the\n",
      "usc 's UNK to to to in\n",
      "## kills in in in in in\n",
      "a the the the the the the the the the\n",
      "johnson 's to to to to for the\n",
      "wings wings re-sign #-year to to deal deal\n",
      "painting &amp; to to to to to to to to to for\n",
      "police ship operations at at in\n",
      "sorenstam 's to to in\n",
      "UNK &amp; to to to for to for\n",
      "canucks forward to to to to to of\n",
      "thousands of of to to in in in in\n",
      "roma extends to #-year to contract contract\n",
      "nato soldier killed in afghanistan\n",
      "former chef refuses to to to for\n",
      "ronaldo says he to to to to\n",
      "agassi williams to at open open\n",
      "UNK 's UNK the the the the\n",
      "<unk> <unk> <unk> en 's <unk>\n",
      "eu to to to to to to for\n",
      "london 's ftse-### index up ## points at at close\n",
      "new democrats to to to for the\n",
      "UNK UNK suspended for for for\n",
      "duval likes for at\n",
      "kevin 's 's the the the a a of of\n",
      "tokyo stocks open higher dollar dollar against yen\n",
      "judge hilton says richie to to to to in\n",
      "woods woods to woods to at\n",
      "nbc 's to to to\n",
      "UNK wins to at at at at at\n",
      "rain of for for for\n",
      "london stock exchange up at midday\n",
      "share prices surge in hong\n",
      "russia beats draw to to in in in cup\n",
      "south to to to world world cup cup\n",
      "broadway 's 's star to of of\n",
      "oprah potter UNK to to to of UNK\n",
      "UNK 's cup cup to to in\n",
      "england sees to england to world cup cup cup\n",
      "ethics <unk> sue at\n",
      "mcgwire sanders to to yankees\n",
      "ucla 's to at game\n",
      "sarah 's hoya to to to to in in\n",
      "ethics UNK sue at\n",
      "kostelic leads to to to to in\n",
      "grizzlies hire named selanne as coach\n",
      "former <unk> <unk> <unk> dies at at ##\n",
      "woman of of of of of of UNK\n",
      "nissan to sue helped for for for\n",
      "u.s. 's u.s. costly to to in in in\n",
      "villarreal signs sign UNK <unk> on\n",
      "us airways in sanctions iraq in iraq iraq iraq\n",
      "UNK 's cup cup cup cup cup\n",
      "jack <unk> <unk> fame hall hall fame fame\n",
      "mtv stewart to the the the the\n",
      "hbo 's UNK the to for UNK\n",
      "share prices close higher higher\n",
      "UNK 's UNK to to UNK\n",
      "<unk> ftse-### 's to to to to in in of <unk> <unk>\n",
      "iran says to troops troops in\n",
      "glenn 's a the to for the\n",
      "census buys secrets memo\n",
      "key of wage in in\n",
      "world cup cup cup cup cup world world world world cup\n",
      "perry singh to to to to at at\n",
      "boeing 's to to in in in\n",
      "us airways to to to\n",
      "ford to to to to to to million\n",
      "ethics of UNK UNK in\n",
      "the the the the the the the the\n",
      "corn 's forecast in\n",
      "spain signs signs to to for for\n",
      "wall street falls lower\n",
      "gillette 's to to to for\n",
      "mets mets mets to to to\n",
      "UNK scores hat to to the cup cup\n",
      "johnny UNK UNK b. b. at\n",
      "UNK 's UNK to the <unk>\n",
      "nadal wins to to to at to at\n",
      "lindsey wins wins wins at\n",
      "chinese hong hong to to to in\n",
      "rain delays play play of of cup\n",
      "<unk> 's <unk> gold in at at at world\n",
      "bode miller wins overall ; to to to\n",
      "bush 's bush bush to to to\n",
      "united cup cup cup cup to to world world cup cup\n",
      "united 's to to world world world in cup cup\n",
      "gold prices fall as dollar dollar slips\n",
      "police police in in in in\n",
      "winger volumes coach coach as as coach coach\n",
      "UNK 's to his broadway broadway to to to the the\n",
      "in to to to to to to the\n",
      "lindsay lohan says simpson she she to for in\n",
      "france to to for #### world championships\n",
      "<unk> <unk> <unk> the of the the\n",
      "UNK UNK UNK for in at at at cup\n",
      "eu 's to to to to to for\n",
      "south korea to to to to in in\n",
      "greece holds #-# #-# #-# in world qualifier\n",
      "david 's 's to to to to of of\n",
      "court court court to to to for anti-quran\n",
      "UNK 's hoya receive to to to in in\n",
      "police police in tons in in in\n",
      "brazil stocks stock percent on on\n",
      "us police of of of of in of of\n",
      "israel calls for to to\n",
      "UNK 's to to to the to to to to the the\n",
      "scientists yorkers in to to a in in in\n",
      "london share prices lower at\n",
      "clippers compensation for on\n",
      "samuel mcconaughey hoya hoya hoya hoya hoya in in in fame\n",
      "els gets to to to to to to to the\n",
      "## killed in in in in\n",
      "revolution defense to for\n",
      "bush president to to to\n",
      "dolphins re-sign d <unk>\n",
      "knoblauch is for decision\n",
      "<unk> the the the the the the the\n",
      "jones cup to on in in cup\n",
      "UNK women to to to to to cup\n",
      "UNK named as at of of\n",
      "red coach to to to to to to\n",
      "bruins hire hire as\n",
      "stars 's knicks to\n",
      "pope president to to to\n",
      "share prices close higher\n",
      "share prices close higher\n",
      "share prices close higher\n",
      "tokyo stocks dollar dollar early trading\n",
      "experts 's to to to to to of\n",
      "bomb explodes near runway in\n",
      "us inflation prices as in in\n",
      "soybeans soybeans prices higher\n",
      "pakistan to sign in\n",
      "UNK coach for england for\n",
      "stocks stocks up mexico brazil in\n",
      "corinthians defeats past #-# in in\n",
      "fire kills at in\n",
      "woods woods to woods to at\n",
      "malaysia israel sign sign cooperation agreement\n",
      "eu 's to to to to to for\n",
      "toledo 's to to to for\n",
      "fire kills kills in in\n",
      "mcgwire 's to to to to to to\n",
      "northridge all-star to to in\n",
      "chelsea extends to joins joins as\n",
      "experts 's in to to to of of of\n",
      "gore is of to to to 's 's\n",
      "UNK named sports scoreboard\n",
      "UNK stewart to to the the the the\n",
      "european stocks stocks in\n",
      "UNK of ruins UNK of in in\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> to of of <unk>\n",
      "mavericks rays to to to in\n",
      "actor artist <unk> dies dies ## ##\n",
      "woman convicted of of to of in in\n",
      "bayern to to out to to the with\n",
      "former lawmaker says to to to to to anti-quran\n",
      "kings need to to in\n",
      "stocks futures fall after to\n",
      "roma signs <unk> UNK joins from from\n",
      "oil prices fall on crude range\n",
      "nadal to to to for at at open open\n",
      "stocks prices on housing in in\n",
      "portugal to play to in in in\n",
      "united states to to to to in world cup\n",
      "study is a to to in UNK\n",
      "lakers sign mets to to\n",
      "daughter 's president to to to to to to to\n",
      "yankees lakers lakers #\n",
      "bruins 's to to to in\n",
      "o'neal madness to to to for\n",
      "former hilton to files to divorce in divorce\n",
      "tokyo stocks open higher higher dollar\n",
      "tokyo stocks lower dollar higher against yen\n",
      "actor <unk> <unk> dies dies ## ##\n",
      "tokyo stocks end lower\n",
      "a the of of of of\n",
      "man 's to to to for for\n",
      "norstrom 's to to to\n",
      "spurs re-sign forward to\n",
      "lemieux favre to to award\n",
      "london 's exchange in lower\n",
      "UNK s to to to to to\n",
      "UNK 's to to to in in indy\n",
      "UNK acquires <unk> UNK\n",
      "german prices prices in\n",
      "UNK 's the to of of\n",
      "tokyo stocks end lower dollar lower yen\n",
      "fire workers UNK in in in\n",
      "woods woods to woods to at the\n",
      "a 's the the the the a the the\n",
      "<unk> sets <unk> sets record at in in marathon\n",
      "us 's iraq species on in in in\n",
      "UNK 's the is to the the\n",
      "UNK voted unbeaten to at title\n",
      "barack robson he to to for next\n",
      "michael 's to to at at nominees\n",
      "agassi to to to for at at open\n",
      "stars sign sign <unk>\n",
      "andretti andretti he to to to to to to to\n",
      "venus williams to to at at\n",
      "re-sign hire hire to\n",
      "tokyo stocks higher midday dollar against yen\n",
      "abc 's UNK to to in\n",
      "# killed in kills at in injures\n",
      "UNK of to in in in in\n",
      "us army to sent to of in\n",
      "explosion explodes in in in\n",
      "wolfsburg beats catania catania #-# #-#\n",
      "actor <unk> <unk> writer <unk> dies\n",
      "israel calls to to on in\n",
      "ford s to to to to to\n",
      "UNK 's 's the with the\n",
      "greece criticizes to million\n",
      "us inflation prices in in in in in in\n",
      "federer says to to to knee surgery\n",
      "singh wins tied to in at\n",
      "nasa posts to space for ###m\n",
      "nasa postpones space category at\n",
      "judge of inmate in in in in\n",
      "microsoft to to #q #q #q\n",
      "federer venus UNK venus in\n",
      "<unk> of of of of of of\n",
      "<unk> 's new UNK\n",
      "## kashmir in in in\n",
      "two police seize in in\n",
      "UNK to urged urged to in in\n",
      "french cyclist player tests to to doping\n",
      "UNK lottery UNK to in\n",
      "UNK UNK champion monte dies at ##\n",
      "strong earthquake in southern\n",
      "agassi williams for\n",
      "two troops find bodies in in\n",
      "UNK 's to wnba in in\n",
      "share prices close prices higher\n",
      "share prices close generally higher\n",
      "hbo lee to to the the for the the\n",
      "a of UNK UNK\n",
      "beijing china project in in in\n",
      "hbo 's UNK to to to the the\n",
      "us says orders buy jobs for to in\n",
      "former UNK dies dies at ##\n",
      "obama s to to to to to\n",
      "a of of a of in in\n",
      "a 's of to to a to to to of of\n",
      "study 's to to to to to to UNK\n",
      "flamengo gp gp gp\n",
      "tropical storm marty forms in off\n",
      "tropical storm forms off in off\n",
      "intel 's UNK UNK to of of\n",
      "mauresmo withdraws withdraws from open open\n",
      "share prices close generally higher\n",
      "tokyo stocks slip dollar higher against yen in\n",
      "sampras davies to to masters\n",
      "death toll toll toll rises rises in ##\n",
      "shuttle shuttle shuttle shuttle shuttle shuttle shuttle\n",
      "woods woods to woods at\n",
      "UNK police seize in in\n",
      "UNK 's to to to to in in\n",
      "UNK of UNK autistic UNK\n",
      "scientists lawmakers UNK to in in\n",
      "UNK to to to to to to in\n",
      "UNK takes to at at at\n",
      "UNK grabs dominate at at at\n",
      "webb aiming to for at at\n",
      "california of of to to in in in\n",
      "UNK 's UNK 's to to to of\n",
      "u.s. aide urges urges to to to\n",
      "UNK replay for for\n",
      "UNK cyclist player banned for for for\n",
      "eu to resume to to to to\n",
      "UNK 's a to to to the the\n",
      "moderate earthquake shakes eastern romania\n",
      "chinese 's to to to to in\n",
      "a the of to of the the\n",
      "goldman to to to for for for for\n",
      "england to play in in in\n",
      "jennifer 's the the the the a a a the\n",
      "comedian clooney of guilty to to in\n",
      "UNK wins for for ryder ryder cup\n",
      "UNK of of <unk> <unk>\n",
      "no. state no. ## no. ## ##\n",
      "selig 's in to in UNK\n",
      "for 's the the the the the the\n",
      "o'neal o'neal to to to to for for\n",
      "spurs scores to to to\n",
      "england coach to to to as to for league\n",
      "sorenstam wins to for at at cup\n",
      "former president president to to to to term\n",
      "former de prix for for for\n",
      "<unk> <unk> the to of the\n",
      "UNK of UNK to in UNK\n",
      "UNK 's UNK to to in in\n",
      "britney spears says says to to to to in\n",
      "agassi davenport withdraws from biscayne\n",
      "u.s. 's in in in in in in in in with\n",
      "gore 's to to in in\n",
      "us oil sales prices to in to ; to in to\n",
      "rangers need to to to in\n",
      "lemieux introduce mourning coach\n",
      "ripken to for for injury\n",
      "<unk> 's for the\n",
      "stocks stocks open on on\n",
      "UNK striker <unk> to player of\n",
      "obama s to to to to to\n",
      "us futures mixed after on\n",
      "giuliani of of to to of of in\n",
      "israel calls new talks\n",
      "UNK 's 's to to to to in\n",
      "former pleads pleads pleads to corruption to\n",
      "gillette to for for UNK\n",
      "obama obama to obama to to to to to\n",
      "UNK striker to to chelsea to to to cup\n",
      "lemieux gets hat to to game\n",
      "russia wins to to team in team\n",
      "former journalist of dies at zoo\n",
      "UNK of oldest <unk> <unk> to to in\n",
      "samuel mcconaughey to hoya to a in in fame\n",
      "dole house iraqi pelosi to to the the\n",
      "us says to troops to in\n",
      "barkley 's to to suns\n",
      "<unk> names UNK #-# #-# in #-#\n",
      "agassi williams to to in\n",
      "UNK 's the of of the the\n",
      "couples 's to to to the the\n",
      "UNK 's UNK the the\n",
      "armstrong armstrong to hoya for at at\n",
      "stocks stocks up mexico brazil brazil\n",
      "brazil to to to world world cup cup cup\n",
      "rob gets to receive the at at at\n",
      "UNK de president #-year to to to\n",
      "UNK 's says to to to in in in in in\n",
      "stephen 's to to to on new\n",
      "UNK bowl a a for the\n",
      "court court doping doping to for for\n",
      "wall street up as of of\n",
      "toyota to to for for\n",
      "brazil to to for world cup cup\n",
      "a UNK to to in for for\n",
      "share prices share higher\n",
      "rusedski withdraws from at at open\n",
      "els has for pga the the the the cup cup\n",
      "cowboys unclear for cowboys\n",
      "UNK 's to to to to to in cup\n",
      "<unk> 's the the the the the\n",
      "baggio robson he to for\n",
      "patrick 's to wife nominees nominees in in\n",
      "spain africa to #-# #-# in to in world world\n",
      "#-##-## 's a to to to of of\n",
      "supreme court to to to to in\n",
      "sao united to as to as\n",
      "bayern extends to to to to to\n",
      "world cup cup for cup\n",
      "leeds midfielder to to to to to loan loan\n",
      "world cup world world world world to in\n",
      "hbo 's to to to at\n",
      "lindsey wins wins world world cup\n",
      "nigeria to squad for world world qualifier\n",
      "devils beat to to to\n",
      "london 's exchange index up ##.##\n",
      "devils 's nets to ##-##\n",
      "sorenstam gets to to in at at\n",
      "ronaldo says he to to to to\n",
      "world cup cup cup of\n",
      "former soviet minister dies dies\n",
      "london 's ftse-### index up ## points at at close close\n",
      "westwood agassi UNK on at at cup\n",
      "france 's to to in in in cup\n",
      "former de <unk> retires <unk>\n",
      "fifa to to to to to to with in\n",
      "UNK 's a the his the the the the\n",
      "UNK cup cup cup cup at cup cup\n",
      "UNK 's to to to to for\n",
      "UNK wins wins wins at at marathon\n",
      "bode to to to to to to giro\n",
      "panthers sign bigger with\n",
      "body of method pose of in in in\n",
      "new 's prices the on\n",
      "new york to in in in in\n",
      "athletes of of to to a in in\n",
      "eu to to join to to to\n",
      "UNK <unk> <unk> writer <unk> dies at\n",
      "manchester to to to to to world cup cup\n",
      "psv united chelsea for for for for\n",
      "judge UNK in in in\n",
      "michael 's to to to to in in\n",
      "us urges iran to to to to to to to\n",
      "rossi wins UNK in at\n",
      "gas dollar at goldman as as on on\n",
      "beijing to symposium to to to\n",
      "ethics accused of gun in in UNK\n",
      "tokyo markets markets as tokyo on street street\n",
      "UNK UNK UNK UNK of in\n",
      "pakistan pm minister to to to to\n",
      "london stocks fall as in in in\n",
      "holyfield robinson to to at fame\n",
      "in york to to to in in in in in\n",
      "showers of parts in in\n",
      "UNK 's cup at cup at cup\n",
      "kostelic wins wins world world cup\n",
      "california of account to to in in\n",
      "stephen singh wins receive at at\n",
      "french 's 's UNK to to to to 's UNK\n",
      "willie 's honors\n",
      "kings sox to to to\n",
      "nissan greenspan to to to to of for of\n",
      "UNK named as as coach coach\n",
      "UNK 's a a to to of of\n",
      "UNK midfielder <unk> joins to as\n",
      "UNK 's to to to the the\n",
      "clippers hire to to arbitration\n",
      "<unk> <unk> <unk> the the the the\n",
      "recession to to to to to for\n",
      "indonesian pm pm pm to\n",
      "UNK robson to to surgery\n",
      "beckham says says to to to to to arsenal\n",
      "UNK s s s to to for for for\n",
      "the me for for the UNK\n",
      "notre scores to to to to\n",
      "red 's to to to\n",
      "woods woods to woods to at\n",
      "madrid says he to to\n",
      "it sopranos is the but the a the the\n",
      "brazil to ##-man for world world cup\n",
      "<unk> <unk> the the of the\n",
      "<unk> 's 's to <unk> <unk> to <unk>\n",
      "northridge says to to to to in in\n",
      "arsenal united arsenal to in in in\n",
      "asian stock markets close higher wall\n",
      "london 's exchange index up ## points at\n",
      "michael UNK to receive to in\n",
      "china 's 's 's 's women 's at\n",
      "the s #### tickets to to for for in in\n",
      "the the the the the the the\n",
      "study of of to to to to to in\n",
      "obama says obama obama obama to to obama to\n",
      "lyon s to to to to to UNK\n",
      "london 's exchange index up ## points\n",
      "UNK wins wins straight super-g\n",
      "ventura 's UNK to to UNK\n",
      "bayern robson keen to to to to of\n",
      "results championship badminton results\n",
      "jennifer 's 's birth to of of\n",
      "mccain mccain to mccain on on on\n",
      "strong earthquake hits central\n",
      "explosion explodes in in in in\n",
      "a 's a a of of UNK\n",
      "kate hudson to birth to in\n",
      "former of founder of <unk> dies dies at ##\n",
      "legendary learns to helped to in\n",
      "UNK wins wins to to at at at cup\n",
      "<unk> 's president to to to to in president\n",
      "singh likes to for daytona\n",
      "world 's to to cup cup cup in in world\n",
      "generally agrees to to to to\n",
      "chelsea signs to to to to\n",
      "judge of of in in in in in in\n",
      "UNK of <unk> <unk> <unk> <unk>\n",
      "usc 's UNK to to to to the\n",
      "ucla 's on to to for\n",
      "bush 's to to bush to\n",
      "it 's is the the the the the\n",
      "<unk> 's 's the UNK <unk>\n",
      "fifa to to to to for for\n",
      "london stock market closed new\n",
      "clemens beat to to\n",
      "woods woods to to for\n",
      "mclaren co-founder berry to to to for\n",
      "no. state no. ##\n",
      "dolphins hire hire as as coach\n",
      "stocks stocks dow early\n",
      "lakers ## lakers #\n",
      "<unk> 's for the the\n",
      "UNK bowl for for\n",
      "UNK 's to at at at\n",
      "google to to for on\n",
      "UNK 's a to to the in in in in\n",
      "former says becomes category to\n",
      "castroneves earns for graf at at\n",
      "lukas gets to to at at\n",
      "soybeans soybeans soybeans higher\n",
      "UNK trojans for ucla\n",
      "former former player player <unk> mid-## in\n",
      "mccain campaign to on on on on\n",
      "saddam 's says to to to to to to to to with\n",
      "singer 's UNK to to to in in\n",
      "UNK 's for the the\n",
      "us soldier dies in baghdad\n",
      "new of of of of to in\n",
      "ballesteros to for for biscayne\n",
      "the of of <unk>\n",
      "cowboys release release to\n",
      "red signs sign to\n",
      "mets mets mets to to\n",
      "a of of of of a in the <unk>\n",
      "baseball state for to\n",
      "UNK of of in to to to in in for\n",
      "UNK 's UNK to in in\n",
      "UNK UNK ruins for delayed\n",
      "england to to to euro for for for cup\n",
      "grizzlies 's to to\n",
      "sonics sox to to to to to\n",
      "hurricane workers shuttle space shuttle\n",
      "judge jury shuttle shuttle for shuttle shuttle\n",
      "new york flock in in in\n",
      "hurricane jury shuttle space shuttle shuttle\n",
      "dolphins hire hire coach as coach\n",
      "two kill killed in in in\n",
      "arafat demands UNK to in in\n",
      "fifa to to for #### world world cup cup\n",
      "<unk> names to to cup in cup\n",
      "united to to for world world cup\n",
      "UNK cup to cup cup as to to to in world cup cup\n",
      "a the a the the a a the the\n",
      "perry gets to to in\n",
      "julia mcconaughey wife expecting\n",
      "UNK 's UNK to to the\n",
      "UNK s parliament parliament parliament\n",
      "moderate earthquake in in ; no ; no no\n",
      "UNK wins wins at at classic\n",
      "cowboys agree agree to terms on contract\n",
      "dollar mixed against euro currencies\n",
      "un to urged to to in\n",
      "china takes to to to for for games\n",
      "tyson wants he to to on\n",
      "everest 's to to to to in in\n",
      "holyfield stewart is the to in the\n",
      "tokyo stocks lower dollar dollar against yen yen\n",
      "devils ## bruins ##-##\n",
      "reality the to to the for the\n",
      "UNK wins to at classic\n",
      "devils # ducks #\n",
      "china scientists china to to to 's in 's\n",
      "UNK 's to to to in UNK\n",
      "fire fire in in in in in\n",
      "no. ## st. ## ## ## ##\n",
      "o'neal rays pitino to to for\n",
      "rays ## seahawks #\n",
      "holyfield shines for for\n",
      "no. # notre dame ## ## ## ## in\n",
      "grizzlies ewing to to to to to to\n",
      "janet s to to to on\n",
      "UNK 's to to in in\n",
      "selig shines for\n",
      "stars sign sign to to deal\n",
      "michael 's 's to to to to in\n",
      "lemieux scores to to to to the\n",
      "UNK wins UNK for in at at at\n",
      "writer-director 's is to on UNK\n",
      "man convicted in in of of\n",
      "tottenham to contract to\n",
      "<unk> 's a a the the UNK\n",
      "UNK switches UNK UNK in in\n",
      "man accused of guilty of slaying\n",
      "jennifer hudson wife wife to\n",
      "key of of of 's 's 's presidential presidential\n",
      "ford &amp; to to to to to to to for\n",
      "nicklaus singh to to to at at at at\n",
      "macao 's to to in in\n",
      "northridge devils to in game\n",
      "UNK 's UNK warming for for\n",
      "singh grabs to at at at\n",
      "UNK switches to to in\n",
      "ecb stock exchange rates\n",
      "UNK stewart a a the the the the\n",
      "UNK 's to to to to to in the\n",
      "<unk> 's a the the the the\n",
      "UNK wins wins for at at title\n",
      "UNK striker to england to in england\n",
      "ballesteros UNK UNK carlo\n",
      "beijing of to to in in\n",
      "new of of war on in in\n",
      "midfielder signs <unk> <unk> to contract from\n",
      "london 's ftse-### index up ## points at at close\n",
      "chinese hk hong to to to to to\n",
      "UNK 's UNK for\n",
      "gold 's fund market in\n",
      "weir overcomes to to to at the the\n",
      "clijsters withdraws for wimbledon wimbledon\n",
      "<unk> named named named coach as to coach team\n",
      "riot cemetery issued in in\n",
      "britney spears granted to for for for\n",
      "<unk> the of the of of of\n",
      "writer-director lee 's the to the the\n",
      "ohio state to to to in in\n",
      "fifa s to england to for for england\n",
      "sampras wins to to to for\n",
      "clinton clinton clinton bush bush bush\n",
      "northridge 's to in game\n",
      "nasa shuttle shuttle space for shuttle\n",
      "sarah 's 's star to to to of of\n",
      "asian stock markets close mostly higher\n",
      "UNK <unk> UNK UNK to of of\n",
      "microsoft to lay for for for\n",
      "bangladesh launches in in\n",
      "gop UNK UNK UNK UNK\n",
      "airlines 's to warming to for for\n",
      "a 's 's a the the the the the\n",
      "world cup host for for\n",
      "phelps to to to to to to at the at\n",
      "article 's UNK to to of UNK\n",
      "UNK 's of of of in in\n",
      "<unk> <unk> <unk> dies ##\n",
      "blackburn sign sign UNK\n",
      "UNK striker joins joins to from from\n",
      "wigan signs sign UNK UNK from\n",
      "tokyo stocks end lower\n",
      "us soldiers eyeing lucrative iraq for the the iraq iraq\n",
      "we 's to to to to to in in\n",
      "hong kong shares in hong percent\n",
      "a the the the the the the\n",
      "UNK 's the the the the\n",
      "the the the the the the the the\n",
      "timeline of of of in\n",
      "simpsons 's a the the\n",
      "pepperdine 's to to to\n",
      "b-share says to as to to the the\n",
      "UNK 's 's to to to to to to to to to\n",
      "woods woods to woods to at the\n",
      "london share prices lower\n",
      "UNK 's to to in in\n",
      "celtic to to to in cup\n",
      "UNK the for the the\n",
      "UNK striker <unk> joins joins for\n",
      "bone 's to to to to for UNK\n",
      "gebrselassie 's to to to to in in\n",
      "federer withdraws to to of wimbledon\n",
      "starr leftist to to to to to\n",
      "chinese to on to to to to\n",
      "ruiz 's to to to in in\n",
      "stocks stocks mixed as mixed\n",
      "UNK 's to to to in in\n",
      "bayern extends to to ham as new coach\n",
      "holyfield 's to to to in\n",
      "england UNK england friendly in\n",
      "iran says minister iran to blames to rights\n",
      "teacher to can a the\n",
      "canada 's grows rate in\n",
      "mccain mccain mccain to to to the\n",
      "the the the the the the the the\n",
      "UNK bowl for for\n",
      "canada 's rate rate rate\n",
      "pope to to to to for\n",
      "judge banned UNK for for\n",
      "UNK earns to at tour\n",
      "<unk> extends contract UNK contract contract\n",
      "spain to to to world world cup cup\n",
      "tokyo stocks slip dollar higher against yen\n",
      "UNK of of of s s presidential\n",
      "residents groups develops cancun in\n",
      "man man pleads guilty in to in\n",
      "fire of of in in in in\n",
      "new turmoil of in in in\n",
      "UNK 's to to to in in\n",
      "stocks stocks after early\n",
      "pepperdine 's to to to to for\n",
      "mavericks sox to to to\n",
      "earnhardt 's to to in\n",
      "rockies bowl for for for\n",
      "UNK switches to to in\n",
      "twitter hudson for for\n",
      "ioc to to to to #### for #### ####\n",
      "els wins to to the at at at\n",
      "a yorkers of the the the the\n",
      "mavericks ## rangers #\n",
      "cameroon beats slovakia #-# in world cup qualifier\n",
      "fire fire at flee in in\n",
      "european to to to to to in\n",
      "safin to to wimbledon wimbledon wimbledon ####\n",
      "us trial accused gun to in UNK UNK\n",
      "former striker as as to for for\n",
      "text of names 's 's 's\n",
      "mauresmo withdraws from at open\n",
      "#-##-## 's to to to in in\n",
      "## killed in in in\n",
      "stocks stocks higher dollar early trading\n",
      "UNK 's aim at at at at\n",
      "actor <unk> of of of dies at\n",
      "thai stock exchange #.##\n",
      "shenzhen stock exchange index up ##.#\n",
      "gore 's to to to to to in in\n",
      "janet jackson 's to to new\n",
      "the the of of the the of\n",
      "a a of the the a a a a a\n",
      "holyfield 's to to to on the\n",
      "UNK 's 's to to to to the the\n",
      "the me for for the UNK\n",
      "the your for the\n",
      "UNK 's UNK the of of\n",
      "the UNK on on on\n",
      "UNK UNK for UNK\n",
      "conan jackson to to to to in\n",
      "a 's of of of of of\n",
      "<unk> of of of of a of of of\n",
      "<unk> 's is the UNK UNK\n",
      "<unk> the the the the\n",
      "bush house to to to on on\n",
      "tips recipe for the UNK\n",
      "how to to to the\n",
      "a 's of of of a in the\n",
      "hbo 's UNK to to to in\n",
      "pulp betty is to to to the\n",
      "parents of a for UNK\n",
      "microsoft UNK transplants UNK\n",
      "UNK marketing on to in in\n",
      "world of to to to in in in\n",
      "it 's a a to for for\n",
      "UNK 's UNK is to the the\n",
      "judge of ruins in in in\n",
      "a of of a a a to in in\n",
      "us vets iraq iraq iraq on iraq iraq\n",
      "it 's the the the the the the the\n",
      "<unk> ways for for\n",
      "UNK UNK UNK UNK in in\n",
      "willie 's for\n",
      "a the a a a a the UNK\n",
      "a the the the the the the the the\n",
      "<unk> the the the the the\n",
      "a 's the to to to to in in\n",
      "UNK switches to for for in\n",
      "a provides of of in\n",
      "google to to for for\n",
      "google to to for for UNK\n",
      "former s s to to to to in\n",
      "saddam of emerges to to to in in in\n",
      "weighing is a the the\n",
      "UNK 's UNK to the UNK\n",
      "weighing is is a in of UNK\n",
      "UNK 's 's to to to to of of\n",
      "republicans to to to to to to in\n",
      "UNK 's the the UNK\n",
      "the the can of the the\n",
      "boeing york to to to to to to to for\n",
      "we a a of to the\n",
      "hollywood 's in to to to to in in\n",
      "UNK 's the the of the of the\n",
      "us house to to to to to to to to\n",
      "UNK of a UNK of in\n",
      "a 's of the of at at the\n",
      "samuel says to hoya hoya hoya to to in\n",
      "<unk> 's the the UNK\n",
      "judge of UNK UNK in in\n",
      "the the of the the\n",
      "toyota 's to to to for to for\n",
      "key of sounds in in\n",
      "boeing airlines orders ### for for to\n",
      "researchers of to to to in in in\n",
      "how ways is the the UNK\n",
      "in the of the the the the the\n",
      "how to can for the\n",
      "scientists of to to to to to in in\n",
      "<unk> the the the of the UNK\n",
      "when your to a a a a the\n",
      "mary 's 's of of UNK\n",
      "the <unk> of of the\n",
      "UNK 's to to to in in\n",
      "judge judge to receive to for for for\n",
      "us to schedule to to to in\n",
      "a 's is a the the the the of\n",
      "hollywood &amp; to to to to to to of\n",
      "#-##-## 's a to to in the\n",
      "judge <unk> names <unk> <unk> <unk> <unk>\n",
      "a the of of of of of\n",
      "UNK 's UNK to to the\n",
      "writer-director 's is the\n",
      "a players to to to be to to in in\n",
      "the the of the\n",
      "UNK 's 's to to to to in\n",
      "a 's 's the UNK UNK\n",
      "clinton clinton to on on on\n",
      "gop of secrets impeachment UNK\n",
      "o.j. simpson employers to to for to UNK\n",
      "obama 's obama to to for\n",
      "the the of the of the the the\n",
      "immigration of of to to in in in\n",
      "u.s. house to to on on on on\n",
      "a me of the the the the the\n",
      "california wave 's in in in in in\n",
      "<unk> <unk> <unk> <unk> dies at\n",
      "why democrats would to to on on\n",
      "a the the the the the the the\n",
      "think your a a a to a the\n",
      "a your a a in of the\n",
      "gop of of to in in in\n",
      "novelist born UNK execution in\n",
      "UNK learns UNK in in in a\n",
      "saddam of to to to to to in in\n",
      "UNK of of bush\n",
      "bush 's to to to in\n",
      "UNK 's the the\n",
      "it 's the the the the the the the the the\n",
      "new says to to to to to in in in\n",
      "UNK 's the the <unk>\n",
      "UNK 's a a is is of UNK\n",
      "UNK 's UNK to to to to in\n",
      "a a a a a a to to the\n",
      "UNK of of UNK in in\n",
      "UNK 's to allows in in\n",
      "in UNK on in in\n",
      "UNK 's to to to to in UNK\n",
      "<unk> 's is the the the UNK\n",
      "<unk> 's is the the UNK\n",
      "UNK 's a to to to in in\n",
      "UNK 's in in in\n",
      "mccain says to to to to to on\n",
      "the the of of of the\n",
      "UNK hilton s box-office for for to to in\n",
      "canadian to strike to in\n",
      "google to to for for for\n",
      "hugh 's 's star to to of of\n",
      "UNK cultures to to to in in\n",
      "a 's 's to to to to to to to to to\n",
      "how your for for the UNK\n",
      "the UNK of\n",
      "a 's a a of in of\n",
      "a of of a a in in in\n",
      "a of of of of of UNK\n",
      "after 's to to to to to in in\n",
      "UNK 's UNK the to UNK\n",
      "some finds to to to to\n",
      "<unk> the the the of the the\n",
      "q&amp;a of of to to in in in\n",
      "former musician UNK editor dies at at\n",
      "beijing to largest largest to in in\n",
      "UNK to to for for for\n",
      "u.n. of UNK to to to in\n",
      "study 's to to to to to in\n",
      "us government to to to for in in\n",
      "a 's of in a a a a a\n",
      "the the the of of women\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new 's 's in in in\n",
      "us 's to to to to to in\n",
      "perry 's to hall hall hall fame\n",
      "new 's of of to for in in of of\n",
      "mcdonald to ipo to to for in\n",
      "a the of the the the the the the\n",
      "new street prices on street\n",
      "UNK watching UNK to to the UNK\n",
      "UNK 's the the UNK\n",
      "UNK of UNK to in in\n",
      "a the to to on\n",
      "google buys to va.\n",
      "UNK owners to to to\n",
      "bruins have to to to for\n",
      "transplants sues for jesus\n",
      "UNK UNK UNK receive hoya to to to in\n",
      "UNK of a a to in in\n",
      "UNK 's UNK the of UNK\n",
      "<unk> the for the the\n",
      "the <unk> of of the\n",
      "the the of of of the\n",
      "<unk> the for the\n",
      "tcu 's to to to to to to to\n",
      "a 's crowd to to in to to to to to the\n",
      "new lawmakers UNK to in in\n",
      "saddam of of 's to in in in of <unk>\n",
      "<unk> 's the the the the the\n",
      "commonwealth recognizes suspends resigns\n",
      "UNK trojans to to to in\n",
      "obama obama to in to on to to to to\n",
      "woods bowl to woods\n",
      "at&amp;t to to to for in\n",
      "UNK 's to at at\n",
      "the of of of of of of\n",
      "mavericks ## mavericks #\n",
      "red wings ducks terms to to overtime\n",
      "nissan 's to to to of of the\n",
      "UNK 's UNK the of UNK\n",
      "in 's in in in in in in to contributed with\n",
      "a 's the the the the the\n",
      "UNK 's UNK the the the\n",
      "abc 's UNK to to in\n",
      "actor 's 's to to to UNK\n",
      "UNK 's a the the UNK\n",
      "<unk> <unk> UNK UNK UNK in\n",
      "cyberspace of on to to in in\n",
      "glenn 's to the\n",
      "UNK wins sbc UNK\n",
      "UNK 's to to of at at the\n",
      "actor 's to to to walk of of fame\n",
      "newcastle fires UNK as for for\n",
      "bucs learned for for for\n",
      "cowboys 's to to to to to the\n",
      "sampras out for at injury\n",
      "UNK to to on in\n",
      "knicks and a to to to to the\n",
      "how to for for\n",
      "UNK 's 's to is to the the the\n",
      "UNK 's UNK to of UNK\n",
      "UNK 's UNK to to for UNK\n",
      "ballesteros wins at retirement\n",
      "kings ## rangers in\n",
      "the the of of the the the\n",
      "simpson 's to to to to to to in\n",
      "UNK <unk> the to of <unk>\n",
      "<unk> 's a for the the\n",
      "UNK 's UNK the to the\n",
      "simpsons 's 's the UNK\n",
      "<unk> the the the the the\n",
      "UNK turmoil UNK in in\n",
      "klitschko stewart to to to to to the\n",
      "bruins sox to to to in\n",
      "us #q profit #q mln ## to ##\n",
      "rangers 's to to in\n",
      "no. ## st. st. ## ## ##\n",
      "<unk> of of of of of of UNK\n",
      "chargers activate mourning arbitration\n",
      "china 's crisis of in for in\n",
      "ventura 's UNK to UNK\n",
      "<unk> the the the the the\n",
      "baseball owners to to to\n",
      "usc 's a to to to in the\n",
      "devils 's to to to in\n",
      "the 's of the of of the\n",
      "a carolina the 's of a in in\n",
      "beijing 's china tourism in in\n",
      "how the is a the of\n",
      "<unk> 's is the the the UNK\n",
      "stocks stocks higher following in\n",
      "sampras davies to to competitive\n",
      "UNK emerges on to in in\n",
      "UNK 's the the for <unk>\n",
      "UNK UNK UNK for\n",
      "angels mets mets to in\n",
      "a 's a a to to of the\n",
      "says knight to to to to to to in\n",
      "reds says to to to to surgery\n",
      "china to to to to for in\n",
      "UNK is a to for for\n",
      "china 's of of to of in in\n",
      "<unk> <unk> <unk> UNK of a of of\n",
      "mavericks rout to ###-##\n",
      "a 's of in in in in in of\n",
      "springsteen ayala at referee\n",
      "us sales sales #.# #.# in ; ; in in\n",
      "how companies on to of of UNK\n",
      "UNK 's UNK to to to to in\n",
      "prisoners workers strike strike in in\n",
      "jets mets to to to to\n",
      "UNK election of of in\n",
      "UNK 's is a the the the the\n",
      "UNK 's UNK to to to the the\n",
      "the 's to to to to in in\n",
      "census 's to to to for\n",
      "the the is the the UNK\n",
      "UNK 's UNK in in\n",
      "a UNK in in in in a the\n",
      "UNK 's a to to to of\n",
      "selig 's UNK the\n",
      "raiders is for for for\n",
      "it bowl the the the the to to the the\n",
      "earnhardt 's to in in at\n",
      "UNK 's a to of the the the the\n",
      "judge of inmate in in in in in\n",
      "the the of of the\n",
      "the the for for the the\n",
      "ruiz 's to to but to to the\n",
      "UNK UNK a in in in\n",
      "UNK 's wears to to to in\n",
      "UNK costs prices market\n",
      "UNK the a the the the the\n",
      "exhibit wars UNK UNK in UNK\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK 's for for for\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "a 's the the the the the the the\n",
      "UNK 's UNK the the UNK\n",
      "sorenstam to to to in in in\n",
      "UNK UNK UNK for for\n",
      "ioc 's looks to to to to to in UNK\n",
      "a of of to to be in in 's\n",
      "the <unk> of of <unk>\n",
      "cowboys mets to to to to to the\n",
      "intel 's defend to in in\n",
      "UNK the the to the the the the\n",
      "a me for for the UNK\n",
      "grizzlies ewing to to to to to to to\n",
      "UNK 's the to to to in in in\n",
      "the 's for for the\n",
      "los angeles daily news budget\n",
      "the the attraction for the the\n",
      "willie ray a to to to the\n",
      "the the for the\n",
      "oil prices fall as record highs\n",
      "devils sox to to to to\n",
      "kings need to kings\n",
      "jack 's 's the UNK\n",
      "UNK looms UNK to in\n",
      "norstrom 's a to for\n",
      "pamela leonard to to to on\n",
      "mets mets to cowboys\n",
      "a 's the the the the the the\n",
      "jets replay to cowboys\n",
      "nissan 's to to for for\n",
      "how to to to be to the\n",
      "bucs is to for for\n",
      "willie 's a the for for\n",
      "exhibit 's UNK UNK to to of UNK\n",
      "a is of of to in in in\n",
      "<unk> me is the the UNK\n",
      "maradona 's to to for\n",
      "the the of of the the the\n",
      "UNK 's UNK to to the\n",
      "bruins UNK coach as\n",
      "UNK 's UNK to to to in in\n",
      "sonics sox to to to for\n",
      "barkley o'neal to to\n",
      "yankees lakers lakers #\n",
      "bonds 's to to to to\n",
      "study of UNK UNK in in UNK\n",
      "us 's stock to to as to a in\n",
      "the the of the UNK\n",
      "vikings qb to to for\n",
      "buchanan 's to to in in\n",
      "the the attraction the the\n",
      "wall street stocks as as of\n",
      "no. dame to to at\n",
      "UNK 's UNK to to the <unk>\n",
      "a the the the the the the the\n",
      "<unk> cannes <unk> writer at cannes\n",
      "a the the a a to to of\n",
      "broncos broncos to to to to to\n",
      "o.j. s to to to new\n",
      "UNK 's prices prices\n",
      "gore 's 's to to a to in\n",
      "stewart gets his for in\n",
      "a the the of of the the\n",
      "clippers ## to for for\n",
      "UNK 's UNK to to to the the\n",
      "hurricane to to bankruptcy station\n",
      "a 's 's to of a to to to for\n",
      "armstrong says to hoya for for\n",
      "a 's of in of a in in in for\n",
      "the recipe of the the\n",
      "broncos broncos to to to to to\n",
      "a of of a of of of UNK\n",
      "in york in a in in in\n",
      "angels mets angels angels\n",
      "crist 's for for\n",
      "<unk> 's the the of the\n",
      "dole clinton to to clinton on on on\n",
      "holyfield 's to to to UNK\n",
      "UNK 's to to to in in\n",
      "scientists 's on to to in in UNK\n",
      "usc 's UNK to to to the\n",
      "UNK 's UNK to of UNK\n",
      "UNK <unk> to at at\n",
      "bush 's clinton to to to to\n",
      "UNK the the\n",
      "a the to to a a the the\n",
      "angels smith angels to for\n",
      "UNK 's on to in\n",
      "the the the of of the the\n",
      "actor 's 's 's to to of of\n",
      "UNK bowl a a for\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "a to can for the\n",
      "UNK 's to to in in in in\n",
      "ucla ivy to to to in\n",
      "mickelson wins lead at at at\n",
      "more the is a the the\n",
      "UNK is to for for\n",
      "buchanan 's to to to for\n",
      "<unk> <unk> of of of the the the of the\n",
      "UNK is to for for\n",
      "UNK hilton 's to to to to in\n",
      "ucla 's to to to in\n",
      "study to can to to of\n",
      "springsteen everest to to to in in\n",
      "UNK 's UNK UNK of UNK\n",
      "cuba to to urged to to in\n",
      "grammy 's 's to to in UNK\n",
      "spurs re-sign agree to to\n",
      "UNK 's UNK UNK to of of UNK\n",
      "police police take control in in in\n",
      "what to to to to be the the\n",
      "phelps s phelps to to to to to in\n",
      "sonics sox knicks to to to to\n",
      "it 's a a to the the\n",
      "UNK <unk> to to to of\n",
      "schilling 's to to to to in\n",
      "yankees 's yankees as to in the\n",
      "devils ## devils ##-##\n",
      "a america a a a a to to in\n",
      "UNK 's UNK to to in\n",
      "patriots is to for for\n",
      "UNK 's to to in in\n",
      "baylor 's to to to\n",
      "els wins to for at at at at\n",
      "author of of of to of of of\n",
      "oh is for for\n",
      "ucla 's to to to to to to to\n",
      "the the of of the\n",
      "heath potter 's to to to to of\n",
      "holyfield sticking a to to for\n",
      "holyfield 's to to in in\n",
      "if 's to to to a to the the\n",
      "raiders fargas for for for\n",
      "malone homers for in\n",
      "study to to to to in\n",
      "tcu 's to to to to to to\n",
      "earnhardt guitarist to receive at\n",
      "gillette sent to UNK\n",
      "<unk> 's <unk> UNK UNK <unk>\n",
      "some 's to to to for for\n",
      "UNK 's UNK to to for UNK\n",
      "a of of of of UNK\n",
      "sarah ono prosecutors to to to to\n",
      "nissan 's to to to on\n",
      "a the the the a a a the the\n",
      "UNK unsure to to in for the\n",
      "the the the the the the the the\n",
      "dole democrats on iraq to to the the the\n",
      "nbc 's to to to to to for\n",
      "UNK 's a to to to for the\n",
      "a 's at to in in in\n",
      "UNK recipe for the\n",
      "bryant smoltz giambi for\n",
      "microsoft say to helped for for to for\n",
      "giants mets to to to to to\n",
      "UNK <unk> <unk> UNK <unk> <unk>\n",
      "sonics sox to to to\n",
      "microsoft sues to madoff\n",
      "holyfield 's to to to the\n",
      "a 's is a the the the of\n",
      "colombian stocks fall as concern concern ; ;\n",
      "i kiss is the the the\n",
      "youtube to to to to in in\n",
      "a the can for the\n",
      "clemens riley yankees to to to to to to\n",
      "devils scores to to to in in\n",
      "lemieux to to to coach\n",
      "colombian stocks fall as concern concern concern\n",
      "chinese chinese to to to to to in\n",
      "UNK UNK UNK for for\n",
      "kings need to to to in\n",
      "bucs 's UNK to to to the\n",
      "the the of of of the of the\n",
      "selig 's to to but in for\n",
      "in some UNK to to for the\n",
      "ethics of UNK macy in in\n",
      "study 's to to to to for for\n",
      "UNK 's UNK to to the <unk>\n",
      "clippers release <unk> on\n",
      "UNK the the the the\n",
      "bruins have for for\n",
      "UNK the the the of the\n",
      "UNK 's 's to a a a in\n",
      "lemieux scores to to to to to over\n",
      "devils state to to to to to in\n",
      "UNK bowl a to for for for\n",
      "UNK years to to to to to in in\n",
      "UNK 's UNK to to <unk>\n",
      "holyfield shines a for UNK\n",
      "bonds tech to to to to\n",
      "johnson panthers to to in in the\n",
      "ventura 's UNK to to\n",
      "lemieux to to to return\n",
      "a the the the the the the the\n",
      "cannes <unk> of to to to of UNK\n",
      "UNK 's UNK the the the\n",
      "mickelson stewart to to the the the the\n",
      "mavericks sox to to\n",
      "ohio state to to to to\n",
      "a the the to the a the the\n",
      "kings defense to ###-##\n",
      "ripken wants to to in\n",
      "mavericks sox to to in\n",
      "devils coach to to to to to to in\n",
      "new york to to in\n",
      "UNK schools UNK UNK\n",
      "in 's in in in in in in in with\n",
      "when is a a a a a the\n",
      "<unk> the the the the the\n",
      "kansas loses to to ##\n",
      "a of of of of a of of of\n",
      "if the to a a a the\n",
      "former 's of to to to to to in\n",
      "UNK 's aim to of at at at\n",
      "revolution owners for scoreboard\n",
      "us to to to to to to in\n",
      "german stocks fall as concern concern prices\n",
      "study to a to to in UNK\n",
      "UNK 's a for for\n",
      "the the of of of UNK\n",
      "<unk> 's the the the the the\n",
      "UNK 's on to to in in the\n",
      "the <unk> <unk> <unk> <unk>\n",
      "norstrom 's UNK to the\n",
      "a the to a to to the\n",
      "UNK schools UNK for in\n",
      "<unk> 's the <unk>\n",
      "<unk> 's UNK the the the the\n",
      "UNK to to to to in\n",
      "scientists 's in to to in in in\n",
      "parcells hope to to to to the\n",
      "britney co-founder iphone to for for\n",
      "mavericks sox to to to in in\n",
      "when your a a a to to to the\n",
      "the the is the the the\n",
      "bucs focused for offense\n",
      "after 's 's to to to to to in in\n",
      "broncos manning to to to to to to\n",
      "the 's the the the the the the\n",
      "in york in in in in in in of the\n",
      "UNK owners to to to in\n",
      "cage 's of to to in in in\n",
      "<unk> 's the the the the the the\n",
      "UNK switches at at\n",
      "the the of of to the the\n",
      "hbo stewart UNK to to to the\n",
      "stewart wins for hall\n",
      "earnhardt wins hall hall hall fame\n",
      "UNK 's a a for for for\n",
      "UNK gets to at at at the\n",
      "democrats house care on on\n",
      "a a a a in in\n",
      "UNK fires to to pinkel\n",
      "<unk> 's for for the the\n",
      "UNK 's for the the\n",
      "knicks 's yankees to to to to in\n",
      "pets 's UNK to to to of of\n",
      "why to to to to in in\n",
      "perry busch to for for for at at at\n",
      "the bowl the the the the the the\n",
      "UNK spears to hoya to hoya in\n",
      "valentin faces for for\n",
      "broncos jets to emphasis on\n",
      "a of of of UNK UNK in of UNK\n",
      "harvick overcomes to at at classic\n",
      "the the of of of the of\n",
      "UNK UNK UNK UNK\n",
      "UNK the for the the\n",
      "UNK the UNK a of to of of\n",
      "UNK missed for for\n",
      "stocks futures after as jobs jobs earnings\n",
      "devils 's to to to in\n",
      "bush 's to to for for\n",
      "UNK s to to to to to with with with\n",
      "o.j. 's to to to in\n",
      "new york of to in in in\n",
      "phelps s to to to to in the the the\n",
      "waves ## ratings on\n",
      "gop UNK on to in in\n",
      "gop UNK on to in in\n",
      "devils 's to to to to to in in\n",
      "malone thankful for for\n",
      "giants giants to to to to\n",
      "a town at a in in\n",
      "wall street explodes as of\n",
      "it 's is is the but the the\n",
      "ucla 's to to in in\n",
      "selig 's UNK to in\n",
      "UNK 's UNK to to in in\n",
      "jackets diagnosed to for for for\n",
      "rangers beat to to to in\n",
      "patriots is to to for\n",
      "UNK of of of of UNK\n",
      "UNK dame for at at\n",
      "if 's a the the but to a the the\n",
      "dodgers fargas to for for for\n",
      "UNK 's the the the <unk>\n",
      "mickelson likes tied hall nelson fame\n",
      "simpson barbecue to to to to to to to\n",
      "u.s. to to to to to for world\n",
      "dole says clinton on to on in\n",
      "UNK health passes to service\n",
      "spurs and to to to\n",
      "a dole a a a a a\n",
      "<unk> 's the of the the the the the the\n",
      "ucla 's to to in in\n",
      "a the the the the the\n",
      "UNK 's for at at\n",
      "UNK notre for ucla\n",
      "when 's a a a the of the\n",
      "tcu 's 's to to to a the\n",
      "bucs b. a a with\n",
      "nbc 's to to to for for\n",
      "a of of to to a to in 's\n",
      "<unk> of of the of of of UNK\n",
      "bruins ## chargers ##\n",
      "kerry ways a to to to a the\n",
      "ucla ivy notre to in game\n",
      "UNK 's for carolina\n",
      "a the the the the the the the\n",
      "UNK 's UNK to to UNK\n",
      "pepperdine 's to to to the the\n",
      "UNK 's to to to to to the\n",
      "study is a a to of UNK\n",
      "delta 's natural in in\n",
      "northridge ## ## ##\n",
      "<unk> 's for for\n",
      "mets ca to to to to\n",
      "UNK s to receive to at in tour\n",
      "dodgers fargas mets for dodgers\n",
      "the the of of of UNK\n",
      "giants mets to to to to\n",
      "in cheese in a a a a a a the\n",
      "duval grabs to to in at at\n",
      "UNK 's a UNK of UNK\n",
      "broncos broncos to to to to to to\n",
      "federer williams to to ; at to at at at\n",
      "roddick says to to to to in\n",
      "new of in in in in in\n",
      "mavericks 's knicks to to to to the the\n",
      "<unk> <unk> wins wins nobel at of prize\n",
      "favre nuggets to to to to the the\n",
      "raiders 's to but to for\n",
      "UNK 's UNK UNK\n",
      "johnson robinson to to at the\n",
      "in 's of to to in in in 's\n",
      "lindros eager to to\n",
      "intel 's on column in in in\n",
      "if 's a the the the the the the the\n",
      "UNK schools UNK UNK UNK\n",
      "exhibit 's UNK UNK\n",
      "selig 's UNK the for\n",
      "holyfield 's to to to to to in in\n",
      "gagne 's he to to to to to the\n",
      "#-##-## hamlet UNK to in in\n",
      "<unk> <unk> <unk> receive nobel at in in\n",
      "crist compensation for expansion\n",
      "how the can for the\n",
      "it hope to to to to to the\n",
      "UNK <unk> UNK to UNK <unk>\n",
      "rangers need to to rangers in\n",
      "ucla 's to to to\n",
      "giuliani of of of to in in in\n",
      "UNK 's UNK is to to in\n",
      "cowboys glad is to for for\n",
      "holyfield 's to in in\n",
      "rays 's for for\n",
      "a 's is a in the\n",
      "UNK of UNK in in in\n",
      "UNK agreement UNK in in\n",
      "bucs 's UNK to to to\n",
      "UNK 's a to to to to the\n",
      "federer withdraws from at\n",
      "grizzlies riley to to to in\n",
      "judge UNK UNK UNK\n",
      "ballesteros ayala UNK\n",
      "UNK 's <unk> UNK of <unk>\n",
      "UNK agreement UNK to in in\n",
      "holyfield stewart is the to in the\n",
      "mets mets mets to\n",
      "the the for recipe\n",
      "<unk> the of of of the the the\n",
      "devils scores to to to #-#\n",
      "UNK 's to to to to to in\n",
      "dodgers mets dodgers dodgers\n",
      "police find find gun to in in\n",
      "lyon s assistant to to to for\n",
      "UNK wins UNK to at at in\n",
      "UNK 's a to to in\n",
      "new york to in in in\n",
      "singh gets to to to in\n",
      "weighing 's UNK to to of of UNK\n",
      "astronauts rouge UNK to to in\n",
      "a UNK a to a in in in\n",
      "aging 's 's to to to to in\n",
      "cyberspace 's UNK to in UNK\n",
      "angels is to for in\n",
      "UNK 's to to to for\n",
      "bush 's to to for\n",
      "the the the of of the the\n",
      "UNK wave on to to in in\n",
      "mlb 's to to to to in\n",
      "rangers lose to to to in\n",
      "UNK 's UNK to UNK\n",
      "UNK 's <unk> to of the <unk>\n",
      "UNK UNK UNK in in\n",
      "agassi has for for\n",
      "cowboys smith to to to to to to\n",
      "sonics sox to to to to\n",
      "the women women women of to to world\n",
      "toyota 's to UNK in in\n",
      "the the the the of the the the\n",
      "how you can for the\n",
      "<unk> 's UNK the the the UNK\n",
      "marilyn 's of to to to to to in\n",
      "UNK is for the\n",
      "it 's a the the the the the the\n",
      "in 's in in in in in in in with with\n",
      "gordon says to to to to in in\n",
      "weighing to for for\n",
      "UNK soup for UNK\n",
      "singh <unk> <unk> award\n",
      "wie overcomes to to to at at\n",
      "us 's to to to for to for in\n",
      "online companies to to on internet\n",
      "UNK 's a the the the the the\n",
      "<unk> 's the the the the the the the\n",
      "braves have to to of\n",
      "UNK fargas for for UNK\n",
      "u.s. stocks rise as bond on as\n",
      "the of of of of of\n",
      "new americans passes to to in\n",
      "singh wins tied for at\n",
      "UNK to to to to for in\n",
      "UNK 's UNK to to of\n",
      "giants giants to the to to to\n",
      "UNK mediocre for UNK\n",
      "a 's in in to a in in in for\n",
      "these 's a the for the\n",
      "cowboys cowboys aikman to cowboys\n",
      "<unk> <unk> <unk> to to the the\n",
      "thousands of of to to to in in 's\n",
      "how a a a a to the\n",
      "it 's to to to to to to the\n",
      "UNK 's the for for\n",
      "the the of of the <unk>\n",
      "UNK schools UNK in in\n",
      "actor <unk> <unk> writer <unk> dies dies dies\n",
      "saddam is is to to in in in\n",
      "exhibit <unk> <unk> UNK UNK <unk>\n",
      "UNK 's <unk> 's the\n",
      "a the the a of is the the\n",
      "for giants to to to to to to to\n",
      "exhibit zoo UNK UNK UNK\n",
      "vista 's for for\n",
      "us senate to to on on in\n",
      "a 's of to to to to in\n",
      "it 's a all for\n",
      "chrysler 's to to to for\n",
      "nissan to to for for UNK\n",
      "<unk> ways for for\n",
      "dodge ayala for for\n",
      "bonds state to to to\n",
      "UNK takes for at at\n",
      "woods woods to woods to to the\n",
      "UNK 's the to of the the the in the the\n",
      "martinez 's to to in in\n",
      "advance 's to to to to to to to for\n",
      "webb grabs to at at\n",
      "nissan 's to to to in in\n",
      "<unk> 's <unk> <unk> <unk> <unk>\n",
      "lemieux to sure to for\n",
      "the 's 's on the for\n",
      "UNK 's to to to in\n",
      "dream 's to to to to for\n",
      "it bowl a a the bowl bowl bowl\n",
      "UNK 's the the the UNK\n",
      "microsoft to to for\n",
      "UNK UNK in in in the\n",
      "mind to to to the to the the the\n",
      "usc 's to to for for\n",
      "<unk> 's the the the the the the\n",
      "woods woods to woods at\n",
      "a the the the the the the the\n",
      "it bowl a a to the the the\n",
      "UNK 's cup cup cup cup cup\n",
      "UNK is to to for\n",
      "gore bush of bush bush\n",
      "UNK 's UNK to to in of\n",
      "sarah 's president receives to to to in of of\n",
      "forgotten of of to in in in in\n",
      "a yorkers the the the the\n",
      "UNK hair for the\n",
      "UNK UNK UNK in in\n",
      "UNK 's for <unk>\n",
      "a me is the UNK\n",
      "UNK owners to for for\n",
      "dodgers mets to to for\n",
      "devils beat to to to in\n",
      "study UNK UNK physical to in in\n",
      "UNK 's to to of of of\n",
      "advance 's 's to to to in in in in the the\n",
      "gore <unk> at UNK\n",
      "UNK ivy UNK to to in in\n",
      "UNK the can a the\n",
      "<unk> of of birth of of at\n",
      "hbo 's 's to to to of UNK\n",
      "doctors UNK a a in in in\n",
      "how you a a a a a\n",
      "clinton clinton clinton on on\n",
      "clinton clinton obama to to in in\n",
      "<unk> artist <unk> venice\n",
      "how to to to the a the\n",
      "it betty is is is the the\n",
      "a the the the the the the the the the\n",
      "UNK box for to in\n",
      "when your to a a to a the\n",
      "bruins is to for for\n",
      "weighing 's of the\n",
      "everett sent to to\n",
      "kings defense homer to to\n",
      "giants need to a for\n",
      "UNK 's on for in\n",
      "a the of the of the the\n",
      "<unk> the of the the the the\n",
      "the need to to to to to\n",
      "dole clinton clinton on clinton in on\n",
      "everett 's to to to to the\n",
      "<unk> me is the for the\n",
      "willie 's a the the\n",
      "bruins hope to to to in\n",
      "dodgers fargas glad for in\n",
      "bucs is to to roberts\n",
      "toyota 's to to to in in\n",
      "sometimes 's to to but the the\n",
      "couples 's to for in in\n",
      "if 's is a a a the the\n",
      "UNK 's UNK the the <unk>\n",
      "phelps overcomes to receive to in in tour\n",
      "janet 's UNK to to UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK beef in to in in in\n",
      "UNK <unk> UNK UNK to of in\n",
      "buchanan 's to to to to on in\n",
      "sonics sox to to to\n",
      "parcells is to to to to\n",
      "in years in to to a to in in\n",
      "the the of of of\n",
      "holyfield gets to on in\n",
      "UNK UNK UNK in in in\n",
      "<unk> the the the of the\n",
      "UNK named named to for for\n",
      "UNK 's UNK to to UNK\n",
      "northridge 's to to in for\n",
      "guantanamo born of execution at\n",
      "clinton clinton clinton clinton clinton\n",
      "a 's a a a a in the\n",
      "if costs stock a a as a a\n",
      "UNK recipe for the\n",
      "clippers sent to to\n",
      "UNK owners to to to\n",
      "california of of to in in in\n",
      "scientists UNK UNK to to in in\n",
      "coyotes sign sign wing to to contract contract\n",
      "UNK 's UNK the the UNK\n",
      "clippers 's to to to for\n",
      "scientists of UNK UNK in in in\n",
      "UNK a&amp;m to to to in in\n",
      "you betty is the the the UNK\n",
      "kerry 's to to to to to for\n",
      "the the the the the the\n",
      "exhibit is of UNK of of UNK\n",
      "the the the\n",
      "fire of take in in in\n",
      "it bowl a a for for for\n",
      "UNK robinson to to game game\n",
      "yankees and yankees to to to the\n",
      "deployment 's 's in in in\n",
      "france 's to to to to to in in\n",
      "barkley 's to to in\n",
      "the 's the a of of\n",
      "couples 's UNK to to in in in\n",
      "UNK 's UNK to to the the\n",
      "judge court to of to in in in in\n",
      "<unk> the the the the the the the the\n",
      "chronology to to to on in\n",
      "ucla 's glad for in\n",
      "woods bowl for for for\n",
      "fifa to to to to to to\n",
      "UNK 's the at of at at\n",
      "<unk> 's for for the the\n",
      "heisman 's UNK to to for\n",
      "some 's to to on on\n",
      "famous actor musician <unk> dies at ##\n",
      "mccain democrats mccain on on\n",
      "the americans of to\n",
      "brazil to for for in\n",
      "UNK 's a to for the\n",
      "UNK funds to to to on\n",
      "els 's to to the the the the\n",
      "rams 's to to to for\n",
      "UNK to to <unk> to for in\n",
      "UNK 's a the the the\n",
      "angels buick for\n",
      "<unk> 's for for the the\n",
      "it 's a a to to the for\n",
      "devils sox to to to in in\n",
      "UNK 's for at\n",
      "dodgers bats dodgers dodgers\n",
      "bush 's clinton bush bush bush to in\n",
      "lemieux to voted to for\n",
      "dodgers sign to dodgers\n",
      "disney 's is the the the\n",
      "simpsons 's UNK the the\n",
      "giants mets to to to to to to\n",
      "a 's is a a of of the\n",
      "if &amp; to to to to to to to of of\n",
      "UNK watching UNK to to UNK\n",
      "UNK wins wins at at at at\n",
      "ayala aiming for for\n",
      "pepperdine 's for in\n",
      "the recipe of the\n",
      "UNK the the of of of UNK\n",
      "selig 's halloween\n",
      "a the of can to to the\n",
      "mets mets mets dodgers\n",
      "jets manning to to for\n",
      "UNK the to to the the\n",
      "<unk> the the the of the the the the\n",
      "mario wins wins to at at at title\n",
      "nascar 's to at in cup\n",
      "UNK 's a to to to the the\n",
      "UNK 's to at at at\n",
      "a the of the of the the the the\n",
      "UNK 's a for for\n",
      "singer says says says to to to to a in in\n",
      "UNK of UNK to to to in in\n",
      "<unk> the the the the the\n",
      "<unk> the the the the\n",
      "cowboys fargas to yankees to to the\n",
      "bryant 's to to to for\n",
      "o'neal o'neal to to to to for\n",
      "yankees rout lakers to\n",
      "UNK 's UNK to to the the\n",
      "<unk> 's 's a a a to of of\n",
      "holyfield 's to on\n",
      "UNK street prices prices\n",
      "a is is a a of UNK\n",
      "china to to on to\n",
      "saddam of in to to in in in in in\n",
      "results of of national in\n",
      "a 's is a the of UNK\n",
      "gillette 's to to in\n",
      "choosing your for the\n",
      "UNK of of to to in in\n",
      "broncos broncos to to to to to to to\n",
      "police ship near tons in in in\n",
      "fed 's 's in in in\n",
      "new york to in in in in\n",
      "bucs clayton is to but to the the\n",
      "u.s. aide military to to\n",
      "stocks street wall wall of as\n",
      "UNK 's UNK to to the\n",
      "it 's is the the but the the the\n",
      "the <unk> of the <unk>\n",
      "els wins wins slalom to second cup cup cup\n",
      "for hillary of the a a a a a the the\n",
      "<unk> me is the the the the\n",
      "malone 's to for UNK\n",
      "UNK insurance to UNK\n",
      "parents is a a to of UNK\n",
      "larsson to he to to for next\n",
      "mickelson stewart to to the at the\n",
      "nbc kiss a to to for the\n",
      "cox cox cox service service\n",
      "it bowl a a to to the\n",
      "UNK 's UNK to in in UNK\n",
      "UNK the a a a the the\n",
      "UNK dates UNK in in\n",
      "microsoft to to stem to in in\n",
      "UNK bowl for super\n",
      "yankees proves to but but to the the\n",
      "UNK UNK UNK UNK\n",
      "raiders fargas to for for\n",
      "microsoft UNK to for\n",
      "judge 's to to to to UNK\n",
      "it 's a a for for for\n",
      "UNK UNK UNK UNK\n",
      "selig is for controversy\n",
      "microsoft to to lacking\n",
      "we salad is a the for\n",
      "u.s. to to to to in in\n",
      "a the the the the the the the\n",
      "the 's is the the UNK\n",
      "UNK the the to of the\n",
      "mcenroe aiming to for\n",
      "<unk> 's a a a to the\n",
      "tyson williams for for\n",
      "a york of the the the\n",
      "california of UNK of in in\n",
      "a of of a a a in of of\n",
      "the recipe for the the\n",
      "bucs b. a a with for\n",
      "study of UNK to in in UNK\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK 's to to for\n",
      "UNK steps for for in\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK 's UNK to to to of\n",
      "a is is the the UNK\n",
      "bush 's to in for for\n",
      "UNK discover UNK\n",
      "mclaren alonso star to to to in in in in\n",
      "UNK of of of of a for in in\n",
      "jimmy 's UNK to to in\n",
      "pepperdine 's on for in\n",
      "a your of a a a a the\n",
      "# injured in kills in\n",
      "<unk> 's the the the <unk>\n",
      "court workers to in in in\n",
      "fossett 's says to to to to to in\n",
      "UNK 's <unk> <unk>\n",
      "airlines to UNK to for\n",
      "a 's of to to to in in\n",
      "UNK 's to to to for for\n",
      "parents 's a UNK of of\n",
      "scientists 's UNK UNK to in in UNK\n",
      "the me for the UNK\n",
      "betty 's the\n",
      "fossett fossett jr. to to in in in in in in\n",
      "holyfield 's to to to in in\n",
      "a 's of a of a of the\n",
      "if 's a a but to a the\n",
      "UNK 's to to to to the the\n",
      "UNK 's is a is the the\n",
      "rangers need to to rangers\n",
      "los angeles daily news budget\n",
      "bonds tech to to ratings\n",
      "study finds a to to in in\n",
      "scientists 's UNK to to in of\n",
      "UNK augusta the to to in in\n",
      "northridge ## to to in\n",
      "UNK 's to to to to to\n",
      "ucla 's to to in\n",
      "UNK state 's to to the\n",
      "a the for for the the\n",
      "UNK UNK UNK to to in in in\n",
      "california turmoil UNK in in in\n",
      "rangers need to rangers\n",
      "in york new to in in in the\n",
      "britney mcconaughey says to to to to\n",
      "patriots need a for\n",
      "UNK should in in in in the the\n",
      "yankees fargas yankees as to to the\n",
      "UNK 's for for\n",
      "clinton clinton on on\n",
      "study 's in to to to in for\n",
      "UNK 's to to to the\n",
      "UNK owners to to to to to in in\n",
      "airlines 's to UNK\n",
      "if is is the the the the the\n",
      "stocks stocks as as as earnings\n",
      "how to to to the for\n",
      "rangers 's to to to to the\n",
      "china kong 's to to to to to to\n",
      "a a of a a the the the the\n",
      "ucla notre to to to\n",
      "UNK the UNK\n",
      "UNK season the UNK\n",
      "UNK 's the the the the\n",
      "springsteen UNK UNK to UNK\n",
      "UNK 's UNK to to UNK\n",
      "ucla 's to to to in in\n",
      "davies voted to to to the\n",
      "UNK 's UNK to UNK\n",
      "supreme suspects in to to in in in in in\n",
      "nissan paradise to for for\n",
      "davies eager to to\n",
      "<unk> <unk> <unk> to to the the the\n",
      "holocaust of of to to in in\n",
      "toyota 's to to to to to to\n",
      "UNK 's the the to the the\n",
      "UNK the the the of the of\n",
      "<unk> 's the the the the\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "in 's of in to to to in in in\n",
      "wall street stocks as as of\n",
      "UNK 's to at at at\n",
      "UNK words UNK to to in\n",
      "<unk> <unk> <unk> <unk>\n",
      "sorenstam 's to to to to the the\n",
      "selig 's the the UNK\n",
      "china 's to to to at at at\n",
      "stewart gets bryant gordon\n",
      "holyfield 's to to in\n",
      "parcells is to to for for\n",
      "the carolina the of the the the\n",
      "perry stewart to to to to the\n",
      "ucla notre to to in in\n",
      "writer-director 's UNK the to the\n",
      "a 're of of the the the\n",
      "china on on on on to\n",
      "the <unk> of of\n",
      "<unk> of of of 's to in in\n",
      "UNK the the to in the\n",
      "the news service business\n",
      "maddux 's to to to to in in\n",
      "jets broncos to jets to to to\n",
      "discounts 's for for the\n",
      "no. # themselves to to to in in\n",
      "bruins hope to to to for\n",
      "fitch all-star mourning arbitration\n",
      "bush clinton clinton clinton clinton bush in in in\n",
      "holyfield 's to to in in\n",
      "mcdonald 's to to to to to in\n",
      "UNK 's UNK to to the the the\n",
      "a the of of of UNK\n",
      "scientists of on to in in\n",
      "lemieux to to to to\n",
      "google companies to to to for for\n",
      "the the of the\n",
      "UNK 's to in\n",
      "former s 's to to to to to of UNK\n",
      "UNK 's UNK for for\n",
      "it 's the the the for the\n",
      "coyotes sign sign agent to <unk>\n",
      "UNK the for the\n",
      "the <unk> of <unk>\n",
      "UNK 's to of for for\n",
      "tips to to to to to the\n",
      "giants mets to to to to\n",
      "UNK companies the a the the the\n",
      "<unk> <unk> the the of a to the 's\n",
      "UNK 's 's to to to in\n",
      "UNK UNK for in in\n",
      "ohio women for cup cup cup\n",
      "devils sox to to to in\n",
      "UNK 's a to to to to in\n",
      "selig 's for for\n",
      "UNK women tournament the of the of the\n",
      "busch 's to to to to the\n",
      "knight sent to expansion\n",
      "scientists of on to to in in\n",
      "pamela roberts to to to for\n",
      "couples 's UNK to to in in\n",
      "<unk> <unk> wins wins the for of the\n",
      "the <unk> of of UNK\n",
      "nissan emerges to to to for\n",
      "obama obama to obama to to to to to\n",
      "simpson 's iphone to to for to for\n",
      "microsoft &amp; to for for for for\n",
      "stephen 's UNK to to on\n",
      "a the hottest a a a to in the\n",
      "a chefs the the the the the\n",
      "disney 's a a of of of UNK\n",
      "ventura 's UNK for UNK\n",
      "pope calls to to to talks\n",
      "australian stock market closes higher\n",
      "air closes in in\n",
      "foreign exchange exchange in higher\n",
      "s. korean main as on #.# percent\n",
      "south africa to host to world games games\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china chinese 's to to to to to to to to to\n",
      "beijing to province to to in\n",
      "dollar dollar exchange higher\n",
      "beijing 's build ancient\n",
      "ecb stock exchange ends higher\n",
      "pakistan pm minister resigns resignation\n",
      "mutombo wants to to surgery\n",
      "s. korean stock down\n",
      "dollar trades lower ## yen in tokyo\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar trades lower lower ## in tokyo\n",
      "dollar trades at lower yen in tokyo\n",
      "stocks close higher in mexico brazil\n",
      "south korea to to for\n",
      "china 's on international opens in\n",
      "ethiopia launches resume to to\n",
      "south to to to to to for in\n",
      "china china of 's 's 's in\n",
      "dollar down in upper ## yen range tokyo\n",
      "dollar remains at lower ## yen range\n",
      "study finds to treatment to cancer cancer\n",
      "bulgarian stock market ends higher higher\n",
      "german stock exchange exchange rates\n",
      "dollar trades lower ## yen in tokyo\n",
      "dollar at at upper yen yen in tokyo\n",
      "german stocks open higher\n",
      "international china artists in in china\n",
      "hang seng china enterprises index up\n",
      "us army to to to to in\n",
      "# killed in injures\n",
      "china lead hong #-# at\n",
      "hk kong share prices close #.##\n",
      "german stock exchange exchange rates\n",
      "new zealand rates closes higher\n",
      "small crashes crashes in\n",
      "crude prices decline on u.s.\n",
      "german stock exchange exchange rates\n",
      "hong kong stocks close higher\n",
      "uganda to to to to talks\n",
      "world to for in world\n",
      "judge of of in in in in\n",
      "australian dollar closes higher\n",
      "nato parliament to to on\n",
      "chronology to on on on in\n",
      "malaysia confirms ##th case of a\\/h#n# flu\n",
      "beijing of on to held held held in\n",
      "australian dollar closes higher\n",
      "wings signs to to to with deal\n",
      "dollar at at upper yen yen in tokyo\n",
      "nikkei opens #.## pct higher\n",
      "dollar trades in upper ## yen in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar trades at upper yen yen in\n",
      "tokyo shares end higher\n",
      "beijing 's china market in\n",
      "china 's first 's 's 's in\n",
      "australian stock market rises\n",
      "philippine shares close #.# percent lower\n",
      "judge editor UNK UNK in in in\n",
      "uganda union to to\n",
      "dollar trades to upper yen yen in tokyo\n",
      "malaysia tin market closes lower\n",
      "china 's first of of in\n",
      "dollar trades lower lower yen in tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "<unk> beats goias #-#\n",
      "london stock market closes higher\n",
      "tunisia beats luxembourg #-# in cup qualifier\n",
      "strong earthquake hits central\n",
      "wall street stocks lower on\n",
      "wall street stocks fall on\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar trades at ## yen in tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar down to upper yen yen in tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar remains at lower ## yen range\n",
      "a 's of a of a in in in in\n",
      "tokyo stocks end lower\n",
      "dollar trades in upper ## yen in tokyo\n",
      "stocks close higher in brazil brazil\n",
      "australian stock market closes\n",
      "former <unk> president <unk> <unk> dies ##\n",
      "new to to to to to to\n",
      "beijing to to to to in\n",
      "beijing to host international fair fair\n",
      "british stock exchange exchange rates\n",
      "german stocks open higher\n",
      "dollar remains lower lower lower ## yen\n",
      "german stocks open higher\n",
      "beijing to to to to fair\n",
      "wall street rally as of of\n",
      "ioc president to to for president\n",
      "chinese mayor meets thai president\n",
      "stock stock exchange closed for\n",
      "chinese to to to to to to in in\n",
      "UNK of conference opens in in\n",
      "us rates rate in in\n",
      "mexican stocks unemployment to in in\n",
      "thai prime president pm to for for\n",
      "new opens embassy opens in\n",
      "international of of of opens opens opens\n",
      "## injured in in in in in\n",
      "chinese hk exhibition on china\n",
      "bush passes <unk> development in\n",
      "bomb explodes in in in\n",
      "small plane derails in in in\n",
      "chinese scientists find large on in\n",
      "oil prices fall higher\n",
      "dollar trades to upper yen yen in tokyo\n",
      "thai stock end close\n",
      "wall street fall on on\n",
      "stocks close higher in mexico brazil\n",
      "dollar trades at lower yen yen in tokyo\n",
      "ioc president president president\n",
      "dollar trades at upper yen yen in\n",
      "china confirms swine swine in\n",
      "dollar trades lower ## yen in tokyo\n",
      "dollar remains lower lower lower ## yen\n",
      "small killed in in in crash\n",
      "tokyo stocks open higher\n",
      "ecb main reference exchange rates\n",
      "hang seng china enterprises index up\n",
      "chinext index opens lower friday\n",
      "dollar trades in upper ## yen in tokyo\n",
      "dollar down in upper ## yen range tokyo\n",
      "chinext index opens lower wednesday\n",
      "moderate quake hits southern\n",
      "chinext index opens lower wednesday\n",
      "myanmar to to to to\n",
      "ethiopia government to to to to\n",
      "wall street stocks end mixed\n",
      "international on on international opens opens\n",
      "china 's china #b billion to in in\n",
      "dollar trades at lower ## yen in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "london stock market london\n",
      "man killed killed in in in\n",
      "tokyo stocks open higher\n",
      "dollar trades at ## yen in tokyo\n",
      "stocks close higher in mexico brazil\n",
      "stocks close higher in mexico brazil\n",
      "chinext index opens lower monday\n",
      "wall street stocks fall on\n",
      "chinext index opens lower wednesday\n",
      "un UNK launches in\n",
      "dollar trades at upper yen yen in tokyo\n",
      "results UNK fair ends in in\n",
      "uganda to hold diplomatic\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> at\n",
      "UNK the the the the the\n",
      "south korean sign UNK agreement\n",
      "china russia vow to boost cooperation cooperation\n",
      "hong kong stocks open higher\n",
      "dollar trades lower ## ## in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "venezuelan president arrives in for\n",
      "australian stocks ends higher\n",
      "air hold in in in\n",
      "dollar down in upper ## yen range tokyo\n",
      "dollar trades at lower ## yen in tokyo\n",
      "u.s. senate to to on\n",
      "hang seng china enterprises index up\n",
      "world 's flame to to to for for\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar down in upper ## yen range tokyo\n",
      "gore of president to to in\n",
      "china ecuador sign cooperation cooperation cooperation\n",
      "eu to to to to for in in in\n",
      "australian stock market closes\n",
      "south korean president ruling to to to\n",
      "tanzanian president visits visits\n",
      "china opens opens international opens opens\n",
      "celtic to to to cup cup cup\n",
      "fujian UNK province in\n",
      "u.s. stocks trade mixed\n",
      "lebanese recognizes UNK\n",
      "germany wins women 's team gold at\n",
      "<unk> wins women 's 's ###m gold\n",
      "psv united ronaldo real madrid madrid\n",
      "facts 's to election\n",
      "u.s. stocks open higher\n",
      "u.s. stocks trade higher\n",
      "china 's on on expressway\n",
      "european stock stock end higher\n",
      "dollar remains at lower ## yen range\n",
      "south africa to UNK to in\n",
      "china china china china chinese\n",
      "beijing l on on opens opens\n",
      "hong kong shares close #.## percent\n",
      "australian dollar closes higher\n",
      "fujian 's project in in\n",
      "chinese premier meets meets president\n",
      "tokyo stocks open higher dollar up against yen\n",
      "results of wins games at\n",
      "chinext index opens lower friday\n",
      "dollar trades lower ## ## in tokyo\n",
      "chinext index opens lower friday\n",
      "chinext index opens lower wednesday\n",
      "chinext index opens lower wednesday\n",
      "australian stock market drops\n",
      "dollar trades at lower ## in tokyo\n",
      "dollar trades in upper ## yen in tokyo\n",
      "rangers sign sign to\n",
      "dollar trades at lower ## in tokyo\n",
      "new zealand sharemarket closes higher\n",
      "chinese scientists hong chinese to in\n",
      "german stocks open higher\n",
      "dollar remains in upper ## yen range tokyo\n",
      "beijing UNK project in in\n",
      "schwab lawyers to to to to to to\n",
      "china hk exhibition opens opens in\n",
      "china hk on on 's to\n",
      "police government UNK to in in\n",
      "german stocks open higher\n",
      "london stock market opens higher\n",
      "tanzanian president leaves visit visit to\n",
      "stocks close lower in costa rica flat flat\n",
      "german stocks open higher\n",
      "new senate cut development in in in\n",
      "phelps wins to to to at world at at at at\n",
      "us of of #,### in in\n",
      "dollar trades at mid-### yen in\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar trades narrowly to yen yen tokyo\n",
      "jakarta stocks close lower\n",
      "dollar trades at lower yen yen in\n",
      "german stocks open higher\n",
      "bulgarian stock market ends higher higher\n",
      "bulgarian stock market ends higher higher\n",
      "dollar trades at lower yen in tokyo\n",
      "china promotes china in in\n",
      "pope president to to to to\n",
      "international conference fair opens in in\n",
      "russia to to international to\n",
      "stocks stocks stocks in\n",
      "united to to to world world cup\n",
      "mexico beat slovakia #-# in\n",
      "<unk> of of 's 's in\n",
      "sino-british jlg lifelong in in\n",
      "<unk> <unk> <unk> UNK UNK\n",
      "recession 's 's in in\n",
      "dollar trades in upper ## yen in tokyo\n",
      "new zealand sharemarket closes higher\n",
      "hong kong stocks close #.## percent lower\n",
      "uganda 's UNK to\n",
      "holmes UNK <unk> dies dies\n",
      "malaysia confirms first swine flu cases cases\n",
      "german stocks open higher\n",
      "chinese shares close on on pct on\n",
      "chinese shares close #.## pct on trade trade\n",
      "shanghai promotes development operational\n",
      "results of opens opens in in\n",
      "london stock exchange up\n",
      "australian stock market rises\n",
      "lindsey wins wins grand prix\n",
      "kuala lumpur stocks close lower\n",
      "dollar remains lower lower lower yen yen\n",
      "german stocks open higher\n",
      "dollar down to upper yen yen in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar trades to upper yen yen in tokyo\n",
      "dollar trades at lower ## yen in tokyo\n",
      "stocks close higher in brazil brazil\n",
      "stocks close higher in brazil brazil\n",
      "UNK 's to arbitration in\n",
      "german stocks open higher\n",
      "athens to to to at at\n",
      "egypt and with #-# #-# in cup\n",
      "oil futures fall fall\n",
      "wall street stocks lower on\n",
      "german stocks open higher\n",
      "u.s. stocks open higher\n",
      "UNK hk in in china\n",
      "stocks close higher in mexico brazil\n",
      "philippine stocks close higher\n",
      "international hosts on on of in\n",
      "shenzhen b-share market down at wednesday close\n",
      "australian stocks record record\n",
      "crude prices decline on weak expectation\n",
      "chinese trade fair opens in\n",
      "tokyo stocks close higher\n",
      "pope president meets to to visit to\n",
      "german stocks exchange higher\n",
      "<unk> <unk> <unk> wins <unk> <unk> film film\n",
      "german stock exchange exchange rates\n",
      "tokyo shares end higher\n",
      "tokyo stocks end lower dollar up against yen\n",
      "former <unk> UNK <unk> dies dies at\n",
      "china 's production upper\n",
      "german stocks end higher\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar trades at lower yen in tokyo\n",
      "china 's first website of of\n",
      "asian to for asian in in\n",
      "some researchers uses to to to to\n",
      "ecb stock exchange exchange higher\n",
      "us man in in in trying spears to in in in in\n",
      "u.s. stocks open higher\n",
      "chinese gears marks chinese in in\n",
      "dollar down in upper ## yen in tokyo\n",
      "dollar trades lower lower yen in tokyo\n",
      "chinese shares stocks up on on on\n",
      "australian stock market rises\n",
      "brazil 's ### to in\n",
      "## of of demanding in in in\n",
      "new zealand stocks close flat\n",
      "perry gets to to in\n",
      "new senate passes operational in\n",
      "brazil to market copa in\n",
      "shanghai b-shares close #.## percent lower trade trade trade\n",
      "eu 's to to to to to in\n",
      "UNK court UNK to to in in\n",
      "in york in to to in in in in\n",
      "new zealand stocks close flat\n",
      "bush 's to bush bush\n",
      "un calls urges to to to to\n",
      "new zealand stocks close #.## percent\n",
      "rubber futures close higher on smaller volumes\n",
      "australian sheffield shield cricket\n",
      "australian sharemarket shield taiwan\n",
      "china 's users in\n",
      "gold opens in in hong kong\n",
      "indian korea to on to in\n",
      "thai stocks prices #.## percent percent\n",
      "UNK wins wins for at cup\n",
      "lemieux riley to to to in\n",
      "rubber futures close on on volumes volumes\n",
      "bank 's bank bank interest rates\n",
      "UNK 's in to to to in in in\n",
      "taiwan stock market closed\n",
      "un chief urges to to to in\n",
      "treasury yields on as as of\n",
      "germany wins women 's 's ###m at\n",
      "new zealand stocks close #.## percent\n",
      "dolphins fires <unk> UNK on\n",
      "UNK beats rattles combined\n",
      "rossi wins in grand prix\n",
      "beijing of to to to in in in\n",
      "beijing of beijing to held to held in\n",
      "thailand financial markets closed\n",
      "malaysia stock exchange exchange\n",
      "a 's 's to to to to of 's\n",
      "beijing 's host international 's opens opens\n",
      "UNK of to in in in in in\n",
      "u.s. forces forces in in in in\n",
      "podium wins wins wins of super-g\n",
      "south africa comes to to to to in in\n",
      "new zealand stocks close #.## percent\n",
      "new zealand stocks close #.## percent\n",
      "webb shines to at at\n",
      "how to can a the the\n",
      "rubber futures close higher on smaller volumes\n",
      "sri lanka says forms to to off\n",
      "barkley is to to to for\n",
      "a of of of 's 's 's in 's of of\n",
      "<unk> wins de\n",
      "hong kong closed markets for for\n",
      "un lawmaker says to to to to to with with\n",
      "bush 's to to to to to\n",
      "new zealand stocks close #.# percent\n",
      "olmert president president to to to to to president president\n",
      "british foreign leaves leaves visit to\n",
      "indian shares close lower\n",
      "new reports first case of disease\n",
      "UNK 's to to to to to to in\n",
      "schumacher schumacher wins san grand prix\n",
      "us 's of iraq of iraq in in\n",
      "arafat government to to to to in\n",
      "germany wins biathlon 's biathlon relay\n",
      "taipei shares close #.# percent lower\n",
      "hong kong markets closed for for\n",
      "rain delays for play for in\n",
      "china financial markets closed for\n",
      "asian financial markets closed\n",
      "taiwan financial markets closed\n",
      "hong kong markets closed for for\n",
      "vietnam to to nuclear to to to to to\n",
      "european 's financial markets\n",
      "china financial markets closed\n",
      "indonesia financial markets closed\n",
      "us sales prices to to to to on on\n",
      "indonesia financial markets closed\n",
      "UNK of of ends in\n",
      "new zealand stocks close flat\n",
      "o'neal o'neal to to for\n",
      "former <unk> <unk> <unk> dies at ##\n",
      "UNK extends contract to to to from contract\n",
      "russia launches boost investment\n",
      "bayern says he to to for for\n",
      "hong kong shares close #.#\n",
      "china to international international to agreements\n",
      "australia zealand new zealand\n",
      "cowboys mets mets to\n",
      "maradona bacon to to to for\n",
      "mccain says to to to\n",
      "it 's is the the the the the the the\n",
      "new 's defend to to for in\n",
      "eu says to to to to nuclear\n",
      "us fall fall as as in\n",
      "nicklaus ripken to to in\n",
      "venus UNK hunter hunter\n",
      "after a to to the the the the the the the\n",
      "lyon president president to to on\n",
      "<unk> wins wins wins marathon marathon marathon\n",
      "UNK striker <unk> joins joins for for\n",
      "agassi williams to to in at in\n",
      "simpson sues gives simpson simpson for to for in\n",
      "UNK ivy UNK to to UNK\n",
      "the the to to the the the\n",
      "london stock exchange up at midday\n",
      "intel 's 's to as in in\n",
      "phelps to to to to to to at at at\n",
      "armstrong armstrong hoya for tour tour tour tour tour\n",
      "microsoft jersey companies to to for to for for for\n",
      "singh wins for at at\n",
      "UNK the the to of of of\n",
      "pope calls calls urges to to to\n",
      "<unk> <unk> <unk> <unk> <unk> at at\n",
      "ethics indicted sue corruption in\n",
      "citigroup #q #q profit profit ## percent\n",
      "ford to to to to to to\n",
      "UNK 's to to to to to to with with\n",
      "a the of the the the the the the\n",
      "<unk> <unk> becomes retires\n",
      "athletes overcomes to to to in in\n",
      "bush 's of bush bush bush to the to\n",
      "boeing 's to to to in in\n",
      "ucla 's to to in game\n",
      "rangers 's yankees to to in the\n",
      "fire workers at in in\n",
      "cowboys broncos sign outfielder defensive to to contract contract\n",
      "holocaust zoo of to to of in\n",
      "lasorda 's 's to he to to in the\n",
      "united states to to team in\n",
      "UNK robinson a at\n",
      "UNK 's jr. debuts to to to in in\n",
      "novelist <unk> <unk> poet at\n",
      "nasa wants files space for\n",
      "lemieux hire named selanne as coach coach\n",
      "former <unk> <unk> <unk> dies at ##\n",
      "obama says to to to to to to to\n",
      "nadal roddick roddick to french at\n",
      "outgoing says to to to to\n",
      "<unk> <unk> <unk> dies dies dies at\n",
      "dollar mixed gold\n",
      "UNK UNK to to in\n",
      "ford to to $ for for\n",
      "european stock markets in\n",
      "stocks up in mexico brazil argentina\n",
      "UNK 's UNK the the\n",
      "red wings defenseman terms to to overtime\n",
      "UNK 's to to at\n",
      "abc 's UNK to in\n",
      "yankees smoltz yankees to\n",
      "latest developments to to in in\n",
      "tyson williams to tyson tyson\n",
      "fifa to to receive on\n",
      "gore 's 's to to to of in\n",
      "<unk> <unk> <unk> <unk> <unk> dies at ##\n",
      "powell <unk> to to to in in\n",
      "fifa to marching to to to\n",
      "<unk> UNK to for for for\n",
      "UNK UNK prix for for in\n",
      "bucs delivers for role\n",
      "knicks 's to to to to in in\n",
      "mavericks ## chargers #\n",
      "germans to to to to to to world cup\n",
      "jennifer spears says to for for for\n",
      "perry bacon to to to to in in\n",
      "UNK 's a for for\n",
      "davies gets to to in\n",
      "giants giants to of to to\n",
      "nbc owners to to to\n",
      "treasury prices in in\n",
      "kings sox to to to to to\n",
      "the giants to to to to\n",
      "vikings vikings chargers to\n",
      "vikings and to to to\n",
      "UNK of of to in in in\n",
      "a york in in a a a a\n",
      "phelps wins to to at at at at at\n",
      "eu 's to to to to to to to for\n",
      "analysts 's to UNK to for\n",
      "agassi davies with\n",
      "gore to of to to to to to china\n",
      "mysterious <unk> fool\n",
      "kings get to to to\n",
      "rangers sign defenseman to\n",
      "UNK 's for for at at\n",
      "world winds world world downhill of in\n",
      "obama obama to to to to to\n",
      "world cup downhill cup canceled to\n",
      "tottenham signs signs signs contract contract contract\n",
      "new people killed in in in province\n",
      "UNK wins ryder at at at cup\n",
      "vista owners to to to to to to to\n",
      "canada inflation rate falls in\n",
      "robin 's to hall hall nominees fame\n",
      "a the of the the the the the\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "jennifer hudson wife wife for baby\n",
      "meat of of to to to to in in\n",
      "strong earthquake hits taiwan\n",
      "in a a a a a a a in\n",
      "gore 's of saddam to to 's 's 's\n",
      "holyfield 's to to to in\n",
      "stocks mixed after in trading\n",
      "singh montgomerie UNK to in at at open\n",
      "dollar falls to mid-### yen yen tokyo\n",
      "treasury prices fall as as of\n",
      "bush obama obama obama\n",
      "UNK joins <unk> joins new coach\n",
      "fossett 's 's to to to to in in\n",
      "after of of to to to to of of\n",
      "bush 's to bush to bush to bush\n",
      "study parks UNK physical of UNK\n",
      "world cup cup cup cup cup\n",
      "UNK 's to to in\n",
      "UNK fires to to for for\n",
      "toyota s to to to to to to to in\n",
      "UNK wins world cup\n",
      "mtv 's to to to for of the\n",
      "it bowl a a for the the\n",
      "janet UNK to to on awards\n",
      "brazil cup to world cup cup cup\n",
      "china markets closed closed for closed holiday\n",
      "mourinho says to to to to to to to for\n",
      "ballesteros faces for\n",
      "lindsey wins wins world world cup\n",
      "bush 's bush bush bush bush the the the to to\n",
      "new york to a a in a\n",
      "us convicted of of of of of of of\n",
      "us convicted of threatening of of in\n",
      "UNK 's to extension in\n",
      "stocks mixed in early trading\n",
      "selig 's UNK to for UNK\n",
      "vikings release hire to\n",
      "UNK ready to in in\n",
      "ohio dame to to to in\n",
      "ripken says to to to to in game\n",
      "toyota to to to to to to in\n",
      "nbc should for for\n",
      "ankiel bacon to to for\n",
      "simpsons 's UNK to to the\n",
      "obama joy obama to to to to\n",
      "blunt 's of to to in UNK\n",
      "london 's ftse-### index up ##.##\n",
      "small plane crashes in crashes\n",
      "commonwealth president president resigns to\n",
      "former s to to to to to for for\n",
      "UNK to inks for for\n",
      "bush to to bush to to to\n",
      "uganda parliament diplomatic to to\n",
      "zaccheroni withdraws from from\n",
      "celtic 's to to to in in\n",
      "pakistan parliament establish no-confidence\n",
      "<unk> <unk> <unk> <unk> <unk> <unk>\n",
      "jennifer hudson sues for for\n",
      "tyson leno to to for UNK\n",
      "UNK brothers UNK to in\n",
      "UNK 's in to a a in the the\n",
      "devils state to to to ##-##\n",
      "panthers re-sign <unk> <unk> <unk>\n",
      "UNK grabs to to at at at\n",
      "clippers fires on\n",
      "man kills in in at in\n",
      "activate wins named to to to the\n",
      "bush 's to to to to to\n",
      "janet downey s to to to of UNK\n",
      "tokyo stock closed closed for holiday holiday\n",
      "els wins to at at at at\n",
      "pope 's president to to to to\n",
      "phillips delivers a for the\n",
      "woods woods to woods at at\n",
      "gold prices close lower in\n",
      "burton 's to to to on in in\n",
      "arsenal milan to must-win fa in\n",
      "<unk> 's for the the\n",
      "conan 's to receive in in\n",
      "roma extends joins to from from\n",
      "phelps 's to on on at at at at at\n",
      "pakistan parliament to to to\n",
      "jennifer singer says to to to baby\n",
      "cowboys release release on from\n",
      "us police in convicted of of in\n",
      "judge jury in sue in\n",
      "UNK wins wins wins at at marathon\n",
      "phelps wins wins at at at at\n",
      "glenn 's UNK for for UNK\n",
      "UNK 's 's to the the the the the the the\n",
      "UNK 's UNK to in in\n",
      "webb wins for at at\n",
      "china beats gold 's table tennis team\n",
      "a 's the the the the the the the\n",
      "f# to to to to for\n",
      "UNK schools in in in\n",
      "turkey 's to cup world cup world world world world cup cup\n",
      "beckham says to beckham to to to to england\n",
      "spain to to to world world cup cup\n",
      "<unk> breeders to to to 's\n",
      "f# says to contador to to to to to for for\n",
      "mickelson stewart to to the the the the\n",
      "rep. 's to to to in\n",
      "woods woods to to woods\n",
      "armstrong de to to to to to for prix\n",
      "UNK cup sure cup cup cup to to world cup\n",
      "no. ## no. ##\n",
      "randy singer musician UNK dies at ##\n",
      "world to largest to to in in\n",
      "world of of of of in in\n",
      "dollar dollar gold gold in\n",
      "simpsons 's UNK the the\n",
      "explosion explosion explosion baghdad\n",
      "bush 's to to on on on\n",
      "no. # notre ##\n",
      "the the of the the UNK\n",
      "UNK 's UNK to to UNK\n",
      "lyon to squad to to on\n",
      "deschamps fires as as manager manager\n",
      "u.s. 's to to to to in in\n",
      "home prices on retail retail\n",
      "couples ivy to to to to in in\n",
      "<unk> 's 's to his the the the the\n",
      "tropical storm becomes category in\n",
      "psv beats to to dutch dutch\n",
      "UNK UNK to to in at at\n",
      "north calls to to to to in\n",
      "mickelson gets to for for at at at\n",
      "german 's interest rates interest\n",
      "wall street defend prices the on\n",
      "police police kill suspected in in\n",
      "fifa to to to to in in in in\n",
      "UNK 's ryder at in cup\n",
      "UNK the the to of\n",
      "UNK 's to to of the\n",
      "rangers need to to to to\n",
      "UNK 's on for in\n",
      "northridge 's to to to to in\n",
      "UNK returns UNK to in in\n",
      "share prices close higher\n",
      "share prices close prices\n",
      "<unk> 's of a a a of of of\n",
      "share prices close higher higher\n",
      "flamengo fires coach coach coach\n",
      "hong stock markets closed for for holiday\n",
      "scientists of of to to in in in\n",
      "strong earthquake hits central\n",
      "tickets to to to to in cup\n",
      "deschamps striker to out of for team\n",
      "shuttle s shuttle to to to to in\n",
      "nadal withdraws withdraws to at at\n",
      "court court to to to in in in\n",
      "two militants militants in in in\n",
      "singer jackson to to to in in\n",
      "pope president says to to to in next\n",
      "prosecutors sues madoff dangerous\n",
      "cuba 's to to to in\n",
      "UNK UNK to for divorce\n",
      "author of of UNK UNK of of UNK\n",
      "shuttle to files to to for for station\n",
      "shuttle shuttle files to for for for station\n",
      "thailand to to import to\n",
      "britney spears files files for for\n",
      "forsberg has has surgery surgery\n",
      "after years 's to to to to in\n",
      "baylor 's for at ryder\n",
      "south korea to to to to in in\n",
      "world 's shoppers to to in in\n",
      "united 's to to world in in\n",
      "mcdonald 's to to to to to for\n",
      "brazil to squad for world world cup cup\n",
      "the <unk> <unk> sundance\n",
      "chinese chinese chinese to to to to\n",
      "armstrong armstrong armstrong for in in\n",
      "commonwealth games games championships african\n",
      "manchester 's hamilton to to to for\n",
      "singh gets to to to to in in\n",
      "spurs fires to manager\n",
      "lippi banned to to for for\n",
      "UNK wins wins wins tour of tour\n",
      "els wins to for the at at at at\n",
      "stocks mixed in early trading\n",
      "russia to to to world world world cup cup\n",
      "UNK shines UNK the\n",
      "# killed in in in in in\n",
      "lindsey wins wins stage tour tour of tour\n",
      "holyfield 's to to to to in in\n",
      "it 's a the to the the the\n",
      "us pleads of guilty of stalking in in\n",
      "clippers ## chargers ##\n",
      "northridge ## no. ## ##\n",
      "jennifer 's 's of of of\n",
      "UNK 's to to the the the the the\n",
      "notre state to to to to to in\n",
      "if 's a the the the the the the\n",
      "bomb explosion in in in in\n",
      "clippers ## chargers #\n",
      "usc 's UNK to to in\n",
      "nbc 's a to to the the the\n",
      "it 's to to to the the the\n",
      "mtv <unk> <unk> the the the <unk>\n",
      "lemieux stars stars to in\n",
      "UNK 's UNK UNK to to of UNK\n",
      "police police kill suspected in in\n",
      "moderate earthquake shakes central romania\n",
      "dodge 's to on in\n",
      "u.s. to to to to to in in in\n",
      "UNK cup to cup cup world in world cup\n",
      "els 's to to the the the at the the\n",
      "UNK 's for to for at ryder\n",
      "the women women women women women 's at world\n",
      "patriots sign pick <unk> pick\n",
      "london 's prices in\n",
      "fire fire in in in in\n",
      "cyberspace of UNK in in\n",
      "court court refuses to for for\n",
      "matthew UNK to receive expecting nominees awards\n",
      "UNK 's for on the the the at cup\n",
      "UNK watching UNK UNK of of\n",
      "stephen 's to to of of awards\n",
      "usc 's UNK to to in in\n",
      "jennifer hudson says netrebko she mtv to for\n",
      "UNK shows consider\n",
      "stocks mixed after jobs jobs\n",
      "duval likes to in\n",
      "UNK jackson to receive to in in\n",
      "matthew mcconaughey 's star star mtv in in of of\n",
      "UNK 's to to in at at\n",
      "UNK ratings ratings for\n",
      "UNK takes sbc at classic\n",
      "bucs is to to to for the\n",
      "woods woods to at at woods\n",
      "activate scores named to to to the\n",
      "the the seize for the\n",
      "exhibit of UNK to in in UNK\n",
      "UNK 's UNK to UNK\n",
      "dollar mixed against euro other\n",
      "lemieux says to to to to to\n",
      "barkley o'neal to surgery\n",
      "rangers need to to in in\n",
      "no. st. no. ## ## ##\n",
      "hbo UNK UNK to the\n",
      "UNK hilton s to to to to in\n",
      "police of of of to in in in in\n",
      "singh busch to to at at the\n",
      "<unk> 's of of of a of of\n",
      "new york to to in in\n",
      "armstrong armstrong hoya hoya to for for\n",
      "mets mets mets to to to to\n",
      "UNK voted UNK to to player of the\n",
      "gore 's 's to to to to to in\n",
      "south africa africa south south to korea world world world world world world\n",
      "new of advocate to to in\n",
      "disney 's is the the\n",
      "UNK bowl a a for for\n",
      "sarah 's says her to a a a in in\n",
      "south to to to to olympic olympic\n",
      "tokyo shares end dollar\n",
      "venus williams to safin wimbledon wimbledon at at\n",
      "tottenham signs <unk> <unk>\n",
      "arsenal milan says to to to to to\n",
      "jennifer s to wife birth to baby\n",
      "UNK s cup to to in world\n",
      "dollar falls higher in\n",
      "in a a a a a a a a for\n",
      "rusedski withdraws play play in league\n",
      "mother police accused of of of of in in\n",
      "<unk> named named as new coach coach\n",
      "china 's to to relay relay relay relay relay\n",
      "matthew guitarist to receive to divorce\n",
      "UNK to to to to at to to to at\n",
      "nicklaus 's to to to to in the\n",
      "UNK 's the the the\n",
      "lemieux to he to to for nhl\n",
      "stocks edge as as as earnings\n",
      "UNK of of of of in in in\n",
      "israel calls to talks with\n",
      "microsoft to to for for for for\n",
      "albania beats to #-# in friendly\n",
      "mets mets mets to to\n",
      "intel 's to for for for\n",
      "safina wins UNK in at at\n",
      "crude oil futures as as opec\n",
      "united to to to world world\n",
      "UNK to to to to to to in\n",
      "<unk> 's 's 's to to to of 's\n",
      "spain to to to cup world cup cup cup\n",
      "reba sinatra 's to to on\n",
      "boeing insurance passes to in in\n",
      "jagr named named to to to the\n",
      "britney hudson wife wife to for\n",
      "bomb police in in in in\n",
      "actor singer 's birth to baby\n",
      "i 's the the the\n",
      "pakistan pm to urges to in\n",
      "us of production in in in in\n",
      "heath is a a a UNK\n",
      "UNK of of zoo in in\n",
      "france 's world world world world world world world world\n",
      "buchanan 's on for UNK\n",
      "inter to to to to\n",
      "west to contract to to contract coach coach\n",
      "south 's to to world world world world world world world world cup\n",
      "zimbabwe 's says to to to for\n",
      "london 's prices up at\n",
      "obama s to obama to\n",
      "dollar dollar gold gold in\n",
      "stocks mixed after early trading\n",
      "bayern striker to to to with weeks\n",
      "eagles hire to to as as coach\n",
      "uganda government to in\n",
      "venus withdraws from wimbledon wimbledon\n",
      "bayern munich to out to to to weeks weeks injury\n",
      "australia to to to world world in in\n",
      "judge of inmate in in in\n",
      "UNK bowl for for\n",
      "pepperdine 's to to to the the\n",
      "UNK to threaten in in\n",
      "us funds hardware to to to to to\n",
      "UNK 's to at at\n",
      "the the the the\n",
      "some the to to on the\n",
      "jury pleads pleads guilty in in\n",
      "stocks edge after jobs jobs\n",
      "a town of a in in\n",
      "<unk> <unk> wins wins marathon marathon\n",
      "after 's to to to to to to in in in\n",
      "former singer and wife to divorce in\n",
      "<unk> <unk> sets wins at at olympic\n",
      "tyson bacon to to to for\n",
      "moderate earthquake hits hits\n",
      "us yields fall as as in in\n",
      "<unk> <unk> UNK of UNK\n",
      "tokyo stocks slip dollar higher against yen\n",
      "UNK 's to to to to to to to the\n",
      "sorenstam 's for in classic\n",
      "scientists reform to to to to in in\n",
      "a is a a a a in in\n",
      "ventura of UNK in in in\n",
      "bush 's on\n",
      "israeli troops kill in in in in\n",
      "UNK coach to to to to in\n",
      "UNK of of of of in in\n",
      "england scores to to to to to to in\n",
      "<unk> named <unk> <unk> #-#\n",
      "wales and albania with #-# in in ####\n",
      "buchanan 's to to to in in\n",
      "uk group to to to to to to in\n",
      "mourinho says to to to to to to to with\n",
      "UNK state to in\n",
      "buchanan potter to to to to of UNK\n",
      "obama obama 's to to to to\n",
      "arsenal milan first for fa serie serie\n",
      "former grand prix hunter\n",
      "UNK 's UNK to in\n",
      "UNK of the UNK in <unk>\n",
      "bayern striker to to to ac to to bayern\n",
      "stocks stocks mixed as as reports\n",
      "janet 's harvey star to to to in of of\n",
      "johannesburg stocks exchange to\n",
      "dollar falls against in currencies\n",
      "china 's to to to to to\n",
      "the 's the the the the the the the\n",
      "panthers anderson notre on in\n",
      "webb cruises to to at at\n",
      "chelsea 's to to to for for\n",
      "UNK 's to but to in\n",
      "judge court to to to to to in\n",
      "former of former of <unk> <unk> dies dies ##\n",
      "<unk> <unk> <unk> <unk> <unk> <unk>\n",
      "rep. 's to to to in in\n",
      "bush calls for to to to\n",
      "moderate earthquake shakes central\n",
      "london stock prices in lower\n",
      "california 's to to to to in in\n",
      "share prices close higher higher\n",
      "no. stars to to in in in cup\n",
      "UNK 's UNK UNK to to in UNK\n",
      "UNK of to to for\n",
      "UNK wins to at at at cup\n",
      "UNK 's the\n",
      "matthew mcconaughey wife receive expecting child\n",
      "greece to to to to\n",
      "boeing 's to to to to to to to\n",
      "mickelson wins for for at at at classic\n",
      "us soldier killed in soldier in\n",
      "michael <unk> wins receive to at <unk>\n",
      "australia africa toss host host in in in in in\n",
      "lindsey vonn wins straight world cup cup\n",
      "in york of a in in in the\n",
      "china 's UNK UNK UNK\n",
      "gore of of a a in in\n",
      "els has to on on the the at cup cup\n",
      "agassi williams to to at\n",
      "sampras davies to to in in\n",
      "police of take in in in in\n",
      "devils beat rip in\n",
      "toyota to to box-office space\n",
      "venus williams on at masters\n",
      "no. ## to to to\n",
      "UNK says to to to to for for\n",
      "beckham says he to to to next\n",
      "psv wins wins for in serie serie\n",
      "lemieux scores hat nba to\n",
      "after to to to to to to to to the olympics\n",
      "world 's world to at at in\n",
      "safin says to to to for for\n",
      "safin roddick to french at at\n",
      "rockies bowl for for for\n",
      "ioc s to to to to to for for\n",
      "UNK to to to to in\n",
      "man accuses in whose of for to in in\n",
      "monday club to of for\n",
      "f# wins to he in in in in in\n",
      "real says he to to\n",
      "microsoft #q #q profit profit as on on\n",
      "a 's a a a a a a the\n",
      "most asian markets close on on on street\n",
      "arsenal milan arsenal united to with with with\n",
      "singh grabs to for at at at\n",
      "armstrong UNK to receive divorce divorce\n",
      "manchester striker to to with with with with\n",
      "moderate earthquake shakes central turkey\n",
      "<unk> <unk> the the of the the\n",
      "tyson says says he to lung to for\n",
      "britney spears says to to for\n",
      "holyfield 's to to to to a\n",
      "UNK 's to to to in in in\n",
      "world 's championships to for at in\n",
      "share prices close higher\n",
      "UNK 's the the to the the\n",
      "busch singh to to to to in in\n",
      "france 's world world world world world world world world world cup\n",
      "london 's exchange up up points\n",
      "beijing to to to to for for ####\n",
      "boeing to to ### for for chrysler\n",
      "us dollar dollar to ### as on\n",
      "police say in dead in in in\n",
      "former s says UNK to to to to in in\n",
      "UNK 's UNK to to <unk>\n",
      "wall street extends on positive\n",
      "chinese kong hong hong to to to for 's\n",
      "the UNK of in in\n",
      "london share prices lower\n",
      "UNK 's UNK UNK of of of\n",
      "federer williams to to to biscayne\n",
      "singh els to to to the the the\n",
      "britney spears sues for conservatorship\n",
      "fire of UNK ballot in in\n",
      "UNK coach to to to for for\n",
      "the the of of the the\n",
      "midfielder signs signs <unk> #-year to to from from loan\n",
      "singh UNK to to to at at at open\n",
      "sorenstam 's to to in in in\n",
      "montgomerie gets to to in at\n",
      "un says says to to to to to to\n",
      "UNK 's a a to the the the\n",
      "boeing 's to to to in in in\n",
      "youtube judge to sue in\n",
      "ucla ivy to to to in\n",
      "rick 's to to to to to to to for\n",
      "phelps s to to to to to for for for\n",
      "sorenstam 's to to to to to to to in\n",
      "serena withdraws withdraws from of open\n",
      "france to to to to world in in cup\n",
      "barcelona united to to to to to\n",
      "if 's to to to of of of of\n",
      "brazil to to for world cup\n",
      "UNK of UNK to to\n",
      "u.s. u.s. related killed in in in\n",
      "author of of to to to of UNK\n",
      "china 's sees in in in in\n",
      "safin says he to to at at at at\n",
      "tottenham signs signs joins\n",
      "deschamps goalkeeper as as coach\n",
      "tyson says he to to to to to to\n",
      "re-sign paulo UNK #-# #-#\n",
      "london stock exchange in higher\n",
      "weir 's to to to to to to to the\n",
      "police police to to to of in\n",
      "UNK 's UNK for\n",
      "citigroup #q profit profit profit on\n",
      "webb klitschko to receive at at\n",
      "arsenal striker to to to milan\n",
      "UNK clooney to to to to to in\n",
      "els wins to for the at at at at\n",
      "moderate earthquake shakes central taiwan\n",
      "miller scores hat for to in win\n",
      "devils sox to to in in\n",
      "springsteen 's to to at\n",
      "devils # devils #\n",
      "webb takes for at at\n",
      "UNK agreements 's to in in in in\n",
      "explosion explosion in in in in\n",
      "UNK coach coach coach coach coach coach coach coach coach\n",
      "shrek UNK UNK to to UNK\n",
      "els wins UNK on on for the at the cup\n",
      "norstrom is a for for\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo stocks lower dollar higher against yen\n",
      "former poet <unk> <unk> dies at at ##\n",
      "martinez riley to to in\n",
      "UNK 's UNK for in\n",
      "UNK state to in\n",
      "clemens 's to to to to in\n",
      "mavericks sox to to to to in\n",
      "broadway 's 's to broadway on for the\n",
      "mavericks # devils #\n",
      "mets mets mets to to to to\n",
      "b-share says he to to to to to to\n",
      "nissan sent trash\n",
      "UNK UNK UNK to to in\n",
      "study 's a to of of UNK\n",
      "giuliani of of UNK of in in in\n",
      "ethics judge sue sue in\n",
      "dolphins recall release UNK to from from pact\n",
      "mavericks ## mavericks #\n",
      "a of of a a a of of\n",
      "ugly 's to its in\n",
      "lemieux hire to to\n",
      "UNK coach to to in in\n",
      "former gibson founder and <unk> dies dies at at ##\n",
      "us says in sent to of to in of in\n",
      "<unk> of of <unk> <unk>\n",
      "chrysler 's sell to to for in\n",
      "china 's to #.#-magnitude to to zoom\n",
      "UNK UNK to receive in in tour\n",
      "a 's is a the the the the\n",
      "UNK UNK UNK for in\n",
      "nissan 's to for for\n",
      "iraq to to opec output\n",
      "share prices close prices\n",
      "us democrats in to to to to to to\n",
      "ripken wants to to for\n",
      "<unk> 's the the the the the\n",
      "UNK 's a a to the the\n",
      "romario says to at in at at at\n",
      "UNK cultures on to to in in in\n",
      "nbc a&amp;m new to to to to in in in\n",
      "UNK wins for for at at\n",
      "former UNK champion dies dies at ##\n",
      "ucla 's to to in game\n",
      "the the the the the the\n",
      "pepperdine 's hat to in game\n",
      "<unk> 's 's\n",
      "south to to to #### #### #### world world world cup\n",
      "london stock prices in\n",
      "conan 's hoya to to to to in in\n",
      "lemieux scores named to to to\n",
      "johnny UNK <unk> dies dies\n",
      "eu parliament new to to to\n",
      "tottenham extends to #-year to contract contract\n",
      "world marks parliamentary on for in\n",
      "janet lee UNK on UNK\n",
      "alpine to to to to in in\n",
      "UNK cup cup cup cup cup cup cup\n",
      "former salad founder of 's dies dies dies at at ##\n",
      "france cup to to to world world world world world cup\n",
      "glenn 's to the the\n",
      "agassi williams to to in at in\n",
      "selanne eager to for\n",
      "beard named named with\n",
      "UNK 's UNK the UNK\n",
      "the the the the of the\n",
      "UNK earns to at in in in\n",
      "UNK UNK UNK UNK in in\n",
      "ruiz 's to to to to in\n",
      "barack robson to to to\n",
      "UNK 's to to to to to to to in\n",
      "gordon says to to to to in\n",
      "a sinatra is the on on UNK\n",
      "selig 's a to in the\n",
      "knicks beat nets to\n",
      "woods woods to woods to at at\n",
      "stocks stocks after after of\n",
      "venus williams withdraws of masters\n",
      "london share prices lower at\n",
      "nyc of of to to to to UNK\n",
      "mavericks rout to to to\n",
      "stocks mixed in early trading\n",
      "moderate earthquake hits central turkey\n",
      "yankees lose yankees to to to to\n",
      "chris mcconaughey wife wife baby\n",
      "reds hire hire as\n",
      "united 's to to world world cup\n",
      "earthquake earthquakes in in\n",
      "rain switches suspended for for for\n",
      "ohio state to to to in in in\n",
      "rusedski withdraws play play of of\n",
      "gagne 's to to to to to the\n",
      "UNK UNK new in of in\n",
      "mccain democrats mccain mccain\n",
      "bush clinton clinton clinton bush bush in in\n",
      "pepperdine gets to at at classic\n",
      "h#n# to to ### to for to million\n",
      "after 's 's to to to to in in\n",
      "home home prices to to to to on\n",
      "oil prices fall on\n",
      "UNK could to on on on to to world world cup\n",
      "earnhardt wins for at\n",
      "supreme activists in sentence of of in in\n",
      "phelps gets to to the the to at cup\n",
      "slovakia wins to to in world cup\n",
      "germans 's to to to to world world\n",
      "<unk> <unk> comes to the the the the the the the\n",
      "united women world cup cup world world world world cup\n",
      "cameroon beats draw #-# in world cup\n",
      "rooney to to to in ####\n",
      "spain to to to world world world world world world\n",
      "weld 's to to to new\n",
      "<unk> named as as coach coach\n",
      "UNK stands to to to in in\n",
      "brazil to to to world world world cup cup\n",
      "ohio state to to to in in to in\n",
      "gingrich nights to to to to to in\n",
      "share prices close higher\n",
      "a of of of of a of the\n",
      "<unk> <unk> <unk> en <unk>\n",
      "precede of of in in in in in in\n",
      "UNK 's for for\n",
      "share prices close higher higher\n",
      "in the of the a a a the of\n",
      "UNK of to to to in in\n",
      "singh cruises to to to to the the\n",
      "bruins 's to to for for\n",
      "new york of a in in\n",
      "fire fire at at at in\n",
      "london stock prices in\n",
      "world 's world on world cup\n",
      "wheat soybeans prices higher\n",
      "palermo wins wins to cup cup cup\n",
      "UNK of of of of in in in\n",
      "# killed killed in in in\n",
      "UNK 's to to to to to in\n",
      "UNK 's to for in\n",
      "fifa s to to to to to #### cup\n",
      "red sign sign <unk> <unk> UNK\n",
      "mccain should mccain on\n",
      "woods woods to woods woods woods\n",
      "tottenham signs sign UNK from\n",
      "alonso alonso to to to in in in to at at at\n",
      "UNK huston a for the the\n",
      "former 's sworn sworn in in in term\n",
      "tottenham says to to to to to to to contract contract\n",
      "police 's pushing to to to to for\n",
      "singer winehouse to guilty to to divorce\n",
      "sorenstam 's to to in at at\n",
      "UNK UNK to to in in the\n",
      "lemieux to toledo to coaching\n",
      "devils devils to to in\n",
      "lindros sanders to to surgery\n",
      "gordon not to to in\n",
      "holyfield stewart is to to on\n",
      "astros hire named to\n",
      "s. reports ##th case cow in\n",
      "UNK UNK UNK to at at <unk>\n",
      "UNK wins wins stage tour tour in the of\n",
      "a provides on on in the\n",
      "a provides of of in\n",
      "un chief urges to to to\n",
      "ac says he to to\n",
      "UNK the UNK the of UNK\n",
      "two explodes in in in in\n",
      "armstrong to to for of in\n",
      "arsenal wins up #-# in in in in\n",
      "perry stewart to to to the\n",
      "judge of UNK in in in\n",
      "actor jovi <unk> writer <unk> <unk> dies at\n",
      "northridge 's to to in in UNK\n",
      "barkley 's to to to to the\n",
      "striker striker <unk> to to to\n",
      "brazil stock stock stock to in in\n",
      "u.s. stocks mixed as bond on earnings\n",
      "UNK 's a to to the the UNK\n",
      "leeds to to to to to on\n",
      "us senate of of on in\n",
      "un to to to to to in\n",
      "safin davies to graf at at\n",
      "air air ### ### in in\n",
      "eu gov to to to to\n",
      "UNK UNK to to of of of of\n",
      "UNK <unk> <unk> to to <unk>\n",
      "a years in to to a in a in\n",
      "<unk> UNK cup cup at at cup\n",
      "south to to to to for for for\n",
      "<unk> women women women women at at the\n",
      "cowboys have n't to to to the\n",
      "a 's wears a a a in in\n",
      "earnhardt 's for in\n",
      "actor musician of UNK dies dies at ##\n",
      "yankees lose yankees to to to to\n",
      "mets fargas to to to to to the\n",
      "mets mets mets to\n",
      "angels fargas to to for for\n",
      "mets mets mets to to to to to the\n",
      "canucks hire defenseman to as\n",
      "stewart delivers to to to for\n",
      "mavericks ## rangers #\n",
      "police police find bodies at in in in\n",
      "woods 's the at at at\n",
      "wolfsburg beats past #-# in brazilian\n",
      "mourinho s to to to to to to to to to for\n",
      "mexican stocks above above ;\n",
      "u.s. 's to to to to to of of of\n",
      "a cup to to to to in in\n",
      "galaxy robson he as at england next\n",
      "london 's exchange index up ##.## points\n",
      "flamengo loans coach retires retires\n",
      "former <unk> of <unk> <unk> <unk> at ##\n",
      "## of in in in in in\n",
      "galaxy 's he to to for for for\n",
      "thai stock exchange #.##\n",
      "kuwait stock exchange ends\n",
      "air closes of in in\n",
      "london stock prices close\n",
      "un king arrives visits arrives\n",
      "thai stock exchange ends\n",
      "UNK is for for\n",
      "UNK job in in the\n",
      "after ferguson sunday to to a in in in in the the\n",
      "a 's 's the on UNK\n",
      "jennifer hudson o.j. netrebko jail on for\n",
      "<unk> the the the the the UNK\n",
      "the the fascinating the the\n",
      "how to can a the the\n",
      "UNK 's to to to to to\n",
      "duval takes to for at at\n",
      "woods woods to woods at at\n",
      "the recipe of <unk>\n",
      "<unk> the the the the\n",
      "a some of the the the a the the\n",
      "ethics of UNK UNK in in\n",
      "police 's UNK hide in in in\n",
      "gators 's in to to to of in\n",
      "new of a a to in in in\n",
      "the the of of of the of the\n",
      "<unk> <unk> the the of the the the\n",
      "nissan provide to to for for\n",
      "a 's of in a a a a in\n",
      "for democrats a the the a a a a the the\n",
      "french 's 's to to to to to in UNK\n",
      "a UNK to to to the\n",
      "UNK 's UNK to to the UNK\n",
      "contains 's 's to a the to in in in\n",
      "gm stocks stocks investors as day currencies week\n",
      "a 's a a of of UNK\n",
      "u.s. troops kill killed killed in iraqi iraq\n",
      "new of UNK the UNK UNK UNK\n",
      "a the for to a the the\n",
      "obama 's obama obama to to to\n",
      "UNK UNK a in of of of\n",
      "in york in the in the the\n",
      "dole 's clinton clinton bush bush to a a in\n",
      "UNK 's UNK the the\n",
      "<unk> bowl for\n",
      "microsoft funds to to on for on\n",
      "the the of of the the\n",
      "new ##k to to to for\n",
      "a of of of of to to of\n",
      "UNK 's the to to the\n",
      "UNK is a for for for\n",
      "how to can for\n",
      "UNK switches for time\n",
      "it 's a a the the the the\n",
      "<unk> 's UNK UNK in\n",
      "rain divorce hit parts\n",
      "UNK UNK UNK for the\n",
      "a a of of of of\n",
      "<unk> 's UNK the the the UNK\n",
      "california 's buys in in\n",
      "google UNK UNK UNK\n",
      "how to can for the\n",
      "holyfield 's to to to for\n",
      "<unk> 's for for for for <unk>\n",
      "UNK UNK to to to a the the\n",
      "UNK 's UNK to to to of\n",
      "<unk> 's the the the UNK\n",
      "UNK 's UNK on UNK\n",
      "judge judge to to to for\n",
      "u.s. senate urged u.s. to to to in\n",
      "mccain mccain mccain to on on on\n",
      "UNK UNK UNK in of in\n",
      "nbc should is all for\n",
      "UNK UNK UNK to in\n",
      "microsoft virus to helped to in in\n",
      "a the of of of of\n",
      "a UNK of a a a in in\n",
      "if 's a the the the a the the the\n",
      "it the of the the for the\n",
      "bush 's to bush bush bush to bush to\n",
      "the <unk> of the UNK\n",
      "china 's china to for in\n",
      "a a a a to to a the\n",
      "dodge 's UNK UNK UNK\n",
      "gore 's for for\n",
      "UNK 's a a to the the\n",
      "these designers is the the UNK\n",
      "new 's u.s. u.s. on in\n",
      "mccain mccain mccain mccain on on\n",
      "a 's of a a a to of of\n",
      "UNK 's a for for for\n",
      "UNK UNK UNK to to <unk>\n",
      "new york in in in in in in of\n",
      "a to to to the the\n",
      "pianist <unk> 's to to to in in in\n",
      "new york to to in in in\n",
      "UNK schools UNK in in UNK\n",
      "buchanan of UNK UNK in in\n",
      "couples 's is to to to to in in in\n",
      "actor <unk> <unk> UNK dies at ##\n",
      "mccain took mccain mccain on on mccain\n",
      "UNK 's UNK to to in UNK\n",
      "UNK named as as coach coach\n",
      "UNK to to buy for for\n",
      "<unk> 's the the the the the the\n",
      "UNK <unk> <unk> receive in <unk>\n",
      "in york the the the the the\n",
      "precede of of to to to to of 's\n",
      "UNK UNK to a in the\n",
      "intel 's prices for as\n",
      "UNK 's UNK UNK of of of UNK\n",
      "in york in to to a in the\n",
      "a the can can to to the\n",
      "UNK owners to to to\n",
      "stephen 's UNK to to UNK\n",
      "sarah 's says to to to to to to in in\n",
      "perry 's 's the but to the\n",
      "scientists of on to to to in in\n",
      "after of of to to the to the the\n",
      "the 's a the the the\n",
      "a 's a a of of UNK\n",
      "nickelodeon sopranos to to to of of UNK\n",
      "beijing to to to to in in\n",
      "us of to to to to to to to\n",
      "intel 's market n't a for\n",
      "if 's is a is for the\n",
      "UNK UNK for the the\n",
      "shields 's to for for\n",
      "beijing vote to to to in\n",
      "airlines 's UNK to in in\n",
      "obama 's obama obama to to to\n",
      "UNK of UNK UNK to in in\n",
      "UNK 's UNK to to to of\n",
      "in some the to the of a the\n",
      "in 's in in in in to in in in for\n",
      "UNK 's is the for the UNK\n",
      "UNK of flock to to in\n",
      "UNK 's in to to in in the\n",
      "the the of of of of UNK\n",
      "new york to to on in\n",
      "new york of in in in\n",
      "twilight 's to to on of fame\n",
      "study 's to to for for for for\n",
      "<unk> the the the of the the\n",
      "queen 's president 's 's to in in the of of of\n",
      "the the the the the\n",
      "UNK 's UNK to to the\n",
      "UNK 's UNK the the UNK\n",
      "UNK 's UNK the the\n",
      "new york new on on in in\n",
      "toyota to to $ for $ $ $\n",
      "<unk> 's a for for\n",
      "UNK kicker for for\n",
      "revolution defense to to\n",
      "a is in a a a a in in\n",
      "new state game to to to in in\n",
      "bruins should to for for\n",
      "ripken 's to to to for\n",
      "revolution need for for\n",
      "UNK 's a a to the the the\n",
      "citigroup earnings earnings prices\n",
      "anderson is to to to to to\n",
      "usc 's UNK to to the\n",
      "UNK 's UNK <unk>\n",
      "space spacecraft to to to to to to in\n",
      "#-##-## 's UNK to to in in\n",
      "obama 's to obama to for obama\n",
      "<unk> the the the the the\n",
      "UNK princeton to to to in\n",
      "UNK UNK UNK UNK to in\n",
      "when you a a a a the\n",
      "a york of the in in\n",
      "UNK 's the the the UNK\n",
      "a of of of of a to in the\n",
      "condemns of of of of a of of of\n",
      "UNK walks for at\n",
      "rangers 's to to in in the\n",
      "UNK <unk> <unk> UNK to to to in\n",
      "willie ray a to to for the\n",
      "grizzlies 's to to to to to\n",
      "a of of of of in\n",
      "UNK 's of a a a of UNK\n",
      "UNK to to to to for\n",
      "UNK of of of in\n",
      "a of of president 's 's in in in of of\n",
      "scientists 's to to to to to for\n",
      "us to to to to to to to to\n",
      "UNK 's a the the the UNK\n",
      "coca-cola 's to warming to for for\n",
      "the <unk> of of <unk>\n",
      "pepperdine 's to in UNK\n",
      "a the the the the the the the\n",
      "experts 's to to to to to for of\n",
      "how to can a the the\n",
      "rangers hope to to to to\n",
      "UNK years to to to to to in in in\n",
      "stock stock market in to\n",
      "singh wins to for at at at at\n",
      "ucla ivy to to to to in\n",
      "a UNK to in in in\n",
      "woods woods to woods to woods\n",
      "UNK is a revolution\n",
      "UNK 's UNK the to the\n",
      "UNK 's UNK for UNK\n",
      "UNK stewart to to to to the the\n",
      "UNK bowl a to for for for\n",
      "UNK dame for ryder ryder\n",
      "bruins bruins to to to\n",
      "UNK 's UNK receive to the the\n",
      "UNK striker UNK as player of of the player\n",
      "UNK mount UNK to in in\n",
      "us 's to to to in in in\n",
      "barkley 's to to to to\n",
      "cowboys release redskins\n",
      "<unk> the for the the\n",
      "UNK club to to to to in\n",
      "northridge 's hat to in in\n",
      "the the of of\n",
      "UNK 's UNK to to UNK\n",
      "springsteen 's UNK to UNK\n",
      "jennifer 's for savory\n",
      "stephen UNK to to at\n",
      "study 's to to to to to for for\n",
      "us house u.s. u.s. on on on\n",
      "hollywood &amp; to to to to to to to of\n",
      "aikman aikman for for\n",
      "a the to a a for the\n",
      "UNK flag UNK to in\n",
      "the bowl a a to the the\n",
      "<unk> designers is the the UNK\n",
      "a 's of in in in\n",
      "a 's of of the a 's a of of the\n",
      "<unk> bowl a for\n",
      "us pleads of guilty to to to in\n",
      "selig 's a to in\n",
      "we 's to to to in in for in\n",
      "willie 's 's the the the the\n",
      "the the of of of the\n",
      "UNK season for <unk>\n",
      "in some new to to of a the\n",
      "the the of the the the the\n",
      "woods woods buick woods to woods the\n",
      "democrats should care on on\n",
      "no. ## no. ## ## ##\n",
      "us <unk> of writer to <unk> in in UNK\n",
      "UNK UNK UNK to in in in\n",
      "ucla 's a to to to for for\n",
      "UNK UNK the at at at at\n",
      "clinton clinton on bush\n",
      "UNK the for the the\n",
      "a the of the of the the\n",
      "microsoft to microsoft xp\n",
      "ripken to to to all-star\n",
      "UNK 's of to to in in in in\n",
      "UNK of UNK UNK UNK in in\n",
      "the 's in in\n",
      "in is of a a a to of of\n",
      "gebrselassie aiming to to in in tour\n",
      "how to can can the the\n",
      "brazil to to world world cup cup\n",
      "holyfield 's to to to on the\n",
      "<unk> me a a the\n",
      "UNK 's mergers UNK\n",
      "breast of of id in in\n",
      "devils 's to to to to to in\n",
      "tokyo stocks end #.## percent percent percent\n",
      "sabbatini wins for at at\n",
      "paint chocolate is a the\n",
      "usc 's UNK to to\n",
      "UNK 's UNK to to UNK\n",
      "UNK <unk> <unk> nobel\n",
      "sundance UNK UNK in\n",
      "sonics agree to to to\n",
      "census to UNK UNK for UNK\n",
      "angels mets mets to in\n",
      "the the the the the\n",
      "gop of of to to in in UNK\n",
      "<unk> <unk> <unk> the of the\n",
      "<unk> of of to to of of UNK\n",
      "broncos broncos to to to to to to\n",
      "toyota to $ $ for $ $ billion\n",
      "UNK <unk> <unk> dies dies\n",
      "UNK 's UNK the of of UNK\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "dodgers ## bruins ##-##\n",
      "<unk> 's the the the the the the of\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "a york of a a a a in\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK 's to to to in\n",
      "UNK 's UNK the the the\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK of UNK UNK in in\n",
      "california lawmakers UNK of in in\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK lee 's the the walk walk fame fame\n",
      "earnhardt wins daytona nelson\n",
      "buchanan 's to to in\n",
      "UNK UNK UNK UNK to in\n",
      "UNK UNK UNK for UNK\n",
      "UNK 's UNK the to the\n",
      "ucla 's to to game\n",
      "in 's in a a a a the in\n",
      "lemieux says to to to to for for\n",
      "<unk> 's to to for\n",
      "condemns of of of a a of of\n",
      "angels is angels for\n",
      "a 's 's the the the the the\n",
      "malone 's to for in\n",
      "UNK 's a a to the the\n",
      "UNK 's to to to to to for of\n",
      "<unk> <unk> oldest wins <unk> <unk> of in <unk>\n",
      "<unk> 's of the the the the the the\n",
      "UNK companies is a in the the\n",
      "kobe wo to to to to the in\n",
      "northridge scores to play to in the\n",
      "recipes recipe for the the\n",
      "UNK of UNK UNK of in\n",
      "microsoft to for for\n",
      "the the of of\n",
      "obama 's obama to to for in\n",
      "new of project UNK in in in\n",
      "when to is a a the\n",
      "dodgers 's to to in\n",
      "a the for can in the\n",
      "UNK UNK UNK to UNK\n",
      "new areas UNK UNK in in\n",
      "couples 's to to to the the\n",
      "holyfield learns to to to for\n",
      "UNK 's UNK to to in\n",
      "the the the the the the the\n",
      "simpson 's says her simpson a to to to to\n",
      "france s to to to to to to in world\n",
      "the the of the the UNK\n",
      "UNK 's UNK to to to of of\n",
      "UNK 's the <unk>\n",
      "UNK 's to for in\n",
      "judge of to in in in in\n",
      "usc 's to to to to in\n",
      "new york to fields in in in\n",
      "burton 's to to to to to in\n",
      "a 's in in in a in in in in\n",
      "stocks prices in light\n",
      "we 's a a a a of the\n",
      "parcells manning to to to to to\n",
      "patriots ratings in for\n",
      "UNK to to to for for in\n",
      "grizzlies scores to to to to to to to\n",
      "simpson 's says to a a to to to\n",
      "contains 's to to to in in\n",
      "after years ago to to to in in in in\n",
      "a 's of of of the of the\n",
      "mets mets mets to to to\n",
      "how the the the the the\n",
      "delta UNK UNK on\n",
      "opec cox to to to as for for for\n",
      "UNK 's UNK UNK to UNK\n",
      "the recipe of the\n",
      "parton 's to to to for\n",
      "springsteen settles for UNK\n",
      "UNK 's 's a of in in in\n",
      "the the the the the the the the the\n",
      "britney to universal for\n",
      "rangers 's to to to to the the\n",
      "it 's a the the the the the the\n",
      "if 's in to to the in in in of\n",
      "a the the a a a a a the\n",
      "forgiving 's for for\n",
      "study of a a in in UNK\n",
      "it 's is the the the the the the\n",
      "norstrom 's to to in\n",
      "saddam 's in to to to to to to with with with\n",
      "the 's to to\n",
      "nissan doors to to for UNK\n",
      "clinton clinton clinton on clinton in\n",
      "agassi williams practice\n",
      "<unk> recipe for\n",
      "u.s. stocks mixed on oil data data\n",
      "study 's to to to to to to\n",
      "angels is angels to cowboys\n",
      "asian stocks fall as asian of rates ;\n",
      "mets mets mets to to to to\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "for mets to to to to to the\n",
      "UNK 's a the is the the UNK\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "<unk> <unk> <unk> to to to in in\n",
      "cowboys cowboys to to to\n",
      "selanne 's to to to in\n",
      "pulp sopranos 's to the the the the of\n",
      "UNK night the the\n",
      "UNK should for for\n",
      "u.s. to to to to to to to\n",
      "UNK of is a in in in\n",
      "<unk> 's UNK the UNK\n",
      "cowboys proves yankees to to\n",
      "UNK fails for revolution\n",
      "parton sent for for for\n",
      "clippers bruins to dodgers\n",
      "rangers blazers blazers to to\n",
      "<unk> watching UNK UNK of UNK\n",
      "deputy to aid aid aid\n",
      "china to to to to in in in\n",
      "a of of of of in UNK\n",
      "reba lee gets on on\n",
      "UNK 's UNK for for\n",
      "UNK 's ryder at ryder cup\n",
      "usc 's to to to to for the\n",
      "UNK 's UNK the UNK\n",
      "denver 's to to to to to to\n",
      "UNK bowl for\n",
      "UNK s UNK to to to in for\n",
      "northridge 's to at in in\n",
      "gore says to to to on on\n",
      "UNK 's to to at for UNK\n",
      "knicks have nets to nets\n",
      "giants mets to mets to to to to to\n",
      "jennifer slumdog wife wife baby\n",
      "grammy <unk> <unk> receive wins at at\n",
      "we 's to to to to to in in\n",
      "ucla ivy for for for\n",
      "UNK ivy a for in\n",
      "UNK the the the\n",
      "i designers is the the UNK\n",
      "UNK 's UNK to of UNK\n",
      "UNK 's to to to to to\n",
      "judge of to to in in in\n",
      "UNK lee 's the the the the the\n",
      "a the the the the the the the the the\n",
      "<unk> 's for the the\n",
      "malone 's to to in\n",
      "UNK 's UNK to the\n",
      "UNK 's UNK a of a of the\n",
      "mavericks camera to to in\n",
      "UNK 's sure golf of at at at\n",
      "i 's UNK to to of UNK\n",
      "bruins bruins to to to\n",
      "UNK town town UNK in in\n",
      "microsoft s buy buy billion $ $ $\n",
      "malone carries for offense\n",
      "obama urges to to to\n",
      "i 's is the for for\n",
      "wall street wall wall the of street\n",
      "UNK 's looks to to to to to to\n",
      "in is a a a a a a a\n",
      "gagne 's a to but to the the\n",
      "<unk> 's is of of UNK\n",
      "israeli of war to to of in in\n",
      "bush 's to to in in\n",
      "it bowl a a for the\n",
      "perry stewart to to to on the\n",
      "new budget defend to to in in\n",
      "<unk> 's UNK UNK of of\n",
      "the me of the\n",
      "nicklaus klitschko to to in\n",
      "oprah 's to to to the of the\n",
      "UNK 's to a of the the the the\n",
      "UNK 's 's to to to of of\n",
      "if 's to to to a a the\n",
      "UNK designers the the\n",
      "pulp sopranos to to to in of\n",
      "UNK shows for for\n",
      "UNK 's UNK to in\n",
      "<unk> years 's to to to to to of\n",
      "UNK bowl a for for\n",
      "transplants born in orphans\n",
      "<unk> 's of to to to to\n",
      "sonics sox to to to to\n",
      "willie 's a to for for\n",
      "els 's to to to to the\n",
      "grizzlies beat celtics ###-##\n",
      "lippi defends for at title\n",
      "<unk> <unk> <unk> venice UNK\n",
      "world of of in at in\n",
      "UNK knight to to to to in in\n",
      "i 's is the but for the\n",
      "UNK 's UNK to UNK\n",
      "UNK 's to to\n",
      "in york new the in in in\n",
      "ucla 's to to to to for the\n",
      "knicks 's to to to to the\n",
      "UNK 's in in in\n",
      "a is of UNK of of UNK\n",
      "no. ## ohio ohio\n",
      "UNK 's a a a a a the\n",
      "dolphins re-sign cornerback <unk> <unk>\n",
      "patriots need to to to to\n",
      "safin overcomes to to in for in\n",
      "venus venus UNK dies at at ##\n",
      "somali says says # to to in in\n",
      "sonics ## to to in\n",
      "new 's to to to to in in in\n",
      "northridge 's to to in game\n",
      "<unk> the the of UNK\n",
      "a tech is is the a in in\n",
      "beijing to to to to in in\n",
      "nissan 's to to to for for\n",
      "ucla carries to for\n",
      "stocks stocks after after 's of\n",
      "UNK 's the\n",
      "cowboys cowboys aikman to\n",
      "pulp sopranos is the the the of the\n",
      "the the is a the the\n",
      "mets to to to to for\n",
      "UNK 's UNK column in in in in\n",
      "<unk> 's the the the\n",
      "saddam 's of in to UNK in in in in with with <unk>\n",
      "scientists of of to to in in in\n",
      "a york of in the the in the of the\n",
      "rockies bowl for for\n",
      "sorenstam wins for at at\n",
      "northridge 's to to in game\n",
      "bush 's 's bush\n",
      "usc 's UNK to to in\n",
      "the the of for the the the\n",
      "davies dominates to in\n",
      "lemieux davies to to to to\n",
      "UNK 's the the the\n",
      "knicks sox to to to to to the\n",
      "the the of the\n",
      "mets mets mets to to\n",
      "armstrong armstrong hoya to in for for for\n",
      "UNK 's a for for\n",
      "UNK woods a a to to for for\n",
      "ucla state to to to to to to\n",
      "new 's is in market\n",
      "in york of the in in in\n",
      "a is of of UNK UNK in of of\n",
      "heath 's is a a to the\n",
      "yankees blazers terms to\n",
      "us 's to to to to to in in\n",
      "UNK bowl to to for for\n",
      "UNK UNK UNK ##km to to at to the\n",
      "selig 's UNK to in\n",
      "canadian 's schedule to in in\n",
      "intel companies is is a a\n",
      "<unk> the the the a a of the\n",
      "wall street wall wall wall of street\n",
      "<unk> me the the the\n",
      "tcu says he to to to to in\n",
      "the the of a of of the\n",
      "holyfield 's to to to to\n",
      "ucla ivy a to to in in\n",
      "us 's inflation in in in in\n",
      "treasury prices on as dollar of\n",
      "pepperdine 's to to to the\n",
      "the the of the of the of\n",
      "dole 's a bush bush a in\n",
      "the the is the the UNK\n",
      "o.j. 's for for for\n",
      "stephen 's 's 's to on on\n",
      "dodgers 's to in\n",
      "UNK 's a to to for for\n",
      "sonics defense to ###-##\n",
      "weir 's to to to to to the\n",
      "celtics sign sign agent wing to to contract contract\n",
      "UNK 's to to of at the at\n",
      "UNK 's UNK to in UNK\n",
      "tech 's gets on\n",
      "number 's dialogue in in\n",
      "UNK 's to to to at at\n",
      "judge UNK UNK receive to in\n",
      "the the on on\n",
      "toyota to goldman $ $ $ $ billion\n",
      "bernanke 's to to to to to of\n",
      "a 's the the of the of the\n",
      "celtics sign sign to terms to to to contract\n",
      "UNK square UNK to in in\n",
      "nyc 's of to to to to of\n",
      "UNK 's UNK for in\n",
      "selig 's in in in UNK\n",
      "<unk> <unk> to to to at at\n",
      "a 's a to to for for\n",
      "devils ### to to in in\n",
      "UNK saves for for the\n",
      "UNK 's UNK to to in in\n",
      "UNK 's UNK UNK to to of UNK\n",
      "UNK 's UNK the the UNK\n",
      "the the that for the the\n",
      "UNK of to to to for\n",
      "a the the the the the\n",
      "it 's is for for for\n",
      "UNK 's to to in in\n",
      "hbo 's UNK the the the\n",
      "<unk> 's UNK the of of of of\n",
      "how to can can the the\n",
      "the carolina to to to in\n",
      "UNK need to for for\n",
      "cowboys defense to to to to\n",
      "perry 's to hall hall hall hall fame\n",
      "drivers 's to to to to to to to for\n",
      "UNK gets to at at classic\n",
      "UNK is the\n",
      "ucla 's for at\n",
      "u.s. 's of to to to to to to to to to\n",
      "dodgers 's dodgers for\n",
      "intel 's prices to to as as\n",
      "scientists 's in to to to to in UNK\n",
      "UNK shortage UNK UNK\n",
      "disney to a a in UNK\n",
      "angels 's angels to angels\n",
      "UNK some in to to to a the the\n",
      "dole dole a to a a a a a\n",
      "<unk> 's 's the UNK\n",
      "the the of of the\n",
      "a the of of of the the\n",
      "nbc 's to to for\n",
      "<unk> 's of a of of of\n",
      "study finds can attitude of\n",
      "phelps shines to to to to for for tour\n",
      "a chefs that a the the the\n",
      "dodgers sox to for for\n",
      "simpson simpson to for simpson for to for to\n",
      "UNK 's in in in\n",
      "bush 's of bush bush\n",
      "some researchers to to to to to\n",
      "it 's 's a for for\n",
      "UNK voters for for for\n",
      "for york to to to to the the\n",
      "UNK 's a to for the\n",
      "you to to to to to the\n",
      "stocks futures after as jobs jobs earnings\n",
      "UNK bowl for for\n",
      "bucs reputation for role\n",
      "yankees sox yankees to to\n",
      "canada 's rate markets closed zealand\n",
      "holyfield roberts for for\n",
      "UNK 's to to at\n",
      "UNK emerges UNK for in UNK\n",
      "brazil stocks fall after on on\n",
      "UNK the for the\n",
      "ucla rallies to in\n",
      "tyson to to to tyson tyson\n",
      "athletes 's to to to to to to\n",
      "mongolian wrestler names chairman\n",
      "a the the the the the the the the\n",
      "it 's the the the the the the a the the the\n",
      "a 's the the the the the the in in the the the\n",
      "UNK wins UNK at at at of\n",
      "janet UNK to to on awards\n",
      "a the of of of in\n",
      "rodriguez smoltz mets for\n",
      "UNK of of of to of of UNK\n",
      "UNK the the the the the\n",
      "usc 's to to to the\n",
      "cowboys cowboys cowboys for\n",
      "UNK UNK the UNK\n",
      "anne renews of to to of UNK\n",
      "us 's urged costly to to to in in\n",
      "<unk> 's of of of of of\n",
      "results of boxing tournament at\n",
      "reeves 's to to to to of in\n",
      "UNK president to to to in\n",
      "<unk> the is the the the the\n",
      "surf 's UNK to to to to UNK\n",
      "the of of of of of\n",
      "discounts 's a to but for for\n",
      "UNK <unk> UNK zoo UNK\n",
      "immigration of to to to to in in\n",
      "the 's the the the the the\n",
      "sorenstam overcomes to to in in\n",
      "UNK 's is the the the the the\n",
      "palffy 's to to to in\n",
      "new york to to to for in\n",
      "<unk> to to to to for\n",
      "gore to to to bush to to\n",
      "it 's is the the the the the the\n",
      "intel 's 's to to a a of of\n",
      "selig 's on on UNK\n",
      "canseco 's a to but for the\n",
      "armstrong s to receive to in in\n",
      "pepperdine 's to to to <unk>\n",
      "junk 's of to to to to in\n",
      "UNK UNK\n",
      "gore UNK UNK UNK\n",
      "a 's to to to to to to in\n",
      "a 's a the the the a a a of of\n",
      "UNK wonder is to to to in\n",
      "<unk> cannes <unk> UNK of UNK\n",
      "UNK 's a to to the the\n",
      "a the the the the the a a a a the\n",
      "davies davies gordon to to for for\n",
      "earnhardt gets to to in in\n",
      "a 's a a of a in of UNK\n",
      "simpson simpson is to to to to\n",
      "a 's sunday the a a in a of the\n",
      "UNK 's a a to to in in in\n",
      "UNK the the of of the of the\n",
      "a the of a of the the\n",
      "bruins have for for for\n",
      "exhibit of of of of of of\n",
      "anderson is a to to <unk>\n",
      "new finds of to on UNK\n",
      "a 's the to to to to\n",
      "how to for to the the the\n",
      "the the to a to to the\n",
      "UNK mediocre a to for\n",
      "mtv 's 's the the the the the\n",
      "world cup world to of in\n",
      "UNK schools for the\n",
      "knicks lose to to to to to to to\n",
      "<unk> movies UNK UNK UNK\n",
      "rangers hope to to to in to in\n",
      "a 's the the the the the the the\n",
      "UNK doll UNK for\n",
      "exhibit of UNK id in UNK\n",
      "UNK 's to at at\n",
      "writer-director 's <unk> <unk>\n",
      "UNK UNK UNK to to in in\n",
      "gop to to to to to in in\n",
      "red agree to to to deal\n",
      "UNK 's UNK to to of UNK\n",
      "experts 's to to to to to to to for\n",
      "how the your your\n",
      "if 's 's to to to to to to\n",
      "braves need UNK patriots\n",
      "the <unk> of of of the\n",
      "england 's to to to to in in\n",
      "dole house on on on\n",
      "new york to to in in for\n",
      "ruiz 's to to to to for the\n",
      "UNK 's a for in the\n",
      "sinatra is for all\n",
      "<unk> 's is on\n",
      "UNK the to the the the\n",
      "UNK UNK to in in\n",
      "the recipe for the the\n",
      "pepperdine gets to to to the\n",
      "davies overcomes to to at at title\n",
      "nbc cultures for\n",
      "in a of a of of of\n",
      "UNK ivy to to to in in\n",
      "UNK 's a to to to to in in\n",
      "i stoppard to all for\n",
      "stars carolina for 's to for for\n",
      "a the the the the the the\n",
      "tips ways for for\n",
      "<unk> 's the the the the\n",
      "simpson 's to to to for UNK\n",
      "the the for the\n",
      "wheat futures close higher higher\n",
      "simpson simpson to simpson simpson simpson to to to for\n",
      "how to your <unk>\n",
      "how 's is a a of UNK\n",
      "kings need to to to\n",
      "UNK of of UNK UNK in in in\n",
      "willie walker a to to to for\n",
      "UNK 's in to to to to to in UNK\n",
      "clemens 's to to to in in\n",
      "<unk> the the the of of UNK\n",
      "UNK <unk> of UNK to to of in\n",
      "UNK 's of of of to for in in in\n",
      "dodgers 's dodgers for\n",
      "bucs fargas to to to to\n",
      "UNK recipe for the\n",
      "mcenroe bacon to receive for\n",
      "the the of of of the\n",
      "ucla 's a to to to to in in\n",
      "UNK 's 's of for for\n",
      "a of of a a a in of\n",
      "how to for to the the\n",
      "UNK of of in in in in\n",
      "the the for the\n",
      "it 's n't n't n't for for\n",
      "UNK <unk> UNK to to in in\n",
      "UNK 's UNK to to to to in\n",
      "UNK 's to to to to for\n",
      "baseball owners to to to\n",
      "UNK of ruins in in in\n",
      "disney 's to to but of the\n",
      "judge trial to gun in in\n",
      "study finds UNK dinosaur of in UNK\n",
      "cowboys proves to to to for\n",
      "author 's of to to to to to of\n",
      "gators 's to to to to in in\n",
      "we 's UNK to to to of UNK\n",
      "us 's profitable in in in\n",
      "sorenstam takes to at at at\n",
      "celtics to to to to\n",
      "mutombo wants he to to for\n",
      "the the of the the the the the\n",
      "saddam of in to in in in in in in\n",
      "notre ## to to in ##\n",
      "phillips 's a the the the the\n",
      "barkley eager to for\n",
      "UNK 's the <unk>\n",
      "UNK robinson to to to game\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couples 's UNK is to to the\n",
      "yankees sox yankees to to in\n",
      "it bowl the the the the to to in the\n",
      "mavericks 's to to in\n",
      "rockies bowl a for for\n",
      "a the of the the the the the\n",
      "angels 's to to to to the\n",
      "bucs finds is to to for\n",
      "obama 's obama obama obama\n",
      "california of of to to in in in\n",
      "the the for the the\n",
      "the 's the of of UNK\n",
      "sarah s to receive to in\n",
      "UNK 's UNK at at\n",
      "UNK UNK UNK to to in in\n",
      "mets ca n't to to to to to the\n",
      "angels UNK angels for\n",
      "UNK club to football for for\n",
      "us rates in in\n",
      "UNK <unk> at at\n",
      "gordon says to to tyson\n",
      "dodgers need to for for\n",
      "bruins hire hire as coach\n",
      "china china china 's 's 's\n",
      "<unk> <unk> <unk> wins <unk> <unk> the the of\n",
      "citigroup UNK increase in\n",
      "bucs 's to to to to to the\n",
      "UNK is for for the\n",
      "study may to column to to for UNK\n",
      "in york new the the the the the\n",
      "alaska ship fends in in in\n",
      "china 's first website of of\n",
      "no. ## st. st. ## ## ##\n",
      "reds hire to has surgery\n",
      "lemieux 's to to for\n",
      "UNK is a for for the\n",
      "ucla 's to to to in\n",
      "in of in in in in in in in in\n",
      "UNK flag UNK to to in\n",
      "mexico stocks fall to on on on\n",
      "toyota 's to to to for to for\n",
      "UNK catching to for game\n",
      "UNK 's UNK to to in\n",
      "a the the the the the the the\n",
      "notre devils to to\n",
      "broncos jets to jets on to\n",
      "UNK owners to to in\n",
      "beware UNK the\n",
      "a cup cup to to a in in\n",
      "the the the the the the the the the the\n",
      "it 's a the the the the the the\n",
      "it bowl a the the the the\n",
      "UNK 's to to to to in the\n",
      "UNK 's a a a a a the of\n",
      "UNK wins to at at at\n",
      "UNK UNK UNK to UNK\n",
      "a clinton of of bush bush the the\n",
      "UNK 's to to to to in\n",
      "a the of of of the\n",
      "<unk> 's the the the UNK\n",
      "the <unk> of the the\n",
      "space to to to to for for for\n",
      "o.j. potter UNK to to of UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> 's of of to to to the 's\n",
      "new york new in the in in the\n",
      "after 's in to in the in in in in in at ##\n",
      "holyfield 's a to in\n",
      "UNK emerges UNK for in\n",
      "holyfield 's a to in\n",
      "author 's 's to to to in\n",
      "willie ray a the to to for\n",
      "a is a UNK in in in\n",
      "UNK 's UNK UNK to to to of\n",
      "UNK agreements to to in the\n",
      "sonics sox to to to\n",
      "gop 's would to to in in\n",
      "vikings nuggets to to to to for\n",
      "vikings vikings to to to to\n",
      "clinton clinton to clinton in in in in to on to\n",
      "UNK 's on for for\n",
      "a the the the of of of\n",
      "UNK agreements to to to in in in\n",
      "UNK 's to to to to to to in\n",
      "dodgers crush for diamondbacks\n",
      "UNK 's UNK the to the the the\n",
      "agassi williams for wimbledon\n",
      "the <unk> of of UNK\n",
      "judge workers workers strike for for\n",
      "UNK camera the to the the the\n",
      "UNK ivy UNK to to to in in\n",
      "UNK 's 's to his a to in of\n",
      "UNK fargas a to to for\n",
      "rangers hope to to to to to\n",
      "how the to can to the\n",
      "UNK recipe for the\n",
      "UNK <unk> <unk> to to <unk>\n",
      "us of feature to to to in in\n",
      "new town UNK to in in\n",
      "the <unk> of of\n",
      "giants mets to to to for\n",
      "giants are to patriots to\n",
      "<unk> 's the the the UNK\n",
      "these 's for n't be for the\n",
      "german stocks fall as amid\n",
      "german stocks fall as investors in in\n",
      "something is the\n",
      "UNK s s to to to to in to the\n",
      "hbo UNK UNK to to <unk>\n",
      "<unk> <unk> <unk> <unk> to at at at\n",
      "UNK 's <unk> <unk>\n",
      "a a of of in in\n",
      "selig 's a to to in for\n",
      "bush 's to to to tax\n",
      "UNK bowl for for UNK\n",
      "us house passes to on on\n",
      "montgomerie replaces UNK at at season\n",
      "woods woods to woods woods\n",
      "UNK organizers to to to in in\n",
      "clinton clinton clinton to obama in in in\n",
      "UNK schools UNK UNK\n",
      "a the of the of the of the\n",
      "gators 's to to to in in\n",
      "how to can a the\n",
      "a 's the the the the is the of the\n",
      "<unk> 's is the the the the\n",
      "a the of the the the the the the the\n",
      "california of to to to to in in\n",
      "usc 's to to to to the the\n",
      "exhibit 's UNK to to to in\n",
      "angels fargas angels for for\n",
      "a <unk> of the of the the the the\n",
      "a the the the is the is the the the\n",
      "sony 's to to to to for\n",
      "UNK 's for for for\n",
      "study 's a to to a in for\n",
      "UNK of UNK to in in UNK\n",
      "barkley eager to to to\n",
      "researchers of to to in in UNK\n",
      "columnist 's UNK to for in\n",
      "mavericks sox to to to to\n",
      "tyson bacon to to for for\n",
      "UNK 's UNK to to in in\n",
      "a 's the to the the the the\n",
      "the honors of sundance\n",
      "the the the the the the the the the\n",
      "cowboys need for cowboys\n",
      "a the the the the the the\n",
      "UNK the the the is the the\n",
      "dodgers lose dodgers for\n",
      "stocks stocks stocks after to in\n",
      "<unk> <unk> for for the the\n",
      "UNK of of of of in in\n",
      "the to to for\n",
      "giants need to for for\n",
      "the the the the the the\n",
      "UNK <unk> UNK <unk>\n",
      "bush clinton clinton bush bush bush in bush in\n",
      "a UNK of of of\n",
      "perry singh to to to in\n",
      "UNK 's a is to the the\n",
      "UNK UNK UNK for in\n",
      "ioc 's to to to to to\n",
      "pepperdine gets to to at at classic\n",
      "a 's a a of UNK\n",
      "patriots need to to to for to\n",
      "cannes of of to to to to UNK\n",
      "UNK UNK secrets UNK in\n",
      "UNK robinson a to to to the the\n",
      "parton bacon to to for\n",
      "s. korean main fall on\n",
      "revolution is to for\n",
      "dow stocks stocks as as in\n",
      "<unk> <unk> the\n",
      "UNK 's to to to to for\n",
      "tyson stewart to to but to the the\n",
      "boeing union to to to to to\n",
      "UNK 's the the\n",
      "judge 's 's to to to to in in\n",
      "ucla 's to to to for\n",
      "hbo s to to to to in\n",
      "UNK 's UNK is to to of\n",
      "couples 's to to at\n",
      "UNK ivy to to to to in in\n",
      "parcells is to for angels\n",
      "UNK owners in to in in in in\n",
      "the to to to to why in 's\n",
      "mcenroe bacon to to in hendrick\n",
      "UNK hilton says simpson to to to in\n",
      "UNK the the the\n",
      "UNK the to to the the\n",
      "UNK takes for at\n",
      "<unk> <unk> the the the of of\n",
      "forgiving 's the the\n",
      "the me is the the UNK\n",
      "google to buy buy for for\n",
      "gop hk on a a in in\n",
      "UNK recipe for the\n",
      "bond prices in in in\n",
      "cowboys manning aikman to to for\n",
      "when your to a a a a the\n",
      "russia 's council assembly to to to to to to with\n",
      "weaver 's to to to in\n",
      "<unk> of at <unk> for\n",
      "analysts 's to to to $ in the\n",
      "buchanan 's to to to on\n",
      "patriots need to for\n",
      "the <unk> for the the UNK\n",
      "UNK the the the the UNK\n",
      "janet lee to to on\n",
      "couples UNK UNK to to in\n",
      "UNK 's UNK to to a in the of\n",
      "a the of the republicans the in the\n",
      "holyfield 's to to in\n",
      "UNK the her the the the of\n",
      "the the of of of\n",
      "rams 's be to to for for\n",
      "UNK 's the the <unk>\n",
      "the UNK the the in in\n",
      "UNK 's is for for for\n",
      "UNK 's the the the <unk>\n",
      "holyfield 's to for for\n",
      "no. dame notre dame ##\n",
      "it 's a the the the the the\n",
      "UNK of to to to in in\n",
      "dodge 's for on at\n",
      "bush 's to to to for in for\n",
      "judge of to in in in in in\n",
      "hollywood 's to box-office to to to in\n",
      "<unk> the the the\n",
      "UNK oats to to of the\n",
      "mavericks rout to to in\n",
      "disney 's a to to of of\n",
      "bush clinton clinton on on in\n",
      "some the to to to to the the\n",
      "stephen UNK UNK 's on\n",
      "ucla 's to to to to in\n",
      "the the of of <unk>\n",
      "it 's is is but the the the the\n",
      "former striker to to to for for\n",
      "UNK <unk> <unk> to to in <unk>\n",
      "UNK is for for for\n",
      "weighing 's a to to of UNK\n",
      "UNK UNK to to to the the\n",
      "a 's 's a a a a in 's\n",
      "goldman 's stock a a on on\n",
      "the the to a to the the\n",
      "a of a a of in in\n",
      "everett 's to in\n",
      "sorenstam 's to to to at\n",
      "a 's of a a a a a of\n",
      "UNK the our\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "UNK 's to to to to in in\n",
      "angels have angels for for\n",
      "holyfield bacon to to to for\n",
      "new passes passes in in\n",
      "UNK the the the the the\n",
      "making the can for the the\n",
      "UNK UNK UNK to in in\n",
      "<unk> <unk> 's to to to to UNK\n",
      "UNK 's for at ryder\n",
      "bush clinton clinton obama on\n",
      "rain delays for for for\n",
      "celtics get to to to\n",
      "UNK 's 's to to to in in\n",
      "UNK of of <unk> <unk> in in\n",
      "UNK bowl for for\n",
      "ford s to to to to to million\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "UNK the of the\n",
      "phillips 's to to to to to\n",
      "world 's to to to to to to to to to\n",
      "UNK 's to to at in\n",
      "woods woods to woods to at\n",
      "lemieux sanders to to\n",
      "exhibit of UNK to to in\n",
      "UNK the the to in\n",
      "judge of to to to in in\n",
      "UNK 's to to in in\n",
      "broncos 's to to to to to\n",
      "buchanan designers of to to to of\n",
      "gop virus UNK UNK in\n",
      "the the of the the UNK\n",
      "nissan grown-ups transplants airwaves\n",
      "UNK UNK UNK in in in\n",
      "woods woods to woods to to the\n",
      "shrek 's UNK the with UNK\n",
      "judge court of of to of in in in\n",
      "gingrich of in to to to to in in in\n",
      "exhibit cannes 's to to to of\n",
      "buchanan 's to to in in\n",
      "sony 's to to to to of of\n",
      "rangers mets mets #-#\n",
      "pakistan parliament says urges to to to\n",
      "UNK UNK UNK UNK in in\n",
      "a a of a of of of\n",
      "toledo 's to to to to for\n",
      "perry stewart UNK to he to the the\n",
      "a the the the the the\n",
      "UNK 's UNK to to in\n",
      "UNK of of a a in in in\n",
      "tips your for for\n",
      "barbecue 's to to to to in UNK\n",
      "UNK state to to in\n",
      "UNK 's for <unk>\n",
      "the <unk> of the\n",
      "UNK 's the the\n",
      "bush 's clinton to in in\n",
      "UNK bowl a a to the\n",
      "the UNK to in in\n",
      "wheat futures prices fall mixed\n",
      "a 's to to to to to in in\n",
      "police 's UNK introduce to in in in\n",
      "the <unk> of\n",
      "<unk> <unk> the the the\n",
      "when your a a but to a the\n",
      "mets mets mets to to\n",
      "UNK UNK UNK of in in\n",
      "ripken says to to to for season\n",
      "the the the the of the\n",
      "study finds to to to in\n",
      "clippers bruins to scoreboard\n",
      "kings rout to kings\n",
      "prime-time 's for UNK\n",
      "UNK a&amp;m a a in in\n",
      "selig is a for for\n",
      "agassi named for UNK\n",
      "ripken wins hat in all-star\n",
      "a 's the the the the the the\n",
      "study of of to of to to in in\n",
      "janet 's to to to of awards\n",
      "if 's n't a be for the\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "treasury prices in in\n",
      "bush 's of bush for\n",
      "the cox news service spot news budget for wednesday june ##\n",
      "in of of a a a in in UNK\n",
      "phillips 's a the for the\n",
      "colleges to sue for for\n",
      "the me of <unk>\n",
      "french to doping for for for\n",
      "new of of to to in in in\n",
      "UNK recession is a the the the\n",
      "heisman 's a to for the\n",
      "UNK 's on for in\n",
      "raiders is to to in the\n",
      "mets mets to to to to\n",
      "UNK bowl a for for for\n",
      "## seized seized seized in\n",
      "bayern striker to to to to with fenerbahce\n",
      "UNK 's to to to to in in in\n",
      "UNK UNK for the the\n",
      "scientists 's to to to in in\n",
      "larsson forsberg commits to to to the\n",
      "if 's to to a a a the the\n",
      "angels is angels for\n",
      "UNK johnson to to of the the the\n",
      "rangers sox to to to to to the\n",
      "lemieux scores to play to #\n",
      "un 's new to to to cabinet\n",
      "u.s. stocks rise as bond bond fall\n",
      "u.s. stocks mixed as bond on yields\n",
      "a of for to the for the the\n",
      "UNK <unk> UNK to to to in\n",
      "UNK dates UNK UNK in in\n",
      "UNK UNK in in in UNK\n",
      "nfl 's to to for\n",
      "galaxy hire hire hire as coach\n",
      "after 's in to to to in in in in in\n",
      "a the of the of of of the\n",
      "a 's of to to to to of\n",
      "#-##-## 's UNK to to the\n",
      "some to to to to on\n",
      "UNK trials to to for\n",
      "willie kiss is to to the the\n",
      "knicks have to to to to the\n",
      "UNK of for for\n",
      "a 's to to in the\n",
      "UNK the for the the\n",
      "northridge all-star for in\n",
      "<unk> <unk> the to the the the the the the\n",
      "microsoft foods to xp for\n",
      "gordon gordon to to to to in the\n",
      "let 's for tops for for the\n",
      "agassi williams to to\n",
      "UNK UNK UNK for in in\n",
      "UNK 's UNK UNK to to to of\n",
      "schwab serbs to to to to to to\n",
      "a UNK for for the UNK\n",
      "UNK 's UNK UNK of in of UNK\n",
      "obama 's to to to to to obama to\n",
      "UNK 's a to to a in in of UNK\n",
      "a the to to to to to the\n",
      "drivers to to to to to to to in\n",
      "if is is a but the the the\n",
      "gore took focuses to in\n",
      "holyfield holyfield to to to for\n",
      "UNK reigns UNK for UNK\n",
      "UNK funds to to to to to on\n",
      "the <unk> of of the\n",
      "a 's 's a a a a the\n",
      "UNK UNK for UNK\n",
      "us house on on to on to to iraq\n",
      "mongolian 's to to to to to UNK\n",
      "UNK me for the the\n",
      "beijing to to to to to to\n",
      "hong kong vow on develops in\n",
      "china to to cooperation cooperation\n",
      "indonesian 's UNK UNK UNK\n",
      "australian dollar closes higher\n",
      "european economy grows to\n",
      "new zealand to to to to for\n",
      "australian sharemarket prices higher\n",
      "canada to to to\n",
      "asian stock stock in in\n",
      "chinext index opens lower friday\n",
      "dollar trades at lower ## yen tokyo\n",
      "stocks close higher in mexico brazil\n",
      "chinext index opens lower monday\n",
      "china russia vow to boost cooperation cooperation\n",
      "dollar at at upper yen yen in tokyo\n",
      "u.s. stocks trade higher\n",
      "stocks close higher in mexico brazil\n",
      "tokyo stocks open higher higher\n",
      "<unk> president president <unk>\n",
      "chinese chinese to to to to in in\n",
      "facts conference on opens in in\n",
      "foreign exchange rates in new zealand\n",
      "eu union to to to to to in\n",
      "UNK 's tribute to to to in\n",
      "dollar down in upper ## yen range tokyo\n",
      "dollar trades in upper yen yen in tokyo\n",
      "## raid seized in\n",
      "dollar at at mid-### yen in\n",
      "s. korean stocks close higher\n",
      "former soviet minister minister dies dies\n",
      "spain beats italy #-# in\n",
      "dollar at at upper yen yen in tokyo\n",
      "chinese 's of major at cities monday\n",
      "dollar trades lower ## ## in tokyo\n",
      "us flu military swine flu\n",
      "gun of put operational in in in\n",
      "UNK of born in in\n",
      "two killed killed in in in\n",
      "china develops on development\n",
      "UNK 's to to in in\n",
      "pope pm minister urges to to in\n",
      "german stock exchange exchange rates\n",
      "eu to to to to to to to in\n",
      "dollar trades at lower lower yen in\n",
      "toyota 's to to to to to\n",
      "china raises to train million to for for for\n",
      "thai stocks end close\n",
      "# killed in in in in in\n",
      "german stock exchange exchange rates\n",
      "former president president sworn sworn\n",
      "china 's china in for\n",
      "german stock exchange exchange rates\n",
      "china to first equipment fair\n",
      "beijing to seize to nuclear\n",
      "UNK wins wins stage of of of\n",
      "china passes passes development in in\n",
      "germany wins wins women 's 's ###m gold\n",
      "lyon wins champions in title title\n",
      "<unk> named as as new of national team\n",
      "hong kong shares close #.#\n",
      "france to to aid to\n",
      "dollar trades lower ## yen in tokyo\n",
      "tokyo stocks open higher\n",
      "venezuelan president president to for\n",
      "bolt president assistant to to to for\n",
      "UNK of provokes in in in\n",
      "china 's of major for market\n",
      "stocks close higher in mexico brazil\n",
      "flamengo of UNK coach soccer\n",
      "UNK 's UNK UNK in\n",
      "a 's of a a in in the\n",
      "u.s. stocks open higher\n",
      "xinhua home in advisory march\n",
      "wall street stocks fall on profit-taking\n",
      "stocks close higher in mexico brazil\n",
      "dollar trades at lower yen in tokyo\n",
      "beijing president to to olympic olympic relay\n",
      "nikkei closes #.## pct higher\n",
      "dollar trades at lower ## yen in\n",
      "s. korean stocks close\n",
      "dollar remains at lower ## yen range\n",
      "dollar trades at lower yen in tokyo\n",
      "u.s. stocks edge as oil\n",
      "beijing chinese on trade opens in\n",
      "german stock reference exchange rates\n",
      "new zealand rates closes new\n",
      "international on on on expressway opens\n",
      "german stocks open higher\n",
      "dollar down in upper ## yen range tokyo\n",
      "german stocks open higher\n",
      "german stocks open higher\n",
      "china 's vow to to to to\n",
      "china to first #.#-magnitude to UNK\n",
      "malaysia africa to to to in\n",
      "thailand of northern in\n",
      "beijing to to on on on\n",
      "wall street up after of of\n",
      "cuba to sign agreement agreement\n",
      "gold 's production in in in in\n",
      "UNK masters at championships\n",
      "strong earthquake hits taiwan\n",
      "pakistan india to sign on agreement\n",
      "china china on on center\n",
      "new york are in in in\n",
      "greece economy 's in\n",
      "australian dollar closes higher\n",
      "int on on on on to\n",
      "china russia vow sign cooperation cooperation\n",
      "beijing to build smoking clean\n",
      "u.s. stocks open lower on modest\n",
      "ethiopia court UNK to of\n",
      "new opens embassy office in\n",
      "in 's of in to in in in of\n",
      "pope calls to to to in\n",
      "u.s. stocks trade higher\n",
      "u.s. stocks open higher\n",
      "jakarta stocks close lower\n",
      "chinese promotes UNK dinosaur\n",
      "hong kong share prices close #.##\n",
      "chinese chinese find to for in\n",
      "dollar trades at mid-### yen in\n",
      "bulgarian stock market ends higher higher\n",
      "bulgarian stock market ends higher higher\n",
      "bulgarian stock market ends higher\n",
      "dollar remains in lower ## yen range\n",
      "china opens industry fujian booming province\n",
      "beijing of on opens opens in in\n",
      "pakistan denies to to to to\n",
      "ethiopia UNK in in\n",
      "two u.s. soldiers killed in iraq\n",
      "boeing to strike strike in in\n",
      "european stocks end #.##\n",
      "dollar trades in upper yen yen in tokyo\n",
      "dollar down in upper ## yen in tokyo\n",
      "foreign exchange rates in new zealand\n",
      "brazil coach voted coach cup cup\n",
      "china hk exhibition fair opens in\n",
      "wall street stocks end mixed\n",
      "chinese vice-premier meets in president\n",
      "UNK UNK player retires for for\n",
      "london stock market opens higher\n",
      "dollar trades at ## yen in tokyo\n",
      "german stocks open higher\n",
      "dollar remains in upper ## yen range tokyo\n",
      "dollar trades lower lower ## in tokyo\n",
      "beijing torch host to to to in in\n",
      "chinext index opens lower lower\n",
      "china russia to expand cooperation cooperation\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar down in upper ## yen in tokyo\n",
      "dollar trades lower ## ## in tokyo\n",
      "brazil to currency to to\n",
      "crude prices decline on on expectation expectation\n",
      "hang seng china enterprises index up\n",
      "pakistan calls to to to to\n",
      "us soldiers iraq u.s. iraq iraq the the the the\n",
      "australian stock market rises\n",
      "china to to to protect in environment\n",
      "international workshop on opens opens in\n",
      "new americans passes to to in UNK\n",
      "UNK festival film ##th opens in in\n",
      "australian stock market closes higher\n",
      "pakistan israel sign sign agreement\n",
      "kuala lumpur stocks close lower\n",
      "unbeaten meat the the the in\n",
      "macao 's to to\n",
      "chrysler 's schedule bank in in\n",
      "chinese of of of 's in in in\n",
      "china kong hong 's to 's 's in 's\n",
      "dollar down in upper ## yen range tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "nikkei closes #.## pct higher\n",
      "dollar down in upper ## yen in tokyo\n",
      "dollar remains in upper ## yen range tokyo\n",
      "south korea to to to dairy\n",
      "dollar trades at to yen in tokyo\n",
      "dollar trades at lower ## yen in\n",
      "s. korean stock markets\n",
      "china 's to securities securities\n",
      "malaysia 's rand closed to\n",
      "u.s. stocks open mixed\n",
      "u.s. stocks open lower on modest\n",
      "wall stocks trade lower on modest\n",
      "oil prices fall below ## dollars\n",
      "china china booming china industry\n",
      "chinese chinese find for for in\n",
      "UNK of on in in in\n",
      "iranian president arrives in for\n",
      "australian stock market rises\n",
      "london stock exchange london stock\n",
      "new york of to in in in in\n",
      "un military embassy visits\n",
      "UNK UNK UNK UNK for in in\n",
      "dollar trades in upper ## yen in tokyo\n",
      "gold 's rate in in\n",
      "dollar down in upper ## yen range tokyo\n",
      "boeing of passes to on in\n",
      "beijing chinese hold meets cooperation\n",
      "china 's to market market market\n",
      "us of of to to in in\n",
      "taiwan shares close close percent percent\n",
      "<unk> beats <unk> #-# #-#\n",
      "UNK 's on to in in\n",
      "UNK 's prices prices\n",
      "mexico beats #-# #-# in\n",
      "new to to to in in\n",
      "u.s. stocks trade higher\n",
      "dollar trades narrowly to yen in tokyo\n",
      "china promotes first equipment\n",
      "china of film of 's in in\n",
      "germany wins men 's gold gold gold\n",
      "british stocks trade higher at midday\n",
      "oil prices fall below ## dollars\n",
      "s. african rand markets\n",
      "u.s. stocks open higher\n",
      "german stocks open higher\n",
      "international international exhibition opens opens in\n",
      "malaysia lumpur stocks close lower\n",
      "wall street rallies on\n",
      "s. korea korea to cooperation agreement\n",
      "bruins fires coach scoreboard\n",
      "china urges to to to to in\n",
      "philippine shares close #.# percent percent\n",
      "china 's fund market market\n",
      "us military crashes in crashes\n",
      "dollar trades at lower ## yen in\n",
      "china russia vow to cooperation cooperation cooperation\n",
      "dollar trades in upper ## yen range tokyo\n",
      "stocks close higher in central america\n",
      "macao to to to to in in\n",
      "chinese chinese cooperation fair\n",
      "<unk> <unk> <unk> of <unk> zoo at the\n",
      "world cup cup of for\n",
      "thailand to host international summit\n",
      "china to to to to to in\n",
      "lebanese prime minister visit visit\n",
      "world of world world at\n",
      "copa 's to to for\n",
      "dollar trades in upper ## yen range tokyo\n",
      "china opens development fujian\n",
      "china to to to to to\n",
      "s. korean stocks close\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar remains lower lower lower yen yen\n",
      "tokyo stocks lower dollar dollar against against yen\n",
      "u.s. stocks end higher\n",
      "dollar down in upper ## yen range tokyo\n",
      "philippine stocks close higher\n",
      "jakarta stocks end lower\n",
      "ethiopia to hold talks\n",
      "stocks close higher in central america\n",
      "dollar trades at ## yen in tokyo\n",
      "dollar trades at ## yen in tokyo\n",
      "german stocks end higher\n",
      "france 's UNK to to women 's world world world cup\n",
      "dollar trades at upper yen yen in tokyo\n",
      "london stock market closes higher\n",
      "china agrees to to to on\n",
      "myanmar to to to to to in\n",
      "philippine president in in for\n",
      "stocks stocks end on on\n",
      "dollar trades in upper yen yen in tokyo\n",
      "court workers to to to\n",
      "stocks close higher in mexico brazil\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar down in upper ## yen range tokyo\n",
      "china 's hold to of\n",
      "china 's t-bond market market market\n",
      "beijing to province to\n",
      "china 's market market monday\n",
      "ballesteros UNK at hospitalized\n",
      "international UNK opens opens in in\n",
      "police people at at at at in\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar trades at upper yen yen in tokyo\n",
      "dollar down in upper yen yen in tokyo\n",
      "german stocks end higher\n",
      "tunisia beats luxembourg #-# in world cup\n",
      "chinese of to to to to to to to\n",
      "china 's of of of in\n",
      "dollar down in upper ## yen range tokyo\n",
      "chinese shares close #.## pct on trade trade\n",
      "ecb stock exchange exchange rates\n",
      "australian dollar closes higher\n",
      "australian dollar closes higher\n",
      "australian dollar closes higher\n",
      "bulgarian stock market ends higher\n",
      "dollar remains in upper ## yen range tokyo\n",
      "UNK of to of to in in\n",
      "australian dollar move to\n",
      "china 's new trade\n",
      "russia to to international nuclear\n",
      "international on on on in in\n",
      "german stocks open higher\n",
      "german stocks open higher\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar trades at mid-### yen in tokyo\n",
      "dollar trades at lower yen in tokyo\n",
      "dollar down to upper yen yen in tokyo\n",
      "dollar trades at upper yen yen in\n",
      "dollar trades at lower yen in tokyo\n",
      "dollar remains at lower ## yen range\n",
      "asian of of women at at in\n",
      "cuba to to about\n",
      "german stocks open higher\n",
      "death toll kills toll in in in\n",
      "UNK wins wins at at title\n",
      "stocks close higher in mexico brazil\n",
      "german stocks open higher\n",
      "german stocks open higher\n",
      "a 's of of to to to to in in\n",
      "china 's first new UNK in\n",
      "china urges influence to protect to stance to in in\n",
      "u.s. stocks trade lower on modest\n",
      "german stocks open higher\n",
      "greek stocks close higher\n",
      "german stocks open lower\n",
      "south zealand to to to in\n",
      "us police stabbed in in in\n",
      "beijing to hold on on\n",
      "wall street up after\n",
      "eu union to to to to to to\n",
      "london stock exchange closed for\n",
      "malaysia tin market closes higher\n",
      "wall street up after of\n",
      "leafs forsberg named out to to weeks weeks season\n",
      "german stocks open higher\n",
      "german stock exchange exchange\n",
      "german stock indexes exchange higher\n",
      "german stock indexes exchange higher\n",
      "british stocks trade higher at midday\n",
      "beijing 's build protect to in\n",
      "dollar trades at mid-### yen in\n",
      "dollar remains at lower ## yen range\n",
      "UNK international fair opens opens in\n",
      "china 's host on expressway\n",
      "pakistan pakistan sign sign agreement agreement\n",
      "shenzhen to to face\n",
      "schilling 's to to to to in\n",
      "UNK of <unk> <unk> <unk> <unk>\n",
      "rubber futures close higher on smaller volumes\n",
      "pakistan pm to in\n",
      "turkish pm says to to to with\n",
      "england s to to to for for\n",
      "bomb explodes in in\n",
      "kings rally rangers kings\n",
      "police of of gun UNK in in\n",
      "new zealand stocks close #.## percent\n",
      "singh gets tied for for for at at\n",
      "man man in guilty to for in in in\n",
      "rubber futures close higher on smaller volumes\n",
      "a the of of of\n",
      "bruins fires coach coach manager\n",
      "stocks mixed in early\n",
      "thailand financial markets closed\n",
      "israel says says to to to in\n",
      "oil prices fall in\n",
      "myanmar calls to to to in\n",
      "s. korean shares close on on\n",
      "UNK ivy a for in\n",
      "bayern out to for\n",
      "<unk> wins women 's 's ###m gold\n",
      "rubber futures close higher on smaller volumes\n",
      "australia win women 's gold gold gold\n",
      "s. korean close #.## #.## percent\n",
      "safin upholds to to in\n",
      "hollywood <unk> <unk> <unk> dies at ##\n",
      "UNK <unk> UNK UNK to in in\n",
      "australia wins men 's gold gold gold\n",
      "asian stock markets close mostly\n",
      "woods woods to woods to woods\n",
      "tottenham midfielder to goalkeeper <unk> to to contract contract\n",
      "democrats should to to to on on\n",
      "eagles signs signs #-year deal deal\n",
      "UNK striker <unk> joins to for\n",
      "uganda to hold talks to\n",
      "schumacher schumacher wins san grand prix\n",
      "UNK of of of 's president\n",
      "commonwealth games podium 's 's 's podium\n",
      "podium wins men 's 's 's floor gold\n",
      "atlantic 's to to to to to to to for\n",
      "scotland beats scotland #-#\n",
      "phelps wins UNK stage tour at of\n",
      "fifa to to tougher to to\n",
      "former soviet pm minister dies dies\n",
      "china stock closed for holiday holiday\n",
      "rubber futures close higher on smaller volumes\n",
      "key facts of s s s\n",
      "red wings agree to to deal\n",
      "lebanese prime minister for\n",
      "brazil stocks end #.## #.##\n",
      "pakistan parliament suspends to\n",
      "new zealand stocks close #.# lower\n",
      "<unk> <unk> <unk> wins <unk> <unk> en en <unk>\n",
      "brazil to play in in\n",
      "china financial markets closed\n",
      "UNK 's to to to in the the\n",
      "malaysian financial markets closed\n",
      "england to play friendly in in in\n",
      "webb grabs to to at at classic\n",
      "asian stock markets close in\n",
      "austria wins women 's biathlon biathlon gold\n",
      "asian to to to to to in\n",
      "a the the of of the the the\n",
      "gore 's to to to to to in in\n",
      "tokyo financial markets closed for holiday\n",
      "hong kong markets closed for for\n",
      "UNK of to to to in in in\n",
      "UNK wins ###cc grand prix\n",
      "<unk> of passed <unk> <unk>\n",
      "new of of UNK in in\n",
      "china financial markets closed\n",
      "UNK fires as as coach\n",
      "facts to to election\n",
      "showers delays prix results\n",
      "larsson says to to to to to to season\n",
      "dragila wins wins at at giro\n",
      "UNK brothers UNK to in in\n",
      "former man of guilty in in\n",
      "UNK 's UNK to to of of\n",
      "UNK takes UNK at at open open\n",
      "a dole of a of of in in\n",
      "new of in in in in in\n",
      "devils 's nets to in in\n",
      "mavericks sox to to to to in\n",
      "world cup cup for for\n",
      "new of of of of in in\n",
      "<unk> <unk> <unk> venice at venice\n",
      "tokyo stocks end lower\n",
      "pope calls for talks cooperation\n",
      "tokyo stocks slip dollar higher against yen\n",
      "former classical of of UNK dies at at ##\n",
      "in years in in in in in in in in contributed contributed contributed\n",
      "UNK <unk> <unk> dies dies at\n",
      "nasa to to files for for\n",
      "beckham says to to to to to to to\n",
      "UNK 's UNK the the UNK\n",
      "judge of to convicted in in in\n",
      "kevin crowe is to is to a the\n",
      "u.s. government to to to for in in\n",
      "gingrich zoo of of of of of UNK\n",
      "devils 's to to in in in\n",
      "UNK 's UNK UNK to of of\n",
      "tokyo stocks open higher u.s.\n",
      "kobe 's to to to for\n",
      "boeing to to to to to in\n",
      "malaysia korea agree to expand to to\n",
      "u.s. military of in in\n",
      "lindsay plea pleads pleads in in in\n",
      "UNK ivy game 's to in in\n",
      "tunisia beats armenia #-# in in friendly\n",
      "tokyo stocks open higher dollar up against yen\n",
      "supreme court says to to to to in in\n",
      "<unk> holds #-# #-# #-#\n",
      "galaxy wins for in UNK\n",
      "tokyo stocks end higher dollar up against yen\n",
      "flamengo named as as as coach coach\n",
      "us proposal for iraq to to to to to iraq iraq\n",
      "<unk> of of to s s in\n",
      "beijing 's of to 's to to to\n",
      "sorenstam wins to at at\n",
      "spain and #-# #-# #-# in\n",
      "contains 's to to to to to the\n",
      "a 's 's the on on of\n",
      "actor <unk> of birth of UNK\n",
      "nasa to to spacewalk for\n",
      "UNK of eclipse to in in\n",
      "samuel and hoya says hoya hoya in in in to a in\n",
      "woods woods to woods at\n",
      "stocks stocks stocks year\n",
      "<unk> 's UNK the of of UNK\n",
      "UNK to cut ### for in\n",
      "favre nuggets to to but to for\n",
      "UNK 's the the the the the\n",
      "UNK wins for at at cup\n",
      "tokyo stocks open higher\n",
      "chelsea signs signs signs <unk> to to contract\n",
      "dole finds a to to to a the the\n",
      "us 's to to to to to to to\n",
      "share kong share higher midday\n",
      "google to sales slow to to\n",
      "jennifer 's says wife to to of of\n",
      "woods woods to woods to at\n",
      "ucla ivy for to in\n",
      "stewart gets to in\n",
      "moderate earthquake hits taiwan taiwan\n",
      "interest prices in in range\n",
      "UNK 's to to of to to the the\n",
      "tokyo stocks end lower\n",
      "rob 's to receive the at to the\n",
      "gingrich finds in gun to in in in in\n",
      "the bowl a a the the\n",
      "UNK banned to doping to for doping\n",
      "UNK ivy a to to to the\n",
      "women women to cup to to to cup\n",
      "cowboys release costly\n",
      "montgomerie withdraws to at at open\n",
      "UNK 's for at\n",
      "gordon davies to to to to in\n",
      "UNK UNK secrets UNK\n",
      "els wins to for in at cup cup\n",
      "mickelson gets to for at at\n",
      "colleges UNK secrets UNK\n",
      "UNK wins wins world world world cup victory victory\n",
      "UNK 's UNK at\n",
      "judge of of of of of in in\n",
      "mickelson gets to for for at at\n",
      "oil prices fall below\n",
      "un 's chief to to to to for presidency\n",
      "ioc s to to to to to to UNK\n",
      "singer ferguson harvey to to to in in in\n",
      "UNK villagers to to to in in in\n",
      "bush 's to to to to to in\n",
      "man convicted man man of of of\n",
      "world cup downhill downhill downhill\n",
      "for 's a the the the the the the the the\n",
      "UNK wins wins world at title\n",
      "oprah bacon to to to to of of\n",
      "study finds a to to to to to in\n",
      "u.s. senate passes to to in in\n",
      "stocks mixed in early trading\n",
      "UNK looms UNK for UNK\n",
      "UNK 's to to to in in cup\n",
      "reba sinatra is to on UNK\n",
      "fire of UNK in in in\n",
      "oil york prices as oil\n",
      "gold silver prices as as\n",
      "boeing to buy ### for for in\n",
      "stocks mixed in early trading\n",
      "<unk> named as as coach coach\n",
      "UNK 's UNK to to in in\n",
      "oil prices fall below\n",
      "china urges vow to protect to cooperation cooperation\n",
      "tropical storm forms forms in in in in\n",
      "treasury prices fall as dollar dollar\n",
      "explosion explodes in in\n",
      "new zealand names to in in\n",
      "UNK singer UNK birth to to baby\n",
      "simpson 's in handy\n",
      "<unk> the the\n",
      "bode wins wins world world world cup\n",
      "giuliani 's UNK UNK UNK\n",
      "a the of of of of the\n",
      "bayern extends to to to\n",
      "britney co-founder to to to for\n",
      "us to to to to to\n",
      "UNK UNK in in in in\n",
      "oh designers is a the the\n",
      "stocks mixed in early trading\n",
      "explosion explosion in in explosion explosion\n",
      "parents of of birth of of\n",
      "clemens dominates a to to to the\n",
      "judge trial accused guilty in in in\n",
      "coyotes sign sign to to deal\n",
      "kevin mcconaughey hoya to to to to in\n",
      "contains 's he to to to to to to to\n",
      "ucla 's to to to to in in\n",
      "judge judge to guilty to in\n",
      "<unk> of sought for for\n",
      "rob 's to receive to to in in\n",
      "UNK voted unbeaten on on in cup\n",
      "a of UNK in in\n",
      "exhibit 's UNK UNK to to of of\n",
      "UNK fastest UNK at at\n",
      "small plane crashes in plane crashes in crashes\n",
      "fire fire at at at in\n",
      "bomb explodes in in in in\n",
      "london stock exchange up at midday\n",
      "london share prices close\n",
      "gagne 's to to to to the the\n",
      "world cup biathlon super-g\n",
      "<unk> 's 's to to to to in\n",
      "china 's to to to world world games\n",
      "nasa sues mars nasa for for\n",
      "athletes 's to to to to to to to for the\n",
      "ireland # ireland #\n",
      "interest rates in in auction\n",
      "patriots sign sign free agent <unk> <unk>\n",
      "grammy <unk> to to to at of awards\n",
      "verplank aiming to at\n",
      "bruins hire as as of\n",
      "tyson says to to in\n",
      "dollar mixed gold\n",
      "canseco 's to to to for\n",
      "UNK 's to to in in in in\n",
      "tropical storm becomes toward off off\n",
      "scotland ## ireland ##\n",
      "london 's ftse-### index up ## points at at close close\n",
      "tickets players to to to to to in\n",
      "UNK UNK UNK to to in\n"
     ]
    }
   ],
   "source": [
    "#saved_weights = './weight/without_attention_weight.hdf5'\n",
    "#model.load_weights(saved_weights)\n",
    "\n",
    "X_test = load_test_data('data/test_article.txt', X_word_to_ix, MAX_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=X_max_len, dtype='int32', padding='post')\n",
    "\n",
    "sequences = []\n",
    "for i in range(0,len(X_test),1000):\n",
    "    predictions = np.argmax(model.predict(X_test[i:i+1000]), axis=2)\n",
    "    for prediction in predictions:\n",
    "        sequence = ' '.join([y_ix_to_word[index] for index in prediction if index > 0])\n",
    "        print(sequence)\n",
    "        sequences.append(sequence)\n",
    "        #np.savetxt('test_result_withoutAttention', sequences, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_test = open('data/test_title.txt', \"r\")\n",
    "y_test = title_test.read().split('\\n')\n",
    "y_test = y_test[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test Title: 7000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.15900612017840307,\n",
       "  'p': 0.20825368480725626,\n",
       "  'r': 0.13709816020507085},\n",
       " 'rouge-2': {'f': 0.048503178388617646,\n",
       "  'p': 0.052334070294784575,\n",
       "  'r': 0.046799183752755179},\n",
       " 'rouge-l': {'f': 0.13413816667724052,\n",
       "  'p': 0.1521198285841143,\n",
       "  'r': 0.13374351433739981}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Length of test Title:',len(y_test), '\\n')\n",
    "\n",
    "#Rouge score\n",
    "#[precision, recall, f_score] = r.rouge_l([system_generated_summary], [manual_summmary])\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "#rouge_score = rouge.get_scores(sequences, y_test, avg=True)\n",
    "rouge_score = rouge.get_scores(sequences, y_test, avg=True)\n",
    "rouge_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Visualization\n",
    "We recommended training the data in batches because of our tensor constraints. This also presents us with a challenge of visualizing loss function and accuracy change with each epoch. Keras has an inbuilt function called fit_generator which takes in a generator function and gives the required batch for training. Use this Function to load data in batches of 100 for 200 steps_per_epoch. Run the training for 10 epochs. Use Keras callbacks to send data to tensorboad (you can look this up online).\n",
    "Once your training is done. Go to command line and run tensorboard. By default Tensorboard opens on 6006 port. Do remember to allow traffic on the same for gcloud (like you did for previous assignment). You can see various metrics depending on what you want to track like loss, accuracy, validation loss and validation accuracy over epochs. Attach the plots of loss and accuracy from the tensorboard display in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 188s - loss: 1.5827 - acc: 0.7578   \n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 188s - loss: 1.1941 - acc: 0.7634   \n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 188s - loss: 1.1662 - acc: 0.7634   \n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 187s - loss: 1.1546 - acc: 0.7634   \n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 187s - loss: 1.1487 - acc: 0.7634   \n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 186s - loss: 1.1442 - acc: 0.7634   \n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 190s - loss: 1.1419 - acc: 0.7634   \n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 186s - loss: 1.1398 - acc: 0.7634   \n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 187s - loss: 1.1383 - acc: 0.7634   \n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 188s - loss: 1.1377 - acc: 0.7634   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f677e204780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100\n",
    "STEPS_PER_EPOCH = 200\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "def generator(X, y, batch_size):\n",
    "    while True:\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[:batch_size]\n",
    "    \n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "        y_seq = process_data(y, y_max_len, y_ix_to_word)\n",
    "        \n",
    "        yield X, y_seq\n",
    "    \n",
    "model.fit_generator(generator(X, y,BATCH_SIZE), epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "image/png": {
       "height": 800,
       "width": 1000
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='tensorboard.png',width=1000,height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidirectional LSTM Encoder Decoder With Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for your LSTM encoder decoder model with attention\n",
    "\n",
    "reference: https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "VOCAB_SIZE = 10000\n",
    "BATCH_SIZE = 128\n",
    "LAYER_NUM = 1\n",
    "HIDDEN_DIM = 128\n",
    "NB_EPOCH = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would've observed that the summaries are not yet perfect. This is because in encoder decoder architecture, only the final state of encoder is used to calculate the probabilities. We now move to a more general approach called attention based approach. In this, we take a weighted sum of all weights of encoder instead of just the last one. You are already provided an attention_decoder.py file with AttentionDecoder. Add this layer on top of your encoder and run the same experiment as before. For this part, you don't need to worry about return_probabilities argument to create_UniLSTMwithAttention function. Just pass it as an argument to your attention decoder layer. When return_probabilities is false, the attention decoder returns prediction model, which is what you need for this part of the assignment. When return_probabilities is true, the attention decoder returns the probability model, which you will be using later in the Analysis part of this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model with Attention\n",
    "from attention_decoder import AttentionDecoder\n",
    "def create_UniLSTMwithAttention(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers, return_probabilities = False):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Creating encoder network\n",
    "    model.add(Embedding(X_vocab_len, hidden_size, input_length=X_max_len, mask_zero=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(RepeatVector(y_max_len))\n",
    "\n",
    "    # Creating decoder network, Attention Decoder\n",
    "    model.add(AttentionDecoder(hidden_size, y_vocab_len))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n",
      "[INFO] Zero padding...\n",
      "[INFO] Compiling model...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Loading data...')\n",
    "X, X_vocab_len, X_word_to_ix, X_ix_to_word, y, y_vocab_len, y_word_to_ix, y_ix_to_word = load_data('data/train_article.txt', 'data/train_title.txt', MAX_LEN, VOCAB_SIZE)\n",
    "\n",
    "# Finding the length of the longest sequence\n",
    "\n",
    "X_max_len = max(max([len(sentence) for sentence in X]), max([len(sentence) for sentence in y]))\n",
    "y_max_len = max(max([len(sentence) for sentence in X]), max([len(sentence) for sentence in y]))\n",
    "\n",
    "# Padding zeros to make all sequences have a same length with the longest one\n",
    "print('[INFO] Zero padding...')\n",
    "X = pad_sequences(X, maxlen=X_max_len, dtype='int32', padding='post')\n",
    "y = pad_sequences(y, maxlen=y_max_len, dtype='int32', padding='post')\n",
    "\n",
    "\n",
    "# Creating the network model\n",
    "print('[INFO] Compiling model...')\n",
    "model = create_UniLSTMwithAttention(X_vocab_len, X_max_len, y_vocab_len, y_max_len, HIDDEN_DIM, LAYER_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32)\n",
      "(50000, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_vocab_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model, as you did before, for the model without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 1th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 28s - loss: 9.2060 - acc: 0.1580 - val_loss: 9.1213 - val_acc: 0.7492\n",
      "[INFO] Training model: epoch 1th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 9.0468 - acc: 0.7590 - val_loss: 7.2572 - val_acc: 0.7547\n",
      "[INFO] Training model: epoch 1th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 6.8255 - acc: 0.7633 - val_loss: 4.0111 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 1th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 3.8629 - acc: 0.7629 - val_loss: 2.5982 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 2.5694 - acc: 0.7670 - val_loss: 2.1056 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 2.2225 - acc: 0.7684 - val_loss: 1.8459 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 1th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 2.1720 - acc: 0.7645 - val_loss: 2.0329 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 1th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 2.0713 - acc: 0.7670 - val_loss: 1.9945 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 1th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9786 - acc: 0.7701 - val_loss: 2.0287 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 2.0515 - acc: 0.7598 - val_loss: 1.9966 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 1th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9300 - acc: 0.7695 - val_loss: 2.1100 - val_acc: 0.7445\n",
      "[INFO] Training model: epoch 1th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.9003 - acc: 0.7695 - val_loss: 1.8152 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 1th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 2.0303 - acc: 0.7590 - val_loss: 1.8751 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.9363 - acc: 0.7719 - val_loss: 1.7848 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 1th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8613 - acc: 0.7746 - val_loss: 1.8111 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8690 - acc: 0.7771 - val_loss: 2.0020 - val_acc: 0.7578\n",
      "[INFO] Training model: epoch 1th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8184 - acc: 0.7756 - val_loss: 1.9884 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 1th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8751 - acc: 0.7740 - val_loss: 1.9347 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7743 - acc: 0.7857 - val_loss: 1.7876 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 1th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8846 - acc: 0.7793 - val_loss: 1.9907 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8883 - acc: 0.7781 - val_loss: 1.8643 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 1th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9086 - acc: 0.7709 - val_loss: 1.9181 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 1th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8760 - acc: 0.7715 - val_loss: 1.7921 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7902 - acc: 0.7855 - val_loss: 1.7852 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 1th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8034 - acc: 0.7838 - val_loss: 2.0076 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.9287 - acc: 0.7742 - val_loss: 1.7829 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8624 - acc: 0.7779 - val_loss: 2.0895 - val_acc: 0.7547\n",
      "[INFO] Training model: epoch 1th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8348 - acc: 0.7797 - val_loss: 1.9114 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 1th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8064 - acc: 0.7816 - val_loss: 1.9714 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 1th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8839 - acc: 0.7729 - val_loss: 1.9692 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 1th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8472 - acc: 0.7820 - val_loss: 1.8635 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 1th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8145 - acc: 0.7814 - val_loss: 2.0270 - val_acc: 0.7531\n",
      "[INFO] Training model: epoch 1th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8605 - acc: 0.7734 - val_loss: 1.8093 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8716 - acc: 0.7754 - val_loss: 1.8941 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 1th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8398 - acc: 0.7746 - val_loss: 1.8361 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 1th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8637 - acc: 0.7758 - val_loss: 1.7962 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 1th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8420 - acc: 0.7783 - val_loss: 1.8991 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7619 - acc: 0.7879 - val_loss: 1.8798 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8141 - acc: 0.7828 - val_loss: 1.8576 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 1th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8037 - acc: 0.7795 - val_loss: 1.8472 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 1th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.8617 - acc: 0.7705 - val_loss: 1.7749 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 1th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8513 - acc: 0.7756 - val_loss: 1.8543 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 1th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8382 - acc: 0.7801 - val_loss: 1.9219 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 1th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.8817 - acc: 0.7725 - val_loss: 1.6986 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 1th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8638 - acc: 0.7746 - val_loss: 1.8026 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8030 - acc: 0.7830 - val_loss: 1.7262 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8705 - acc: 0.7736 - val_loss: 1.8351 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9335 - acc: 0.7641 - val_loss: 1.8422 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8033 - acc: 0.7814 - val_loss: 1.8646 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9351 - acc: 0.7670 - val_loss: 1.9753 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 1th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9593 - acc: 0.7627 - val_loss: 1.9854 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 1th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8183 - acc: 0.7789 - val_loss: 1.9547 - val_acc: 0.7594\n",
      "[INFO] Training model: epoch 1th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8934 - acc: 0.7719 - val_loss: 1.8776 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8831 - acc: 0.7695 - val_loss: 1.8145 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 1th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7493 - acc: 0.7877 - val_loss: 1.9272 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 1th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8592 - acc: 0.7768 - val_loss: 1.8967 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9126 - acc: 0.7709 - val_loss: 1.7700 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8997 - acc: 0.7703 - val_loss: 1.8146 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 1th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8411 - acc: 0.7785 - val_loss: 1.8370 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8812 - acc: 0.7682 - val_loss: 1.7630 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8103 - acc: 0.7775 - val_loss: 1.8655 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8232 - acc: 0.7770 - val_loss: 1.7991 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 1th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8607 - acc: 0.7736 - val_loss: 1.7785 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.8256 - acc: 0.7766 - val_loss: 1.6961 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 1th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7078 - acc: 0.7879 - val_loss: 1.7312 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8256 - acc: 0.7812 - val_loss: 1.7973 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 1th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8179 - acc: 0.7770 - val_loss: 1.8163 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 1th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8227 - acc: 0.7773 - val_loss: 1.8266 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 1th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 8s - loss: 1.7939 - acc: 0.7836 - val_loss: 1.6856 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 1th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9248 - acc: 0.7682 - val_loss: 1.8730 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 1th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9205 - acc: 0.7723 - val_loss: 1.8316 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8737 - acc: 0.7791 - val_loss: 1.7095 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 1th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7976 - acc: 0.7805 - val_loss: 1.7456 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8429 - acc: 0.7721 - val_loss: 1.9840 - val_acc: 0.7594\n",
      "[INFO] Training model: epoch 1th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.8314 - acc: 0.7758 - val_loss: 1.9255 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 1th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9422 - acc: 0.7666 - val_loss: 1.7246 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7915 - acc: 0.7793 - val_loss: 1.7479 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 1th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.8675 - acc: 0.7744 - val_loss: 1.6792 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 1th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8964 - acc: 0.7725 - val_loss: 2.0913 - val_acc: 0.7539\n",
      "[INFO] Training model: epoch 1th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7784 - acc: 0.7865 - val_loss: 1.7993 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.8415 - acc: 0.7756 - val_loss: 1.6420 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 1th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7843 - acc: 0.7832 - val_loss: 1.7465 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8498 - acc: 0.7738 - val_loss: 1.9396 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 1th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7976 - acc: 0.7766 - val_loss: 1.8697 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 1th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7426 - acc: 0.7898 - val_loss: 1.8375 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 1th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8578 - acc: 0.7736 - val_loss: 1.8156 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8024 - acc: 0.7785 - val_loss: 1.8009 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8282 - acc: 0.7787 - val_loss: 1.9404 - val_acc: 0.7578\n",
      "[INFO] Training model: epoch 1th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8734 - acc: 0.7723 - val_loss: 1.8396 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 1th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8056 - acc: 0.7768 - val_loss: 1.7383 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 1th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8346 - acc: 0.7766 - val_loss: 1.8553 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7316 - acc: 0.7859 - val_loss: 1.7225 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9926 - acc: 0.7578 - val_loss: 1.8113 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7328 - acc: 0.7881 - val_loss: 1.9167 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8331 - acc: 0.7750 - val_loss: 1.7412 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 1th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8024 - acc: 0.7768 - val_loss: 1.8697 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8097 - acc: 0.7768 - val_loss: 1.8035 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7948 - acc: 0.7787 - val_loss: 1.7927 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 1th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8170 - acc: 0.7734 - val_loss: 1.6637 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 1th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7921 - acc: 0.7818 - val_loss: 1.6958 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 1th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6806 - acc: 0.7898 - val_loss: 1.9492 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 1th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6676 - acc: 0.7918 - val_loss: 1.8956 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 1th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8473 - acc: 0.7693 - val_loss: 1.7587 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8533 - acc: 0.7701 - val_loss: 1.9085 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 1th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8618 - acc: 0.7693 - val_loss: 1.6921 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7477 - acc: 0.7846 - val_loss: 1.8565 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 1th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7741 - acc: 0.7781 - val_loss: 1.7220 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 1th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8151 - acc: 0.7787 - val_loss: 1.7337 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7249 - acc: 0.7852 - val_loss: 1.6697 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8062 - acc: 0.7779 - val_loss: 1.8145 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7680 - acc: 0.7812 - val_loss: 1.7862 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6770 - acc: 0.7900 - val_loss: 1.7330 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.6632 - acc: 0.7945 - val_loss: 1.5875 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 1th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7360 - acc: 0.7840 - val_loss: 1.7471 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 1th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7880 - acc: 0.7797 - val_loss: 1.8575 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 1th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7445 - acc: 0.7850 - val_loss: 1.7179 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8085 - acc: 0.7791 - val_loss: 1.7320 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8485 - acc: 0.7711 - val_loss: 1.7169 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 1th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7652 - acc: 0.7795 - val_loss: 1.6460 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 1th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8103 - acc: 0.7758 - val_loss: 1.7726 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8062 - acc: 0.7766 - val_loss: 1.7317 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8238 - acc: 0.7754 - val_loss: 1.8702 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7254 - acc: 0.7863 - val_loss: 1.7474 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 1th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7782 - acc: 0.7799 - val_loss: 1.7977 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 1th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6565 - acc: 0.7957 - val_loss: 1.8205 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8602 - acc: 0.7730 - val_loss: 1.7368 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7627 - acc: 0.7850 - val_loss: 1.8830 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 1th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7248 - acc: 0.7834 - val_loss: 1.7914 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7714 - acc: 0.7844 - val_loss: 1.7741 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8443 - acc: 0.7699 - val_loss: 1.9239 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 1th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7755 - acc: 0.7809 - val_loss: 1.6247 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 1th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7389 - acc: 0.7869 - val_loss: 1.9612 - val_acc: 0.7547\n",
      "[INFO] Training model: epoch 1th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8123 - acc: 0.7789 - val_loss: 1.7624 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8351 - acc: 0.7684 - val_loss: 1.7334 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 1th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7860 - acc: 0.7828 - val_loss: 1.8061 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6769 - acc: 0.7904 - val_loss: 1.8360 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 1th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8338 - acc: 0.7734 - val_loss: 1.6625 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7705 - acc: 0.7764 - val_loss: 1.6976 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 1th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7254 - acc: 0.7830 - val_loss: 1.7248 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7487 - acc: 0.7805 - val_loss: 1.7820 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6813 - acc: 0.7912 - val_loss: 1.8451 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 1th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7621 - acc: 0.7822 - val_loss: 1.7894 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7544 - acc: 0.7836 - val_loss: 1.7848 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 1th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.7766 - acc: 0.7783 - val_loss: 1.5728 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 1th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8392 - acc: 0.7723 - val_loss: 2.0907 - val_acc: 0.7414\n",
      "[INFO] Training model: epoch 1th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7837 - acc: 0.7797 - val_loss: 1.7685 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8490 - acc: 0.7684 - val_loss: 1.7248 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 1th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7812 - acc: 0.7799 - val_loss: 1.7954 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 1th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.8107 - acc: 0.7787 - val_loss: 1.7736 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7889 - acc: 0.7809 - val_loss: 1.6921 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 1th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7057 - acc: 0.7857 - val_loss: 1.7550 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8067 - acc: 0.7789 - val_loss: 1.8185 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 1th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7406 - acc: 0.7754 - val_loss: 1.6657 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 1th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7862 - acc: 0.7773 - val_loss: 1.8445 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8416 - acc: 0.7748 - val_loss: 1.7186 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7228 - acc: 0.7828 - val_loss: 1.8885 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7767 - acc: 0.7766 - val_loss: 1.8929 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 1th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7831 - acc: 0.7701 - val_loss: 1.6121 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 1th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8730 - acc: 0.7645 - val_loss: 1.7841 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6736 - acc: 0.7908 - val_loss: 1.9919 - val_acc: 0.7492\n",
      "[INFO] Training model: epoch 1th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7975 - acc: 0.7742 - val_loss: 1.7813 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7855 - acc: 0.7775 - val_loss: 1.7520 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 1th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7276 - acc: 0.7844 - val_loss: 1.6981 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 1th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7216 - acc: 0.7848 - val_loss: 1.9014 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 1th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8291 - acc: 0.7699 - val_loss: 1.7724 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 1th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7434 - acc: 0.7855 - val_loss: 1.8091 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7495 - acc: 0.7779 - val_loss: 1.8325 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 1th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6870 - acc: 0.7865 - val_loss: 1.7709 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 1th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7052 - acc: 0.7859 - val_loss: 2.0373 - val_acc: 0.7508\n",
      "[INFO] Training model: epoch 1th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7933 - acc: 0.7770 - val_loss: 1.8823 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 1th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 8s - loss: 1.7649 - acc: 0.7787 - val_loss: 1.5687 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 1th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7825 - acc: 0.7754 - val_loss: 1.9873 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 1th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7965 - acc: 0.7777 - val_loss: 1.9145 - val_acc: 0.7602\n",
      "[INFO] Training model: epoch 1th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7593 - acc: 0.7783 - val_loss: 1.8719 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 1th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8056 - acc: 0.7680 - val_loss: 1.7145 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 1th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7176 - acc: 0.7854 - val_loss: 1.7484 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 1th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.6982 - acc: 0.7875 - val_loss: 1.5413 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 1th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7583 - acc: 0.7828 - val_loss: 1.7343 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6696 - acc: 0.7891 - val_loss: 1.7247 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7110 - acc: 0.7865 - val_loss: 1.8911 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 1th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8039 - acc: 0.7750 - val_loss: 1.7255 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 1th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7858 - acc: 0.7781 - val_loss: 1.6666 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 1th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7146 - acc: 0.7826 - val_loss: 1.8437 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 1th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7259 - acc: 0.7848 - val_loss: 1.6985 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7167 - acc: 0.7832 - val_loss: 1.7356 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 1th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7620 - acc: 0.7791 - val_loss: 1.8489 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 1th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7914 - acc: 0.7764 - val_loss: 1.6287 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 1th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6584 - acc: 0.7908 - val_loss: 1.9297 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 1th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6658 - acc: 0.7904 - val_loss: 1.8185 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 1th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8268 - acc: 0.7738 - val_loss: 1.7489 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 1th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6438 - acc: 0.7934 - val_loss: 1.7453 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 1th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8431 - acc: 0.7674 - val_loss: 1.6250 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 1th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6641 - acc: 0.7914 - val_loss: 1.6566 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 1th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7772 - acc: 0.7768 - val_loss: 1.6152 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 1th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7489 - acc: 0.7801 - val_loss: 1.7421 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6534 - acc: 0.7895 - val_loss: 1.9714 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 1th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6956 - acc: 0.7834 - val_loss: 1.9091 - val_acc: 0.7602\n",
      "[INFO] Training model: epoch 1th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6883 - acc: 0.7861 - val_loss: 1.5571 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 1th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8676 - acc: 0.7658 - val_loss: 1.8312 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 1th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7412 - acc: 0.7852 - val_loss: 1.7720 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 1th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8414 - acc: 0.7734 - val_loss: 1.6939 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 1th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7197 - acc: 0.7900 - val_loss: 1.7235 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 1th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6921 - acc: 0.7832 - val_loss: 1.8797 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 1th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7726 - acc: 0.7775 - val_loss: 1.7414 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 1th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7414 - acc: 0.7822 - val_loss: 1.7071 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 1th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8009 - acc: 0.7736 - val_loss: 1.7109 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6851 - acc: 0.7887 - val_loss: 1.6706 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 1th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.7448 - acc: 0.7828 - val_loss: 1.4997 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 1th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7701 - acc: 0.7771 - val_loss: 1.8683 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 1th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7609 - acc: 0.7799 - val_loss: 1.5536 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 1th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7172 - acc: 0.7812 - val_loss: 1.7169 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7456 - acc: 0.7820 - val_loss: 1.6679 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 1th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7747 - acc: 0.7730 - val_loss: 1.6980 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6945 - acc: 0.7883 - val_loss: 1.8622 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 1th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6913 - acc: 0.7879 - val_loss: 1.5813 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 1th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8400 - acc: 0.7744 - val_loss: 1.6962 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 1th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7480 - acc: 0.7779 - val_loss: 1.7018 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7614 - acc: 0.7773 - val_loss: 1.7033 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 1th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6323 - acc: 0.7957 - val_loss: 1.6644 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7152 - acc: 0.7838 - val_loss: 1.6343 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 1th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6993 - acc: 0.7900 - val_loss: 1.7862 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 1th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6675 - acc: 0.7893 - val_loss: 1.7569 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 1th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7430 - acc: 0.7840 - val_loss: 1.6825 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 1th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7401 - acc: 0.7816 - val_loss: 1.6887 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 1th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7460 - acc: 0.7830 - val_loss: 1.7085 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 1th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7892 - acc: 0.7754 - val_loss: 1.5820 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 1th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7415 - acc: 0.7818 - val_loss: 1.8344 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 1th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8022 - acc: 0.7771 - val_loss: 1.7107 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 1th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8039 - acc: 0.7756 - val_loss: 1.8321 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 1th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7013 - acc: 0.7850 - val_loss: 1.8626 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 1th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7953 - acc: 0.7734 - val_loss: 1.7045 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 1th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7507 - acc: 0.7771 - val_loss: 1.9343 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 1th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8415 - acc: 0.7689 - val_loss: 1.8205 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 1th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7283 - acc: 0.7824 - val_loss: 1.6654 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 1th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7093 - acc: 0.7850 - val_loss: 1.8053 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 1th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6668 - acc: 0.7922 - val_loss: 1.7533 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7191 - acc: 0.7832 - val_loss: 1.6983 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 1th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6831 - acc: 0.7906 - val_loss: 1.7250 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 1th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6687 - acc: 0.7889 - val_loss: 1.8997 - val_acc: 0.7555\n",
      "[INFO] Training model: epoch 1th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7078 - acc: 0.7840 - val_loss: 1.7331 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 1th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6026 - acc: 0.7957 - val_loss: 1.5848 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 1th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7719 - acc: 0.7791 - val_loss: 1.7014 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7288 - acc: 0.7789 - val_loss: 1.6810 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 1th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7573 - acc: 0.7777 - val_loss: 1.8211 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 1th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7413 - acc: 0.7781 - val_loss: 1.6979 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 1th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7357 - acc: 0.7793 - val_loss: 1.6989 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 1th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7687 - acc: 0.7775 - val_loss: 1.6874 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 1th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7436 - acc: 0.7879 - val_loss: 1.8207 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 1th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6754 - acc: 0.7883 - val_loss: 1.7476 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 1th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7674 - acc: 0.7771 - val_loss: 1.6543 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 2th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8153 - acc: 0.7691 - val_loss: 1.7494 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6555 - acc: 0.7881 - val_loss: 1.7373 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 2th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7803 - acc: 0.7748 - val_loss: 1.6653 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 2th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7592 - acc: 0.7824 - val_loss: 1.7184 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 2th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6631 - acc: 0.7871 - val_loss: 1.7690 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7824 - acc: 0.7719 - val_loss: 1.8945 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 2th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7135 - acc: 0.7822 - val_loss: 1.6671 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6407 - acc: 0.7930 - val_loss: 1.7501 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6620 - acc: 0.7891 - val_loss: 1.7559 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7115 - acc: 0.7838 - val_loss: 1.8153 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6353 - acc: 0.7898 - val_loss: 2.0811 - val_acc: 0.7461\n",
      "[INFO] Training model: epoch 2th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7699 - acc: 0.7744 - val_loss: 1.7418 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7575 - acc: 0.7791 - val_loss: 1.6805 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6497 - acc: 0.7895 - val_loss: 1.7912 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7167 - acc: 0.7789 - val_loss: 1.6724 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 2th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8765 - acc: 0.7648 - val_loss: 1.6544 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8021 - acc: 0.7756 - val_loss: 1.6284 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 2th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7138 - acc: 0.7824 - val_loss: 1.6010 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 2th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6883 - acc: 0.7814 - val_loss: 1.5711 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 2th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6497 - acc: 0.7912 - val_loss: 1.6522 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 2th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8711 - acc: 0.7684 - val_loss: 1.6844 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6867 - acc: 0.7854 - val_loss: 1.7062 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7634 - acc: 0.7766 - val_loss: 1.8692 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7320 - acc: 0.7848 - val_loss: 1.8271 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 2th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7447 - acc: 0.7809 - val_loss: 1.5983 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 2th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6956 - acc: 0.7854 - val_loss: 1.7473 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 2th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7548 - acc: 0.7768 - val_loss: 2.0988 - val_acc: 0.7430\n",
      "[INFO] Training model: epoch 2th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7317 - acc: 0.7826 - val_loss: 1.5813 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 2th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 7s - loss: 1.8051 - acc: 0.7738 - val_loss: 1.4692 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 2th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7135 - acc: 0.7811 - val_loss: 1.5402 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 2th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6759 - acc: 0.7875 - val_loss: 1.5453 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 2th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5900 - acc: 0.7990 - val_loss: 1.5019 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 2th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6878 - acc: 0.7863 - val_loss: 1.7007 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 2th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7163 - acc: 0.7824 - val_loss: 1.6966 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 2th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8150 - acc: 0.7717 - val_loss: 1.7996 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 2th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8101 - acc: 0.7725 - val_loss: 1.8021 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.6861 - acc: 0.7830 - val_loss: 1.4492 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 2th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7654 - acc: 0.7777 - val_loss: 1.8327 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 2th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7557 - acc: 0.7799 - val_loss: 1.7440 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7335 - acc: 0.7803 - val_loss: 1.7539 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7156 - acc: 0.7779 - val_loss: 1.7221 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 2th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6772 - acc: 0.7854 - val_loss: 1.8010 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 2th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7534 - acc: 0.7801 - val_loss: 1.6423 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 2th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7161 - acc: 0.7807 - val_loss: 1.6951 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7729 - acc: 0.7738 - val_loss: 1.8520 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 2th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6749 - acc: 0.7900 - val_loss: 1.6741 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 2th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7598 - acc: 0.7727 - val_loss: 1.7103 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7199 - acc: 0.7811 - val_loss: 1.6126 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 2th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6550 - acc: 0.7861 - val_loss: 1.7904 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6937 - acc: 0.7814 - val_loss: 1.6258 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6406 - acc: 0.7887 - val_loss: 1.6606 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7592 - acc: 0.7785 - val_loss: 1.7739 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 2th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6929 - acc: 0.7818 - val_loss: 1.7172 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7664 - acc: 0.7732 - val_loss: 1.7239 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 2th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6485 - acc: 0.7881 - val_loss: 1.7698 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7346 - acc: 0.7799 - val_loss: 1.5231 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 2th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6112 - acc: 0.7977 - val_loss: 1.5336 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 2th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7445 - acc: 0.7771 - val_loss: 1.7726 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6918 - acc: 0.7816 - val_loss: 1.7673 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8828 - acc: 0.7664 - val_loss: 1.7148 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 2th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6263 - acc: 0.7893 - val_loss: 1.7352 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6378 - acc: 0.7902 - val_loss: 1.7781 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 2th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7962 - acc: 0.7734 - val_loss: 1.7352 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 2th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7327 - acc: 0.7807 - val_loss: 1.7430 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 2th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7323 - acc: 0.7809 - val_loss: 1.7221 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7083 - acc: 0.7840 - val_loss: 1.7625 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 2th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7341 - acc: 0.7801 - val_loss: 1.5857 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 2th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6817 - acc: 0.7850 - val_loss: 1.5659 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 2th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7217 - acc: 0.7812 - val_loss: 1.5891 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 2th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7726 - acc: 0.7717 - val_loss: 1.5207 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 2th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8252 - acc: 0.7687 - val_loss: 1.7089 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7370 - acc: 0.7842 - val_loss: 1.8647 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 2th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5552 - acc: 0.7994 - val_loss: 1.8320 - val_acc: 0.7609\n",
      "[INFO] Training model: epoch 2th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6707 - acc: 0.7879 - val_loss: 1.6301 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7150 - acc: 0.7844 - val_loss: 1.6867 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 2th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6576 - acc: 0.7838 - val_loss: 1.7187 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6531 - acc: 0.7842 - val_loss: 1.8339 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 2th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7668 - acc: 0.7803 - val_loss: 1.6475 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7721 - acc: 0.7791 - val_loss: 1.7115 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7122 - acc: 0.7762 - val_loss: 1.7602 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6537 - acc: 0.7918 - val_loss: 1.6747 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6544 - acc: 0.7885 - val_loss: 1.5561 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 2th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7360 - acc: 0.7754 - val_loss: 1.5419 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 2th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7440 - acc: 0.7771 - val_loss: 1.9424 - val_acc: 0.7555\n",
      "[INFO] Training model: epoch 2th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7091 - acc: 0.7803 - val_loss: 1.5123 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 2th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6909 - acc: 0.7863 - val_loss: 1.6578 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6430 - acc: 0.7895 - val_loss: 1.5812 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 2th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6589 - acc: 0.7906 - val_loss: 1.4848 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 2th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6419 - acc: 0.7941 - val_loss: 1.5997 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 2th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7228 - acc: 0.7801 - val_loss: 1.8242 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7397 - acc: 0.7785 - val_loss: 1.7922 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 2th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6588 - acc: 0.7871 - val_loss: 1.7167 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6757 - acc: 0.7840 - val_loss: 1.6340 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 2th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7261 - acc: 0.7783 - val_loss: 1.6045 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 2th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7254 - acc: 0.7791 - val_loss: 1.7122 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6519 - acc: 0.7900 - val_loss: 1.7344 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6424 - acc: 0.7926 - val_loss: 1.7247 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6725 - acc: 0.7875 - val_loss: 1.6976 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 2th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7310 - acc: 0.7822 - val_loss: 1.8209 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7318 - acc: 0.7814 - val_loss: 1.7428 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 2th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7104 - acc: 0.7795 - val_loss: 1.7392 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7195 - acc: 0.7793 - val_loss: 1.7150 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7308 - acc: 0.7832 - val_loss: 1.7375 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7257 - acc: 0.7793 - val_loss: 1.8207 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6633 - acc: 0.7900 - val_loss: 1.6651 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 2th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7729 - acc: 0.7742 - val_loss: 1.8060 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 2th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7519 - acc: 0.7818 - val_loss: 1.6414 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 2th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6595 - acc: 0.7908 - val_loss: 1.6060 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 2th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7299 - acc: 0.7805 - val_loss: 1.6292 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 2th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6718 - acc: 0.7855 - val_loss: 1.7472 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 2th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6778 - acc: 0.7848 - val_loss: 1.8240 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 2th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7047 - acc: 0.7820 - val_loss: 1.8030 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7783 - acc: 0.7785 - val_loss: 1.7436 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6758 - acc: 0.7896 - val_loss: 1.9054 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 2th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6423 - acc: 0.7867 - val_loss: 1.6296 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7151 - acc: 0.7822 - val_loss: 1.7624 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7178 - acc: 0.7789 - val_loss: 1.7351 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 2th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8005 - acc: 0.7703 - val_loss: 1.6821 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 2th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6906 - acc: 0.7895 - val_loss: 1.6368 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 2th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7481 - acc: 0.7771 - val_loss: 1.7728 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 2th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7453 - acc: 0.7822 - val_loss: 1.6276 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6813 - acc: 0.7836 - val_loss: 1.7158 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 2th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7938 - acc: 0.7738 - val_loss: 1.6371 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 2th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6688 - acc: 0.7891 - val_loss: 1.8769 - val_acc: 0.7609\n",
      "[INFO] Training model: epoch 2th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6281 - acc: 0.7865 - val_loss: 1.7077 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 2th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6971 - acc: 0.7857 - val_loss: 1.7423 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 2th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6022 - acc: 0.7953 - val_loss: 1.5154 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 2th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7109 - acc: 0.7809 - val_loss: 1.7827 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7490 - acc: 0.7768 - val_loss: 1.9585 - val_acc: 0.7461\n",
      "[INFO] Training model: epoch 2th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7435 - acc: 0.7771 - val_loss: 1.8169 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 2th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6857 - acc: 0.7867 - val_loss: 1.6540 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7457 - acc: 0.7846 - val_loss: 1.7235 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7461 - acc: 0.7791 - val_loss: 1.7359 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 2th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7278 - acc: 0.7791 - val_loss: 1.5696 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 2th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7924 - acc: 0.7744 - val_loss: 1.7310 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 2th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.9007 - acc: 0.7646 - val_loss: 1.6919 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 2th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6299 - acc: 0.7916 - val_loss: 1.6071 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7939 - acc: 0.7721 - val_loss: 1.8332 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 2th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7181 - acc: 0.7842 - val_loss: 1.9007 - val_acc: 0.7594\n",
      "[INFO] Training model: epoch 2th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7354 - acc: 0.7791 - val_loss: 1.6249 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 2th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6894 - acc: 0.7838 - val_loss: 1.7332 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 2th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7366 - acc: 0.7824 - val_loss: 1.6334 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7390 - acc: 0.7766 - val_loss: 1.7493 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 2th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7052 - acc: 0.7799 - val_loss: 1.6255 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 2th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7576 - acc: 0.7758 - val_loss: 1.7438 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7879 - acc: 0.7719 - val_loss: 1.7368 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7128 - acc: 0.7811 - val_loss: 1.8217 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 2th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7703 - acc: 0.7775 - val_loss: 1.6293 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7460 - acc: 0.7803 - val_loss: 1.9013 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 2th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6876 - acc: 0.7838 - val_loss: 2.0129 - val_acc: 0.7563\n",
      "[INFO] Training model: epoch 2th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5565 - acc: 0.8012 - val_loss: 1.6358 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6008 - acc: 0.7932 - val_loss: 1.8583 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 2th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8319 - acc: 0.7717 - val_loss: 1.7278 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7083 - acc: 0.7854 - val_loss: 1.7537 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 2th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6517 - acc: 0.7859 - val_loss: 1.8257 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6944 - acc: 0.7871 - val_loss: 1.7927 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 2th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7194 - acc: 0.7803 - val_loss: 1.6818 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6773 - acc: 0.7877 - val_loss: 1.7809 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 2th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6369 - acc: 0.7916 - val_loss: 1.7589 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6476 - acc: 0.7889 - val_loss: 1.7853 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 2th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6640 - acc: 0.7867 - val_loss: 1.7480 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6494 - acc: 0.7852 - val_loss: 1.5845 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 2th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6620 - acc: 0.7865 - val_loss: 1.7623 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 2th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8258 - acc: 0.7678 - val_loss: 1.6409 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 2th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6856 - acc: 0.7844 - val_loss: 1.7175 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 2th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6365 - acc: 0.7900 - val_loss: 1.7158 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 2th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6967 - acc: 0.7820 - val_loss: 1.6491 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 2th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7125 - acc: 0.7814 - val_loss: 1.6849 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 2th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7955 - acc: 0.7715 - val_loss: 1.6906 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7192 - acc: 0.7820 - val_loss: 1.8107 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 2th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7728 - acc: 0.7752 - val_loss: 1.8735 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 2th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6946 - acc: 0.7842 - val_loss: 1.7371 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6702 - acc: 0.7883 - val_loss: 1.7285 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7874 - acc: 0.7738 - val_loss: 1.7167 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6626 - acc: 0.7881 - val_loss: 1.7468 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 2th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6451 - acc: 0.7873 - val_loss: 1.7932 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 2th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6381 - acc: 0.7906 - val_loss: 1.8156 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 2th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6756 - acc: 0.7871 - val_loss: 1.8087 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 2th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7051 - acc: 0.7836 - val_loss: 1.6988 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 2th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6897 - acc: 0.7854 - val_loss: 1.6646 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 2th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7238 - acc: 0.7771 - val_loss: 1.6132 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 2th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6879 - acc: 0.7871 - val_loss: 1.7448 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 2th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7288 - acc: 0.7789 - val_loss: 1.5983 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 2th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7478 - acc: 0.7756 - val_loss: 1.7244 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 2th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6033 - acc: 0.7920 - val_loss: 1.8749 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 2th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7255 - acc: 0.7811 - val_loss: 1.8457 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 2th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6843 - acc: 0.7830 - val_loss: 1.6652 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7370 - acc: 0.7758 - val_loss: 1.5299 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 2th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7262 - acc: 0.7797 - val_loss: 1.7631 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7167 - acc: 0.7820 - val_loss: 1.8945 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 2th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7243 - acc: 0.7818 - val_loss: 1.7039 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 2th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7189 - acc: 0.7801 - val_loss: 1.6648 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 2th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6632 - acc: 0.7879 - val_loss: 1.6876 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6971 - acc: 0.7820 - val_loss: 1.5804 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6343 - acc: 0.7955 - val_loss: 1.7467 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 2th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7200 - acc: 0.7793 - val_loss: 1.6900 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6451 - acc: 0.7922 - val_loss: 1.5235 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 2th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6222 - acc: 0.7887 - val_loss: 1.5912 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 2th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6962 - acc: 0.7887 - val_loss: 1.7148 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6857 - acc: 0.7861 - val_loss: 1.5111 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 2th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6390 - acc: 0.7893 - val_loss: 1.8000 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6746 - acc: 0.7871 - val_loss: 1.5699 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 2th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6556 - acc: 0.7887 - val_loss: 1.5984 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 2th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6931 - acc: 0.7875 - val_loss: 1.6035 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 2th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6247 - acc: 0.7918 - val_loss: 1.6971 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 2th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6827 - acc: 0.7871 - val_loss: 1.7583 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 2th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7087 - acc: 0.7822 - val_loss: 1.8835 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 2th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6393 - acc: 0.7936 - val_loss: 1.7351 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 2th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6638 - acc: 0.7865 - val_loss: 1.7294 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 2th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7649 - acc: 0.7793 - val_loss: 1.6372 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7628 - acc: 0.7773 - val_loss: 1.6837 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6900 - acc: 0.7807 - val_loss: 1.5497 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 2th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6648 - acc: 0.7836 - val_loss: 1.5900 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 2th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6694 - acc: 0.7877 - val_loss: 1.8304 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 2th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6762 - acc: 0.7859 - val_loss: 1.8944 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 2th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8141 - acc: 0.7754 - val_loss: 1.7985 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 2th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7383 - acc: 0.7787 - val_loss: 1.6550 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 2th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8155 - acc: 0.7705 - val_loss: 1.6662 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 2th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7559 - acc: 0.7789 - val_loss: 1.7489 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6184 - acc: 0.7910 - val_loss: 1.6605 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8096 - acc: 0.7738 - val_loss: 1.6830 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 2th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6888 - acc: 0.7869 - val_loss: 1.8194 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 2th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7285 - acc: 0.7779 - val_loss: 1.7346 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 2th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6411 - acc: 0.7902 - val_loss: 1.6948 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 2th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7268 - acc: 0.7793 - val_loss: 1.4699 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 2th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6436 - acc: 0.7879 - val_loss: 1.8226 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 2th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6442 - acc: 0.7848 - val_loss: 1.8081 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 2th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6885 - acc: 0.7811 - val_loss: 1.6693 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7000 - acc: 0.7854 - val_loss: 1.7438 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 2th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6683 - acc: 0.7855 - val_loss: 1.6880 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 2th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7344 - acc: 0.7791 - val_loss: 1.7757 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 2th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6847 - acc: 0.7859 - val_loss: 1.6484 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7023 - acc: 0.7799 - val_loss: 1.5035 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 2th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6699 - acc: 0.7844 - val_loss: 1.6809 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 2th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7045 - acc: 0.7818 - val_loss: 1.6523 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 2th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6925 - acc: 0.7848 - val_loss: 1.6059 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 2th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8212 - acc: 0.7689 - val_loss: 1.9461 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 2th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6827 - acc: 0.7857 - val_loss: 1.7107 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 2th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6504 - acc: 0.7863 - val_loss: 1.6804 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 2th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5968 - acc: 0.7957 - val_loss: 1.7590 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 2th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6989 - acc: 0.7785 - val_loss: 1.6837 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 2th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7010 - acc: 0.7812 - val_loss: 1.6672 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6257 - acc: 0.7906 - val_loss: 1.7261 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 2th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7574 - acc: 0.7770 - val_loss: 1.7125 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 2th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6922 - acc: 0.7826 - val_loss: 1.6653 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 2th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6829 - acc: 0.7893 - val_loss: 1.8142 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 2th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7530 - acc: 0.7775 - val_loss: 1.7163 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 2th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5284 - acc: 0.7992 - val_loss: 1.5800 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 2th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6295 - acc: 0.7906 - val_loss: 1.5703 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 2th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7269 - acc: 0.7811 - val_loss: 1.6386 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 3th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6098 - acc: 0.7910 - val_loss: 1.5521 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6216 - acc: 0.7895 - val_loss: 1.7317 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 3th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6576 - acc: 0.7893 - val_loss: 1.6079 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 3th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.7330 - acc: 0.7752 - val_loss: 1.4337 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 3th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7515 - acc: 0.7768 - val_loss: 1.7187 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6278 - acc: 0.7945 - val_loss: 1.7691 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 3th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6909 - acc: 0.7836 - val_loss: 1.6839 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 3th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7721 - acc: 0.7752 - val_loss: 1.6645 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 3th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 5s - loss: 1.6616 - acc: 0.7842 - val_loss: 1.3822 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 3th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6741 - acc: 0.7822 - val_loss: 1.5919 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6764 - acc: 0.7801 - val_loss: 1.5648 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6831 - acc: 0.7830 - val_loss: 1.7380 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 3th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6708 - acc: 0.7846 - val_loss: 1.8577 - val_acc: 0.7578\n",
      "[INFO] Training model: epoch 3th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7280 - acc: 0.7791 - val_loss: 1.7724 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6198 - acc: 0.7938 - val_loss: 1.4821 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 3th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6253 - acc: 0.7932 - val_loss: 1.7050 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 3th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7511 - acc: 0.7703 - val_loss: 1.5505 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 3th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7048 - acc: 0.7801 - val_loss: 1.6606 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 3th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6521 - acc: 0.7836 - val_loss: 1.7213 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6862 - acc: 0.7830 - val_loss: 1.5982 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 3th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6988 - acc: 0.7816 - val_loss: 1.6632 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7351 - acc: 0.7781 - val_loss: 1.5801 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 3th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7693 - acc: 0.7715 - val_loss: 1.7192 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7226 - acc: 0.7811 - val_loss: 1.6265 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7186 - acc: 0.7746 - val_loss: 1.6409 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6788 - acc: 0.7832 - val_loss: 1.6245 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6489 - acc: 0.7846 - val_loss: 1.7729 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 3th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6140 - acc: 0.7896 - val_loss: 1.5988 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 3th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6175 - acc: 0.7863 - val_loss: 1.6259 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 3th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6517 - acc: 0.7826 - val_loss: 1.7482 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7321 - acc: 0.7779 - val_loss: 1.7179 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6542 - acc: 0.7797 - val_loss: 1.6456 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 3th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6748 - acc: 0.7828 - val_loss: 1.6296 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 3th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6707 - acc: 0.7861 - val_loss: 1.5840 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 3th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7328 - acc: 0.7783 - val_loss: 1.5112 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 3th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6865 - acc: 0.7854 - val_loss: 1.7981 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 3th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6141 - acc: 0.7873 - val_loss: 1.7201 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 3th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7123 - acc: 0.7834 - val_loss: 1.7066 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6283 - acc: 0.7906 - val_loss: 1.6390 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 3th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6096 - acc: 0.7906 - val_loss: 1.6797 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 3th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6985 - acc: 0.7809 - val_loss: 1.5380 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6288 - acc: 0.7875 - val_loss: 1.6693 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 3th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7171 - acc: 0.7820 - val_loss: 1.6966 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6550 - acc: 0.7834 - val_loss: 1.7504 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 3th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7500 - acc: 0.7777 - val_loss: 1.6967 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6763 - acc: 0.7865 - val_loss: 1.8758 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 3th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6716 - acc: 0.7852 - val_loss: 1.8522 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 3th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.8293 - acc: 0.7643 - val_loss: 1.6211 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7646 - acc: 0.7701 - val_loss: 1.6321 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 3th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6095 - acc: 0.7924 - val_loss: 1.6455 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 3th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6172 - acc: 0.7949 - val_loss: 1.7935 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 3th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6216 - acc: 0.7902 - val_loss: 1.5755 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 3th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6455 - acc: 0.7889 - val_loss: 1.7656 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 3th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6330 - acc: 0.7877 - val_loss: 1.5792 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 3th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7150 - acc: 0.7838 - val_loss: 1.6801 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 3th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5603 - acc: 0.7959 - val_loss: 1.6330 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 3th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6107 - acc: 0.7932 - val_loss: 1.7571 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 3th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7182 - acc: 0.7807 - val_loss: 1.7282 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 3th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7367 - acc: 0.7779 - val_loss: 1.6473 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 3th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7576 - acc: 0.7768 - val_loss: 1.8191 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 3th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6511 - acc: 0.7797 - val_loss: 1.7670 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 3th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6663 - acc: 0.7807 - val_loss: 1.8609 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 3th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7312 - acc: 0.7742 - val_loss: 1.7129 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7025 - acc: 0.7811 - val_loss: 1.6118 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 3th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5673 - acc: 0.7949 - val_loss: 1.5576 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 3th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5459 - acc: 0.7967 - val_loss: 1.7544 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 3th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5748 - acc: 0.7967 - val_loss: 1.7049 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 3th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6307 - acc: 0.7906 - val_loss: 1.7210 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6252 - acc: 0.7904 - val_loss: 1.6938 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7029 - acc: 0.7770 - val_loss: 1.6907 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 3th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6201 - acc: 0.7871 - val_loss: 1.8069 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 3th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6746 - acc: 0.7852 - val_loss: 1.6360 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6768 - acc: 0.7855 - val_loss: 1.5604 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 3th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6410 - acc: 0.7861 - val_loss: 1.7398 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 3th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6467 - acc: 0.7865 - val_loss: 1.6177 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 3th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6807 - acc: 0.7883 - val_loss: 1.4966 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 3th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6330 - acc: 0.7922 - val_loss: 1.6942 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 3th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7171 - acc: 0.7789 - val_loss: 1.7352 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6277 - acc: 0.7895 - val_loss: 1.5937 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 3th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7107 - acc: 0.7820 - val_loss: 1.5443 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6433 - acc: 0.7871 - val_loss: 1.5702 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 3th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6803 - acc: 0.7791 - val_loss: 1.7984 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 3th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7048 - acc: 0.7852 - val_loss: 1.7371 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7106 - acc: 0.7736 - val_loss: 1.5905 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 3th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6641 - acc: 0.7916 - val_loss: 1.7287 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7178 - acc: 0.7771 - val_loss: 1.5714 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 3th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7652 - acc: 0.7752 - val_loss: 1.6260 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 3th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7239 - acc: 0.7762 - val_loss: 1.6411 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6939 - acc: 0.7758 - val_loss: 1.5666 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 3th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7228 - acc: 0.7795 - val_loss: 1.9529 - val_acc: 0.7563\n",
      "[INFO] Training model: epoch 3th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6677 - acc: 0.7889 - val_loss: 1.6614 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 3th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6897 - acc: 0.7824 - val_loss: 1.8109 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6959 - acc: 0.7809 - val_loss: 1.8186 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 3th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6937 - acc: 0.7848 - val_loss: 1.8834 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 3th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7082 - acc: 0.7787 - val_loss: 1.7895 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6668 - acc: 0.7844 - val_loss: 1.7729 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 3th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7469 - acc: 0.7729 - val_loss: 1.7956 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 3th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6000 - acc: 0.7912 - val_loss: 1.7574 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6143 - acc: 0.7924 - val_loss: 1.6274 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6422 - acc: 0.7879 - val_loss: 1.7079 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 3th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6371 - acc: 0.7857 - val_loss: 1.5676 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 3th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6128 - acc: 0.7924 - val_loss: 1.7069 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 3th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6182 - acc: 0.7877 - val_loss: 1.6256 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 3th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7250 - acc: 0.7768 - val_loss: 1.5530 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 3th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7463 - acc: 0.7764 - val_loss: 1.7926 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 3th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6842 - acc: 0.7852 - val_loss: 1.5617 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 3th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6679 - acc: 0.7818 - val_loss: 1.5426 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 3th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6516 - acc: 0.7855 - val_loss: 1.6618 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 3th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6208 - acc: 0.7910 - val_loss: 1.7692 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 3th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6091 - acc: 0.7885 - val_loss: 1.7174 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 3th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6359 - acc: 0.7869 - val_loss: 1.5229 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 3th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6341 - acc: 0.7852 - val_loss: 1.6496 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 3th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7485 - acc: 0.7699 - val_loss: 1.5300 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 3th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7769 - acc: 0.7713 - val_loss: 1.7115 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5658 - acc: 0.7938 - val_loss: 1.7823 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 3th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7286 - acc: 0.7820 - val_loss: 1.6563 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 3th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6434 - acc: 0.7891 - val_loss: 1.5607 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 3th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5772 - acc: 0.7928 - val_loss: 1.6098 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 3th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6667 - acc: 0.7883 - val_loss: 1.6040 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 3th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5376 - acc: 0.7977 - val_loss: 1.7529 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7607 - acc: 0.7750 - val_loss: 1.6199 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 3th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6464 - acc: 0.7861 - val_loss: 1.6637 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6021 - acc: 0.7879 - val_loss: 1.6358 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5707 - acc: 0.7961 - val_loss: 1.5952 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 3th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5692 - acc: 0.7967 - val_loss: 1.8293 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 3th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5710 - acc: 0.7986 - val_loss: 1.6835 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 3th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6675 - acc: 0.7857 - val_loss: 1.7154 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 3th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6097 - acc: 0.7887 - val_loss: 1.5900 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 3th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6410 - acc: 0.7867 - val_loss: 1.6636 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 3th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7567 - acc: 0.7740 - val_loss: 1.6397 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7396 - acc: 0.7756 - val_loss: 1.6235 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6480 - acc: 0.7906 - val_loss: 1.6589 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6685 - acc: 0.7830 - val_loss: 1.7348 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6081 - acc: 0.7889 - val_loss: 1.7344 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 3th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5709 - acc: 0.7990 - val_loss: 1.6662 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5914 - acc: 0.7947 - val_loss: 1.7302 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 3th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5534 - acc: 0.7973 - val_loss: 1.5015 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 3th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6578 - acc: 0.7846 - val_loss: 1.5722 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 3th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6569 - acc: 0.7857 - val_loss: 1.6033 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6451 - acc: 0.7836 - val_loss: 1.6076 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6401 - acc: 0.7830 - val_loss: 1.5689 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6891 - acc: 0.7820 - val_loss: 1.7425 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6135 - acc: 0.7951 - val_loss: 1.5854 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6835 - acc: 0.7863 - val_loss: 1.7179 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6153 - acc: 0.7908 - val_loss: 1.6652 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 3th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7655 - acc: 0.7748 - val_loss: 1.6109 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6237 - acc: 0.7916 - val_loss: 1.6406 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 3th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6148 - acc: 0.7895 - val_loss: 1.4589 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 3th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7206 - acc: 0.7801 - val_loss: 1.7857 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 3th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6859 - acc: 0.7809 - val_loss: 1.7972 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6872 - acc: 0.7832 - val_loss: 1.6589 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 3th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6851 - acc: 0.7848 - val_loss: 1.4776 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 3th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7117 - acc: 0.7766 - val_loss: 1.6260 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6344 - acc: 0.7865 - val_loss: 1.5541 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 3th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6622 - acc: 0.7846 - val_loss: 1.6266 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 3th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5746 - acc: 0.7924 - val_loss: 1.8429 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 3th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6432 - acc: 0.7846 - val_loss: 1.7025 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5995 - acc: 0.7914 - val_loss: 1.5419 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7765 - acc: 0.7729 - val_loss: 1.6478 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 3th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6595 - acc: 0.7854 - val_loss: 1.7363 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 3th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5507 - acc: 0.7988 - val_loss: 1.9736 - val_acc: 0.7531\n",
      "[INFO] Training model: epoch 3th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6551 - acc: 0.7854 - val_loss: 1.6509 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6520 - acc: 0.7854 - val_loss: 1.7830 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 3th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7158 - acc: 0.7801 - val_loss: 1.6366 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 3th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6489 - acc: 0.7873 - val_loss: 1.5587 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 3th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6328 - acc: 0.7896 - val_loss: 1.5860 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 3th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6331 - acc: 0.7893 - val_loss: 1.6924 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 3th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5567 - acc: 0.7943 - val_loss: 1.6696 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 3th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5867 - acc: 0.7961 - val_loss: 1.5167 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 3th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7102 - acc: 0.7734 - val_loss: 1.7522 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 3th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6067 - acc: 0.7936 - val_loss: 1.6072 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 3th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6293 - acc: 0.7910 - val_loss: 1.6019 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 3th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7132 - acc: 0.7805 - val_loss: 1.5349 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 3th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7664 - acc: 0.7756 - val_loss: 1.6566 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 3th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6209 - acc: 0.7889 - val_loss: 1.7998 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 3th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5873 - acc: 0.7941 - val_loss: 1.7123 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6337 - acc: 0.7871 - val_loss: 1.5962 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 3th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7369 - acc: 0.7760 - val_loss: 1.8387 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 3th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6069 - acc: 0.7898 - val_loss: 1.6766 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 3th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6785 - acc: 0.7832 - val_loss: 1.7069 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 3th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5562 - acc: 0.7982 - val_loss: 1.7630 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 3th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6413 - acc: 0.7824 - val_loss: 1.7964 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6432 - acc: 0.7898 - val_loss: 1.6396 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 3th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6305 - acc: 0.7838 - val_loss: 1.6640 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 3th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5888 - acc: 0.7930 - val_loss: 1.7260 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5786 - acc: 0.7932 - val_loss: 1.5180 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 3th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6340 - acc: 0.7844 - val_loss: 1.7086 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6367 - acc: 0.7898 - val_loss: 1.6259 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 3th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6383 - acc: 0.7865 - val_loss: 1.6863 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 3th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6325 - acc: 0.7885 - val_loss: 1.5631 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6415 - acc: 0.7893 - val_loss: 1.5152 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 3th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6446 - acc: 0.7869 - val_loss: 1.4802 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 3th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5974 - acc: 0.7900 - val_loss: 1.4666 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6309 - acc: 0.7854 - val_loss: 1.4123 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 3th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7315 - acc: 0.7781 - val_loss: 1.6623 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6712 - acc: 0.7859 - val_loss: 1.4577 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 3th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5950 - acc: 0.7924 - val_loss: 1.6351 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 3th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6741 - acc: 0.7838 - val_loss: 1.6198 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 3th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7641 - acc: 0.7803 - val_loss: 1.8194 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 3th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5675 - acc: 0.7938 - val_loss: 1.7986 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 3th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6539 - acc: 0.7865 - val_loss: 1.8442 - val_acc: 0.7602\n",
      "[INFO] Training model: epoch 3th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6007 - acc: 0.7912 - val_loss: 1.5115 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 3th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6798 - acc: 0.7775 - val_loss: 1.4975 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 3th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5875 - acc: 0.7900 - val_loss: 1.7663 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 3th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6550 - acc: 0.7828 - val_loss: 1.5716 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 3th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6945 - acc: 0.7809 - val_loss: 1.6556 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6986 - acc: 0.7791 - val_loss: 1.7402 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 3th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6126 - acc: 0.7920 - val_loss: 1.5996 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 3th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6329 - acc: 0.7863 - val_loss: 1.7510 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 3th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6783 - acc: 0.7840 - val_loss: 1.5481 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 3th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6261 - acc: 0.7877 - val_loss: 1.6283 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 3th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5812 - acc: 0.7969 - val_loss: 1.5330 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 3th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5412 - acc: 0.7918 - val_loss: 1.6514 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 3th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6287 - acc: 0.7912 - val_loss: 1.7580 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 3th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7039 - acc: 0.7793 - val_loss: 1.6892 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 3th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5917 - acc: 0.7896 - val_loss: 1.6226 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7135 - acc: 0.7771 - val_loss: 1.7634 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 3th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6565 - acc: 0.7885 - val_loss: 1.6079 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 3th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6691 - acc: 0.7838 - val_loss: 1.5701 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 3th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6163 - acc: 0.7957 - val_loss: 1.5238 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 3th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6938 - acc: 0.7791 - val_loss: 1.7699 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 3th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5857 - acc: 0.7943 - val_loss: 1.7966 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 3th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6899 - acc: 0.7781 - val_loss: 1.4802 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 3th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7470 - acc: 0.7762 - val_loss: 1.6522 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 3th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5754 - acc: 0.7957 - val_loss: 1.5752 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 3th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7465 - acc: 0.7766 - val_loss: 1.7048 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6930 - acc: 0.7824 - val_loss: 1.5488 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 3th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6618 - acc: 0.7883 - val_loss: 1.7156 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 3th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7021 - acc: 0.7789 - val_loss: 1.5364 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 3th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6927 - acc: 0.7791 - val_loss: 1.5171 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 3th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7727 - acc: 0.7689 - val_loss: 1.6316 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5828 - acc: 0.7943 - val_loss: 1.6602 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5661 - acc: 0.7922 - val_loss: 1.4929 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 3th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6358 - acc: 0.7844 - val_loss: 1.5609 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 3th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6478 - acc: 0.7848 - val_loss: 1.5764 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 3th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5857 - acc: 0.7951 - val_loss: 1.6675 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 3th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7210 - acc: 0.7789 - val_loss: 1.5068 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 3th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6443 - acc: 0.7881 - val_loss: 1.4531 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 3th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6103 - acc: 0.7900 - val_loss: 1.6568 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 3th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6434 - acc: 0.7850 - val_loss: 1.4584 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 3th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7427 - acc: 0.7783 - val_loss: 1.3844 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 3th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6370 - acc: 0.7875 - val_loss: 1.6843 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 3th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6169 - acc: 0.7904 - val_loss: 1.6726 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 3th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7725 - acc: 0.7715 - val_loss: 1.5961 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 3th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6788 - acc: 0.7826 - val_loss: 1.4381 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 3th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6448 - acc: 0.7852 - val_loss: 1.7724 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 3th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6988 - acc: 0.7750 - val_loss: 1.5243 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 3th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6612 - acc: 0.7859 - val_loss: 1.8416 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 3th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5811 - acc: 0.7938 - val_loss: 1.7500 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 3th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7087 - acc: 0.7768 - val_loss: 1.7451 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 4th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6357 - acc: 0.7844 - val_loss: 1.6113 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6382 - acc: 0.7844 - val_loss: 1.6290 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6700 - acc: 0.7830 - val_loss: 1.3943 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6949 - acc: 0.7775 - val_loss: 1.4603 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6748 - acc: 0.7826 - val_loss: 1.5678 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 4th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6521 - acc: 0.7846 - val_loss: 1.8038 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 4th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6840 - acc: 0.7846 - val_loss: 1.6605 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 4th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6154 - acc: 0.7889 - val_loss: 1.7434 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 4th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5471 - acc: 0.7971 - val_loss: 1.7902 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 4th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6681 - acc: 0.7832 - val_loss: 1.6646 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6665 - acc: 0.7789 - val_loss: 1.6426 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 4th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5575 - acc: 0.7955 - val_loss: 1.5320 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6086 - acc: 0.7895 - val_loss: 1.5710 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 4th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6736 - acc: 0.7820 - val_loss: 1.5908 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 4th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6767 - acc: 0.7799 - val_loss: 1.7005 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 4th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6081 - acc: 0.7906 - val_loss: 1.6037 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 4th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6146 - acc: 0.7885 - val_loss: 1.8072 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 4th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6347 - acc: 0.7842 - val_loss: 1.5641 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7490 - acc: 0.7697 - val_loss: 1.5474 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 4th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5591 - acc: 0.7939 - val_loss: 1.5900 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 4th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5193 - acc: 0.7984 - val_loss: 1.5175 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6443 - acc: 0.7812 - val_loss: 1.5598 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 4th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6690 - acc: 0.7863 - val_loss: 1.6490 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7393 - acc: 0.7742 - val_loss: 1.5978 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5591 - acc: 0.7871 - val_loss: 1.5737 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6516 - acc: 0.7842 - val_loss: 1.7593 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 4th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6539 - acc: 0.7828 - val_loss: 1.6221 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 4th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6922 - acc: 0.7797 - val_loss: 1.5726 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 4th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6606 - acc: 0.7811 - val_loss: 1.5612 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5817 - acc: 0.7924 - val_loss: 1.6433 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 4th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5758 - acc: 0.7867 - val_loss: 1.6969 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 4th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5541 - acc: 0.7941 - val_loss: 1.5483 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6299 - acc: 0.7863 - val_loss: 1.6005 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7068 - acc: 0.7803 - val_loss: 1.6548 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6251 - acc: 0.7848 - val_loss: 1.5558 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5882 - acc: 0.7893 - val_loss: 1.5923 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 4th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6537 - acc: 0.7820 - val_loss: 1.5801 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6697 - acc: 0.7863 - val_loss: 1.7722 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 4th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6370 - acc: 0.7834 - val_loss: 1.5291 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6154 - acc: 0.7840 - val_loss: 1.5561 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 4th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6735 - acc: 0.7797 - val_loss: 1.6753 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6339 - acc: 0.7867 - val_loss: 1.8173 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 4th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7519 - acc: 0.7691 - val_loss: 1.6802 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 4th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5076 - acc: 0.8021 - val_loss: 1.5711 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5440 - acc: 0.7916 - val_loss: 1.5639 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 4th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5474 - acc: 0.7936 - val_loss: 1.7772 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 4th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6309 - acc: 0.7861 - val_loss: 1.5755 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6901 - acc: 0.7795 - val_loss: 1.5554 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 4th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6385 - acc: 0.7859 - val_loss: 1.6955 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6869 - acc: 0.7789 - val_loss: 1.5990 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 4th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5395 - acc: 0.7943 - val_loss: 1.7611 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 4th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5685 - acc: 0.7924 - val_loss: 1.7838 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 4th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6222 - acc: 0.7871 - val_loss: 1.6395 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7138 - acc: 0.7742 - val_loss: 1.7479 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 4th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6094 - acc: 0.7906 - val_loss: 1.6832 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 4th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6954 - acc: 0.7826 - val_loss: 1.5504 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6794 - acc: 0.7838 - val_loss: 1.5169 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 4th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5430 - acc: 0.7934 - val_loss: 1.7301 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 4th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6844 - acc: 0.7814 - val_loss: 1.8100 - val_acc: 0.7563\n",
      "[INFO] Training model: epoch 4th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6527 - acc: 0.7812 - val_loss: 1.5774 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 4th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5435 - acc: 0.7979 - val_loss: 1.6148 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5511 - acc: 0.7939 - val_loss: 1.7195 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 4th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6599 - acc: 0.7830 - val_loss: 1.5624 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5550 - acc: 0.7924 - val_loss: 1.6560 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6350 - acc: 0.7844 - val_loss: 1.6848 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6976 - acc: 0.7725 - val_loss: 1.6731 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 4th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6178 - acc: 0.7881 - val_loss: 1.6353 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 4th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7027 - acc: 0.7750 - val_loss: 1.5969 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 4th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5873 - acc: 0.7887 - val_loss: 1.6682 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 4th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6078 - acc: 0.7826 - val_loss: 1.6410 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 4th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6475 - acc: 0.7836 - val_loss: 1.6901 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 4th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6565 - acc: 0.7879 - val_loss: 1.5753 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 4th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6151 - acc: 0.7863 - val_loss: 1.5496 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 4th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6509 - acc: 0.7854 - val_loss: 1.4899 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5962 - acc: 0.7910 - val_loss: 1.6100 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 4th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6029 - acc: 0.7916 - val_loss: 1.5705 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6475 - acc: 0.7824 - val_loss: 1.7707 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 4th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5573 - acc: 0.7938 - val_loss: 1.4652 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6458 - acc: 0.7875 - val_loss: 1.7789 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6953 - acc: 0.7797 - val_loss: 1.5737 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6756 - acc: 0.7807 - val_loss: 1.6259 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 4th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5788 - acc: 0.7891 - val_loss: 1.4795 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 4th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6062 - acc: 0.7877 - val_loss: 1.5438 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6135 - acc: 0.7900 - val_loss: 1.5213 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6625 - acc: 0.7850 - val_loss: 1.4519 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7169 - acc: 0.7748 - val_loss: 1.4760 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 4th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6314 - acc: 0.7873 - val_loss: 1.5114 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6137 - acc: 0.7912 - val_loss: 1.5775 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 4th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5800 - acc: 0.7924 - val_loss: 1.6217 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5425 - acc: 0.7934 - val_loss: 1.7631 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 4th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5124 - acc: 0.7990 - val_loss: 1.6005 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6533 - acc: 0.7820 - val_loss: 1.5707 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 4th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6291 - acc: 0.7848 - val_loss: 1.3885 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 4th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6767 - acc: 0.7842 - val_loss: 1.5401 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5178 - acc: 0.7957 - val_loss: 1.7646 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 4th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5731 - acc: 0.7896 - val_loss: 1.7347 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 4th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4615 - acc: 0.8021 - val_loss: 1.6620 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5943 - acc: 0.7881 - val_loss: 1.3979 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 4th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7019 - acc: 0.7838 - val_loss: 1.5315 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6068 - acc: 0.7900 - val_loss: 1.5127 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5637 - acc: 0.7939 - val_loss: 1.6042 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6454 - acc: 0.7848 - val_loss: 1.5711 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5365 - acc: 0.7953 - val_loss: 1.7685 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 4th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5760 - acc: 0.7910 - val_loss: 1.5765 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6492 - acc: 0.7867 - val_loss: 1.6279 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6674 - acc: 0.7824 - val_loss: 1.5059 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7006 - acc: 0.7803 - val_loss: 1.6954 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6387 - acc: 0.7857 - val_loss: 1.5572 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6223 - acc: 0.7871 - val_loss: 1.7044 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 4th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5260 - acc: 0.7986 - val_loss: 1.6967 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 4th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6951 - acc: 0.7807 - val_loss: 1.7073 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 4th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5702 - acc: 0.7945 - val_loss: 1.5834 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 4th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5929 - acc: 0.7951 - val_loss: 1.6596 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 4th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6563 - acc: 0.7812 - val_loss: 1.6578 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6454 - acc: 0.7850 - val_loss: 1.4014 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 4th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6004 - acc: 0.7885 - val_loss: 1.7929 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 4th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5825 - acc: 0.7938 - val_loss: 1.4838 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5554 - acc: 0.7912 - val_loss: 1.4503 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 4th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6010 - acc: 0.7904 - val_loss: 1.6073 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 4th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5577 - acc: 0.7955 - val_loss: 1.5487 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7019 - acc: 0.7770 - val_loss: 1.5296 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 4th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6746 - acc: 0.7812 - val_loss: 1.6690 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6126 - acc: 0.7881 - val_loss: 1.7581 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 4th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5921 - acc: 0.7916 - val_loss: 1.6961 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 4th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6681 - acc: 0.7832 - val_loss: 1.6621 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 4th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6872 - acc: 0.7793 - val_loss: 1.6710 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 4th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6126 - acc: 0.7869 - val_loss: 1.7542 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6496 - acc: 0.7838 - val_loss: 1.6135 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 4th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7209 - acc: 0.7752 - val_loss: 1.7455 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 4th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5907 - acc: 0.7863 - val_loss: 1.5615 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7128 - acc: 0.7775 - val_loss: 1.4693 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6338 - acc: 0.7816 - val_loss: 1.6008 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 4th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6640 - acc: 0.7842 - val_loss: 1.5319 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 4th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6593 - acc: 0.7859 - val_loss: 1.5706 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6107 - acc: 0.7930 - val_loss: 1.5629 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5734 - acc: 0.7928 - val_loss: 1.4507 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 4th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6266 - acc: 0.7865 - val_loss: 1.5343 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 4th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6852 - acc: 0.7818 - val_loss: 1.5492 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 4th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7195 - acc: 0.7758 - val_loss: 1.5195 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 4th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5525 - acc: 0.7994 - val_loss: 1.9171 - val_acc: 0.7500\n",
      "[INFO] Training model: epoch 4th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6398 - acc: 0.7801 - val_loss: 1.6871 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 4th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5515 - acc: 0.7934 - val_loss: 1.5156 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.5934 - acc: 0.7883 - val_loss: 1.2961 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 4th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7502 - acc: 0.7764 - val_loss: 1.6268 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6541 - acc: 0.7854 - val_loss: 1.5588 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7593 - acc: 0.7713 - val_loss: 1.7269 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 4th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5598 - acc: 0.7951 - val_loss: 1.5122 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 4th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7409 - acc: 0.7717 - val_loss: 1.5605 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6241 - acc: 0.7873 - val_loss: 1.5547 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6016 - acc: 0.7898 - val_loss: 1.6025 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 4th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6444 - acc: 0.7828 - val_loss: 1.5384 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 4th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6585 - acc: 0.7836 - val_loss: 1.6242 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6258 - acc: 0.7885 - val_loss: 1.5495 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 4th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5991 - acc: 0.7898 - val_loss: 1.6285 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 4th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6451 - acc: 0.7838 - val_loss: 1.5341 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5641 - acc: 0.7930 - val_loss: 1.5324 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5853 - acc: 0.7908 - val_loss: 1.6874 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 4th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5932 - acc: 0.7943 - val_loss: 1.6174 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6643 - acc: 0.7844 - val_loss: 1.4592 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6470 - acc: 0.7854 - val_loss: 1.5810 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 4th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6578 - acc: 0.7852 - val_loss: 1.5589 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 4th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5512 - acc: 0.7918 - val_loss: 1.5012 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 4th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5858 - acc: 0.7910 - val_loss: 1.4524 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 4th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6517 - acc: 0.7871 - val_loss: 1.6409 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6583 - acc: 0.7814 - val_loss: 1.5340 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6045 - acc: 0.7871 - val_loss: 1.6449 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 4th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5882 - acc: 0.7922 - val_loss: 1.5970 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7097 - acc: 0.7766 - val_loss: 1.5088 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 4th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5572 - acc: 0.7945 - val_loss: 1.5736 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4975 - acc: 0.7986 - val_loss: 1.4863 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 4th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6090 - acc: 0.7881 - val_loss: 1.4400 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6099 - acc: 0.7891 - val_loss: 1.6001 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6518 - acc: 0.7818 - val_loss: 1.4789 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6078 - acc: 0.7887 - val_loss: 1.9055 - val_acc: 0.7609\n",
      "[INFO] Training model: epoch 4th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5412 - acc: 0.7959 - val_loss: 1.6558 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 4th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7878 - acc: 0.7705 - val_loss: 1.6800 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 4th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5674 - acc: 0.7938 - val_loss: 1.5737 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6501 - acc: 0.7852 - val_loss: 1.4377 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 4th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5903 - acc: 0.7910 - val_loss: 1.7248 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 4th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6637 - acc: 0.7855 - val_loss: 1.5902 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 4th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5874 - acc: 0.7924 - val_loss: 1.5953 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6398 - acc: 0.7836 - val_loss: 1.6430 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 4th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5580 - acc: 0.7969 - val_loss: 1.4457 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 4th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4786 - acc: 0.7998 - val_loss: 1.7924 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 4th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5955 - acc: 0.7902 - val_loss: 1.4624 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 4th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6017 - acc: 0.7918 - val_loss: 1.5192 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6855 - acc: 0.7822 - val_loss: 1.7217 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 4th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6440 - acc: 0.7842 - val_loss: 1.6192 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 4th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5309 - acc: 0.7973 - val_loss: 1.5743 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6389 - acc: 0.7881 - val_loss: 1.4880 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 4th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5811 - acc: 0.7918 - val_loss: 1.6628 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 4th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5238 - acc: 0.7990 - val_loss: 1.6842 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 4th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5891 - acc: 0.7908 - val_loss: 1.7273 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6319 - acc: 0.7852 - val_loss: 1.5382 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 4th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6599 - acc: 0.7750 - val_loss: 1.6620 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 4th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5819 - acc: 0.7916 - val_loss: 1.5816 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 4th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6201 - acc: 0.7889 - val_loss: 1.6215 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 4th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5681 - acc: 0.7949 - val_loss: 1.6032 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 4th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6864 - acc: 0.7789 - val_loss: 1.7187 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 4th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5801 - acc: 0.7885 - val_loss: 1.7520 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 4th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5605 - acc: 0.7912 - val_loss: 1.5411 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6075 - acc: 0.7912 - val_loss: 1.5238 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 4th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6390 - acc: 0.7822 - val_loss: 1.7178 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 4th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6424 - acc: 0.7857 - val_loss: 1.5689 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 4th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6355 - acc: 0.7910 - val_loss: 1.6968 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 4th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5066 - acc: 0.8043 - val_loss: 1.5086 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 4th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6679 - acc: 0.7801 - val_loss: 1.7402 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 4th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7194 - acc: 0.7738 - val_loss: 1.6685 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 4th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6620 - acc: 0.7830 - val_loss: 1.5898 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 4th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6319 - acc: 0.7838 - val_loss: 1.5030 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6538 - acc: 0.7854 - val_loss: 1.6150 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 4th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5787 - acc: 0.7934 - val_loss: 1.5646 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 4th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7413 - acc: 0.7682 - val_loss: 1.6062 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6668 - acc: 0.7818 - val_loss: 1.5613 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6564 - acc: 0.7820 - val_loss: 1.4981 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6470 - acc: 0.7828 - val_loss: 1.5831 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 4th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7571 - acc: 0.7727 - val_loss: 1.6428 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 4th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6972 - acc: 0.7791 - val_loss: 1.4796 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7885 - acc: 0.7707 - val_loss: 1.4106 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 4th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6746 - acc: 0.7768 - val_loss: 1.7908 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 4th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5798 - acc: 0.7881 - val_loss: 1.5639 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 4th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6738 - acc: 0.7797 - val_loss: 1.5665 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5411 - acc: 0.7990 - val_loss: 1.6200 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6064 - acc: 0.7887 - val_loss: 1.5848 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5938 - acc: 0.7906 - val_loss: 1.6708 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 4th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5715 - acc: 0.7945 - val_loss: 1.6298 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6143 - acc: 0.7859 - val_loss: 1.5588 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 4th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6205 - acc: 0.7850 - val_loss: 1.5704 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 4th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6367 - acc: 0.7891 - val_loss: 1.6396 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 4th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6227 - acc: 0.7861 - val_loss: 1.5583 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6520 - acc: 0.7824 - val_loss: 1.6124 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 4th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5850 - acc: 0.7943 - val_loss: 1.6190 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 4th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6889 - acc: 0.7801 - val_loss: 1.7166 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 4th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6147 - acc: 0.7877 - val_loss: 1.6412 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6349 - acc: 0.7840 - val_loss: 1.4781 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 4th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7140 - acc: 0.7781 - val_loss: 1.5733 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 4th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5071 - acc: 0.8016 - val_loss: 1.7365 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 4th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5784 - acc: 0.7914 - val_loss: 1.5328 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 4th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6474 - acc: 0.7807 - val_loss: 1.6367 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5735 - acc: 0.7885 - val_loss: 1.5096 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 4th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5945 - acc: 0.7855 - val_loss: 1.6733 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 4th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6331 - acc: 0.7842 - val_loss: 1.6181 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 4th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6310 - acc: 0.7875 - val_loss: 1.5257 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 4th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5978 - acc: 0.7869 - val_loss: 1.7390 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 4th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7060 - acc: 0.7766 - val_loss: 1.5982 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 4th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5960 - acc: 0.7893 - val_loss: 1.6604 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 4th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6054 - acc: 0.7869 - val_loss: 1.7132 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 4th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6500 - acc: 0.7850 - val_loss: 1.5699 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 4th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6371 - acc: 0.7824 - val_loss: 1.6551 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 4th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5295 - acc: 0.7977 - val_loss: 1.5952 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 5th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6218 - acc: 0.7896 - val_loss: 1.4734 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 5th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6385 - acc: 0.7855 - val_loss: 1.5746 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6086 - acc: 0.7875 - val_loss: 1.6015 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5837 - acc: 0.7893 - val_loss: 1.5758 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5539 - acc: 0.7902 - val_loss: 1.7854 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 5th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5876 - acc: 0.7859 - val_loss: 1.6525 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 5th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5983 - acc: 0.7883 - val_loss: 1.5975 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5804 - acc: 0.7887 - val_loss: 1.4702 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 5th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6648 - acc: 0.7820 - val_loss: 1.5317 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 5th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6486 - acc: 0.7834 - val_loss: 1.5182 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 5th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5871 - acc: 0.7846 - val_loss: 1.3408 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 5th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5998 - acc: 0.7832 - val_loss: 1.5915 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6014 - acc: 0.7848 - val_loss: 1.7150 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 5th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4946 - acc: 0.8053 - val_loss: 1.7707 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 5th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5317 - acc: 0.7934 - val_loss: 1.5067 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 5th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6167 - acc: 0.7883 - val_loss: 1.4529 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5910 - acc: 0.7848 - val_loss: 1.6517 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6354 - acc: 0.7877 - val_loss: 1.6639 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 5th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6034 - acc: 0.7902 - val_loss: 1.5063 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5763 - acc: 0.7918 - val_loss: 1.6831 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 5th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6403 - acc: 0.7846 - val_loss: 1.7460 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 5th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5217 - acc: 0.7967 - val_loss: 1.5933 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 5th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5348 - acc: 0.7912 - val_loss: 1.5672 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5959 - acc: 0.7854 - val_loss: 1.7478 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 5th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6659 - acc: 0.7793 - val_loss: 1.5451 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5902 - acc: 0.7900 - val_loss: 1.5608 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6433 - acc: 0.7791 - val_loss: 1.6661 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 5th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6302 - acc: 0.7777 - val_loss: 1.6377 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6047 - acc: 0.7896 - val_loss: 1.5415 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6608 - acc: 0.7844 - val_loss: 1.6465 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 5th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5500 - acc: 0.7912 - val_loss: 1.7062 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 5th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6789 - acc: 0.7777 - val_loss: 1.5978 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 5th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5036 - acc: 0.7990 - val_loss: 1.5168 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 5th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5967 - acc: 0.7885 - val_loss: 1.4931 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5475 - acc: 0.7928 - val_loss: 1.6037 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 5th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5755 - acc: 0.7867 - val_loss: 1.5441 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 5th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.7059 - acc: 0.7791 - val_loss: 1.5789 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5549 - acc: 0.7961 - val_loss: 1.5646 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 5th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5390 - acc: 0.7916 - val_loss: 1.6131 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 5th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5920 - acc: 0.7879 - val_loss: 1.5349 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 5th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5828 - acc: 0.7900 - val_loss: 1.5354 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5149 - acc: 0.7965 - val_loss: 1.4682 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 5th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6562 - acc: 0.7791 - val_loss: 1.7438 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 5th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6029 - acc: 0.7910 - val_loss: 1.4278 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 5th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6287 - acc: 0.7877 - val_loss: 1.7838 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 5th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6069 - acc: 0.7887 - val_loss: 1.5650 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 5th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6396 - acc: 0.7766 - val_loss: 1.5164 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 5th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5588 - acc: 0.7893 - val_loss: 1.5478 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7496 - acc: 0.7736 - val_loss: 1.5377 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6011 - acc: 0.7799 - val_loss: 1.4383 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 5th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6106 - acc: 0.7898 - val_loss: 1.7015 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 5th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5627 - acc: 0.7943 - val_loss: 1.6437 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 5th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5553 - acc: 0.7943 - val_loss: 1.4690 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 5th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6537 - acc: 0.7830 - val_loss: 1.6944 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5416 - acc: 0.7971 - val_loss: 1.5426 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5316 - acc: 0.7928 - val_loss: 1.7092 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 5th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6785 - acc: 0.7768 - val_loss: 1.4511 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 5th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6535 - acc: 0.7834 - val_loss: 1.7537 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 5th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 5s - loss: 1.5642 - acc: 0.7924 - val_loss: 1.2148 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 5th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6247 - acc: 0.7857 - val_loss: 1.5175 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 5th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5458 - acc: 0.7926 - val_loss: 1.6936 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 5th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6990 - acc: 0.7744 - val_loss: 1.7317 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 5th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5616 - acc: 0.7959 - val_loss: 1.5855 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 5th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5444 - acc: 0.7965 - val_loss: 1.5949 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5458 - acc: 0.7945 - val_loss: 1.7592 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 5th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6849 - acc: 0.7775 - val_loss: 1.5450 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5769 - acc: 0.7926 - val_loss: 1.4614 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 5th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5732 - acc: 0.7902 - val_loss: 1.4930 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 5th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6713 - acc: 0.7793 - val_loss: 1.8146 - val_acc: 0.7523\n",
      "[INFO] Training model: epoch 5th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6118 - acc: 0.7881 - val_loss: 1.5514 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 5th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5841 - acc: 0.7908 - val_loss: 1.4217 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6338 - acc: 0.7836 - val_loss: 1.6031 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 5th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6063 - acc: 0.7869 - val_loss: 1.4533 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 5th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7300 - acc: 0.7781 - val_loss: 1.5561 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5503 - acc: 0.7936 - val_loss: 1.4917 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 5th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6376 - acc: 0.7850 - val_loss: 1.5537 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 5th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6568 - acc: 0.7842 - val_loss: 1.4793 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6412 - acc: 0.7803 - val_loss: 1.7430 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 5th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6111 - acc: 0.7844 - val_loss: 1.6627 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 5th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5075 - acc: 0.7984 - val_loss: 1.4238 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 5th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5948 - acc: 0.7916 - val_loss: 1.6712 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 5th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5749 - acc: 0.7891 - val_loss: 1.4792 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 5th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6090 - acc: 0.7926 - val_loss: 1.5684 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 5th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5780 - acc: 0.7945 - val_loss: 1.6192 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 5th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5675 - acc: 0.7895 - val_loss: 1.3955 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 5th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5782 - acc: 0.7900 - val_loss: 1.7068 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 5th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5072 - acc: 0.7973 - val_loss: 1.4423 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6681 - acc: 0.7768 - val_loss: 1.6151 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6450 - acc: 0.7885 - val_loss: 1.8434 - val_acc: 0.7602\n",
      "[INFO] Training model: epoch 5th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5749 - acc: 0.7920 - val_loss: 1.5546 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6349 - acc: 0.7859 - val_loss: 1.6462 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6441 - acc: 0.7836 - val_loss: 1.6038 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6375 - acc: 0.7812 - val_loss: 1.8201 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 5th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6037 - acc: 0.7902 - val_loss: 1.5447 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 5th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5347 - acc: 0.7951 - val_loss: 1.6166 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 5th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6036 - acc: 0.7875 - val_loss: 1.4888 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 5th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6091 - acc: 0.7855 - val_loss: 1.4894 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6577 - acc: 0.7773 - val_loss: 1.6602 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 5th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6024 - acc: 0.7926 - val_loss: 1.6862 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5552 - acc: 0.7930 - val_loss: 1.5478 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 5th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6218 - acc: 0.7832 - val_loss: 1.6727 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6348 - acc: 0.7836 - val_loss: 1.5094 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6789 - acc: 0.7838 - val_loss: 1.4704 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5544 - acc: 0.7930 - val_loss: 1.5796 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5888 - acc: 0.7896 - val_loss: 1.4857 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 5th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6009 - acc: 0.7920 - val_loss: 1.5594 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 5th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6500 - acc: 0.7814 - val_loss: 1.5326 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 5th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5884 - acc: 0.7938 - val_loss: 1.5134 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 5th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7143 - acc: 0.7756 - val_loss: 1.5908 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 5th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5916 - acc: 0.7887 - val_loss: 1.6599 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 5th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5515 - acc: 0.7951 - val_loss: 1.4848 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7302 - acc: 0.7738 - val_loss: 1.5122 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 5th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5585 - acc: 0.7912 - val_loss: 1.5345 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5493 - acc: 0.7922 - val_loss: 1.6451 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 5th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6276 - acc: 0.7848 - val_loss: 1.6832 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 5th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5983 - acc: 0.7869 - val_loss: 1.4269 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6551 - acc: 0.7787 - val_loss: 1.5777 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 5th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6695 - acc: 0.7820 - val_loss: 1.5998 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 5th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6164 - acc: 0.7883 - val_loss: 1.8122 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 5th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5540 - acc: 0.7928 - val_loss: 1.5663 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 5th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5303 - acc: 0.7949 - val_loss: 1.6164 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 5th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6118 - acc: 0.7842 - val_loss: 1.4581 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 5th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5558 - acc: 0.7965 - val_loss: 1.5854 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 5th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5551 - acc: 0.7941 - val_loss: 1.6658 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 5th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5936 - acc: 0.7879 - val_loss: 1.6189 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 5th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5608 - acc: 0.7939 - val_loss: 1.4788 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 5th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6018 - acc: 0.7869 - val_loss: 1.5325 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 5th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7585 - acc: 0.7682 - val_loss: 1.7027 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 5th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6018 - acc: 0.7883 - val_loss: 1.6752 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 5th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6024 - acc: 0.7859 - val_loss: 1.5513 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 5th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6844 - acc: 0.7803 - val_loss: 1.3994 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 5th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5720 - acc: 0.7871 - val_loss: 1.5789 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5972 - acc: 0.7898 - val_loss: 1.5218 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5527 - acc: 0.7928 - val_loss: 1.6251 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 5th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5327 - acc: 0.7893 - val_loss: 1.4498 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 5th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5762 - acc: 0.7869 - val_loss: 1.5512 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 5th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6662 - acc: 0.7795 - val_loss: 1.3943 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 5th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5574 - acc: 0.7941 - val_loss: 1.5502 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5481 - acc: 0.7975 - val_loss: 1.6482 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6472 - acc: 0.7834 - val_loss: 1.4285 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 5th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5959 - acc: 0.7873 - val_loss: 1.5381 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 5th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7098 - acc: 0.7762 - val_loss: 1.8041 - val_acc: 0.7539\n",
      "[INFO] Training model: epoch 5th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5596 - acc: 0.7918 - val_loss: 1.6686 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 5th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5951 - acc: 0.7920 - val_loss: 1.4970 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 5th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5691 - acc: 0.7904 - val_loss: 1.7384 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 5th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5473 - acc: 0.7902 - val_loss: 1.4519 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 5th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5609 - acc: 0.7922 - val_loss: 1.5403 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 5th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5646 - acc: 0.7908 - val_loss: 1.6929 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 5th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5929 - acc: 0.7877 - val_loss: 1.6422 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 5th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5466 - acc: 0.7951 - val_loss: 1.5606 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5847 - acc: 0.7885 - val_loss: 1.6438 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 5th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5176 - acc: 0.7947 - val_loss: 1.4964 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 5th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5385 - acc: 0.7963 - val_loss: 1.5050 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 5th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6689 - acc: 0.7789 - val_loss: 1.7513 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 5th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5473 - acc: 0.7926 - val_loss: 1.6179 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 5th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7245 - acc: 0.7750 - val_loss: 1.6341 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5417 - acc: 0.7945 - val_loss: 1.4637 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 5th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6599 - acc: 0.7824 - val_loss: 1.6732 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 5th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5701 - acc: 0.7914 - val_loss: 1.5832 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 5th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6212 - acc: 0.7891 - val_loss: 1.7915 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 5th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5426 - acc: 0.7934 - val_loss: 1.5696 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 5th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6396 - acc: 0.7822 - val_loss: 1.4843 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 5th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5940 - acc: 0.7857 - val_loss: 1.6918 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5882 - acc: 0.7857 - val_loss: 1.5760 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6248 - acc: 0.7859 - val_loss: 1.7456 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 5th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5765 - acc: 0.7949 - val_loss: 1.6629 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6379 - acc: 0.7885 - val_loss: 1.6788 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 5th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5763 - acc: 0.7902 - val_loss: 1.5042 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6097 - acc: 0.7871 - val_loss: 1.5160 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6006 - acc: 0.7893 - val_loss: 1.6769 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 5th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5602 - acc: 0.7936 - val_loss: 1.2972 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 5th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6154 - acc: 0.7820 - val_loss: 1.5200 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 5th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4779 - acc: 0.7971 - val_loss: 1.4068 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6015 - acc: 0.7844 - val_loss: 1.7573 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 5th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5877 - acc: 0.7908 - val_loss: 1.5767 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 5th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6159 - acc: 0.7838 - val_loss: 1.4189 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 5th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5644 - acc: 0.7908 - val_loss: 1.7908 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 5th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6048 - acc: 0.7820 - val_loss: 1.4548 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 5th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5220 - acc: 0.7955 - val_loss: 1.6341 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5885 - acc: 0.7900 - val_loss: 1.6333 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 5th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5925 - acc: 0.7865 - val_loss: 1.4571 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 5th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6433 - acc: 0.7854 - val_loss: 1.4421 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6721 - acc: 0.7801 - val_loss: 1.5164 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 5th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6566 - acc: 0.7814 - val_loss: 1.5284 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 5th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6085 - acc: 0.7898 - val_loss: 1.4657 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5837 - acc: 0.7912 - val_loss: 1.6108 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5736 - acc: 0.7910 - val_loss: 1.4828 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 5th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5996 - acc: 0.7850 - val_loss: 1.6905 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 5th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6318 - acc: 0.7867 - val_loss: 1.5957 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6201 - acc: 0.7871 - val_loss: 1.4941 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 5th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5683 - acc: 0.7922 - val_loss: 1.4870 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 5th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6290 - acc: 0.7846 - val_loss: 1.7199 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 5th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5973 - acc: 0.7918 - val_loss: 1.5778 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 5th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6126 - acc: 0.7922 - val_loss: 1.6470 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6234 - acc: 0.7873 - val_loss: 1.6669 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 5th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6780 - acc: 0.7736 - val_loss: 1.6657 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 5th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6436 - acc: 0.7887 - val_loss: 1.5098 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6051 - acc: 0.7873 - val_loss: 1.6820 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 5th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5826 - acc: 0.7879 - val_loss: 1.4637 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 5th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6447 - acc: 0.7834 - val_loss: 1.6221 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 5th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5401 - acc: 0.7908 - val_loss: 1.5126 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6166 - acc: 0.7922 - val_loss: 1.5111 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 5th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5360 - acc: 0.7945 - val_loss: 1.5634 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 5th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6706 - acc: 0.7799 - val_loss: 1.6014 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 5th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5568 - acc: 0.7951 - val_loss: 1.5187 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 5th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5051 - acc: 0.7971 - val_loss: 1.5751 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 5th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5783 - acc: 0.7930 - val_loss: 1.6171 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 5th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6525 - acc: 0.7857 - val_loss: 1.6783 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5978 - acc: 0.7867 - val_loss: 1.3804 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 5th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5604 - acc: 0.7908 - val_loss: 1.5250 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 5th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5252 - acc: 0.7971 - val_loss: 1.4429 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 5th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5925 - acc: 0.7838 - val_loss: 1.5208 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 5th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5478 - acc: 0.7932 - val_loss: 1.6191 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 5th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5684 - acc: 0.7893 - val_loss: 1.7050 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 5th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6489 - acc: 0.7836 - val_loss: 1.6162 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5681 - acc: 0.7910 - val_loss: 1.8198 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 5th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5683 - acc: 0.7879 - val_loss: 1.7716 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 5th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4568 - acc: 0.8020 - val_loss: 1.7212 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 5th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5311 - acc: 0.7930 - val_loss: 1.4861 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6801 - acc: 0.7797 - val_loss: 1.4875 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 5th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6032 - acc: 0.7816 - val_loss: 1.5297 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 5th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6919 - acc: 0.7775 - val_loss: 1.6250 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6515 - acc: 0.7859 - val_loss: 1.5771 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 5th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7184 - acc: 0.7756 - val_loss: 1.5232 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 5th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6165 - acc: 0.7869 - val_loss: 1.7032 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6773 - acc: 0.7746 - val_loss: 1.8031 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 5th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6285 - acc: 0.7809 - val_loss: 1.5040 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 5th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5177 - acc: 0.7945 - val_loss: 1.6795 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 5th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6173 - acc: 0.7854 - val_loss: 1.3947 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 5th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5983 - acc: 0.7877 - val_loss: 1.5138 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 5th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6060 - acc: 0.7881 - val_loss: 1.4238 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 5th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5194 - acc: 0.7928 - val_loss: 1.8239 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 5th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5063 - acc: 0.7980 - val_loss: 1.8957 - val_acc: 0.7508\n",
      "[INFO] Training model: epoch 5th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6122 - acc: 0.7877 - val_loss: 1.7265 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 5th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6505 - acc: 0.7828 - val_loss: 1.6115 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 5th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5536 - acc: 0.7957 - val_loss: 1.8319 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 5th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5887 - acc: 0.7941 - val_loss: 1.5214 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5798 - acc: 0.7951 - val_loss: 1.5379 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 5th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5370 - acc: 0.7957 - val_loss: 1.7059 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 5th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5743 - acc: 0.7904 - val_loss: 1.5744 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 5th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5776 - acc: 0.7852 - val_loss: 1.7147 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 5th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5859 - acc: 0.7869 - val_loss: 1.5692 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 5th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6330 - acc: 0.7857 - val_loss: 1.6087 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 5th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6327 - acc: 0.7879 - val_loss: 1.5852 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 5th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5728 - acc: 0.7900 - val_loss: 1.5137 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 5th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4887 - acc: 0.8010 - val_loss: 1.3074 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 5th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5756 - acc: 0.7936 - val_loss: 1.6015 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 5th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6548 - acc: 0.7824 - val_loss: 1.6861 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 5th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6260 - acc: 0.7852 - val_loss: 1.6263 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 5th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5664 - acc: 0.7916 - val_loss: 1.6543 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 6th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6416 - acc: 0.7814 - val_loss: 1.6640 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 6th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6341 - acc: 0.7791 - val_loss: 1.4874 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5263 - acc: 0.7926 - val_loss: 1.6274 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 6th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5603 - acc: 0.7900 - val_loss: 1.5712 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5811 - acc: 0.7914 - val_loss: 1.4897 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6481 - acc: 0.7828 - val_loss: 1.6592 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 6th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5970 - acc: 0.7877 - val_loss: 1.6405 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6278 - acc: 0.7842 - val_loss: 1.8921 - val_acc: 0.7492\n",
      "[INFO] Training model: epoch 6th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6361 - acc: 0.7828 - val_loss: 1.6798 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 6th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5503 - acc: 0.7887 - val_loss: 1.4225 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 6th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5528 - acc: 0.7896 - val_loss: 1.5654 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 6th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6018 - acc: 0.7863 - val_loss: 1.5300 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 6th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6356 - acc: 0.7795 - val_loss: 1.5834 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 6th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5990 - acc: 0.7861 - val_loss: 1.4560 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 6th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5844 - acc: 0.7834 - val_loss: 1.5026 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 6th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5292 - acc: 0.7980 - val_loss: 1.8007 - val_acc: 0.7594\n",
      "[INFO] Training model: epoch 6th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6113 - acc: 0.7824 - val_loss: 1.6100 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5507 - acc: 0.7906 - val_loss: 1.6246 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 6th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6505 - acc: 0.7775 - val_loss: 1.4764 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5981 - acc: 0.7867 - val_loss: 1.4800 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5735 - acc: 0.7928 - val_loss: 1.5602 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6446 - acc: 0.7771 - val_loss: 1.4916 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 6th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5685 - acc: 0.7951 - val_loss: 1.6889 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 6th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4921 - acc: 0.8000 - val_loss: 1.4523 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 6th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6040 - acc: 0.7855 - val_loss: 1.4667 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 6th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5866 - acc: 0.7869 - val_loss: 1.5389 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 6th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5452 - acc: 0.7982 - val_loss: 1.5240 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5092 - acc: 0.7943 - val_loss: 1.4652 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 6th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6007 - acc: 0.7836 - val_loss: 1.5720 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5773 - acc: 0.7855 - val_loss: 1.7215 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 6th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5320 - acc: 0.7912 - val_loss: 1.7051 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5850 - acc: 0.7877 - val_loss: 1.7115 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 6th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6618 - acc: 0.7791 - val_loss: 1.3892 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 6th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5906 - acc: 0.7908 - val_loss: 1.4814 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 6th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6786 - acc: 0.7791 - val_loss: 1.6010 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5213 - acc: 0.7973 - val_loss: 1.6270 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 6th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4887 - acc: 0.7984 - val_loss: 1.5768 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5779 - acc: 0.7885 - val_loss: 1.4590 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 6th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5199 - acc: 0.7922 - val_loss: 1.4160 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5771 - acc: 0.7893 - val_loss: 1.5794 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 6th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5290 - acc: 0.7955 - val_loss: 1.4103 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 6th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5510 - acc: 0.7936 - val_loss: 1.5509 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5041 - acc: 0.7971 - val_loss: 1.5420 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 6th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5376 - acc: 0.7938 - val_loss: 1.4970 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5945 - acc: 0.7861 - val_loss: 1.4822 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7284 - acc: 0.7707 - val_loss: 1.6540 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 6th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6122 - acc: 0.7848 - val_loss: 1.6103 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 6th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5379 - acc: 0.7943 - val_loss: 1.5628 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5513 - acc: 0.7918 - val_loss: 1.7538 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 6th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5264 - acc: 0.7986 - val_loss: 1.4044 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 6th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5906 - acc: 0.7820 - val_loss: 1.6124 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5811 - acc: 0.7854 - val_loss: 1.5523 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5876 - acc: 0.7863 - val_loss: 1.4252 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5251 - acc: 0.7941 - val_loss: 1.6052 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 6th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6370 - acc: 0.7775 - val_loss: 1.6409 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6191 - acc: 0.7846 - val_loss: 1.4310 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5196 - acc: 0.7906 - val_loss: 1.5736 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 6th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5705 - acc: 0.7906 - val_loss: 1.6116 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 6th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5113 - acc: 0.7982 - val_loss: 1.5748 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5633 - acc: 0.7914 - val_loss: 1.5176 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 6th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5390 - acc: 0.7939 - val_loss: 1.6020 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 6th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5334 - acc: 0.7902 - val_loss: 1.5568 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5745 - acc: 0.7893 - val_loss: 1.7002 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 6th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6154 - acc: 0.7832 - val_loss: 1.4795 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 6th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5748 - acc: 0.7895 - val_loss: 1.4911 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 6th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6400 - acc: 0.7771 - val_loss: 1.5207 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 6th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5233 - acc: 0.7965 - val_loss: 1.4649 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 6th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5660 - acc: 0.7885 - val_loss: 1.4756 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6227 - acc: 0.7863 - val_loss: 1.4735 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 6th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5961 - acc: 0.7873 - val_loss: 1.4056 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5863 - acc: 0.7875 - val_loss: 1.4026 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 6th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5309 - acc: 0.7984 - val_loss: 1.4306 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5480 - acc: 0.7936 - val_loss: 1.5016 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 6th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5854 - acc: 0.7869 - val_loss: 1.6894 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 6th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7390 - acc: 0.7707 - val_loss: 1.6722 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 6th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6012 - acc: 0.7861 - val_loss: 1.6116 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5524 - acc: 0.7945 - val_loss: 1.6607 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5959 - acc: 0.7842 - val_loss: 1.6471 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 6th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4879 - acc: 0.7975 - val_loss: 1.6090 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6175 - acc: 0.7883 - val_loss: 1.5752 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 6th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5134 - acc: 0.7990 - val_loss: 1.5202 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5664 - acc: 0.7887 - val_loss: 1.5690 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 6th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6459 - acc: 0.7770 - val_loss: 1.5739 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4472 - acc: 0.8047 - val_loss: 1.5945 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 6th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5167 - acc: 0.7979 - val_loss: 1.5928 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6769 - acc: 0.7748 - val_loss: 1.5210 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 6th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6276 - acc: 0.7857 - val_loss: 1.4929 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5651 - acc: 0.7916 - val_loss: 1.5090 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5656 - acc: 0.7928 - val_loss: 1.5833 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 6th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6856 - acc: 0.7793 - val_loss: 1.5516 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4939 - acc: 0.7967 - val_loss: 1.4976 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5722 - acc: 0.7902 - val_loss: 1.4994 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 6th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5519 - acc: 0.7914 - val_loss: 1.4181 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 6th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5116 - acc: 0.7971 - val_loss: 1.5823 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5350 - acc: 0.7910 - val_loss: 1.7973 - val_acc: 0.7609\n",
      "[INFO] Training model: epoch 6th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5183 - acc: 0.7947 - val_loss: 1.6457 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 6th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5290 - acc: 0.7936 - val_loss: 1.3617 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 6th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6829 - acc: 0.7793 - val_loss: 1.6463 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 6th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6155 - acc: 0.7887 - val_loss: 1.7140 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 6th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4950 - acc: 0.7990 - val_loss: 1.6813 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 6th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5040 - acc: 0.7977 - val_loss: 1.6392 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5475 - acc: 0.7945 - val_loss: 1.5872 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5098 - acc: 0.7979 - val_loss: 1.5768 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 6th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5671 - acc: 0.7932 - val_loss: 1.6622 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 6th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5007 - acc: 0.7979 - val_loss: 1.7712 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 6th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5291 - acc: 0.7938 - val_loss: 1.6525 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6145 - acc: 0.7822 - val_loss: 1.6146 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 6th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6181 - acc: 0.7893 - val_loss: 1.5825 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 6th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5796 - acc: 0.7895 - val_loss: 1.6243 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6256 - acc: 0.7859 - val_loss: 1.5028 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5837 - acc: 0.7861 - val_loss: 1.6345 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 6th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5628 - acc: 0.7906 - val_loss: 1.4842 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 6th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5645 - acc: 0.7906 - val_loss: 1.5040 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 6th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5958 - acc: 0.7898 - val_loss: 1.4194 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 6th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6819 - acc: 0.7777 - val_loss: 1.5845 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5822 - acc: 0.7945 - val_loss: 1.5442 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5830 - acc: 0.7906 - val_loss: 1.4902 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5688 - acc: 0.7896 - val_loss: 1.6895 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 6th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5864 - acc: 0.7879 - val_loss: 1.5428 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 6th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5429 - acc: 0.7906 - val_loss: 1.4206 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5882 - acc: 0.7838 - val_loss: 1.6036 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5335 - acc: 0.7963 - val_loss: 1.6115 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5742 - acc: 0.7910 - val_loss: 1.5430 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5808 - acc: 0.7906 - val_loss: 1.4779 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 6th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6016 - acc: 0.7908 - val_loss: 1.4761 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 6th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6064 - acc: 0.7859 - val_loss: 1.6039 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5852 - acc: 0.7877 - val_loss: 1.6053 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5812 - acc: 0.7910 - val_loss: 1.6147 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4983 - acc: 0.8014 - val_loss: 1.3914 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 6th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6289 - acc: 0.7809 - val_loss: 1.5557 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5640 - acc: 0.7914 - val_loss: 1.4894 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6417 - acc: 0.7859 - val_loss: 1.5826 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 6th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6040 - acc: 0.7818 - val_loss: 1.4887 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5520 - acc: 0.7932 - val_loss: 1.5374 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 6th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5782 - acc: 0.7865 - val_loss: 1.6226 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5494 - acc: 0.7957 - val_loss: 1.3469 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5578 - acc: 0.7908 - val_loss: 1.5223 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6120 - acc: 0.7820 - val_loss: 1.6626 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6707 - acc: 0.7848 - val_loss: 1.4311 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 6th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5881 - acc: 0.7869 - val_loss: 1.5885 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 6th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6731 - acc: 0.7789 - val_loss: 1.5439 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 6th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5821 - acc: 0.7865 - val_loss: 1.5054 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 6th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5761 - acc: 0.7949 - val_loss: 1.4929 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 6th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5927 - acc: 0.7908 - val_loss: 1.4953 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 6th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5433 - acc: 0.7939 - val_loss: 1.6088 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 6th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5786 - acc: 0.7883 - val_loss: 1.5951 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 6th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4983 - acc: 0.7939 - val_loss: 1.6990 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 6th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5476 - acc: 0.7877 - val_loss: 1.3519 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 6th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4285 - acc: 0.8066 - val_loss: 1.5120 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5303 - acc: 0.7945 - val_loss: 1.5404 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4972 - acc: 0.7967 - val_loss: 1.6369 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 6th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5693 - acc: 0.7926 - val_loss: 1.4687 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 6th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5477 - acc: 0.7926 - val_loss: 1.8403 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 6th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6212 - acc: 0.7842 - val_loss: 1.5728 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5062 - acc: 0.7969 - val_loss: 1.4427 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6225 - acc: 0.7795 - val_loss: 1.5407 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5765 - acc: 0.7826 - val_loss: 1.4855 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 6th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5733 - acc: 0.7924 - val_loss: 1.4635 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5885 - acc: 0.7869 - val_loss: 1.4906 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6074 - acc: 0.7881 - val_loss: 1.5878 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 6th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5610 - acc: 0.7896 - val_loss: 1.6498 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6531 - acc: 0.7805 - val_loss: 1.5330 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6048 - acc: 0.7895 - val_loss: 1.3564 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 6th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4580 - acc: 0.8045 - val_loss: 1.4265 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 6th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4997 - acc: 0.7939 - val_loss: 1.4084 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 6th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5614 - acc: 0.7922 - val_loss: 1.5807 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 6th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7069 - acc: 0.7754 - val_loss: 1.6371 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 6th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6151 - acc: 0.7838 - val_loss: 1.5525 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5619 - acc: 0.7934 - val_loss: 1.5632 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 6th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5649 - acc: 0.7908 - val_loss: 1.6526 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 6th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7951 - val_loss: 1.5471 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4926 - acc: 0.7998 - val_loss: 1.5935 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 6th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5686 - acc: 0.7867 - val_loss: 1.5133 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 6th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6171 - acc: 0.7881 - val_loss: 1.6458 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 6th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5307 - acc: 0.7924 - val_loss: 1.6020 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 6th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4796 - acc: 0.7969 - val_loss: 1.4228 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 6th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5393 - acc: 0.7924 - val_loss: 1.5154 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 6th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.7002 - acc: 0.7787 - val_loss: 1.5259 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5793 - acc: 0.7898 - val_loss: 1.5315 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 6th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5400 - acc: 0.7922 - val_loss: 1.4178 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5948 - acc: 0.7881 - val_loss: 1.6655 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 6th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5830 - acc: 0.7896 - val_loss: 1.4485 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6197 - acc: 0.7838 - val_loss: 1.3841 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 6th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6453 - acc: 0.7799 - val_loss: 1.4818 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 6th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5511 - acc: 0.7963 - val_loss: 1.4454 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 6th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5810 - acc: 0.7889 - val_loss: 1.5238 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5149 - acc: 0.7963 - val_loss: 1.5961 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5974 - acc: 0.7859 - val_loss: 1.7846 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 6th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5901 - acc: 0.7889 - val_loss: 1.6437 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6355 - acc: 0.7828 - val_loss: 1.5559 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5208 - acc: 0.7988 - val_loss: 1.4900 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 6th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5691 - acc: 0.7900 - val_loss: 1.5575 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 6th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5906 - acc: 0.7812 - val_loss: 1.5606 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 6th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6004 - acc: 0.7830 - val_loss: 1.5901 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 6th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5686 - acc: 0.7912 - val_loss: 1.7051 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 6th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6731 - acc: 0.7752 - val_loss: 1.4274 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 6th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6135 - acc: 0.7873 - val_loss: 1.7733 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 6th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5089 - acc: 0.8016 - val_loss: 1.5581 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 6th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6492 - acc: 0.7832 - val_loss: 1.5417 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5469 - acc: 0.7967 - val_loss: 1.5674 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 6th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5557 - acc: 0.7887 - val_loss: 1.4053 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5727 - acc: 0.7926 - val_loss: 1.5752 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 6th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5567 - acc: 0.7926 - val_loss: 1.7134 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5896 - acc: 0.7859 - val_loss: 1.6109 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 6th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6178 - acc: 0.7826 - val_loss: 1.6236 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 6th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5690 - acc: 0.7932 - val_loss: 1.6529 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 6th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6605 - acc: 0.7801 - val_loss: 1.7542 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 6th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5238 - acc: 0.7980 - val_loss: 1.6797 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 6th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5598 - acc: 0.7900 - val_loss: 1.4553 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6692 - acc: 0.7820 - val_loss: 1.4895 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6601 - acc: 0.7777 - val_loss: 1.6232 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6498 - acc: 0.7773 - val_loss: 1.4986 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 6th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6405 - acc: 0.7830 - val_loss: 1.5622 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 6th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6082 - acc: 0.7830 - val_loss: 1.5615 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 6th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6551 - acc: 0.7787 - val_loss: 1.6394 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 6th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6936 - acc: 0.7754 - val_loss: 1.5717 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6561 - acc: 0.7840 - val_loss: 1.4183 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 6th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5816 - acc: 0.7902 - val_loss: 1.4905 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 6th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5040 - acc: 0.7963 - val_loss: 1.5252 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 6th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5815 - acc: 0.7857 - val_loss: 1.4902 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6040 - acc: 0.7809 - val_loss: 1.7513 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 6th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6104 - acc: 0.7898 - val_loss: 1.5524 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 6th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6365 - acc: 0.7824 - val_loss: 1.5854 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 6th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6132 - acc: 0.7844 - val_loss: 1.5170 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 6th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5964 - acc: 0.7857 - val_loss: 1.6140 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5740 - acc: 0.7920 - val_loss: 1.5490 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 6th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5031 - acc: 0.7906 - val_loss: 1.5151 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 6th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5464 - acc: 0.7955 - val_loss: 1.5025 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5424 - acc: 0.7955 - val_loss: 1.7029 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 6th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5724 - acc: 0.7910 - val_loss: 1.6237 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 6th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5332 - acc: 0.7928 - val_loss: 1.5857 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 6th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6729 - acc: 0.7807 - val_loss: 1.5011 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 6th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5422 - acc: 0.7955 - val_loss: 1.5005 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 6th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5388 - acc: 0.7980 - val_loss: 1.6540 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 6th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5624 - acc: 0.7914 - val_loss: 1.7347 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 6th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5175 - acc: 0.7947 - val_loss: 1.7014 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 6th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5218 - acc: 0.7975 - val_loss: 1.6921 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 6th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6507 - acc: 0.7836 - val_loss: 1.5583 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 6th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6556 - acc: 0.7844 - val_loss: 1.5351 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 6th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6169 - acc: 0.7811 - val_loss: 1.4644 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 6th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5618 - acc: 0.7920 - val_loss: 1.7425 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 6th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4840 - acc: 0.8021 - val_loss: 1.5939 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 6th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6018 - acc: 0.7869 - val_loss: 1.5821 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 6th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5507 - acc: 0.7865 - val_loss: 1.5079 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 6th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5291 - acc: 0.7969 - val_loss: 1.6445 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 6th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6001 - acc: 0.7900 - val_loss: 1.4558 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 6th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4824 - acc: 0.7998 - val_loss: 1.7345 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 6th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6348 - acc: 0.7857 - val_loss: 1.6734 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 6th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5929 - acc: 0.7904 - val_loss: 1.5545 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 6th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6583 - acc: 0.7834 - val_loss: 1.5315 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5274 - acc: 0.7941 - val_loss: 1.7189 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 7th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5995 - acc: 0.7820 - val_loss: 1.6565 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 7th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5090 - acc: 0.7924 - val_loss: 1.5386 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 7th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4501 - acc: 0.8014 - val_loss: 1.5818 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 7th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5956 - acc: 0.7885 - val_loss: 1.5552 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4988 - acc: 0.7957 - val_loss: 1.5704 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5768 - acc: 0.7893 - val_loss: 1.7703 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 7th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5633 - acc: 0.7928 - val_loss: 1.4197 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 7th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5623 - acc: 0.7902 - val_loss: 1.5804 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 7th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5691 - acc: 0.7887 - val_loss: 1.6086 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5911 - acc: 0.7859 - val_loss: 1.8175 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 7th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5337 - acc: 0.7934 - val_loss: 1.4699 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6307 - acc: 0.7814 - val_loss: 1.5610 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 7th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6284 - acc: 0.7812 - val_loss: 1.7972 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 7th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5344 - acc: 0.7975 - val_loss: 1.4625 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5079 - acc: 0.7951 - val_loss: 1.4952 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 7th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4833 - acc: 0.7984 - val_loss: 1.5765 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5643 - acc: 0.7873 - val_loss: 1.6814 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 7th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6550 - acc: 0.7801 - val_loss: 1.5892 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 7th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5810 - acc: 0.7877 - val_loss: 1.5552 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5841 - acc: 0.7883 - val_loss: 1.4583 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5226 - acc: 0.7906 - val_loss: 1.4627 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6368 - acc: 0.7803 - val_loss: 1.4246 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 7th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5690 - acc: 0.7900 - val_loss: 1.3838 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 7th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4607 - acc: 0.8016 - val_loss: 1.5724 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 7th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5063 - acc: 0.7945 - val_loss: 1.4807 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 7th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5740 - acc: 0.7941 - val_loss: 1.6681 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 7th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5709 - acc: 0.7895 - val_loss: 1.6254 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 7th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5112 - acc: 0.7910 - val_loss: 1.5188 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 7th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4913 - acc: 0.8043 - val_loss: 1.8450 - val_acc: 0.7594\n",
      "[INFO] Training model: epoch 7th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5886 - acc: 0.7832 - val_loss: 1.4448 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 7th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4854 - acc: 0.7980 - val_loss: 1.5520 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5492 - acc: 0.7904 - val_loss: 1.5790 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5635 - acc: 0.7896 - val_loss: 1.5732 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 7th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4950 - acc: 0.8039 - val_loss: 1.5873 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 7th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5033 - acc: 0.7939 - val_loss: 1.6470 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5147 - acc: 0.7951 - val_loss: 1.7332 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 7th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5716 - acc: 0.7871 - val_loss: 1.5787 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4929 - acc: 0.7979 - val_loss: 1.7000 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 7th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4950 - acc: 0.7947 - val_loss: 1.7804 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 7th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5982 - acc: 0.7854 - val_loss: 1.4042 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 7th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5263 - acc: 0.7926 - val_loss: 1.4132 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 7th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5901 - acc: 0.7867 - val_loss: 1.6715 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 7th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5366 - acc: 0.7945 - val_loss: 1.5413 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5358 - acc: 0.7945 - val_loss: 1.5248 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5594 - acc: 0.7934 - val_loss: 1.6009 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 7th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5007 - acc: 0.7998 - val_loss: 1.6892 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 7th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5844 - acc: 0.7828 - val_loss: 1.4651 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 7th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5222 - acc: 0.7930 - val_loss: 1.6427 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 7th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5850 - acc: 0.7883 - val_loss: 1.4528 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 7th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6473 - acc: 0.7777 - val_loss: 1.6594 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 7th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4950 - acc: 0.7949 - val_loss: 1.6077 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 7th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5517 - acc: 0.7920 - val_loss: 1.6331 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 7th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6122 - acc: 0.7826 - val_loss: 1.3992 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 7th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4904 - acc: 0.7994 - val_loss: 1.3881 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 7th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5138 - acc: 0.7930 - val_loss: 1.7292 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 7th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5157 - acc: 0.7979 - val_loss: 1.6677 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 7th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6513 - acc: 0.7803 - val_loss: 1.4733 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4989 - acc: 0.7967 - val_loss: 1.5649 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4907 - acc: 0.7996 - val_loss: 1.4522 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 7th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5941 - acc: 0.7928 - val_loss: 1.5206 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5906 - acc: 0.7805 - val_loss: 1.4274 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 7th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5498 - acc: 0.7883 - val_loss: 1.6152 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 7th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5407 - acc: 0.7893 - val_loss: 1.6394 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 7th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5587 - acc: 0.7873 - val_loss: 1.5025 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 7th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5175 - acc: 0.7941 - val_loss: 1.5092 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4606 - acc: 0.7988 - val_loss: 1.7228 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 7th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4289 - acc: 0.8010 - val_loss: 1.6950 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 7th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5771 - acc: 0.7900 - val_loss: 1.4542 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 7th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5788 - acc: 0.7865 - val_loss: 1.5348 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6293 - acc: 0.7793 - val_loss: 1.5719 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 7th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5051 - acc: 0.7928 - val_loss: 1.7287 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 7th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5211 - acc: 0.7959 - val_loss: 1.4335 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5759 - acc: 0.7824 - val_loss: 1.5479 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 7th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6074 - acc: 0.7812 - val_loss: 1.4709 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 7th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5309 - acc: 0.7922 - val_loss: 1.5196 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5348 - acc: 0.7926 - val_loss: 1.5763 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 7th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4972 - acc: 0.7975 - val_loss: 1.5881 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5330 - acc: 0.7947 - val_loss: 1.6663 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 7th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5383 - acc: 0.7949 - val_loss: 1.4389 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 7th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6012 - acc: 0.7832 - val_loss: 1.4564 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5947 - acc: 0.7873 - val_loss: 1.4366 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 7th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5993 - acc: 0.7873 - val_loss: 1.6407 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 7th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5807 - acc: 0.7883 - val_loss: 1.6362 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 7th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5093 - acc: 0.7957 - val_loss: 1.5244 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4852 - acc: 0.7998 - val_loss: 1.4572 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 7th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4824 - acc: 0.7998 - val_loss: 1.6068 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 7th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4388 - acc: 0.8023 - val_loss: 1.5632 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 7th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5850 - acc: 0.7844 - val_loss: 1.5347 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6281 - acc: 0.7881 - val_loss: 1.5333 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 7th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5174 - acc: 0.7934 - val_loss: 1.6744 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6039 - acc: 0.7850 - val_loss: 1.5755 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 7th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4502 - acc: 0.8053 - val_loss: 1.5629 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 7th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5670 - acc: 0.7881 - val_loss: 1.5914 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 7th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6222 - acc: 0.7787 - val_loss: 1.7626 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 7th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5320 - acc: 0.7936 - val_loss: 1.4731 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4696 - acc: 0.8041 - val_loss: 1.6359 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 7th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6178 - acc: 0.7809 - val_loss: 1.6909 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 7th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6270 - acc: 0.7811 - val_loss: 1.3859 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 7th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4668 - acc: 0.7969 - val_loss: 1.5988 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 7th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6461 - acc: 0.7812 - val_loss: 1.5585 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4567 - acc: 0.8010 - val_loss: 1.4555 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 7th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5654 - acc: 0.7887 - val_loss: 1.6556 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4953 - acc: 0.7961 - val_loss: 1.5252 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6094 - acc: 0.7812 - val_loss: 1.4640 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5499 - acc: 0.7869 - val_loss: 1.6379 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 7th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5845 - acc: 0.7914 - val_loss: 1.7459 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 7th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6792 - acc: 0.7771 - val_loss: 1.4135 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 7th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4817 - acc: 0.7969 - val_loss: 1.4502 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5664 - acc: 0.7914 - val_loss: 1.4762 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 7th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4998 - acc: 0.7998 - val_loss: 1.3668 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 7th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5436 - acc: 0.7928 - val_loss: 1.6500 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 7th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5514 - acc: 0.7865 - val_loss: 1.3558 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 7th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5882 - acc: 0.7893 - val_loss: 1.4774 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 7th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6221 - acc: 0.7854 - val_loss: 1.6994 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 7th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5548 - acc: 0.7926 - val_loss: 1.6315 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 7th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4994 - acc: 0.7941 - val_loss: 1.4139 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 7th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5603 - acc: 0.7891 - val_loss: 1.5352 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5776 - acc: 0.7916 - val_loss: 1.5793 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6577 - acc: 0.7793 - val_loss: 1.5090 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6554 - acc: 0.7807 - val_loss: 1.4637 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5430 - acc: 0.7910 - val_loss: 1.6110 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5656 - acc: 0.7826 - val_loss: 1.5012 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 7th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4896 - acc: 0.7973 - val_loss: 1.4056 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 7th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5434 - acc: 0.7930 - val_loss: 1.6367 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 7th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6700 - acc: 0.7762 - val_loss: 1.4803 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5895 - acc: 0.7887 - val_loss: 1.6638 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 7th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5839 - acc: 0.7904 - val_loss: 1.5391 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 7th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5857 - acc: 0.7887 - val_loss: 1.6322 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 7th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5776 - acc: 0.7883 - val_loss: 1.5634 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 7th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5146 - acc: 0.7932 - val_loss: 1.5140 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 7th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5372 - acc: 0.7951 - val_loss: 1.6883 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 7th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5920 - acc: 0.7867 - val_loss: 1.7832 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 7th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4774 - acc: 0.8012 - val_loss: 1.7498 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 7th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5280 - acc: 0.7953 - val_loss: 1.5880 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 7th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5681 - acc: 0.7936 - val_loss: 1.4139 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 7th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4975 - acc: 0.7938 - val_loss: 1.6532 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 7th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4618 - acc: 0.7996 - val_loss: 1.6730 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 7th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6499 - acc: 0.7756 - val_loss: 1.3325 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 7th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5400 - acc: 0.7902 - val_loss: 1.4211 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 7th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5461 - acc: 0.7912 - val_loss: 1.6673 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 7th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5750 - acc: 0.7807 - val_loss: 1.5620 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5796 - acc: 0.7891 - val_loss: 1.6107 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 7th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4629 - acc: 0.8012 - val_loss: 1.7112 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 7th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5609 - acc: 0.7938 - val_loss: 1.3921 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 7th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5206 - acc: 0.7994 - val_loss: 1.5276 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 7th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4974 - acc: 0.8008 - val_loss: 1.5568 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5419 - acc: 0.7967 - val_loss: 1.6944 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 7th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5108 - acc: 0.7947 - val_loss: 1.5620 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 7th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6110 - acc: 0.7863 - val_loss: 1.5024 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4722 - acc: 0.7975 - val_loss: 1.5728 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5179 - acc: 0.7924 - val_loss: 1.5722 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4312 - acc: 0.8059 - val_loss: 1.7421 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 7th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4493 - acc: 0.8025 - val_loss: 1.5109 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6182 - acc: 0.7805 - val_loss: 1.4629 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 7th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5695 - acc: 0.7916 - val_loss: 1.4738 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 7th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5641 - acc: 0.7914 - val_loss: 1.5080 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5164 - acc: 0.7971 - val_loss: 1.5013 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 7th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5646 - acc: 0.7877 - val_loss: 1.6053 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 7th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6182 - acc: 0.7867 - val_loss: 1.6392 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 7th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5539 - acc: 0.7922 - val_loss: 1.4442 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5121 - acc: 0.7982 - val_loss: 1.8793 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 7th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6069 - acc: 0.7879 - val_loss: 1.5267 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6461 - acc: 0.7842 - val_loss: 1.4900 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 7th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5977 - acc: 0.7850 - val_loss: 1.5894 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 7th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6047 - acc: 0.7814 - val_loss: 1.4893 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 7th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6165 - acc: 0.7824 - val_loss: 1.5216 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5409 - acc: 0.7883 - val_loss: 1.7414 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 7th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5600 - acc: 0.7922 - val_loss: 1.6683 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5759 - acc: 0.7877 - val_loss: 1.5290 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5596 - acc: 0.7867 - val_loss: 1.4664 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6623 - acc: 0.7797 - val_loss: 1.5260 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5593 - acc: 0.7885 - val_loss: 1.7093 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 7th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4537 - acc: 0.8004 - val_loss: 1.4344 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5893 - acc: 0.7836 - val_loss: 1.6117 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 7th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4978 - acc: 0.8000 - val_loss: 1.4659 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 7th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5829 - acc: 0.7871 - val_loss: 1.5384 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5495 - acc: 0.7916 - val_loss: 1.5925 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 7th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6017 - acc: 0.7811 - val_loss: 1.4156 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 7th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5174 - acc: 0.7977 - val_loss: 1.6647 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 7th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6484 - acc: 0.7834 - val_loss: 1.6511 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 7th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6019 - acc: 0.7857 - val_loss: 1.5559 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 7th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5457 - acc: 0.7898 - val_loss: 1.6116 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5062 - acc: 0.7963 - val_loss: 1.6041 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 7th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5347 - acc: 0.7914 - val_loss: 1.4657 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5380 - acc: 0.7941 - val_loss: 1.5877 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6083 - acc: 0.7854 - val_loss: 1.8771 - val_acc: 0.7516\n",
      "[INFO] Training model: epoch 7th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6703 - acc: 0.7814 - val_loss: 1.4633 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 7th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5833 - acc: 0.7895 - val_loss: 1.4419 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 7th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5923 - acc: 0.7859 - val_loss: 1.3027 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 7th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6354 - acc: 0.7838 - val_loss: 1.6425 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 7th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5425 - acc: 0.7922 - val_loss: 1.7896 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 7th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5440 - acc: 0.7945 - val_loss: 1.4164 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 7th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5950 - acc: 0.7873 - val_loss: 1.4203 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 7th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5611 - acc: 0.7922 - val_loss: 1.6010 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 7th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6118 - acc: 0.7854 - val_loss: 1.5633 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 7th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5295 - acc: 0.7982 - val_loss: 1.3563 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 7th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5904 - acc: 0.7867 - val_loss: 1.8209 - val_acc: 0.7531\n",
      "[INFO] Training model: epoch 7th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5185 - acc: 0.7963 - val_loss: 1.6269 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 7th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6440 - acc: 0.7818 - val_loss: 1.6645 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 7th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5538 - acc: 0.7908 - val_loss: 1.4486 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 7th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6222 - acc: 0.7842 - val_loss: 1.5499 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5777 - acc: 0.7887 - val_loss: 1.6694 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 7th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5813 - acc: 0.7893 - val_loss: 1.5539 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 7th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6435 - acc: 0.7834 - val_loss: 1.5477 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 7th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5509 - acc: 0.7943 - val_loss: 1.5531 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 7th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5328 - acc: 0.7961 - val_loss: 1.5864 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 7th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5126 - acc: 0.7973 - val_loss: 1.3635 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 7th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5976 - acc: 0.7873 - val_loss: 1.6102 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5011 - acc: 0.7945 - val_loss: 1.6104 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 7th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5727 - acc: 0.7859 - val_loss: 1.4494 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5437 - acc: 0.7930 - val_loss: 1.5425 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 7th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6349 - acc: 0.7814 - val_loss: 1.5145 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6070 - acc: 0.7873 - val_loss: 1.5770 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 7th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5074 - acc: 0.8041 - val_loss: 1.5155 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 7th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6060 - acc: 0.7834 - val_loss: 1.5554 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 7th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5343 - acc: 0.7904 - val_loss: 1.6361 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 7th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5894 - acc: 0.7904 - val_loss: 1.4494 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 7th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6261 - acc: 0.7836 - val_loss: 1.4076 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 7th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5331 - acc: 0.7967 - val_loss: 1.6164 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4352 - acc: 0.7982 - val_loss: 1.6286 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 7th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5132 - acc: 0.7932 - val_loss: 1.4292 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 7th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6070 - acc: 0.7863 - val_loss: 1.8594 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 7th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5626 - acc: 0.7906 - val_loss: 1.5730 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 7th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5577 - acc: 0.7879 - val_loss: 1.5627 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 7th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5500 - acc: 0.7926 - val_loss: 1.6311 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5191 - acc: 0.7932 - val_loss: 1.5057 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 7th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5268 - acc: 0.7936 - val_loss: 1.6086 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 7th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5453 - acc: 0.7928 - val_loss: 1.4865 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 7th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5477 - acc: 0.7902 - val_loss: 1.5457 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 7th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4666 - acc: 0.8045 - val_loss: 1.6106 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 7th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5083 - acc: 0.7949 - val_loss: 1.8331 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 7th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6109 - acc: 0.7873 - val_loss: 1.4447 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 7th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5527 - acc: 0.7914 - val_loss: 1.5153 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 7th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6074 - acc: 0.7807 - val_loss: 1.4229 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 7th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5478 - acc: 0.7904 - val_loss: 1.5917 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 7th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4711 - acc: 0.8016 - val_loss: 1.4172 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 7th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4461 - acc: 0.8027 - val_loss: 1.3591 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 7th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6053 - acc: 0.7854 - val_loss: 1.3819 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 7th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6667 - acc: 0.7797 - val_loss: 1.4292 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 7th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5353 - acc: 0.7908 - val_loss: 1.6747 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 7th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5883 - acc: 0.7906 - val_loss: 1.4854 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 7th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5769 - acc: 0.7916 - val_loss: 1.6067 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 7th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5575 - acc: 0.7918 - val_loss: 1.4210 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 7th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4930 - acc: 0.7959 - val_loss: 1.4695 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 7th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6080 - acc: 0.7848 - val_loss: 1.4737 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 7th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7947 - val_loss: 1.4738 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 7th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5722 - acc: 0.7883 - val_loss: 1.7310 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 7th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5538 - acc: 0.7867 - val_loss: 1.6315 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 7th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5962 - acc: 0.7852 - val_loss: 1.4360 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 8th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4610 - acc: 0.7990 - val_loss: 1.8467 - val_acc: 0.7469\n",
      "[INFO] Training model: epoch 8th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5319 - acc: 0.7895 - val_loss: 1.4046 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 8th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5470 - acc: 0.7908 - val_loss: 1.6242 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5899 - acc: 0.7895 - val_loss: 1.5278 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 8th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4843 - acc: 0.7965 - val_loss: 1.6288 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5145 - acc: 0.7938 - val_loss: 1.4670 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 8th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5460 - acc: 0.7902 - val_loss: 1.6633 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 8th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5627 - acc: 0.7852 - val_loss: 1.5138 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 8th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5050 - acc: 0.7934 - val_loss: 1.5453 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 8th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4756 - acc: 0.8010 - val_loss: 1.5652 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 8th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4644 - acc: 0.7977 - val_loss: 1.4096 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 8th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5282 - acc: 0.7912 - val_loss: 1.5869 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 8th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4678 - acc: 0.8029 - val_loss: 1.6777 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 8th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5968 - acc: 0.7873 - val_loss: 1.6682 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 8th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5781 - acc: 0.7879 - val_loss: 1.7091 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 8th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4557 - acc: 0.7951 - val_loss: 1.3804 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 8th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5030 - acc: 0.7941 - val_loss: 1.5478 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5408 - acc: 0.7928 - val_loss: 1.6871 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 8th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5179 - acc: 0.7934 - val_loss: 1.4270 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 8th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4206 - acc: 0.8021 - val_loss: 1.6692 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 8th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5859 - acc: 0.7828 - val_loss: 1.4848 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 8th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5005 - acc: 0.7959 - val_loss: 1.7008 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 8th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5433 - acc: 0.7873 - val_loss: 1.5821 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5562 - acc: 0.7889 - val_loss: 1.7774 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 8th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4876 - acc: 0.7941 - val_loss: 1.6180 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6165 - acc: 0.7777 - val_loss: 1.5041 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 8th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5052 - acc: 0.7912 - val_loss: 1.4065 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 8th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5149 - acc: 0.7973 - val_loss: 1.6093 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4645 - acc: 0.8039 - val_loss: 1.5441 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 8th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4825 - acc: 0.7977 - val_loss: 1.7808 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 8th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4830 - acc: 0.8012 - val_loss: 1.3491 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 8th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4321 - acc: 0.8020 - val_loss: 1.4554 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5804 - acc: 0.7861 - val_loss: 1.3819 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 8th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5845 - acc: 0.7848 - val_loss: 1.6067 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 8th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4468 - acc: 0.8041 - val_loss: 1.4844 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 8th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5877 - acc: 0.7775 - val_loss: 1.5302 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5408 - acc: 0.7881 - val_loss: 1.5897 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 8th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5915 - acc: 0.7881 - val_loss: 1.5708 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5371 - acc: 0.7896 - val_loss: 1.6261 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 8th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5535 - acc: 0.7848 - val_loss: 1.4442 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 8th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5809 - acc: 0.7879 - val_loss: 1.3638 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 8th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5086 - acc: 0.7924 - val_loss: 1.3986 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 8th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4812 - acc: 0.7967 - val_loss: 1.4788 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 8th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5192 - acc: 0.7900 - val_loss: 1.3122 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 8th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5636 - acc: 0.7875 - val_loss: 1.5749 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5175 - acc: 0.7947 - val_loss: 1.5075 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5586 - acc: 0.7887 - val_loss: 1.4297 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 8th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6013 - acc: 0.7830 - val_loss: 1.7437 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 8th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5124 - acc: 0.7977 - val_loss: 1.4763 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5880 - acc: 0.7871 - val_loss: 1.5520 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 8th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6006 - acc: 0.7848 - val_loss: 1.4436 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 8th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5578 - acc: 0.7871 - val_loss: 1.5252 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5646 - acc: 0.7896 - val_loss: 1.7307 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5522 - acc: 0.7852 - val_loss: 1.5318 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 8th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5901 - acc: 0.7898 - val_loss: 1.5055 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 8th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5272 - acc: 0.7990 - val_loss: 1.4724 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6597 - acc: 0.7783 - val_loss: 1.6477 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 8th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5968 - acc: 0.7850 - val_loss: 1.4602 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 8th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4956 - acc: 0.7953 - val_loss: 1.6403 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5030 - acc: 0.7930 - val_loss: 1.5050 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 8th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5162 - acc: 0.7932 - val_loss: 1.6752 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 8th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5163 - acc: 0.7963 - val_loss: 1.6850 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 8th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5351 - acc: 0.7926 - val_loss: 1.6768 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 8th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6109 - acc: 0.7830 - val_loss: 1.5357 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 8th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6135 - acc: 0.7840 - val_loss: 1.2626 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 8th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5288 - acc: 0.7912 - val_loss: 1.6448 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 8th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5103 - acc: 0.7961 - val_loss: 1.7477 - val_acc: 0.7578\n",
      "[INFO] Training model: epoch 8th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5595 - acc: 0.7910 - val_loss: 1.5526 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4700 - acc: 0.7973 - val_loss: 1.5663 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5799 - acc: 0.7859 - val_loss: 1.5247 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4874 - acc: 0.7969 - val_loss: 1.6634 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5475 - acc: 0.7904 - val_loss: 1.3164 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 8th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4520 - acc: 0.8016 - val_loss: 1.6710 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3916 - acc: 0.8094 - val_loss: 1.6121 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 8th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5428 - acc: 0.7865 - val_loss: 1.4686 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 8th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6054 - acc: 0.7830 - val_loss: 1.7201 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 8th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4769 - acc: 0.7975 - val_loss: 1.4901 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 8th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5996 - acc: 0.7885 - val_loss: 1.5511 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5598 - acc: 0.7889 - val_loss: 1.4119 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 8th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5168 - acc: 0.7926 - val_loss: 1.6257 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 8th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5759 - acc: 0.7879 - val_loss: 1.4823 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4802 - acc: 0.7971 - val_loss: 1.6177 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5584 - acc: 0.7885 - val_loss: 1.3801 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 8th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5036 - acc: 0.7977 - val_loss: 1.4849 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5609 - acc: 0.7918 - val_loss: 1.6648 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4933 - acc: 0.7990 - val_loss: 1.4098 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 8th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5916 - acc: 0.7887 - val_loss: 1.6695 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4903 - acc: 0.7990 - val_loss: 1.5099 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 8th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4920 - acc: 0.7949 - val_loss: 1.5267 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4848 - acc: 0.7988 - val_loss: 1.4042 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 8th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4270 - acc: 0.8059 - val_loss: 1.4967 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 8th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4581 - acc: 0.8016 - val_loss: 1.6002 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 8th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5965 - acc: 0.7842 - val_loss: 1.6817 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 8th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5969 - acc: 0.7844 - val_loss: 1.4580 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 8th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7990 - val_loss: 1.6504 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 8th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6081 - acc: 0.7809 - val_loss: 1.5627 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4345 - acc: 0.8000 - val_loss: 1.6873 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 8th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5758 - acc: 0.7820 - val_loss: 1.4749 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 8th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5628 - acc: 0.7920 - val_loss: 1.5913 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 8th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5364 - acc: 0.7914 - val_loss: 1.5342 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5710 - acc: 0.7939 - val_loss: 1.7107 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 8th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5784 - acc: 0.7873 - val_loss: 1.6710 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 8th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5447 - acc: 0.7873 - val_loss: 1.6359 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 8th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4933 - acc: 0.7955 - val_loss: 1.4483 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 8th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5005 - acc: 0.7969 - val_loss: 1.5708 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 8th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5237 - acc: 0.7910 - val_loss: 1.6314 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 8th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5311 - acc: 0.7908 - val_loss: 1.5661 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5181 - acc: 0.7902 - val_loss: 1.7401 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 8th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6450 - acc: 0.7768 - val_loss: 1.5228 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 8th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5221 - acc: 0.7947 - val_loss: 1.5768 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 8th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5196 - acc: 0.7908 - val_loss: 1.5308 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 8th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5613 - acc: 0.7941 - val_loss: 1.4204 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 8th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4129 - acc: 0.8068 - val_loss: 1.5940 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 8th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5956 - acc: 0.7854 - val_loss: 1.7397 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 8th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5521 - acc: 0.7891 - val_loss: 1.3601 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 8th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5406 - acc: 0.7895 - val_loss: 1.3654 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 8th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5946 - acc: 0.7850 - val_loss: 1.7087 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5752 - acc: 0.7867 - val_loss: 1.5026 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4412 - acc: 0.8014 - val_loss: 1.4088 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 8th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5347 - acc: 0.7924 - val_loss: 1.4909 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 8th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6274 - acc: 0.7854 - val_loss: 1.6130 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 8th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6249 - acc: 0.7828 - val_loss: 1.3689 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 8th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5345 - acc: 0.7891 - val_loss: 1.3845 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 8th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5729 - acc: 0.7893 - val_loss: 1.3608 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 8th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5502 - acc: 0.7922 - val_loss: 1.6286 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4503 - acc: 0.8045 - val_loss: 1.4482 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 8th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5567 - acc: 0.7936 - val_loss: 1.6387 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5097 - acc: 0.7924 - val_loss: 1.6739 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5342 - acc: 0.7957 - val_loss: 1.8391 - val_acc: 0.7570\n",
      "[INFO] Training model: epoch 8th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6193 - acc: 0.7807 - val_loss: 1.2543 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 8th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5911 - acc: 0.7850 - val_loss: 1.4571 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5031 - acc: 0.7930 - val_loss: 1.7043 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5710 - acc: 0.7902 - val_loss: 1.5512 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5020 - acc: 0.7928 - val_loss: 1.6497 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5410 - acc: 0.7910 - val_loss: 1.5415 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 8th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5562 - acc: 0.7873 - val_loss: 1.6094 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4555 - acc: 0.8033 - val_loss: 1.5318 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 8th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5568 - acc: 0.7918 - val_loss: 1.5789 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 8th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5352 - acc: 0.7896 - val_loss: 1.4805 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 8th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4837 - acc: 0.8020 - val_loss: 1.5531 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 8th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5095 - acc: 0.7912 - val_loss: 1.5132 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6097 - acc: 0.7830 - val_loss: 1.7031 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 8th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5574 - acc: 0.7877 - val_loss: 1.7111 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 8th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5967 - acc: 0.7891 - val_loss: 1.4705 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5330 - acc: 0.7936 - val_loss: 1.5531 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4617 - acc: 0.8021 - val_loss: 1.4914 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4792 - acc: 0.7945 - val_loss: 1.4555 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 8th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5979 - acc: 0.7857 - val_loss: 1.7055 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 8th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5248 - acc: 0.7932 - val_loss: 1.4917 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 8th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4799 - acc: 0.7982 - val_loss: 1.5655 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5371 - acc: 0.7900 - val_loss: 1.4574 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 8th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5304 - acc: 0.7920 - val_loss: 1.6695 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5379 - acc: 0.7877 - val_loss: 1.6928 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 8th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6842 - acc: 0.7732 - val_loss: 1.4626 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 8th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5821 - acc: 0.7832 - val_loss: 1.6181 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 8th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5915 - acc: 0.7922 - val_loss: 1.4668 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5151 - acc: 0.7936 - val_loss: 1.4878 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 8th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5415 - acc: 0.7885 - val_loss: 1.6115 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 8th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4447 - acc: 0.8049 - val_loss: 1.4842 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 8th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5015 - acc: 0.7969 - val_loss: 1.6407 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 8th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4710 - acc: 0.7996 - val_loss: 1.4849 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 8th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6001 - acc: 0.7855 - val_loss: 1.4509 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 8th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4878 - acc: 0.7998 - val_loss: 1.4886 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 8th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5668 - acc: 0.7842 - val_loss: 1.5314 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 8th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5638 - acc: 0.7854 - val_loss: 1.5948 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 8th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5032 - acc: 0.7969 - val_loss: 1.3487 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 8th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5269 - acc: 0.7934 - val_loss: 1.3744 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 8th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5120 - acc: 0.7920 - val_loss: 1.5468 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 8th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5690 - acc: 0.7879 - val_loss: 1.7613 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 8th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5849 - acc: 0.7871 - val_loss: 1.3752 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 8th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5719 - acc: 0.7885 - val_loss: 1.5043 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 8th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5677 - acc: 0.7869 - val_loss: 1.4182 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 8th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6573 - acc: 0.7846 - val_loss: 1.5332 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 8th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5822 - acc: 0.7850 - val_loss: 1.5578 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4327 - acc: 0.8010 - val_loss: 1.5739 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 8th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5316 - acc: 0.7953 - val_loss: 1.5953 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 8th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5052 - acc: 0.7988 - val_loss: 1.4382 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 8th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6056 - acc: 0.7879 - val_loss: 1.5362 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5567 - acc: 0.7877 - val_loss: 1.5213 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 8th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5066 - acc: 0.7998 - val_loss: 1.5074 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5050 - acc: 0.7963 - val_loss: 1.6882 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5527 - acc: 0.7883 - val_loss: 1.5208 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6594 - acc: 0.7791 - val_loss: 1.6173 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5316 - acc: 0.7912 - val_loss: 1.6440 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 8th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5916 - acc: 0.7807 - val_loss: 1.5708 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 8th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4959 - acc: 0.7955 - val_loss: 1.7607 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 8th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5961 - acc: 0.7855 - val_loss: 1.6219 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4956 - acc: 0.7945 - val_loss: 1.4638 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 8th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5054 - acc: 0.7945 - val_loss: 1.5298 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 8th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5625 - acc: 0.7889 - val_loss: 1.5877 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 8th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5802 - acc: 0.7891 - val_loss: 1.5577 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 8th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5802 - acc: 0.7855 - val_loss: 1.4067 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 8th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5662 - acc: 0.7908 - val_loss: 1.5283 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 8th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4856 - acc: 0.8020 - val_loss: 1.6941 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 8th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6221 - acc: 0.7834 - val_loss: 1.5891 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 8th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4796 - acc: 0.7965 - val_loss: 1.5245 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 8th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5539 - acc: 0.7912 - val_loss: 1.7093 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 8th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5143 - acc: 0.7939 - val_loss: 1.4493 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 8th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6131 - acc: 0.7832 - val_loss: 1.5412 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 8th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5547 - acc: 0.7949 - val_loss: 1.4969 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 8th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6070 - acc: 0.7809 - val_loss: 1.5299 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 8th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4932 - acc: 0.7975 - val_loss: 1.6766 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 8th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5685 - acc: 0.7881 - val_loss: 1.4889 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 8th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5337 - acc: 0.7881 - val_loss: 1.5552 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4291 - acc: 0.8006 - val_loss: 1.3891 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 8th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5228 - acc: 0.7893 - val_loss: 1.5610 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5868 - acc: 0.7836 - val_loss: 1.4351 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 8th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5745 - acc: 0.7955 - val_loss: 1.3878 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 8th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5713 - acc: 0.7873 - val_loss: 1.3166 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 8th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4891 - acc: 0.7949 - val_loss: 1.5755 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 8th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4771 - acc: 0.8018 - val_loss: 1.5313 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5579 - acc: 0.7922 - val_loss: 1.6750 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5473 - acc: 0.7891 - val_loss: 1.4251 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 8th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5923 - acc: 0.7846 - val_loss: 1.5927 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5770 - acc: 0.7875 - val_loss: 1.5346 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5415 - acc: 0.7924 - val_loss: 1.6172 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 8th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5666 - acc: 0.7922 - val_loss: 1.5731 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 8th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5269 - acc: 0.7955 - val_loss: 1.4789 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 8th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5565 - acc: 0.7902 - val_loss: 1.3850 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 8th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3868 - acc: 0.8078 - val_loss: 1.6328 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 8th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5446 - acc: 0.7912 - val_loss: 1.5007 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 8th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5026 - acc: 0.7932 - val_loss: 1.6218 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 8th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4730 - acc: 0.8029 - val_loss: 1.4804 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 8th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5876 - acc: 0.7879 - val_loss: 1.6194 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 8th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5240 - acc: 0.7910 - val_loss: 1.7736 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 8th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4987 - acc: 0.7951 - val_loss: 1.6790 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 8th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4525 - acc: 0.8066 - val_loss: 1.7652 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 8th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5937 - acc: 0.7902 - val_loss: 1.5518 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 8th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4450 - acc: 0.8014 - val_loss: 1.4735 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 8th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4581 - acc: 0.8006 - val_loss: 1.3022 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 8th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5050 - acc: 0.7938 - val_loss: 1.5389 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 8th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3997 - acc: 0.8072 - val_loss: 1.5858 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5720 - acc: 0.7875 - val_loss: 1.6896 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 8th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5314 - acc: 0.7953 - val_loss: 1.3744 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 8th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5888 - acc: 0.7861 - val_loss: 1.2914 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 8th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5904 - acc: 0.7855 - val_loss: 1.5727 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5673 - acc: 0.7857 - val_loss: 1.6981 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 8th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4551 - acc: 0.8074 - val_loss: 1.5501 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 8th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5570 - acc: 0.7893 - val_loss: 1.6337 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 8th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5687 - acc: 0.7898 - val_loss: 1.6586 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 8th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6578 - acc: 0.7754 - val_loss: 1.4221 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 8th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4878 - acc: 0.8045 - val_loss: 1.5406 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 8th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6318 - acc: 0.7812 - val_loss: 1.4775 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 8th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6107 - acc: 0.7816 - val_loss: 1.6141 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 8th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5556 - acc: 0.7896 - val_loss: 1.4291 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 8th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5325 - acc: 0.7885 - val_loss: 1.4957 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 8th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5497 - acc: 0.7896 - val_loss: 1.4340 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 8th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5240 - acc: 0.7895 - val_loss: 1.4556 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 8th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4919 - acc: 0.7963 - val_loss: 1.5016 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 8th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4378 - acc: 0.7990 - val_loss: 1.4630 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 9th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5428 - acc: 0.7895 - val_loss: 1.3072 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 9th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4885 - acc: 0.7969 - val_loss: 1.5160 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 9th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4627 - acc: 0.8008 - val_loss: 1.4877 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5590 - acc: 0.7840 - val_loss: 1.9014 - val_acc: 0.7492\n",
      "[INFO] Training model: epoch 9th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4401 - acc: 0.8020 - val_loss: 1.4393 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 9th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5819 - acc: 0.7844 - val_loss: 1.4260 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 9th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6199 - acc: 0.7791 - val_loss: 1.6609 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4708 - acc: 0.7996 - val_loss: 1.4753 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5205 - acc: 0.7953 - val_loss: 1.5711 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 9th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4951 - acc: 0.7936 - val_loss: 1.4526 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 9th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5133 - acc: 0.7918 - val_loss: 1.4116 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 9th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5079 - acc: 0.7902 - val_loss: 1.7520 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 9th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4984 - acc: 0.7908 - val_loss: 1.6251 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 9th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4819 - acc: 0.7980 - val_loss: 1.5398 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5528 - acc: 0.7861 - val_loss: 1.5188 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 9th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4831 - acc: 0.7949 - val_loss: 1.5981 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4198 - acc: 0.8043 - val_loss: 1.5811 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4938 - acc: 0.7951 - val_loss: 1.5243 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 9th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5094 - acc: 0.7936 - val_loss: 1.5417 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5497 - acc: 0.7871 - val_loss: 1.6176 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4839 - acc: 0.7912 - val_loss: 1.7235 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 9th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5072 - acc: 0.7871 - val_loss: 1.4693 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3626 - acc: 0.8064 - val_loss: 1.5411 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 9th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6006 - acc: 0.7838 - val_loss: 1.4671 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 9th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5353 - acc: 0.7875 - val_loss: 1.7384 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 9th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5728 - acc: 0.7865 - val_loss: 1.4306 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 9th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4965 - acc: 0.7924 - val_loss: 1.5634 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 9th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5176 - acc: 0.7914 - val_loss: 1.4090 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 9th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5348 - acc: 0.7891 - val_loss: 1.5440 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 9th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4839 - acc: 0.7916 - val_loss: 1.5560 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 9th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5332 - acc: 0.7865 - val_loss: 1.4337 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 9th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4989 - acc: 0.7936 - val_loss: 1.6211 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5183 - acc: 0.7912 - val_loss: 1.3081 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 9th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5041 - acc: 0.7936 - val_loss: 1.4548 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 9th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6255 - acc: 0.7848 - val_loss: 1.3253 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 9th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5725 - acc: 0.7826 - val_loss: 1.4523 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 9th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5289 - acc: 0.7922 - val_loss: 1.6256 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 9th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5493 - acc: 0.7895 - val_loss: 1.5334 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 9th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5260 - acc: 0.7873 - val_loss: 1.4403 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 9th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5059 - acc: 0.7939 - val_loss: 1.5671 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 9th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4669 - acc: 0.7973 - val_loss: 1.4186 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5525 - acc: 0.7900 - val_loss: 1.4965 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4837 - acc: 0.7963 - val_loss: 1.5717 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5477 - acc: 0.7855 - val_loss: 1.6846 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 9th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5748 - acc: 0.7854 - val_loss: 1.3862 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 9th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6103 - acc: 0.7771 - val_loss: 1.6030 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 9th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5218 - acc: 0.7910 - val_loss: 1.5140 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4787 - acc: 0.7973 - val_loss: 1.5779 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 9th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5212 - acc: 0.7896 - val_loss: 1.5460 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 9th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5560 - acc: 0.7850 - val_loss: 1.4642 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4847 - acc: 0.7936 - val_loss: 1.3647 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 9th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5327 - acc: 0.7955 - val_loss: 1.5120 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5312 - acc: 0.7875 - val_loss: 1.6910 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 9th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5365 - acc: 0.7902 - val_loss: 1.5216 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5475 - acc: 0.7885 - val_loss: 1.5942 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 9th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4963 - acc: 0.7930 - val_loss: 1.7256 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 9th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5117 - acc: 0.7922 - val_loss: 1.4567 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4778 - acc: 0.8004 - val_loss: 1.3921 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 9th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4330 - acc: 0.8008 - val_loss: 1.4528 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 9th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5680 - acc: 0.7922 - val_loss: 1.3923 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 9th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5405 - acc: 0.7881 - val_loss: 1.5533 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 9th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5180 - acc: 0.7916 - val_loss: 1.5513 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4396 - acc: 0.8053 - val_loss: 1.4440 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5435 - acc: 0.7930 - val_loss: 1.5342 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 9th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5450 - acc: 0.7857 - val_loss: 1.5157 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 9th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5803 - acc: 0.7869 - val_loss: 1.4252 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 9th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5721 - acc: 0.7873 - val_loss: 1.5786 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4793 - acc: 0.7971 - val_loss: 1.3554 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 9th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4188 - acc: 0.7959 - val_loss: 1.4941 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 9th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5442 - acc: 0.7898 - val_loss: 1.6157 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 9th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5896 - acc: 0.7885 - val_loss: 1.5308 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 9th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5046 - acc: 0.7922 - val_loss: 1.5520 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 9th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5553 - acc: 0.7893 - val_loss: 1.4668 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 9th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4963 - acc: 0.7953 - val_loss: 1.4338 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 9th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5416 - acc: 0.7912 - val_loss: 1.2541 - val_acc: 0.8305\n",
      "[INFO] Training model: epoch 9th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5581 - acc: 0.7883 - val_loss: 1.5099 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5281 - acc: 0.7912 - val_loss: 1.5656 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 9th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5493 - acc: 0.7826 - val_loss: 1.5279 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 9th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5273 - acc: 0.7980 - val_loss: 1.3605 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 9th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4883 - acc: 0.7965 - val_loss: 1.5650 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6334 - acc: 0.7740 - val_loss: 1.3990 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5667 - acc: 0.7889 - val_loss: 1.5773 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 9th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5163 - acc: 0.7941 - val_loss: 1.3308 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 9th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5869 - acc: 0.7844 - val_loss: 1.4201 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 9th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5158 - acc: 0.7908 - val_loss: 1.5993 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 9th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5009 - acc: 0.7928 - val_loss: 1.5472 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 9th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5002 - acc: 0.8006 - val_loss: 1.5105 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5787 - acc: 0.7854 - val_loss: 1.6608 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5066 - acc: 0.7896 - val_loss: 1.5269 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 9th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5473 - acc: 0.7887 - val_loss: 1.3830 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 9th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5183 - acc: 0.7910 - val_loss: 1.4454 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 9th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4917 - acc: 0.7936 - val_loss: 1.3136 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 9th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5322 - acc: 0.7951 - val_loss: 1.3608 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 9th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5868 - acc: 0.7838 - val_loss: 1.4979 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5285 - acc: 0.7906 - val_loss: 1.5987 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5295 - acc: 0.7912 - val_loss: 1.3655 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 9th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5517 - acc: 0.7910 - val_loss: 1.6550 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 9th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4944 - acc: 0.7918 - val_loss: 1.4406 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5697 - acc: 0.7875 - val_loss: 1.5171 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 9th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4922 - acc: 0.7947 - val_loss: 1.4441 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 9th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4401 - acc: 0.8049 - val_loss: 1.5351 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5377 - acc: 0.7939 - val_loss: 1.5337 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4454 - acc: 0.8039 - val_loss: 1.5232 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5533 - acc: 0.7895 - val_loss: 1.3256 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 9th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5546 - acc: 0.7879 - val_loss: 1.5788 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 9th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5435 - acc: 0.7949 - val_loss: 1.4326 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 9th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5427 - acc: 0.7900 - val_loss: 1.6641 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5808 - acc: 0.7855 - val_loss: 1.4372 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 9th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4120 - acc: 0.8092 - val_loss: 1.4171 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 9th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5422 - acc: 0.7930 - val_loss: 1.8124 - val_acc: 0.7563\n",
      "[INFO] Training model: epoch 9th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4735 - acc: 0.7971 - val_loss: 1.6641 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5255 - acc: 0.7883 - val_loss: 1.3751 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 9th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5127 - acc: 0.7938 - val_loss: 1.4766 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5125 - acc: 0.7945 - val_loss: 1.4192 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 9th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5823 - acc: 0.7855 - val_loss: 1.6678 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 9th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4976 - acc: 0.7994 - val_loss: 1.4745 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 9th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5056 - acc: 0.7947 - val_loss: 1.5466 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 9th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6031 - acc: 0.7797 - val_loss: 1.4941 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 9th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4309 - acc: 0.8023 - val_loss: 1.3445 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 9th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5504 - acc: 0.7916 - val_loss: 1.5383 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4838 - acc: 0.7930 - val_loss: 1.6132 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 9th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5114 - acc: 0.7932 - val_loss: 1.6157 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4767 - acc: 0.7977 - val_loss: 1.4891 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 9th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5524 - acc: 0.7875 - val_loss: 1.3325 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 9th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5225 - acc: 0.7959 - val_loss: 1.5229 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 9th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4620 - acc: 0.7992 - val_loss: 1.5392 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 9th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4688 - acc: 0.7982 - val_loss: 1.5642 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4771 - acc: 0.7984 - val_loss: 1.5126 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4281 - acc: 0.8033 - val_loss: 1.5374 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 9th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5515 - acc: 0.7877 - val_loss: 1.4492 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 9th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5171 - acc: 0.7924 - val_loss: 1.6780 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 9th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5267 - acc: 0.7877 - val_loss: 1.6949 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 9th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5242 - acc: 0.7906 - val_loss: 1.5060 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4989 - acc: 0.7943 - val_loss: 1.7949 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 9th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5757 - acc: 0.7854 - val_loss: 1.4458 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 9th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5333 - acc: 0.7904 - val_loss: 1.5372 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5298 - acc: 0.7936 - val_loss: 1.5707 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 9th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5178 - acc: 0.7961 - val_loss: 1.3750 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 9th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5369 - acc: 0.7906 - val_loss: 1.3635 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 9th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4848 - acc: 0.7932 - val_loss: 1.4368 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 9th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5558 - acc: 0.7877 - val_loss: 1.5335 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7938 - val_loss: 1.5140 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 9th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4980 - acc: 0.7932 - val_loss: 1.6557 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 9th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5952 - acc: 0.7777 - val_loss: 1.4631 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4419 - acc: 0.8008 - val_loss: 1.5833 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5243 - acc: 0.7955 - val_loss: 1.6331 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 9th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5685 - acc: 0.7895 - val_loss: 1.3362 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 9th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5141 - acc: 0.7959 - val_loss: 1.5451 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 9th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5342 - acc: 0.7926 - val_loss: 1.6952 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 9th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5410 - acc: 0.7920 - val_loss: 1.5342 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6289 - acc: 0.7850 - val_loss: 1.7938 - val_acc: 0.7602\n",
      "[INFO] Training model: epoch 9th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5162 - acc: 0.7955 - val_loss: 1.4933 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 9th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4767 - acc: 0.8006 - val_loss: 1.3885 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 9th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5395 - acc: 0.7914 - val_loss: 1.4890 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 9th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4564 - acc: 0.8000 - val_loss: 1.6341 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 9th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6369 - acc: 0.7779 - val_loss: 1.5945 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 9th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5656 - acc: 0.7865 - val_loss: 1.4521 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 9th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4675 - acc: 0.7984 - val_loss: 1.3847 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 9th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5047 - acc: 0.7926 - val_loss: 1.5672 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 9th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5492 - acc: 0.7898 - val_loss: 1.5961 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 9th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5915 - acc: 0.7848 - val_loss: 1.4382 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5562 - acc: 0.7896 - val_loss: 1.3485 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 9th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4315 - acc: 0.7967 - val_loss: 1.4456 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 9th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4736 - acc: 0.7969 - val_loss: 1.5070 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 9th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5331 - acc: 0.7932 - val_loss: 1.6908 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 9th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6125 - acc: 0.7820 - val_loss: 1.5470 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5712 - acc: 0.7793 - val_loss: 1.5050 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 9th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5450 - acc: 0.7912 - val_loss: 1.5938 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5187 - acc: 0.7893 - val_loss: 1.7184 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 9th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5692 - acc: 0.7885 - val_loss: 1.6062 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 9th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5387 - acc: 0.7869 - val_loss: 1.4818 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 9th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5148 - acc: 0.7963 - val_loss: 1.4000 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 9th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4305 - acc: 0.8035 - val_loss: 1.5327 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 9th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5031 - acc: 0.7951 - val_loss: 1.4783 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 9th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4964 - acc: 0.7943 - val_loss: 1.6506 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 9th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5597 - acc: 0.7887 - val_loss: 1.4817 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 9th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5563 - acc: 0.7863 - val_loss: 1.5313 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 9th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5724 - acc: 0.7883 - val_loss: 1.6419 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 9th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4502 - acc: 0.7994 - val_loss: 1.5012 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 9th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4601 - acc: 0.8021 - val_loss: 1.5925 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 9th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5752 - acc: 0.7883 - val_loss: 1.5279 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5033 - acc: 0.7990 - val_loss: 1.5798 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5042 - acc: 0.7953 - val_loss: 1.4783 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4621 - acc: 0.8010 - val_loss: 1.4849 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5322 - acc: 0.7912 - val_loss: 1.5775 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5414 - acc: 0.7885 - val_loss: 1.3555 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 9th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3678 - acc: 0.8121 - val_loss: 1.5042 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 9th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5789 - acc: 0.7838 - val_loss: 1.6287 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 9th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5565 - acc: 0.7855 - val_loss: 1.5858 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 9th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4779 - acc: 0.7984 - val_loss: 1.4559 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 9th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5910 - acc: 0.7834 - val_loss: 1.4180 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 9th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5086 - acc: 0.7961 - val_loss: 1.5239 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 9th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7953 - val_loss: 1.5274 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 9th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4709 - acc: 0.8014 - val_loss: 1.4418 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 9th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5410 - acc: 0.7895 - val_loss: 1.4797 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 9th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4720 - acc: 0.8000 - val_loss: 1.5336 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 9th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5704 - acc: 0.7877 - val_loss: 1.6239 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 9th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6189 - acc: 0.7799 - val_loss: 1.6104 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 9th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5394 - acc: 0.7930 - val_loss: 1.3506 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 9th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.4830 - acc: 0.7939 - val_loss: 1.1758 - val_acc: 0.8305\n",
      "[INFO] Training model: epoch 9th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4710 - acc: 0.7988 - val_loss: 1.5967 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 9th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5677 - acc: 0.7877 - val_loss: 1.4897 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 9th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5802 - acc: 0.7857 - val_loss: 1.3187 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 9th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5017 - acc: 0.7932 - val_loss: 1.3721 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 9th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4925 - acc: 0.7910 - val_loss: 1.5443 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 9th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5517 - acc: 0.7920 - val_loss: 1.5772 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 9th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4632 - acc: 0.7949 - val_loss: 1.4922 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 9th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5507 - acc: 0.7938 - val_loss: 1.4435 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 9th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5035 - acc: 0.7957 - val_loss: 1.5222 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 9th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6157 - acc: 0.7869 - val_loss: 1.5094 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6300 - acc: 0.7758 - val_loss: 1.6763 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 9th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5850 - acc: 0.7865 - val_loss: 1.6762 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 9th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6329 - acc: 0.7750 - val_loss: 1.4136 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 9th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4817 - acc: 0.7982 - val_loss: 1.5000 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 9th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5137 - acc: 0.7947 - val_loss: 1.4265 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5394 - acc: 0.7922 - val_loss: 1.6009 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 9th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5649 - acc: 0.7891 - val_loss: 1.5576 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 9th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5461 - acc: 0.7912 - val_loss: 1.5138 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 9th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5762 - acc: 0.7848 - val_loss: 1.5982 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4426 - acc: 0.8010 - val_loss: 1.4336 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 9th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.6017 - acc: 0.7875 - val_loss: 1.5273 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 9th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5330 - acc: 0.7926 - val_loss: 1.5968 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 9th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6052 - acc: 0.7820 - val_loss: 1.4266 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 9th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5692 - acc: 0.7873 - val_loss: 1.5982 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 9th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5101 - acc: 0.7893 - val_loss: 1.5632 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 9th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4902 - acc: 0.7920 - val_loss: 1.4913 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4508 - acc: 0.8004 - val_loss: 1.4793 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4518 - acc: 0.7988 - val_loss: 1.4983 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 9th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4932 - acc: 0.7941 - val_loss: 1.4878 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5503 - acc: 0.7873 - val_loss: 1.6195 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 9th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5033 - acc: 0.7941 - val_loss: 1.5546 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 9th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5175 - acc: 0.7977 - val_loss: 1.4103 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 9th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5555 - acc: 0.7945 - val_loss: 1.4349 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 9th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4586 - acc: 0.8012 - val_loss: 1.5530 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 9th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5045 - acc: 0.7912 - val_loss: 1.4703 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 9th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6180 - acc: 0.7834 - val_loss: 1.2971 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 9th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4621 - acc: 0.8020 - val_loss: 1.4696 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 9th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5606 - acc: 0.7865 - val_loss: 1.6443 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 9th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5484 - acc: 0.7873 - val_loss: 1.4728 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 9th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5001 - acc: 0.7947 - val_loss: 1.4845 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 9th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5599 - acc: 0.7926 - val_loss: 1.3161 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 9th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5170 - acc: 0.7900 - val_loss: 1.3413 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 9th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5029 - acc: 0.7957 - val_loss: 1.5050 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5774 - acc: 0.7861 - val_loss: 1.4259 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 9th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5748 - acc: 0.7840 - val_loss: 1.4423 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5030 - acc: 0.7900 - val_loss: 1.5926 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 9th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4776 - acc: 0.7990 - val_loss: 1.5026 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 9th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5654 - acc: 0.7889 - val_loss: 1.7252 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 9th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5115 - acc: 0.7902 - val_loss: 1.3898 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 9th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4427 - acc: 0.8049 - val_loss: 1.5821 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4533 - acc: 0.7959 - val_loss: 1.4709 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5127 - acc: 0.7945 - val_loss: 1.5110 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5532 - acc: 0.7906 - val_loss: 1.5609 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 10th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4378 - acc: 0.8023 - val_loss: 1.4988 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5383 - acc: 0.7859 - val_loss: 1.5015 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4940 - acc: 0.7982 - val_loss: 1.3279 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 10th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4600 - acc: 0.7963 - val_loss: 1.3299 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 10th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5468 - acc: 0.7873 - val_loss: 1.3548 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 10th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5316 - acc: 0.7871 - val_loss: 1.4549 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 10th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5232 - acc: 0.7855 - val_loss: 1.7134 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 10th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5421 - acc: 0.7869 - val_loss: 1.6924 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 10th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4915 - acc: 0.7943 - val_loss: 1.6712 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 10th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5829 - acc: 0.7820 - val_loss: 1.5458 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4984 - acc: 0.7938 - val_loss: 1.4369 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4918 - acc: 0.7912 - val_loss: 1.5559 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 10th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5929 - acc: 0.7840 - val_loss: 1.4100 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 10th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4953 - acc: 0.7889 - val_loss: 1.4261 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 10th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4160 - acc: 0.8020 - val_loss: 1.5433 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5033 - acc: 0.7887 - val_loss: 1.3666 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 10th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3511 - acc: 0.8074 - val_loss: 1.5527 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 10th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4608 - acc: 0.7980 - val_loss: 1.6290 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 10th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4682 - acc: 0.7967 - val_loss: 1.4577 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5221 - acc: 0.7891 - val_loss: 1.4043 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 10th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5155 - acc: 0.7910 - val_loss: 1.3814 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 10th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5518 - acc: 0.7902 - val_loss: 1.5239 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 10th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3766 - acc: 0.8094 - val_loss: 1.4812 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4250 - acc: 0.8031 - val_loss: 1.5885 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6108 - acc: 0.7797 - val_loss: 1.4442 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4715 - acc: 0.7951 - val_loss: 1.4377 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 10th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5043 - acc: 0.7961 - val_loss: 1.6117 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 10th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4840 - acc: 0.7891 - val_loss: 1.7124 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 10th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5733 - acc: 0.7824 - val_loss: 1.5963 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6116 - acc: 0.7768 - val_loss: 1.3606 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 10th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5364 - acc: 0.7885 - val_loss: 1.5921 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 10th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3955 - acc: 0.7994 - val_loss: 1.4416 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 10th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4569 - acc: 0.7988 - val_loss: 1.5701 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4830 - acc: 0.7928 - val_loss: 1.4954 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 10th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4248 - acc: 0.8010 - val_loss: 1.4797 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3744 - acc: 0.8109 - val_loss: 1.6363 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 10th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3839 - acc: 0.8061 - val_loss: 1.4220 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 10th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4830 - acc: 0.7961 - val_loss: 1.4836 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4297 - acc: 0.8016 - val_loss: 1.4133 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 10th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5613 - acc: 0.7852 - val_loss: 1.4746 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4656 - acc: 0.7912 - val_loss: 1.6475 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 10th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5182 - acc: 0.7893 - val_loss: 1.5600 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5961 - acc: 0.7842 - val_loss: 1.3950 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 10th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3954 - acc: 0.8055 - val_loss: 1.4512 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 10th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6068 - acc: 0.7850 - val_loss: 1.4817 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 10th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5044 - acc: 0.7943 - val_loss: 1.5678 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 10th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5055 - acc: 0.7939 - val_loss: 1.5218 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5709 - acc: 0.7865 - val_loss: 1.4939 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 10th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4691 - acc: 0.7934 - val_loss: 1.4097 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 10th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4656 - acc: 0.7947 - val_loss: 1.4360 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5119 - acc: 0.7932 - val_loss: 1.5440 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5091 - acc: 0.7936 - val_loss: 1.4757 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5007 - acc: 0.7941 - val_loss: 1.4588 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5138 - acc: 0.7920 - val_loss: 1.3099 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 10th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5125 - acc: 0.7926 - val_loss: 1.5940 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 10th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4915 - acc: 0.7949 - val_loss: 1.3989 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 10th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5655 - acc: 0.7893 - val_loss: 1.4198 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 10th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4872 - acc: 0.7984 - val_loss: 1.3027 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 10th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4430 - acc: 0.8033 - val_loss: 1.5007 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5252 - acc: 0.7918 - val_loss: 1.4257 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 10th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6103 - acc: 0.7822 - val_loss: 1.6124 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 10th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5011 - acc: 0.7895 - val_loss: 1.7021 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 10th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6117 - acc: 0.7812 - val_loss: 1.4365 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5007 - acc: 0.7951 - val_loss: 1.4520 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 10th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5563 - acc: 0.7889 - val_loss: 1.4512 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 10th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5488 - acc: 0.7881 - val_loss: 1.3403 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 10th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5120 - acc: 0.7918 - val_loss: 1.4462 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 10th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5389 - acc: 0.7930 - val_loss: 1.4662 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4827 - acc: 0.7947 - val_loss: 1.4843 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 10th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4569 - acc: 0.7967 - val_loss: 1.6209 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 10th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5064 - acc: 0.7938 - val_loss: 1.3403 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 10th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4454 - acc: 0.8002 - val_loss: 1.5083 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5901 - acc: 0.7803 - val_loss: 1.4090 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 10th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4939 - acc: 0.7984 - val_loss: 1.4966 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 10th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4853 - acc: 0.8016 - val_loss: 1.5194 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4904 - acc: 0.7945 - val_loss: 1.2972 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 10th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4255 - acc: 0.8076 - val_loss: 1.4250 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5229 - acc: 0.7852 - val_loss: 1.4208 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 10th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4091 - acc: 0.8035 - val_loss: 1.4417 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 10th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5847 - acc: 0.7812 - val_loss: 1.1794 - val_acc: 0.8352\n",
      "[INFO] Training model: epoch 10th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5509 - acc: 0.7932 - val_loss: 1.6306 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 10th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4864 - acc: 0.7930 - val_loss: 1.5946 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5480 - acc: 0.7885 - val_loss: 1.8316 - val_acc: 0.7500\n",
      "[INFO] Training model: epoch 10th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4886 - acc: 0.7969 - val_loss: 1.3944 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6913 - acc: 0.7672 - val_loss: 1.4525 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 10th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5801 - acc: 0.7805 - val_loss: 1.4240 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5713 - acc: 0.7895 - val_loss: 1.4409 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5372 - acc: 0.7904 - val_loss: 1.5068 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4022 - acc: 0.8057 - val_loss: 1.5421 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 10th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5676 - acc: 0.7826 - val_loss: 1.5070 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5347 - acc: 0.7879 - val_loss: 1.5350 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 10th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4350 - acc: 0.8039 - val_loss: 1.6731 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 10th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5592 - acc: 0.7895 - val_loss: 1.4269 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5682 - acc: 0.7873 - val_loss: 1.5438 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5042 - acc: 0.7916 - val_loss: 1.4837 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 10th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5266 - acc: 0.7893 - val_loss: 1.6307 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 10th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4218 - acc: 0.8031 - val_loss: 1.4986 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 10th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5293 - acc: 0.7941 - val_loss: 1.4936 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4805 - acc: 0.7979 - val_loss: 1.6034 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 10th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3960 - acc: 0.8010 - val_loss: 1.4422 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5162 - acc: 0.7914 - val_loss: 1.5680 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 10th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5295 - acc: 0.7887 - val_loss: 1.7092 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 10th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6474 - acc: 0.7791 - val_loss: 1.6730 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 10th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4887 - acc: 0.7893 - val_loss: 1.5047 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 10th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5005 - acc: 0.7967 - val_loss: 1.5034 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 10th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4374 - acc: 0.7967 - val_loss: 1.5825 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 10th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4587 - acc: 0.8039 - val_loss: 1.7926 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 10th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5512 - acc: 0.7883 - val_loss: 1.6685 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 10th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6232 - acc: 0.7805 - val_loss: 1.6572 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 10th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4651 - acc: 0.7934 - val_loss: 1.5987 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 10th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5393 - acc: 0.7902 - val_loss: 1.4174 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5020 - acc: 0.7967 - val_loss: 1.4243 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5558 - acc: 0.7873 - val_loss: 1.5676 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 10th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.5815 - acc: 0.7816 - val_loss: 1.1241 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 10th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5064 - acc: 0.7979 - val_loss: 1.5957 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 10th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4494 - acc: 0.8043 - val_loss: 1.4398 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4882 - acc: 0.7906 - val_loss: 1.4720 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4711 - acc: 0.7996 - val_loss: 1.4229 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4809 - acc: 0.7963 - val_loss: 1.6441 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 10th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5829 - acc: 0.7871 - val_loss: 1.5263 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4521 - acc: 0.8037 - val_loss: 1.4642 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 10th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5708 - acc: 0.7848 - val_loss: 1.5619 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 10th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5298 - acc: 0.7941 - val_loss: 1.4404 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5072 - acc: 0.7955 - val_loss: 1.5798 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5030 - acc: 0.7949 - val_loss: 1.5025 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5488 - acc: 0.7863 - val_loss: 1.4633 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5359 - acc: 0.7883 - val_loss: 1.3475 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 10th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5678 - acc: 0.7852 - val_loss: 1.4715 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5360 - acc: 0.7861 - val_loss: 1.4640 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4288 - acc: 0.8031 - val_loss: 1.5188 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 10th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5992 - acc: 0.7811 - val_loss: 1.4779 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 10th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4444 - acc: 0.8023 - val_loss: 1.6021 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 10th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5004 - acc: 0.7920 - val_loss: 1.4884 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 10th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4652 - acc: 0.7986 - val_loss: 1.6094 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 10th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5141 - acc: 0.7939 - val_loss: 1.3975 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 10th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5357 - acc: 0.7908 - val_loss: 1.4021 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 10th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4435 - acc: 0.7982 - val_loss: 1.5342 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4147 - acc: 0.8010 - val_loss: 1.4554 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4472 - acc: 0.7971 - val_loss: 1.6009 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4717 - acc: 0.7949 - val_loss: 1.5468 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 10th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5106 - acc: 0.7924 - val_loss: 1.4664 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4905 - acc: 0.7914 - val_loss: 1.2914 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 10th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4934 - acc: 0.7967 - val_loss: 1.5753 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5364 - acc: 0.7852 - val_loss: 1.4590 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 10th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4984 - acc: 0.7953 - val_loss: 1.3125 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 10th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5528 - acc: 0.7855 - val_loss: 1.5603 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 10th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4820 - acc: 0.7947 - val_loss: 1.4212 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4432 - acc: 0.8010 - val_loss: 1.7359 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 10th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5232 - acc: 0.7906 - val_loss: 1.5160 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4974 - acc: 0.7916 - val_loss: 1.6381 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 10th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5436 - acc: 0.7904 - val_loss: 1.8651 - val_acc: 0.7555\n",
      "[INFO] Training model: epoch 10th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4426 - acc: 0.7967 - val_loss: 1.4930 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5545 - acc: 0.7807 - val_loss: 1.6232 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 10th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4826 - acc: 0.7953 - val_loss: 1.5522 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4984 - acc: 0.7977 - val_loss: 1.5028 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4169 - acc: 0.8018 - val_loss: 1.5906 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 10th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5190 - acc: 0.7904 - val_loss: 1.8443 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 10th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4707 - acc: 0.7977 - val_loss: 1.4625 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 10th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5975 - acc: 0.7885 - val_loss: 1.5406 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 10th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4694 - acc: 0.7945 - val_loss: 1.4041 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 10th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5049 - acc: 0.7957 - val_loss: 1.4248 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 10th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4493 - acc: 0.8010 - val_loss: 1.2507 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 10th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5855 - acc: 0.7852 - val_loss: 1.5145 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 10th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4718 - acc: 0.7928 - val_loss: 1.4508 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 10th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5894 - acc: 0.7771 - val_loss: 1.6797 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 10th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4914 - acc: 0.7965 - val_loss: 1.4527 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 10th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5100 - acc: 0.7941 - val_loss: 1.5042 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5271 - acc: 0.7898 - val_loss: 1.5059 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 10th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4743 - acc: 0.7951 - val_loss: 1.4211 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 10th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4583 - acc: 0.8002 - val_loss: 1.4403 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 10th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3945 - acc: 0.8072 - val_loss: 1.5084 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 10th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4786 - acc: 0.7965 - val_loss: 1.4670 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5694 - acc: 0.7822 - val_loss: 1.3974 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 10th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5399 - acc: 0.7912 - val_loss: 1.5400 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5755 - acc: 0.7812 - val_loss: 1.6566 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 10th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5808 - acc: 0.7910 - val_loss: 1.5982 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 10th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4130 - acc: 0.8041 - val_loss: 1.4494 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5247 - acc: 0.7910 - val_loss: 1.4335 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 10th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6189 - acc: 0.7766 - val_loss: 1.4288 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 10th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5623 - acc: 0.7859 - val_loss: 1.4884 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5470 - acc: 0.7859 - val_loss: 1.6361 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 10th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4692 - acc: 0.7920 - val_loss: 1.3104 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 10th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5599 - acc: 0.7838 - val_loss: 1.6321 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 10th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4908 - acc: 0.7930 - val_loss: 1.4874 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 10th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4838 - acc: 0.7994 - val_loss: 1.3884 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 10th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5921 - acc: 0.7793 - val_loss: 1.4317 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 10th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4557 - acc: 0.8021 - val_loss: 1.4957 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5745 - acc: 0.7918 - val_loss: 1.5629 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 10th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5346 - acc: 0.7859 - val_loss: 1.3606 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 10th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4481 - acc: 0.8008 - val_loss: 1.5432 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 10th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5205 - acc: 0.7918 - val_loss: 1.5099 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4377 - acc: 0.8055 - val_loss: 1.4194 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 10th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5062 - acc: 0.7938 - val_loss: 1.3582 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 10th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5448 - acc: 0.7934 - val_loss: 1.5103 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 10th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5184 - acc: 0.7924 - val_loss: 1.6379 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 10th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5106 - acc: 0.7988 - val_loss: 1.4653 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 10th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5289 - acc: 0.7910 - val_loss: 1.5414 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 10th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5183 - acc: 0.7955 - val_loss: 1.3703 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 10th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5376 - acc: 0.7941 - val_loss: 1.6607 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 10th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5194 - acc: 0.7914 - val_loss: 1.7527 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 10th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4354 - acc: 0.8027 - val_loss: 1.3536 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 10th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5777 - acc: 0.7822 - val_loss: 1.6492 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 10th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5996 - acc: 0.7805 - val_loss: 1.4603 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 10th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4712 - acc: 0.8008 - val_loss: 1.4341 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4702 - acc: 0.7918 - val_loss: 1.2875 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 10th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4626 - acc: 0.7984 - val_loss: 1.4708 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5631 - acc: 0.7875 - val_loss: 1.5311 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 10th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4457 - acc: 0.7998 - val_loss: 1.6188 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 10th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5103 - acc: 0.7943 - val_loss: 1.3132 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 10th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4669 - acc: 0.7994 - val_loss: 1.6290 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 10th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5367 - acc: 0.7873 - val_loss: 1.5672 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5109 - acc: 0.7980 - val_loss: 1.3130 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 10th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4003 - acc: 0.8053 - val_loss: 1.6044 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 10th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5040 - acc: 0.7961 - val_loss: 1.5583 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5120 - acc: 0.7963 - val_loss: 1.4751 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 10th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4701 - acc: 0.7963 - val_loss: 1.4648 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5334 - acc: 0.7887 - val_loss: 1.2945 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 10th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5479 - acc: 0.7926 - val_loss: 1.6890 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 10th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5272 - acc: 0.7939 - val_loss: 1.3031 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 10th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5269 - acc: 0.7930 - val_loss: 1.5486 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 10th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4726 - acc: 0.8000 - val_loss: 1.5790 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 10th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5625 - acc: 0.7885 - val_loss: 1.6177 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 10th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4873 - acc: 0.8002 - val_loss: 1.5699 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 10th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4828 - acc: 0.7910 - val_loss: 1.4636 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 10th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5317 - acc: 0.7930 - val_loss: 1.5044 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6034 - acc: 0.7816 - val_loss: 1.3995 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 10th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4582 - acc: 0.7965 - val_loss: 1.5255 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 10th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5355 - acc: 0.7883 - val_loss: 1.4688 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 10th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5090 - acc: 0.7914 - val_loss: 1.5085 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 10th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4258 - acc: 0.8041 - val_loss: 1.5580 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 10th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5168 - acc: 0.7938 - val_loss: 1.5863 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 10th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3803 - acc: 0.8082 - val_loss: 1.3464 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 10th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5853 - acc: 0.7896 - val_loss: 1.4754 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4859 - acc: 0.7986 - val_loss: 1.4373 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 10th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5627 - acc: 0.7873 - val_loss: 1.3981 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 10th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5706 - acc: 0.7863 - val_loss: 1.4751 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4482 - acc: 0.8008 - val_loss: 1.4748 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 10th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4161 - acc: 0.8049 - val_loss: 1.5466 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 10th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5352 - acc: 0.7912 - val_loss: 1.6935 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 10th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5372 - acc: 0.7902 - val_loss: 1.6261 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 10th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5726 - acc: 0.7887 - val_loss: 1.6562 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 10th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4523 - acc: 0.8021 - val_loss: 1.4621 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 10th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4931 - acc: 0.7988 - val_loss: 1.6719 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 10th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5447 - acc: 0.7869 - val_loss: 1.5498 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 10th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4304 - acc: 0.8000 - val_loss: 1.4693 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 10th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4885 - acc: 0.7918 - val_loss: 1.5829 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 10th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5063 - acc: 0.7891 - val_loss: 1.6537 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 11th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4722 - acc: 0.7957 - val_loss: 1.5174 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 11th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5291 - acc: 0.7828 - val_loss: 1.4185 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5543 - acc: 0.7865 - val_loss: 1.7303 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 11th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5228 - acc: 0.7861 - val_loss: 1.2899 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 11th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5538 - acc: 0.7869 - val_loss: 1.5190 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4550 - acc: 0.7934 - val_loss: 1.5856 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4465 - acc: 0.7977 - val_loss: 1.5977 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 11th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4866 - acc: 0.7979 - val_loss: 1.3373 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4870 - acc: 0.7920 - val_loss: 1.4223 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 11th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5093 - acc: 0.7879 - val_loss: 1.4384 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 11th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4402 - acc: 0.8020 - val_loss: 1.5883 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4640 - acc: 0.7953 - val_loss: 1.5014 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4934 - acc: 0.7902 - val_loss: 1.4855 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 11th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5347 - acc: 0.7844 - val_loss: 1.3779 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 11th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5620 - acc: 0.7824 - val_loss: 1.4307 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 11th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5133 - acc: 0.7912 - val_loss: 1.5511 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5024 - acc: 0.7932 - val_loss: 1.4932 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 11th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4992 - acc: 0.8029 - val_loss: 1.2787 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 11th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5282 - acc: 0.7869 - val_loss: 1.4103 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 11th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4889 - acc: 0.7936 - val_loss: 1.4329 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4583 - acc: 0.7947 - val_loss: 1.4941 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3861 - acc: 0.7986 - val_loss: 1.6016 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 11th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4737 - acc: 0.7967 - val_loss: 1.4433 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 11th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4744 - acc: 0.7930 - val_loss: 1.4598 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4657 - acc: 0.7947 - val_loss: 1.3020 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 11th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5772 - acc: 0.7814 - val_loss: 1.4249 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 11th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3536 - acc: 0.8146 - val_loss: 1.4680 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4897 - acc: 0.7900 - val_loss: 1.6133 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5172 - acc: 0.7896 - val_loss: 1.3195 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5274 - acc: 0.7873 - val_loss: 1.5041 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 11th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5771 - acc: 0.7844 - val_loss: 1.7221 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 11th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5156 - acc: 0.7910 - val_loss: 1.5906 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 11th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5532 - acc: 0.7855 - val_loss: 1.3366 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 11th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5305 - acc: 0.7893 - val_loss: 1.5229 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4313 - acc: 0.8006 - val_loss: 1.4513 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5009 - acc: 0.7908 - val_loss: 1.4541 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 11th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4430 - acc: 0.8053 - val_loss: 1.4398 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 11th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4274 - acc: 0.8014 - val_loss: 1.5116 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4577 - acc: 0.7982 - val_loss: 1.4112 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 11th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4438 - acc: 0.7955 - val_loss: 1.3975 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 11th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4754 - acc: 0.7947 - val_loss: 1.5083 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7969 - val_loss: 1.3511 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 11th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4389 - acc: 0.7975 - val_loss: 1.5242 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 11th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4738 - acc: 0.7949 - val_loss: 1.3893 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5204 - acc: 0.7918 - val_loss: 1.4517 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 11th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4329 - acc: 0.7986 - val_loss: 1.5649 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4734 - acc: 0.7943 - val_loss: 1.5261 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3744 - acc: 0.8041 - val_loss: 1.4538 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4182 - acc: 0.8037 - val_loss: 1.5590 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7939 - val_loss: 1.3880 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4981 - acc: 0.7977 - val_loss: 1.4718 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 11th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4466 - acc: 0.7992 - val_loss: 1.5187 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3630 - acc: 0.8051 - val_loss: 1.4623 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4983 - acc: 0.7930 - val_loss: 1.4226 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 11th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4090 - acc: 0.8051 - val_loss: 1.5430 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 11th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5206 - acc: 0.7914 - val_loss: 1.6476 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 11th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4952 - acc: 0.7947 - val_loss: 1.5010 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 11th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4001 - acc: 0.8041 - val_loss: 1.4885 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 11th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4432 - acc: 0.8025 - val_loss: 1.4568 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4996 - acc: 0.7918 - val_loss: 1.4973 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4688 - acc: 0.7932 - val_loss: 1.4743 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5092 - acc: 0.7941 - val_loss: 1.3466 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 11th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5304 - acc: 0.7889 - val_loss: 1.5760 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 11th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3985 - acc: 0.8061 - val_loss: 1.3965 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 11th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5017 - acc: 0.7906 - val_loss: 1.5336 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4572 - acc: 0.7963 - val_loss: 1.4208 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3937 - acc: 0.8055 - val_loss: 1.2619 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 11th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5694 - acc: 0.7852 - val_loss: 1.3554 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 11th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4739 - acc: 0.7969 - val_loss: 1.3926 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 11th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5995 - acc: 0.7758 - val_loss: 1.4815 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 11th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5565 - acc: 0.7896 - val_loss: 1.3995 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 11th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5070 - acc: 0.7891 - val_loss: 1.5967 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 11th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4129 - acc: 0.8018 - val_loss: 1.4750 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4902 - acc: 0.7934 - val_loss: 1.5062 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4465 - acc: 0.7971 - val_loss: 1.6846 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 11th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4205 - acc: 0.8041 - val_loss: 1.6013 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5575 - acc: 0.7857 - val_loss: 1.4858 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3831 - acc: 0.8008 - val_loss: 1.4527 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 11th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5037 - acc: 0.7898 - val_loss: 1.3598 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 11th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5172 - acc: 0.7861 - val_loss: 1.5563 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 11th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6020 - acc: 0.7807 - val_loss: 1.4382 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6138 - acc: 0.7775 - val_loss: 1.6725 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 11th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4619 - acc: 0.7914 - val_loss: 1.4700 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 11th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5180 - acc: 0.7896 - val_loss: 1.5811 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 11th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4508 - acc: 0.7922 - val_loss: 1.4398 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 11th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5691 - acc: 0.7830 - val_loss: 1.5231 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5044 - acc: 0.7885 - val_loss: 1.3478 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 11th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5239 - acc: 0.7881 - val_loss: 1.4645 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 11th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5469 - acc: 0.7863 - val_loss: 1.4137 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4227 - acc: 0.7994 - val_loss: 1.5954 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4489 - acc: 0.7982 - val_loss: 1.5749 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 11th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4876 - acc: 0.7928 - val_loss: 1.5545 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 11th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4377 - acc: 0.8041 - val_loss: 1.4079 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4245 - acc: 0.8000 - val_loss: 1.4477 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 11th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5420 - acc: 0.7891 - val_loss: 1.6822 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 11th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4857 - acc: 0.7957 - val_loss: 1.4660 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4448 - acc: 0.8000 - val_loss: 1.4003 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5071 - acc: 0.7902 - val_loss: 1.4380 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6159 - acc: 0.7770 - val_loss: 1.4370 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 11th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4011 - acc: 0.8082 - val_loss: 1.5346 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5271 - acc: 0.7939 - val_loss: 1.4571 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5128 - acc: 0.7908 - val_loss: 1.5166 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 11th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4787 - acc: 0.7949 - val_loss: 1.7551 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 11th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4378 - acc: 0.8004 - val_loss: 1.4876 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4109 - acc: 0.8014 - val_loss: 1.6962 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 11th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4477 - acc: 0.7975 - val_loss: 1.4700 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 11th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5709 - acc: 0.7863 - val_loss: 1.5722 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4388 - acc: 0.8016 - val_loss: 1.2630 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 11th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4809 - acc: 0.7902 - val_loss: 1.4628 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4924 - acc: 0.7932 - val_loss: 1.4969 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4492 - acc: 0.8008 - val_loss: 1.5159 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3645 - acc: 0.8078 - val_loss: 1.4389 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 11th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5285 - acc: 0.7844 - val_loss: 1.6066 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 11th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4922 - acc: 0.7900 - val_loss: 1.4184 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 11th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4559 - acc: 0.7988 - val_loss: 1.5374 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 11th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4825 - acc: 0.7959 - val_loss: 1.4850 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5222 - acc: 0.7939 - val_loss: 1.5736 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 11th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4723 - acc: 0.7982 - val_loss: 1.6670 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 11th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5240 - acc: 0.7891 - val_loss: 1.5239 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 11th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4785 - acc: 0.7973 - val_loss: 1.5069 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 11th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4775 - acc: 0.7951 - val_loss: 1.5163 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 11th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4828 - acc: 0.7930 - val_loss: 1.6456 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5239 - acc: 0.7900 - val_loss: 1.3820 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4465 - acc: 0.8000 - val_loss: 1.5973 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5108 - acc: 0.7902 - val_loss: 1.5845 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 11th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4753 - acc: 0.8016 - val_loss: 1.5427 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 11th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4597 - acc: 0.7967 - val_loss: 1.3560 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4536 - acc: 0.8010 - val_loss: 1.4618 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4795 - acc: 0.7941 - val_loss: 1.5741 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 11th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4587 - acc: 0.7969 - val_loss: 1.6002 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 11th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4738 - acc: 0.7926 - val_loss: 1.6618 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 11th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4490 - acc: 0.7986 - val_loss: 1.5281 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 11th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4492 - acc: 0.7984 - val_loss: 1.3889 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 11th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4790 - acc: 0.7941 - val_loss: 1.4638 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4695 - acc: 0.7957 - val_loss: 1.3934 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5001 - acc: 0.7945 - val_loss: 1.6173 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 11th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5114 - acc: 0.7875 - val_loss: 1.4366 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4634 - acc: 0.7988 - val_loss: 1.5133 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4905 - acc: 0.7953 - val_loss: 1.4015 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 11th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5499 - acc: 0.7848 - val_loss: 1.5488 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5154 - acc: 0.7930 - val_loss: 1.5138 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 11th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4584 - acc: 0.7986 - val_loss: 1.7838 - val_acc: 0.7555\n",
      "[INFO] Training model: epoch 11th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5325 - acc: 0.7900 - val_loss: 1.5566 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4862 - acc: 0.7918 - val_loss: 1.4470 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 11th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4370 - acc: 0.7990 - val_loss: 1.4174 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 11th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4527 - acc: 0.8000 - val_loss: 1.5003 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4702 - acc: 0.7961 - val_loss: 1.2962 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 11th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5673 - acc: 0.7811 - val_loss: 1.5614 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 11th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4519 - acc: 0.8000 - val_loss: 1.5241 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 11th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5674 - acc: 0.7838 - val_loss: 1.5532 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 11th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5726 - acc: 0.7859 - val_loss: 1.5557 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 11th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6497 - acc: 0.7727 - val_loss: 1.4637 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 11th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5377 - acc: 0.7877 - val_loss: 1.5941 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 11th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4957 - acc: 0.7973 - val_loss: 1.7657 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 11th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5405 - acc: 0.7885 - val_loss: 1.4203 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 11th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4076 - acc: 0.8037 - val_loss: 1.6252 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 11th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5412 - acc: 0.7850 - val_loss: 1.4925 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 11th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6269 - acc: 0.7770 - val_loss: 1.6139 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4866 - acc: 0.7949 - val_loss: 1.5556 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5815 - acc: 0.7836 - val_loss: 1.4285 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 11th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4798 - acc: 0.7957 - val_loss: 1.5456 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 11th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4610 - acc: 0.7994 - val_loss: 1.6032 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4625 - acc: 0.7984 - val_loss: 1.4142 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 11th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4522 - acc: 0.7980 - val_loss: 1.3807 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5132 - acc: 0.7945 - val_loss: 1.6556 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5085 - acc: 0.7918 - val_loss: 1.5289 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 11th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4989 - acc: 0.7945 - val_loss: 1.5428 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 11th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5124 - acc: 0.7852 - val_loss: 1.5329 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5305 - acc: 0.7891 - val_loss: 1.4745 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4474 - acc: 0.7990 - val_loss: 1.4432 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 11th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5136 - acc: 0.7928 - val_loss: 1.5164 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 11th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5521 - acc: 0.7848 - val_loss: 1.2997 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 11th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5359 - acc: 0.7904 - val_loss: 1.3451 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 11th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3966 - acc: 0.8090 - val_loss: 1.4969 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 11th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3732 - acc: 0.8063 - val_loss: 1.5160 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 11th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4958 - acc: 0.7955 - val_loss: 1.7269 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 11th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4642 - acc: 0.7977 - val_loss: 1.4827 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 11th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4303 - acc: 0.8014 - val_loss: 1.5945 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3649 - acc: 0.8086 - val_loss: 1.5154 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4499 - acc: 0.8002 - val_loss: 1.5279 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5089 - acc: 0.7924 - val_loss: 1.3728 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 11th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6507 - acc: 0.7797 - val_loss: 1.1963 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 11th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4708 - acc: 0.8012 - val_loss: 1.5520 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 11th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5573 - acc: 0.7857 - val_loss: 1.3506 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 11th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5555 - acc: 0.7889 - val_loss: 1.3971 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 11th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5422 - acc: 0.7867 - val_loss: 1.4636 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5036 - acc: 0.7904 - val_loss: 1.5194 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 11th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5027 - acc: 0.7906 - val_loss: 1.5707 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 11th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5165 - acc: 0.7916 - val_loss: 1.5869 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4541 - acc: 0.8000 - val_loss: 1.3694 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 11th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5157 - acc: 0.7947 - val_loss: 1.4053 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4928 - acc: 0.7928 - val_loss: 1.5802 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 11th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4562 - acc: 0.7955 - val_loss: 1.4648 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 11th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5023 - acc: 0.7926 - val_loss: 1.4587 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4667 - acc: 0.7975 - val_loss: 1.4656 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 11th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4480 - acc: 0.8006 - val_loss: 1.5548 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5714 - acc: 0.7855 - val_loss: 1.3857 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 11th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5354 - acc: 0.7912 - val_loss: 1.7151 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 11th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5201 - acc: 0.7885 - val_loss: 1.4025 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5162 - acc: 0.7918 - val_loss: 1.6001 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 11th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5585 - acc: 0.7865 - val_loss: 1.5230 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 11th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4786 - acc: 0.7973 - val_loss: 1.4316 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 11th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4870 - acc: 0.8010 - val_loss: 1.4834 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4903 - acc: 0.7926 - val_loss: 1.4462 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4723 - acc: 0.7975 - val_loss: 1.4308 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 11th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4421 - acc: 0.8039 - val_loss: 1.4281 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4974 - acc: 0.7934 - val_loss: 1.5561 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4943 - acc: 0.7932 - val_loss: 1.5799 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 11th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5295 - acc: 0.7906 - val_loss: 1.5854 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 11th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6033 - acc: 0.7854 - val_loss: 1.3666 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 11th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4567 - acc: 0.7982 - val_loss: 1.5130 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 11th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5811 - acc: 0.7877 - val_loss: 1.4522 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 11th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5218 - acc: 0.7881 - val_loss: 1.4547 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 11th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5832 - acc: 0.7830 - val_loss: 1.5861 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 11th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5150 - acc: 0.7902 - val_loss: 1.4538 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 11th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5415 - acc: 0.7910 - val_loss: 1.5132 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4867 - acc: 0.7969 - val_loss: 1.3677 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 11th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5158 - acc: 0.7918 - val_loss: 1.4406 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4027 - acc: 0.8070 - val_loss: 1.6514 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 11th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4847 - acc: 0.7969 - val_loss: 1.4840 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 11th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4899 - acc: 0.7979 - val_loss: 1.4924 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 11th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4498 - acc: 0.7979 - val_loss: 1.4034 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 11th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4686 - acc: 0.7977 - val_loss: 1.3909 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 11th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4985 - acc: 0.7932 - val_loss: 1.5666 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 11th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4356 - acc: 0.8074 - val_loss: 1.4434 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 11th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4544 - acc: 0.8018 - val_loss: 1.4424 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5262 - acc: 0.7918 - val_loss: 1.3476 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4775 - acc: 0.7961 - val_loss: 1.4528 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4631 - acc: 0.7967 - val_loss: 1.5839 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 11th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6066 - acc: 0.7824 - val_loss: 1.5622 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 11th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5026 - acc: 0.7961 - val_loss: 1.5925 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 11th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5430 - acc: 0.7893 - val_loss: 1.2024 - val_acc: 0.8344\n",
      "[INFO] Training model: epoch 11th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4307 - acc: 0.8029 - val_loss: 1.6505 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 11th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5617 - acc: 0.7887 - val_loss: 1.5126 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 11th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6075 - acc: 0.7814 - val_loss: 1.4004 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 11th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5902 - acc: 0.7873 - val_loss: 1.5201 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 11th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4745 - acc: 0.7924 - val_loss: 1.5476 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 11th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4808 - acc: 0.7973 - val_loss: 1.5554 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 11th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5442 - acc: 0.7881 - val_loss: 1.3712 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 11th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5026 - acc: 0.7941 - val_loss: 1.4059 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 11th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5753 - acc: 0.7883 - val_loss: 1.5080 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 11th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7895 - val_loss: 1.4243 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 11th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3571 - acc: 0.8094 - val_loss: 1.3601 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6282 - acc: 0.7812 - val_loss: 1.4064 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4275 - acc: 0.8008 - val_loss: 1.4060 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 11th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4635 - acc: 0.8008 - val_loss: 1.3731 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 11th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5410 - acc: 0.7859 - val_loss: 1.3863 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 11th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5566 - acc: 0.7834 - val_loss: 1.5624 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 11th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3958 - acc: 0.8066 - val_loss: 1.3671 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 11th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6355 - acc: 0.7721 - val_loss: 1.3830 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 12th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4840 - acc: 0.7928 - val_loss: 1.6694 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 12th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4729 - acc: 0.7951 - val_loss: 1.4364 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 12th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4489 - acc: 0.7967 - val_loss: 1.4218 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 12th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4178 - acc: 0.8004 - val_loss: 1.5685 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 12th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4086 - acc: 0.8016 - val_loss: 1.2448 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 12th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4293 - acc: 0.8002 - val_loss: 1.3581 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 12th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4718 - acc: 0.7953 - val_loss: 1.6451 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 12th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3998 - acc: 0.8021 - val_loss: 1.6390 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 12th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4856 - acc: 0.7908 - val_loss: 1.5635 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4410 - acc: 0.7939 - val_loss: 1.3585 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5611 - acc: 0.7863 - val_loss: 1.3038 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 12th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3652 - acc: 0.8070 - val_loss: 1.5210 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5345 - acc: 0.7869 - val_loss: 1.4212 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3940 - acc: 0.8027 - val_loss: 1.4333 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 12th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4190 - acc: 0.7984 - val_loss: 1.5056 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4577 - acc: 0.7955 - val_loss: 1.5287 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4792 - acc: 0.7910 - val_loss: 1.6011 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 12th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3466 - acc: 0.8078 - val_loss: 1.3480 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 12th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4949 - acc: 0.7906 - val_loss: 1.6571 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 12th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4756 - acc: 0.7953 - val_loss: 1.6166 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 12th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4422 - acc: 0.8010 - val_loss: 1.5065 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 12th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4796 - acc: 0.7953 - val_loss: 1.5080 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 12th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4151 - acc: 0.8008 - val_loss: 1.6072 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 12th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4907 - acc: 0.7916 - val_loss: 1.5856 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 12th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7906 - val_loss: 1.3647 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 12th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4546 - acc: 0.7926 - val_loss: 1.4167 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4960 - acc: 0.7916 - val_loss: 1.3438 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 12th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7902 - val_loss: 1.4558 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5304 - acc: 0.7828 - val_loss: 1.4772 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 12th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3736 - acc: 0.8061 - val_loss: 1.5716 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 12th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4581 - acc: 0.7955 - val_loss: 1.3856 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4418 - acc: 0.7996 - val_loss: 1.7248 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 12th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4844 - acc: 0.7924 - val_loss: 1.3907 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 12th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4422 - acc: 0.7994 - val_loss: 1.4265 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 12th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3655 - acc: 0.8100 - val_loss: 1.6356 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 12th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4542 - acc: 0.8000 - val_loss: 1.4040 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4962 - acc: 0.7945 - val_loss: 1.4053 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3987 - acc: 0.8035 - val_loss: 1.5508 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3829 - acc: 0.8055 - val_loss: 1.3928 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 12th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4607 - acc: 0.7943 - val_loss: 1.2375 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 12th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4074 - acc: 0.8021 - val_loss: 1.3395 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 12th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5021 - acc: 0.7969 - val_loss: 1.6368 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 12th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5696 - acc: 0.7822 - val_loss: 1.4341 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 12th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3780 - acc: 0.8074 - val_loss: 1.4492 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 12th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4841 - acc: 0.7902 - val_loss: 1.5798 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 12th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4055 - acc: 0.7996 - val_loss: 1.3342 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 12th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4566 - acc: 0.7934 - val_loss: 1.4358 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 12th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4442 - acc: 0.7953 - val_loss: 1.4339 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 12th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4829 - acc: 0.7967 - val_loss: 1.4627 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 12th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4751 - acc: 0.7928 - val_loss: 1.5335 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 12th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3374 - acc: 0.8063 - val_loss: 1.6604 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 12th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5677 - acc: 0.7842 - val_loss: 1.4710 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 12th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4841 - acc: 0.7924 - val_loss: 1.4633 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 12th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5061 - acc: 0.7910 - val_loss: 1.4479 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 12th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5321 - acc: 0.7869 - val_loss: 1.4380 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 12th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4958 - acc: 0.7934 - val_loss: 1.3648 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 12th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5020 - acc: 0.7889 - val_loss: 1.5293 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 12th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4373 - acc: 0.8000 - val_loss: 1.3973 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4550 - acc: 0.7941 - val_loss: 1.3022 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4925 - acc: 0.7883 - val_loss: 1.2793 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 12th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4491 - acc: 0.7947 - val_loss: 1.3858 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 12th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5064 - acc: 0.7936 - val_loss: 1.3717 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4452 - acc: 0.7990 - val_loss: 1.6497 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 12th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5242 - acc: 0.7910 - val_loss: 1.4181 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4129 - acc: 0.8037 - val_loss: 1.3923 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 12th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4679 - acc: 0.8010 - val_loss: 1.4072 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 12th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5170 - acc: 0.7881 - val_loss: 1.4887 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4606 - acc: 0.7932 - val_loss: 1.5994 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 12th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5154 - acc: 0.7951 - val_loss: 1.4517 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4251 - acc: 0.8020 - val_loss: 1.4169 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3792 - acc: 0.8053 - val_loss: 1.4634 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 12th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6092 - acc: 0.7822 - val_loss: 1.5627 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5254 - acc: 0.7877 - val_loss: 1.4466 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5779 - acc: 0.7805 - val_loss: 1.5081 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 12th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5023 - acc: 0.7934 - val_loss: 1.4628 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 12th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3703 - acc: 0.8086 - val_loss: 1.7289 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 12th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4372 - acc: 0.7955 - val_loss: 1.4186 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 12th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4007 - acc: 0.8051 - val_loss: 1.6818 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 12th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5305 - acc: 0.7924 - val_loss: 1.2865 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 12th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4365 - acc: 0.8014 - val_loss: 1.4205 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 12th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5086 - acc: 0.7914 - val_loss: 1.4700 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 12th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4821 - acc: 0.7955 - val_loss: 1.4288 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3838 - acc: 0.8090 - val_loss: 1.5573 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 12th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5593 - acc: 0.7828 - val_loss: 1.7509 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 12th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3826 - acc: 0.7996 - val_loss: 1.4773 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3925 - acc: 0.8061 - val_loss: 1.3580 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 12th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5526 - acc: 0.7873 - val_loss: 1.3648 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 12th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4801 - acc: 0.7947 - val_loss: 1.4977 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5167 - acc: 0.7902 - val_loss: 1.5224 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 12th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5324 - acc: 0.7848 - val_loss: 1.5148 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 12th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4913 - acc: 0.7924 - val_loss: 1.5774 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 12th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4088 - acc: 0.8045 - val_loss: 1.5843 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4424 - acc: 0.7986 - val_loss: 1.5146 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 12th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4828 - acc: 0.7975 - val_loss: 1.4441 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 12th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5419 - acc: 0.7885 - val_loss: 1.5124 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 12th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5459 - acc: 0.7879 - val_loss: 1.6931 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 12th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4980 - acc: 0.7895 - val_loss: 1.5195 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 12th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4045 - acc: 0.7990 - val_loss: 1.4073 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4138 - acc: 0.8033 - val_loss: 1.3851 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 12th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4703 - acc: 0.7980 - val_loss: 1.4645 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 12th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4625 - acc: 0.7924 - val_loss: 1.4640 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4922 - acc: 0.7904 - val_loss: 1.5421 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7996 - val_loss: 1.4497 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5087 - acc: 0.7924 - val_loss: 1.5823 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 12th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4737 - acc: 0.7920 - val_loss: 1.5051 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 12th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4490 - acc: 0.7979 - val_loss: 1.2996 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 12th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4213 - acc: 0.8014 - val_loss: 1.4780 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5423 - acc: 0.7885 - val_loss: 1.5179 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 12th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4748 - acc: 0.7902 - val_loss: 1.4995 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 12th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4509 - acc: 0.8006 - val_loss: 1.3827 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 12th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4995 - acc: 0.7916 - val_loss: 1.3789 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 12th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4911 - acc: 0.7889 - val_loss: 1.4110 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 12th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4530 - acc: 0.8008 - val_loss: 1.4246 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4497 - acc: 0.8014 - val_loss: 1.5222 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 12th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4877 - acc: 0.7932 - val_loss: 1.5156 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3912 - acc: 0.8053 - val_loss: 1.5628 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 12th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4986 - acc: 0.7906 - val_loss: 1.4856 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4029 - acc: 0.7996 - val_loss: 1.4581 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4709 - acc: 0.7947 - val_loss: 1.4538 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 12th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5401 - acc: 0.7834 - val_loss: 1.3103 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 12th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7934 - val_loss: 1.5191 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 12th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4640 - acc: 0.7914 - val_loss: 1.5282 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 12th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4742 - acc: 0.7914 - val_loss: 1.4980 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4441 - acc: 0.7990 - val_loss: 1.6491 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 12th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3760 - acc: 0.8066 - val_loss: 1.5326 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 12th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4905 - acc: 0.7986 - val_loss: 1.3576 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4082 - acc: 0.8000 - val_loss: 1.7032 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 12th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.7967 - val_loss: 1.3371 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 12th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5186 - acc: 0.7869 - val_loss: 1.6279 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 12th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4511 - acc: 0.7945 - val_loss: 1.6858 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 12th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4841 - acc: 0.7951 - val_loss: 1.5593 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 12th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5222 - acc: 0.7900 - val_loss: 1.3099 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 12th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5820 - acc: 0.7803 - val_loss: 1.5449 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5289 - acc: 0.7875 - val_loss: 1.6256 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 12th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5737 - acc: 0.7771 - val_loss: 1.3774 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 12th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4437 - acc: 0.7971 - val_loss: 1.4526 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 12th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5623 - acc: 0.7873 - val_loss: 1.4715 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5530 - acc: 0.7832 - val_loss: 1.3292 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 12th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4469 - acc: 0.7992 - val_loss: 1.4219 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 12th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5228 - acc: 0.7861 - val_loss: 1.4364 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4770 - acc: 0.7953 - val_loss: 1.5977 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5295 - acc: 0.7904 - val_loss: 1.5541 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 12th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4489 - acc: 0.7998 - val_loss: 1.5553 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 12th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4885 - acc: 0.7953 - val_loss: 1.6097 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 12th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4719 - acc: 0.7936 - val_loss: 1.3744 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 12th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4846 - acc: 0.7898 - val_loss: 1.5895 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 12th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5092 - acc: 0.7893 - val_loss: 1.5925 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 12th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3940 - acc: 0.8061 - val_loss: 1.4918 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4165 - acc: 0.7977 - val_loss: 1.4176 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 12th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4696 - acc: 0.7920 - val_loss: 1.6740 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 12th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4688 - acc: 0.7955 - val_loss: 1.4188 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5919 - acc: 0.7822 - val_loss: 1.5180 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 12th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4351 - acc: 0.7969 - val_loss: 1.6086 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 12th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5239 - acc: 0.7932 - val_loss: 1.5661 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5927 - acc: 0.7838 - val_loss: 1.5312 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 12th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5475 - acc: 0.7887 - val_loss: 1.5311 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 12th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5085 - acc: 0.7957 - val_loss: 1.3522 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 12th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5036 - acc: 0.7932 - val_loss: 1.4589 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 12th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4983 - acc: 0.7926 - val_loss: 1.3602 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 12th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4917 - acc: 0.7951 - val_loss: 1.6288 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 12th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4635 - acc: 0.7945 - val_loss: 1.4895 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4752 - acc: 0.8012 - val_loss: 1.5117 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 12th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4732 - acc: 0.7977 - val_loss: 1.6728 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 12th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4109 - acc: 0.8023 - val_loss: 1.3321 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 12th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5050 - acc: 0.7920 - val_loss: 1.5225 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4836 - acc: 0.7949 - val_loss: 1.4709 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 12th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4884 - acc: 0.7934 - val_loss: 1.3671 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 12th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4584 - acc: 0.7967 - val_loss: 1.7429 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 12th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4799 - acc: 0.7949 - val_loss: 1.3843 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 12th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4548 - acc: 0.8021 - val_loss: 1.6064 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 12th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4342 - acc: 0.8021 - val_loss: 1.3978 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 12th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4967 - acc: 0.7938 - val_loss: 1.4576 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4988 - acc: 0.7934 - val_loss: 1.3854 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5161 - acc: 0.7938 - val_loss: 1.4295 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4206 - acc: 0.8025 - val_loss: 1.5414 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 12th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4722 - acc: 0.7947 - val_loss: 1.2389 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 12th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5537 - acc: 0.7838 - val_loss: 1.4685 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4501 - acc: 0.8031 - val_loss: 1.4091 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5696 - acc: 0.7830 - val_loss: 1.4205 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5550 - acc: 0.7832 - val_loss: 1.3888 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4686 - acc: 0.7957 - val_loss: 1.2724 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 12th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4562 - acc: 0.7992 - val_loss: 1.3888 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 12th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5544 - acc: 0.7852 - val_loss: 1.4488 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 12th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4783 - acc: 0.7955 - val_loss: 1.5737 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 12th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5297 - acc: 0.7920 - val_loss: 1.4481 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5212 - acc: 0.7947 - val_loss: 1.3771 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 12th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5186 - acc: 0.7895 - val_loss: 1.2192 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 12th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5456 - acc: 0.7863 - val_loss: 1.4671 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 12th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4004 - acc: 0.8006 - val_loss: 1.5303 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 12th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5004 - acc: 0.7924 - val_loss: 1.4799 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 12th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4706 - acc: 0.7928 - val_loss: 1.4333 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 12th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5189 - acc: 0.7945 - val_loss: 1.6490 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 12th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4126 - acc: 0.8004 - val_loss: 1.5086 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 12th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5140 - acc: 0.7920 - val_loss: 1.4711 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5017 - acc: 0.7961 - val_loss: 1.5162 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 12th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4511 - acc: 0.7984 - val_loss: 1.4557 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 12th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4895 - acc: 0.7918 - val_loss: 1.4186 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5924 - acc: 0.7809 - val_loss: 1.4651 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 12th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4021 - acc: 0.8070 - val_loss: 1.3066 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 12th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5375 - acc: 0.7922 - val_loss: 1.4216 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5954 - acc: 0.7848 - val_loss: 1.3857 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 12th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3808 - acc: 0.8051 - val_loss: 1.5002 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4924 - acc: 0.7953 - val_loss: 1.4699 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 12th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5257 - acc: 0.7875 - val_loss: 1.3025 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 12th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4831 - acc: 0.7951 - val_loss: 1.4961 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 12th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4299 - acc: 0.7988 - val_loss: 1.3387 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 12th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4434 - acc: 0.8029 - val_loss: 1.5101 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5656 - acc: 0.7873 - val_loss: 1.4363 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 12th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4339 - acc: 0.8010 - val_loss: 1.6567 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 12th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4813 - acc: 0.7977 - val_loss: 1.4208 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 12th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4955 - acc: 0.7926 - val_loss: 1.5075 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5435 - acc: 0.7908 - val_loss: 1.4253 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 12th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5302 - acc: 0.7912 - val_loss: 1.3553 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 12th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4229 - acc: 0.8016 - val_loss: 1.4788 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 12th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4378 - acc: 0.7994 - val_loss: 1.6039 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 12th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5155 - acc: 0.7855 - val_loss: 1.5428 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 12th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4844 - acc: 0.7938 - val_loss: 1.5393 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5436 - acc: 0.7910 - val_loss: 1.3569 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 12th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5735 - acc: 0.7832 - val_loss: 1.1627 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 12th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4758 - acc: 0.7992 - val_loss: 1.6141 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 12th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5405 - acc: 0.7938 - val_loss: 1.6302 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 12th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5668 - acc: 0.7844 - val_loss: 1.4705 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 12th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4776 - acc: 0.7941 - val_loss: 1.4078 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 12th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4743 - acc: 0.7992 - val_loss: 1.5746 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 12th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5803 - acc: 0.7846 - val_loss: 1.4830 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 12th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4918 - acc: 0.7973 - val_loss: 1.4637 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6363 - acc: 0.7756 - val_loss: 1.5124 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 12th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5277 - acc: 0.7873 - val_loss: 1.4545 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 12th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5166 - acc: 0.7916 - val_loss: 1.5673 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 12th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5663 - acc: 0.7883 - val_loss: 1.3576 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4015 - acc: 0.8041 - val_loss: 1.4187 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 12th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4747 - acc: 0.7977 - val_loss: 1.5289 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 12th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4793 - acc: 0.7994 - val_loss: 1.6597 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 12th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5093 - acc: 0.7902 - val_loss: 1.4203 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3708 - acc: 0.8055 - val_loss: 1.4362 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 12th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5515 - acc: 0.7818 - val_loss: 1.3682 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 12th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4481 - acc: 0.7992 - val_loss: 1.4844 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 12th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4570 - acc: 0.7957 - val_loss: 1.4758 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 12th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4202 - acc: 0.7951 - val_loss: 1.5967 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 12th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4271 - acc: 0.8014 - val_loss: 1.6128 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 12th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4764 - acc: 0.8021 - val_loss: 1.4314 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 12th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4943 - acc: 0.7932 - val_loss: 1.4621 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 12th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4729 - acc: 0.8008 - val_loss: 1.5454 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 12th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5188 - acc: 0.7879 - val_loss: 1.3647 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 12th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5982 - acc: 0.7812 - val_loss: 1.3478 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 12th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5678 - acc: 0.7908 - val_loss: 1.4326 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 12th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5064 - acc: 0.7893 - val_loss: 1.3631 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 12th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4560 - acc: 0.7986 - val_loss: 1.4250 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 12th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4628 - acc: 0.7992 - val_loss: 1.5422 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 12th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4217 - acc: 0.8012 - val_loss: 1.4881 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 13th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5170 - acc: 0.7914 - val_loss: 1.3432 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 13th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5049 - acc: 0.7924 - val_loss: 1.5274 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 13th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4084 - acc: 0.7998 - val_loss: 1.4560 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4876 - acc: 0.7932 - val_loss: 1.4269 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4729 - acc: 0.7922 - val_loss: 1.2976 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 13th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4625 - acc: 0.7986 - val_loss: 1.5091 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 13th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3976 - acc: 0.8033 - val_loss: 1.3373 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 13th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4413 - acc: 0.7971 - val_loss: 1.5637 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 13th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5075 - acc: 0.7859 - val_loss: 1.2609 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 13th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4574 - acc: 0.7977 - val_loss: 1.5877 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 13th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4044 - acc: 0.7971 - val_loss: 1.2497 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 13th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5429 - acc: 0.7848 - val_loss: 1.4996 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 13th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3738 - acc: 0.8084 - val_loss: 1.4518 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3734 - acc: 0.8057 - val_loss: 1.4554 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4806 - acc: 0.7932 - val_loss: 1.5607 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 13th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3985 - acc: 0.8057 - val_loss: 1.4002 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 13th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4742 - acc: 0.7955 - val_loss: 1.5786 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 13th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5304 - acc: 0.7865 - val_loss: 1.4550 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 13th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5059 - acc: 0.7865 - val_loss: 1.4816 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 13th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5314 - acc: 0.7811 - val_loss: 1.3166 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4264 - acc: 0.7982 - val_loss: 1.4312 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 13th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5285 - acc: 0.7850 - val_loss: 1.4643 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 13th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3801 - acc: 0.8018 - val_loss: 1.5426 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5279 - acc: 0.7840 - val_loss: 1.4335 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 13th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4405 - acc: 0.7924 - val_loss: 1.4082 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 13th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3660 - acc: 0.8068 - val_loss: 1.5285 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 13th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5164 - acc: 0.7865 - val_loss: 1.3948 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 13th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3810 - acc: 0.8055 - val_loss: 1.5029 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4305 - acc: 0.7979 - val_loss: 1.4564 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4396 - acc: 0.7986 - val_loss: 1.4185 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 13th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4404 - acc: 0.7957 - val_loss: 1.3410 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 13th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4721 - acc: 0.7977 - val_loss: 1.3035 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 13th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5285 - acc: 0.7865 - val_loss: 1.3974 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 13th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4999 - acc: 0.7877 - val_loss: 1.6470 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 13th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4014 - acc: 0.8064 - val_loss: 1.6378 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4783 - acc: 0.7936 - val_loss: 1.2498 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 13th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3831 - acc: 0.8039 - val_loss: 1.4015 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 13th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4355 - acc: 0.8027 - val_loss: 1.5257 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 13th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5083 - acc: 0.7885 - val_loss: 1.6053 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 13th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3951 - acc: 0.8037 - val_loss: 1.3612 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 13th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4523 - acc: 0.7945 - val_loss: 1.4651 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 13th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4121 - acc: 0.8002 - val_loss: 1.4471 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5043 - acc: 0.7908 - val_loss: 1.6573 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 13th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4353 - acc: 0.7975 - val_loss: 1.3833 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 13th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5352 - acc: 0.7844 - val_loss: 1.3150 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 13th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4161 - acc: 0.8008 - val_loss: 1.3432 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 13th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3828 - acc: 0.8053 - val_loss: 1.4604 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3952 - acc: 0.8076 - val_loss: 1.3771 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 13th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4680 - acc: 0.7959 - val_loss: 1.5409 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 13th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3627 - acc: 0.8051 - val_loss: 1.4036 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 13th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5546 - acc: 0.7844 - val_loss: 1.3274 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 13th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4001 - acc: 0.7975 - val_loss: 1.4988 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 13th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4168 - acc: 0.8037 - val_loss: 1.6349 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 13th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5138 - acc: 0.7893 - val_loss: 1.4338 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 13th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4905 - acc: 0.7934 - val_loss: 1.2844 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 13th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5046 - acc: 0.7959 - val_loss: 1.6440 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 13th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4395 - acc: 0.8039 - val_loss: 1.4435 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4311 - acc: 0.8039 - val_loss: 1.3038 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 13th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4380 - acc: 0.7990 - val_loss: 1.4628 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 13th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4343 - acc: 0.8000 - val_loss: 1.3584 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 13th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4443 - acc: 0.7979 - val_loss: 1.3166 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 13th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4736 - acc: 0.7953 - val_loss: 1.4210 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4801 - acc: 0.7984 - val_loss: 1.2837 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 13th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5746 - acc: 0.7857 - val_loss: 1.4303 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4912 - acc: 0.7947 - val_loss: 1.4606 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 13th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4617 - acc: 0.7994 - val_loss: 1.4937 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 13th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4223 - acc: 0.8027 - val_loss: 1.5855 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 13th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3978 - acc: 0.8055 - val_loss: 1.3835 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 13th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4564 - acc: 0.7945 - val_loss: 1.4120 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5381 - acc: 0.7857 - val_loss: 1.4636 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5471 - acc: 0.7861 - val_loss: 1.6218 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 13th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4475 - acc: 0.8004 - val_loss: 1.4292 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 13th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3790 - acc: 0.8053 - val_loss: 1.5025 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 13th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5409 - acc: 0.7854 - val_loss: 1.5760 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 13th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5145 - acc: 0.7879 - val_loss: 1.6116 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 13th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4317 - acc: 0.7994 - val_loss: 1.4373 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4813 - acc: 0.7928 - val_loss: 1.5605 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 13th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3961 - acc: 0.8027 - val_loss: 1.4798 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5357 - acc: 0.7887 - val_loss: 1.3883 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 13th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3921 - acc: 0.8008 - val_loss: 1.4410 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 13th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3553 - acc: 0.8068 - val_loss: 1.2806 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 13th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3880 - acc: 0.8051 - val_loss: 1.4823 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4433 - acc: 0.7977 - val_loss: 1.5165 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4114 - acc: 0.8010 - val_loss: 1.5286 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 13th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4975 - acc: 0.7959 - val_loss: 1.4064 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 13th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4218 - acc: 0.8012 - val_loss: 1.4561 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 13th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5336 - acc: 0.7891 - val_loss: 1.5992 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 13th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5006 - acc: 0.7881 - val_loss: 1.6196 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 13th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4456 - acc: 0.7969 - val_loss: 1.1938 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 13th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4679 - acc: 0.7951 - val_loss: 1.3588 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 13th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4336 - acc: 0.8033 - val_loss: 1.5786 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 13th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5331 - acc: 0.7861 - val_loss: 1.6168 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 13th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5476 - acc: 0.7881 - val_loss: 1.7314 - val_acc: 0.7563\n",
      "[INFO] Training model: epoch 13th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3954 - acc: 0.8057 - val_loss: 1.3663 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 13th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3820 - acc: 0.8029 - val_loss: 1.3475 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 13th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4344 - acc: 0.7971 - val_loss: 1.4383 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 13th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5202 - acc: 0.7930 - val_loss: 1.4600 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 13th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4305 - acc: 0.7965 - val_loss: 1.3843 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 13th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4176 - acc: 0.7943 - val_loss: 1.4804 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4512 - acc: 0.8000 - val_loss: 1.4039 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 13th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4481 - acc: 0.7967 - val_loss: 1.5220 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 13th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5038 - acc: 0.7928 - val_loss: 1.5151 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4937 - acc: 0.7877 - val_loss: 1.4664 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 13th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5210 - acc: 0.7881 - val_loss: 1.4532 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4281 - acc: 0.7947 - val_loss: 1.3837 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4165 - acc: 0.8004 - val_loss: 1.4542 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3374 - acc: 0.8094 - val_loss: 1.5243 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 13th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4479 - acc: 0.7953 - val_loss: 1.4561 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 13th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4940 - acc: 0.7906 - val_loss: 1.4760 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 13th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4210 - acc: 0.8018 - val_loss: 1.6710 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 13th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4544 - acc: 0.7986 - val_loss: 1.4656 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5011 - acc: 0.7957 - val_loss: 1.4266 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4677 - acc: 0.7938 - val_loss: 1.4882 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4431 - acc: 0.7943 - val_loss: 1.4859 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 13th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5027 - acc: 0.7877 - val_loss: 1.6080 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4602 - acc: 0.7916 - val_loss: 1.4347 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5160 - acc: 0.7926 - val_loss: 1.3814 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 13th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4851 - acc: 0.7908 - val_loss: 1.3867 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 13th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5234 - acc: 0.7883 - val_loss: 1.4767 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4601 - acc: 0.7963 - val_loss: 1.2988 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 13th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4475 - acc: 0.7988 - val_loss: 1.4696 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5563 - acc: 0.7883 - val_loss: 1.5806 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 13th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4161 - acc: 0.7992 - val_loss: 1.6943 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 13th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5179 - acc: 0.7902 - val_loss: 1.3535 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5873 - acc: 0.7805 - val_loss: 1.5708 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 13th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4467 - acc: 0.7986 - val_loss: 1.5055 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 13th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4308 - acc: 0.7977 - val_loss: 1.6566 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 13th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5583 - acc: 0.7865 - val_loss: 1.5154 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 13th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5287 - acc: 0.7889 - val_loss: 1.5140 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4753 - acc: 0.7945 - val_loss: 1.4858 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5051 - acc: 0.7896 - val_loss: 1.5112 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4815 - acc: 0.7939 - val_loss: 1.5145 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 13th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3894 - acc: 0.8041 - val_loss: 1.4445 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4311 - acc: 0.7986 - val_loss: 1.3429 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4469 - acc: 0.7936 - val_loss: 1.4374 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 13th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4551 - acc: 0.8002 - val_loss: 1.6228 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 13th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4075 - acc: 0.7998 - val_loss: 1.6749 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 13th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4003 - acc: 0.8035 - val_loss: 1.4631 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 13th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4070 - acc: 0.8006 - val_loss: 1.6759 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 13th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4766 - acc: 0.7930 - val_loss: 1.3495 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 13th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4748 - acc: 0.7941 - val_loss: 1.4723 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 13th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4061 - acc: 0.7961 - val_loss: 1.3893 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 13th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4047 - acc: 0.8031 - val_loss: 1.3632 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 13th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5090 - acc: 0.7932 - val_loss: 1.5406 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4048 - acc: 0.8066 - val_loss: 1.4408 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4404 - acc: 0.7938 - val_loss: 1.4284 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4606 - acc: 0.7945 - val_loss: 1.4395 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 13th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3868 - acc: 0.8068 - val_loss: 1.5616 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 13th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4551 - acc: 0.7959 - val_loss: 1.3536 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 13th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4496 - acc: 0.8002 - val_loss: 1.5019 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4907 - acc: 0.7936 - val_loss: 1.4140 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4224 - acc: 0.8053 - val_loss: 1.4850 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 13th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7992 - val_loss: 1.5727 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4590 - acc: 0.7988 - val_loss: 1.4708 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 13th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4360 - acc: 0.8020 - val_loss: 1.3255 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 13th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4426 - acc: 0.7979 - val_loss: 1.4576 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 13th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5437 - acc: 0.7902 - val_loss: 1.5092 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 13th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5351 - acc: 0.7934 - val_loss: 1.2373 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 13th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4585 - acc: 0.7961 - val_loss: 1.2205 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 13th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4477 - acc: 0.7977 - val_loss: 1.4714 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 13th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5356 - acc: 0.7871 - val_loss: 1.4555 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5440 - acc: 0.7883 - val_loss: 1.4903 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 13th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5032 - acc: 0.7930 - val_loss: 1.5554 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 13th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4642 - acc: 0.7965 - val_loss: 1.4779 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5674 - acc: 0.7873 - val_loss: 1.5378 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 13th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5257 - acc: 0.7836 - val_loss: 1.5961 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5326 - acc: 0.7896 - val_loss: 1.5862 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4797 - acc: 0.7891 - val_loss: 1.5181 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 13th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4474 - acc: 0.7939 - val_loss: 1.3684 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 13th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4203 - acc: 0.7969 - val_loss: 1.5302 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4990 - acc: 0.7934 - val_loss: 1.3958 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 13th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4231 - acc: 0.8021 - val_loss: 1.4901 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 13th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4470 - acc: 0.7955 - val_loss: 1.4381 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 13th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5151 - acc: 0.7859 - val_loss: 1.3229 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 13th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4949 - acc: 0.7916 - val_loss: 1.6493 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 13th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5039 - acc: 0.7900 - val_loss: 1.4677 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 13th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4457 - acc: 0.7953 - val_loss: 1.5458 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 13th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5764 - acc: 0.7867 - val_loss: 1.4497 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 13th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5192 - acc: 0.7844 - val_loss: 1.6441 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 13th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4789 - acc: 0.7920 - val_loss: 1.3802 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 13th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4096 - acc: 0.8016 - val_loss: 1.3928 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 13th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3970 - acc: 0.8057 - val_loss: 1.5505 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 13th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4027 - acc: 0.8049 - val_loss: 1.5092 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 13th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5538 - acc: 0.7855 - val_loss: 1.4098 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 13th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4822 - acc: 0.7955 - val_loss: 1.5673 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4174 - acc: 0.7922 - val_loss: 1.4472 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 13th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4943 - acc: 0.7932 - val_loss: 1.5684 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 13th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4892 - acc: 0.7939 - val_loss: 1.2842 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 13th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5148 - acc: 0.7891 - val_loss: 1.4700 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 13th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4312 - acc: 0.7992 - val_loss: 1.5492 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 13th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4753 - acc: 0.7939 - val_loss: 1.4358 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 13th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4621 - acc: 0.7959 - val_loss: 1.4782 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5283 - acc: 0.7857 - val_loss: 1.5052 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 13th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5412 - acc: 0.7877 - val_loss: 1.1979 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 13th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5756 - acc: 0.7832 - val_loss: 1.4944 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 13th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4129 - acc: 0.8002 - val_loss: 1.4863 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 13th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7965 - val_loss: 1.4235 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 13th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4761 - acc: 0.7926 - val_loss: 1.4824 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4537 - acc: 0.7986 - val_loss: 1.4361 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 13th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4881 - acc: 0.7943 - val_loss: 1.4008 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 13th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4294 - acc: 0.8051 - val_loss: 1.6531 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 13th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4568 - acc: 0.8002 - val_loss: 1.6014 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 13th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4734 - acc: 0.7986 - val_loss: 1.4027 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 13th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4341 - acc: 0.8010 - val_loss: 1.6326 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 13th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4133 - acc: 0.8063 - val_loss: 1.7010 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 13th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5566 - acc: 0.7852 - val_loss: 1.4733 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4460 - acc: 0.8004 - val_loss: 1.4131 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 13th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4638 - acc: 0.7953 - val_loss: 1.4749 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 13th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4381 - acc: 0.7947 - val_loss: 1.2650 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 13th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4438 - acc: 0.7977 - val_loss: 1.5374 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 13th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5555 - acc: 0.7895 - val_loss: 1.3980 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 13th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4327 - acc: 0.7982 - val_loss: 1.6922 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 13th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4862 - acc: 0.7957 - val_loss: 1.5911 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 13th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4530 - acc: 0.8004 - val_loss: 1.5790 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4858 - acc: 0.7951 - val_loss: 1.2967 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 13th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5599 - acc: 0.7900 - val_loss: 1.3278 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 13th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4623 - acc: 0.7994 - val_loss: 1.2865 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 13th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4859 - acc: 0.7939 - val_loss: 1.5164 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 13th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4721 - acc: 0.7949 - val_loss: 1.5398 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 13th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5023 - acc: 0.7908 - val_loss: 1.4187 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 13th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5203 - acc: 0.7906 - val_loss: 1.2580 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 13th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4586 - acc: 0.7973 - val_loss: 1.3333 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 13th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4840 - acc: 0.7980 - val_loss: 1.5539 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5963 - acc: 0.7801 - val_loss: 1.6646 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 13th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4459 - acc: 0.7977 - val_loss: 1.5948 - val_acc: 0.7625\n",
      "[INFO] Training model: epoch 13th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5630 - acc: 0.7869 - val_loss: 1.2187 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 13th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5281 - acc: 0.7893 - val_loss: 1.3927 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 13th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5422 - acc: 0.7822 - val_loss: 1.5535 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 13th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4372 - acc: 0.7998 - val_loss: 1.5824 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 13th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4690 - acc: 0.7996 - val_loss: 1.5118 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 13th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4905 - acc: 0.7920 - val_loss: 1.3284 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 13th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4745 - acc: 0.7957 - val_loss: 1.3460 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4384 - acc: 0.7996 - val_loss: 1.3682 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 13th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3982 - acc: 0.8039 - val_loss: 1.5975 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 13th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4835 - acc: 0.7916 - val_loss: 1.3490 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 13th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4749 - acc: 0.7951 - val_loss: 1.4196 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 13th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4036 - acc: 0.7977 - val_loss: 1.5121 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 13th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4835 - acc: 0.7922 - val_loss: 1.4107 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 13th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4647 - acc: 0.8000 - val_loss: 1.4410 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 13th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4480 - acc: 0.7949 - val_loss: 1.5412 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 13th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4514 - acc: 0.7955 - val_loss: 1.5808 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 13th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4144 - acc: 0.8084 - val_loss: 1.6978 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 13th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4823 - acc: 0.7912 - val_loss: 1.5501 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 13th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4592 - acc: 0.7945 - val_loss: 1.3184 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 13th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4142 - acc: 0.8021 - val_loss: 1.4623 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 13th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4347 - acc: 0.7963 - val_loss: 1.4253 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 13th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4914 - acc: 0.7936 - val_loss: 1.4403 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 13th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4886 - acc: 0.7893 - val_loss: 1.5607 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 13th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5533 - acc: 0.7865 - val_loss: 1.5853 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 13th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5153 - acc: 0.7934 - val_loss: 1.4230 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 14th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4576 - acc: 0.7910 - val_loss: 1.4387 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 14th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5081 - acc: 0.7867 - val_loss: 1.4422 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 14th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4178 - acc: 0.7992 - val_loss: 1.3568 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 14th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5171 - acc: 0.7889 - val_loss: 1.5268 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 14th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3936 - acc: 0.8066 - val_loss: 1.3282 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5098 - acc: 0.7850 - val_loss: 1.5921 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 14th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.5279 - acc: 0.7807 - val_loss: 1.4159 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 14th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4970 - acc: 0.7906 - val_loss: 1.5729 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 14th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3975 - acc: 0.8031 - val_loss: 1.6114 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 14th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4231 - acc: 0.7986 - val_loss: 1.6670 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 14th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4124 - acc: 0.7980 - val_loss: 1.5171 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 14th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4585 - acc: 0.7928 - val_loss: 1.3845 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.8045 - val_loss: 1.3928 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 14th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4178 - acc: 0.7975 - val_loss: 1.5198 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 14th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3747 - acc: 0.8018 - val_loss: 1.6687 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 14th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4009 - acc: 0.8004 - val_loss: 1.4489 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3987 - acc: 0.8010 - val_loss: 1.4961 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 14th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3978 - acc: 0.8014 - val_loss: 1.3957 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 14th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3893 - acc: 0.8035 - val_loss: 1.6423 - val_acc: 0.7648\n",
      "[INFO] Training model: epoch 14th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4775 - acc: 0.7951 - val_loss: 1.3328 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 14th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5210 - acc: 0.7896 - val_loss: 1.2560 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 14th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4924 - acc: 0.7871 - val_loss: 1.2966 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 14th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3955 - acc: 0.8006 - val_loss: 1.4730 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 14th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4237 - acc: 0.7996 - val_loss: 1.5976 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 14th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4210 - acc: 0.7977 - val_loss: 1.4421 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 14th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4375 - acc: 0.7957 - val_loss: 1.5015 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 14th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3771 - acc: 0.8016 - val_loss: 1.3954 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3404 - acc: 0.8098 - val_loss: 1.6045 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4503 - acc: 0.7934 - val_loss: 1.4981 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 14th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4014 - acc: 0.7953 - val_loss: 1.5605 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 14th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4715 - acc: 0.7941 - val_loss: 1.4958 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3233 - acc: 0.8109 - val_loss: 1.3920 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 14th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4133 - acc: 0.7998 - val_loss: 1.3403 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 14th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3596 - acc: 0.8070 - val_loss: 1.5601 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 14th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4566 - acc: 0.7908 - val_loss: 1.4727 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 14th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4986 - acc: 0.7914 - val_loss: 1.6344 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 14th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3738 - acc: 0.8084 - val_loss: 1.3432 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 14th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4592 - acc: 0.7939 - val_loss: 1.5018 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5044 - acc: 0.7934 - val_loss: 1.6324 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 14th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5335 - acc: 0.7859 - val_loss: 1.4279 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5189 - acc: 0.7859 - val_loss: 1.5215 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5207 - acc: 0.7906 - val_loss: 1.3756 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 14th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4635 - acc: 0.7963 - val_loss: 1.4398 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 14th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5576 - acc: 0.7822 - val_loss: 1.4080 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 14th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4106 - acc: 0.8016 - val_loss: 1.4998 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4395 - acc: 0.7955 - val_loss: 1.5051 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4144 - acc: 0.7996 - val_loss: 1.1887 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 14th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3565 - acc: 0.8086 - val_loss: 1.3074 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 14th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4549 - acc: 0.7926 - val_loss: 1.4861 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5061 - acc: 0.7889 - val_loss: 1.3360 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 14th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3848 - acc: 0.8037 - val_loss: 1.3617 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 14th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4924 - acc: 0.7934 - val_loss: 1.5223 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3441 - acc: 0.8070 - val_loss: 1.2815 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 14th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4374 - acc: 0.7945 - val_loss: 1.6729 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 14th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3929 - acc: 0.8047 - val_loss: 1.4657 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 14th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.7957 - val_loss: 1.3736 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 14th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4586 - acc: 0.7938 - val_loss: 1.5863 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3870 - acc: 0.8084 - val_loss: 1.6508 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 14th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3392 - acc: 0.8061 - val_loss: 1.4503 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 14th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4249 - acc: 0.7992 - val_loss: 1.3700 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 14th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5696 - acc: 0.7855 - val_loss: 1.3434 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4728 - acc: 0.7904 - val_loss: 1.1263 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 14th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4494 - acc: 0.7949 - val_loss: 1.6121 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 14th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4960 - acc: 0.7930 - val_loss: 1.4996 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 14th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5660 - acc: 0.7811 - val_loss: 1.4225 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 14th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5165 - acc: 0.7855 - val_loss: 1.4596 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4595 - acc: 0.7939 - val_loss: 1.2625 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 14th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5002 - acc: 0.7924 - val_loss: 1.5289 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4365 - acc: 0.7949 - val_loss: 1.6336 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 14th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5257 - acc: 0.7809 - val_loss: 1.5588 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 14th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5102 - acc: 0.7859 - val_loss: 1.5659 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 14th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4784 - acc: 0.7961 - val_loss: 1.3520 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 14th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4546 - acc: 0.7947 - val_loss: 1.2923 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 14th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5719 - acc: 0.7789 - val_loss: 1.6154 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 14th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4702 - acc: 0.7959 - val_loss: 1.3565 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 14th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4215 - acc: 0.7998 - val_loss: 1.5814 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 14th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4517 - acc: 0.7977 - val_loss: 1.3764 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 14th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4249 - acc: 0.7980 - val_loss: 1.4006 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 14th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4073 - acc: 0.8025 - val_loss: 1.6382 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 14th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4254 - acc: 0.7979 - val_loss: 1.2971 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 14th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4456 - acc: 0.8031 - val_loss: 1.4247 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 14th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4679 - acc: 0.7941 - val_loss: 1.5135 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 14th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4729 - acc: 0.7953 - val_loss: 1.3254 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 14th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7930 - val_loss: 1.2696 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 14th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3512 - acc: 0.8072 - val_loss: 1.3666 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 14th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5100 - acc: 0.7883 - val_loss: 1.4245 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 14th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4397 - acc: 0.7949 - val_loss: 1.3167 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 14th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3796 - acc: 0.8031 - val_loss: 1.5851 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 14th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4756 - acc: 0.7957 - val_loss: 1.4801 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 14th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4027 - acc: 0.8016 - val_loss: 1.3975 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 14th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4901 - acc: 0.7916 - val_loss: 1.4992 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7986 - val_loss: 1.6078 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 14th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3872 - acc: 0.8031 - val_loss: 1.3082 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 14th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4641 - acc: 0.7930 - val_loss: 1.4683 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 14th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4519 - acc: 0.7977 - val_loss: 1.4361 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 14th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5214 - acc: 0.7887 - val_loss: 1.3853 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 14th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7957 - val_loss: 1.4878 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4282 - acc: 0.8010 - val_loss: 1.4258 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4266 - acc: 0.7967 - val_loss: 1.5633 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 14th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4470 - acc: 0.7994 - val_loss: 1.4396 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 14th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4573 - acc: 0.7924 - val_loss: 1.5310 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4722 - acc: 0.7975 - val_loss: 1.4227 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 14th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3970 - acc: 0.8039 - val_loss: 1.3952 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 14th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4569 - acc: 0.7938 - val_loss: 1.5463 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4529 - acc: 0.7936 - val_loss: 1.3013 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 14th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4047 - acc: 0.8025 - val_loss: 1.4665 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4631 - acc: 0.7941 - val_loss: 1.5949 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 14th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5427 - acc: 0.7854 - val_loss: 1.2847 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 14th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3581 - acc: 0.8066 - val_loss: 1.5414 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 14th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4463 - acc: 0.7977 - val_loss: 1.4606 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 14th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4976 - acc: 0.7859 - val_loss: 1.4161 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 14th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4384 - acc: 0.8000 - val_loss: 1.4894 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 14th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4859 - acc: 0.7912 - val_loss: 1.4972 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 14th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5222 - acc: 0.7891 - val_loss: 1.3453 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4732 - acc: 0.7947 - val_loss: 1.5444 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 14th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4842 - acc: 0.7920 - val_loss: 1.4534 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4807 - acc: 0.7912 - val_loss: 1.3601 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 14th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3924 - acc: 0.8027 - val_loss: 1.2239 - val_acc: 0.8383\n",
      "[INFO] Training model: epoch 14th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3692 - acc: 0.8086 - val_loss: 1.4747 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 14th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4177 - acc: 0.8033 - val_loss: 1.3381 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4476 - acc: 0.7939 - val_loss: 1.4813 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 14th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4397 - acc: 0.8000 - val_loss: 1.3846 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4567 - acc: 0.7975 - val_loss: 1.4820 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4573 - acc: 0.7975 - val_loss: 1.4362 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4584 - acc: 0.7961 - val_loss: 1.4871 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5109 - acc: 0.7852 - val_loss: 1.6328 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 14th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4231 - acc: 0.7982 - val_loss: 1.4524 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 14th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5118 - acc: 0.7873 - val_loss: 1.3124 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 14th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4927 - acc: 0.7879 - val_loss: 1.5290 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 14th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5059 - acc: 0.7877 - val_loss: 1.5400 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 14th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5086 - acc: 0.7867 - val_loss: 1.5536 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 14th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4408 - acc: 0.7979 - val_loss: 1.3220 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 14th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5022 - acc: 0.7928 - val_loss: 1.3867 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 14th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.3795 - acc: 0.8035 - val_loss: 1.0834 - val_acc: 0.8367\n",
      "[INFO] Training model: epoch 14th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4127 - acc: 0.8051 - val_loss: 1.4352 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4759 - acc: 0.7930 - val_loss: 1.4739 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 14th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5236 - acc: 0.7918 - val_loss: 1.3846 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 14th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5817 - acc: 0.7787 - val_loss: 1.5915 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 14th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4363 - acc: 0.8039 - val_loss: 1.4740 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 14th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4688 - acc: 0.7947 - val_loss: 1.5946 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 14th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3747 - acc: 0.8039 - val_loss: 1.3783 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 14th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4520 - acc: 0.8021 - val_loss: 1.4788 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 14th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5057 - acc: 0.7922 - val_loss: 1.4360 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4709 - acc: 0.7926 - val_loss: 1.4024 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 14th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4504 - acc: 0.7951 - val_loss: 1.4517 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 14th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5183 - acc: 0.7906 - val_loss: 1.6163 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 14th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5222 - acc: 0.7867 - val_loss: 1.3980 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 14th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3958 - acc: 0.8123 - val_loss: 1.4134 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 14th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4423 - acc: 0.7977 - val_loss: 1.4110 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 14th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4659 - acc: 0.7934 - val_loss: 1.4077 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 14th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5176 - acc: 0.7932 - val_loss: 1.5466 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 14th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4856 - acc: 0.7963 - val_loss: 1.4563 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4471 - acc: 0.7984 - val_loss: 1.3442 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 14th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5086 - acc: 0.7895 - val_loss: 1.3528 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 14th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3980 - acc: 0.8029 - val_loss: 1.4925 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5066 - acc: 0.7914 - val_loss: 1.4278 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4054 - acc: 0.8053 - val_loss: 1.4181 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 14th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4309 - acc: 0.7996 - val_loss: 1.4505 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4696 - acc: 0.7930 - val_loss: 1.4058 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 14th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4877 - acc: 0.7949 - val_loss: 1.4455 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 14th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4958 - acc: 0.7924 - val_loss: 1.6174 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 14th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4959 - acc: 0.7936 - val_loss: 1.3451 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 14th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5143 - acc: 0.7885 - val_loss: 1.2708 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 14th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7914 - val_loss: 1.7585 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 14th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3915 - acc: 0.8066 - val_loss: 1.4741 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 14th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4925 - acc: 0.7930 - val_loss: 1.3783 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 14th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4397 - acc: 0.7975 - val_loss: 1.5354 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 14th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4719 - acc: 0.7951 - val_loss: 1.6234 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 14th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5422 - acc: 0.7859 - val_loss: 1.5346 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 14th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4209 - acc: 0.8004 - val_loss: 1.4879 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4577 - acc: 0.7945 - val_loss: 1.3728 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 14th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4216 - acc: 0.7988 - val_loss: 1.4253 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 14th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4367 - acc: 0.8018 - val_loss: 1.6093 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 14th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4813 - acc: 0.7957 - val_loss: 1.4952 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 14th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5432 - acc: 0.7840 - val_loss: 1.4425 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3981 - acc: 0.8031 - val_loss: 1.4318 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3853 - acc: 0.8020 - val_loss: 1.5772 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 14th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4690 - acc: 0.7951 - val_loss: 1.5467 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 14th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2739 - acc: 0.8133 - val_loss: 1.4425 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 14th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3647 - acc: 0.8037 - val_loss: 1.3514 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 14th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4162 - acc: 0.8020 - val_loss: 1.4030 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 14th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4641 - acc: 0.7945 - val_loss: 1.6036 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 14th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4836 - acc: 0.7924 - val_loss: 1.5094 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4849 - acc: 0.7955 - val_loss: 1.3386 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 14th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4960 - acc: 0.7898 - val_loss: 1.4439 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 14th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4195 - acc: 0.8029 - val_loss: 1.6203 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 14th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4947 - acc: 0.7920 - val_loss: 1.6094 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 14th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4210 - acc: 0.8006 - val_loss: 1.7025 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 14th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4377 - acc: 0.7994 - val_loss: 1.3905 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 14th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4465 - acc: 0.7988 - val_loss: 1.5121 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 14th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4967 - acc: 0.7932 - val_loss: 1.3615 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4006 - acc: 0.8057 - val_loss: 1.5400 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 14th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3755 - acc: 0.8043 - val_loss: 1.5060 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 14th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5052 - acc: 0.7959 - val_loss: 1.5262 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 14th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4763 - acc: 0.7982 - val_loss: 1.5275 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4441 - acc: 0.7959 - val_loss: 1.4910 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 14th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3596 - acc: 0.8086 - val_loss: 1.4193 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 14th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4030 - acc: 0.7996 - val_loss: 1.5302 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 14th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4356 - acc: 0.8016 - val_loss: 1.5377 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 14th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4555 - acc: 0.7936 - val_loss: 1.2130 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 14th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4726 - acc: 0.7891 - val_loss: 1.4866 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3659 - acc: 0.8078 - val_loss: 1.3555 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 14th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4873 - acc: 0.7969 - val_loss: 1.5172 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 14th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4276 - acc: 0.7963 - val_loss: 1.4497 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5275 - acc: 0.7867 - val_loss: 1.3894 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 14th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4359 - acc: 0.7982 - val_loss: 1.4404 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3899 - acc: 0.8057 - val_loss: 1.3098 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 14th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4242 - acc: 0.7963 - val_loss: 1.4049 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 14th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5084 - acc: 0.7908 - val_loss: 1.6239 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 14th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4951 - acc: 0.7967 - val_loss: 1.4654 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 14th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5631 - acc: 0.7834 - val_loss: 1.4316 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 14th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5949 - acc: 0.7820 - val_loss: 1.3440 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 14th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7949 - val_loss: 1.4437 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4156 - acc: 0.8039 - val_loss: 1.5259 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 14th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4062 - acc: 0.8029 - val_loss: 1.5970 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 14th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5129 - acc: 0.7914 - val_loss: 1.6114 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 14th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4138 - acc: 0.7971 - val_loss: 1.3224 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 14th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3935 - acc: 0.8063 - val_loss: 1.5110 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 14th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3552 - acc: 0.8084 - val_loss: 1.6310 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 14th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4987 - acc: 0.7947 - val_loss: 1.4729 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 14th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5008 - acc: 0.7932 - val_loss: 1.5002 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 14th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.8074 - val_loss: 1.6070 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 14th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3890 - acc: 0.8066 - val_loss: 1.5744 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 14th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5013 - acc: 0.7896 - val_loss: 1.4298 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 14th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3899 - acc: 0.8043 - val_loss: 1.4380 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 14th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4145 - acc: 0.8010 - val_loss: 1.4036 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 14th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4759 - acc: 0.7934 - val_loss: 1.4612 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 14th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5044 - acc: 0.7879 - val_loss: 1.5502 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 14th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4933 - acc: 0.7926 - val_loss: 1.6247 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 14th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5032 - acc: 0.7906 - val_loss: 1.3640 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 14th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4048 - acc: 0.8045 - val_loss: 1.6764 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 14th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4056 - acc: 0.8027 - val_loss: 1.5719 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 14th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3775 - acc: 0.8068 - val_loss: 1.2473 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 14th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4450 - acc: 0.7926 - val_loss: 1.4239 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 14th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5131 - acc: 0.7834 - val_loss: 1.5180 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 14th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4329 - acc: 0.8012 - val_loss: 1.4052 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 14th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3751 - acc: 0.8076 - val_loss: 1.3702 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 14th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4060 - acc: 0.8029 - val_loss: 1.5360 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 14th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5581 - acc: 0.7846 - val_loss: 1.6494 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 14th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4480 - acc: 0.7967 - val_loss: 1.5540 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 14th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4733 - acc: 0.7930 - val_loss: 1.3937 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 14th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4112 - acc: 0.8027 - val_loss: 1.5563 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 14th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5053 - acc: 0.7877 - val_loss: 1.2641 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 14th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.8002 - val_loss: 1.5945 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 14th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4528 - acc: 0.7984 - val_loss: 1.5049 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 14th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4948 - acc: 0.7938 - val_loss: 1.4968 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 14th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4430 - acc: 0.7961 - val_loss: 1.5161 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 14th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3617 - acc: 0.8063 - val_loss: 1.3928 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 14th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4599 - acc: 0.7980 - val_loss: 1.3214 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 14th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5168 - acc: 0.7941 - val_loss: 1.3618 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 15th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3844 - acc: 0.7988 - val_loss: 1.4242 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 15th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4237 - acc: 0.7965 - val_loss: 1.3070 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 15th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3768 - acc: 0.8029 - val_loss: 1.4243 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 15th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4064 - acc: 0.7980 - val_loss: 1.5829 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 15th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4212 - acc: 0.7975 - val_loss: 1.3410 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4457 - acc: 0.7957 - val_loss: 1.3429 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 15th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4809 - acc: 0.7922 - val_loss: 1.4044 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4868 - acc: 0.7873 - val_loss: 1.5245 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3293 - acc: 0.8105 - val_loss: 1.2653 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 15th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3624 - acc: 0.8057 - val_loss: 1.4312 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4979 - acc: 0.7904 - val_loss: 1.5022 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4828 - acc: 0.7928 - val_loss: 1.2517 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 15th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3725 - acc: 0.8061 - val_loss: 1.3589 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 15th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4961 - acc: 0.7857 - val_loss: 1.4751 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 15th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5335 - acc: 0.7873 - val_loss: 1.7030 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 15th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4274 - acc: 0.7988 - val_loss: 1.4014 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3989 - acc: 0.8025 - val_loss: 1.5002 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 15th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4976 - acc: 0.7850 - val_loss: 1.1731 - val_acc: 0.8383\n",
      "[INFO] Training model: epoch 15th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4754 - acc: 0.7957 - val_loss: 1.4446 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 15th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4451 - acc: 0.7959 - val_loss: 1.3538 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 15th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4424 - acc: 0.7889 - val_loss: 1.4182 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 15th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4744 - acc: 0.7914 - val_loss: 1.6205 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 15th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3828 - acc: 0.8004 - val_loss: 1.3162 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 15th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4245 - acc: 0.8000 - val_loss: 1.6262 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 15th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4997 - acc: 0.7865 - val_loss: 1.3474 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 15th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3236 - acc: 0.8109 - val_loss: 1.3505 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 15th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4457 - acc: 0.7926 - val_loss: 1.3636 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3729 - acc: 0.8000 - val_loss: 1.2937 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 15th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4632 - acc: 0.7906 - val_loss: 1.5485 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 15th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4283 - acc: 0.7936 - val_loss: 1.5597 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 15th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4162 - acc: 0.7922 - val_loss: 1.5373 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3821 - acc: 0.8010 - val_loss: 1.4042 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 15th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3664 - acc: 0.8063 - val_loss: 1.4690 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 15th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3603 - acc: 0.8057 - val_loss: 1.4545 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3627 - acc: 0.8047 - val_loss: 1.3549 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 15th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4828 - acc: 0.7900 - val_loss: 1.3972 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3075 - acc: 0.8131 - val_loss: 1.5314 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 15th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4460 - acc: 0.7969 - val_loss: 1.4064 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 15th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5382 - acc: 0.7857 - val_loss: 1.5328 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4245 - acc: 0.8033 - val_loss: 1.3458 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4023 - acc: 0.7967 - val_loss: 1.5423 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 15th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3806 - acc: 0.8020 - val_loss: 1.3626 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 15th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3887 - acc: 0.7980 - val_loss: 1.1804 - val_acc: 0.8281\n",
      "[INFO] Training model: epoch 15th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4271 - acc: 0.7982 - val_loss: 1.3967 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4937 - acc: 0.7875 - val_loss: 1.5796 - val_acc: 0.7633\n",
      "[INFO] Training model: epoch 15th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4204 - acc: 0.7961 - val_loss: 1.4710 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 15th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4280 - acc: 0.7990 - val_loss: 1.2498 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 15th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4142 - acc: 0.7994 - val_loss: 1.5500 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 15th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4977 - acc: 0.7918 - val_loss: 1.5079 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 15th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5360 - acc: 0.7840 - val_loss: 1.5964 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 15th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3997 - acc: 0.8025 - val_loss: 1.5247 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 15th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4085 - acc: 0.8029 - val_loss: 1.3971 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 15th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.8063 - val_loss: 1.3743 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 15th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3682 - acc: 0.8012 - val_loss: 1.3477 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 15th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4967 - acc: 0.7898 - val_loss: 1.4493 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3711 - acc: 0.8076 - val_loss: 1.2909 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 15th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3739 - acc: 0.8033 - val_loss: 1.4931 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 15th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5220 - acc: 0.7932 - val_loss: 1.4934 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 15th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4583 - acc: 0.7918 - val_loss: 1.6479 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 15th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3953 - acc: 0.8010 - val_loss: 1.4223 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 15th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5149 - acc: 0.7859 - val_loss: 1.5133 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 15th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3928 - acc: 0.7986 - val_loss: 1.4346 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3606 - acc: 0.8074 - val_loss: 1.5360 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 15th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5459 - acc: 0.7844 - val_loss: 1.5727 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 15th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4592 - acc: 0.7887 - val_loss: 1.3559 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 15th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4075 - acc: 0.8010 - val_loss: 1.5612 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 15th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4286 - acc: 0.7969 - val_loss: 1.3461 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 15th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4117 - acc: 0.8000 - val_loss: 1.2542 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 15th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3479 - acc: 0.8066 - val_loss: 1.2958 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 15th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4989 - acc: 0.7887 - val_loss: 1.4795 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5230 - acc: 0.7863 - val_loss: 1.5479 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 15th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4630 - acc: 0.7961 - val_loss: 1.5092 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3923 - acc: 0.8043 - val_loss: 1.4970 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4398 - acc: 0.7992 - val_loss: 1.3384 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 15th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3913 - acc: 0.8055 - val_loss: 1.4167 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4448 - acc: 0.7953 - val_loss: 1.2525 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 15th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4424 - acc: 0.7957 - val_loss: 1.3601 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 15th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4652 - acc: 0.7918 - val_loss: 1.2266 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 15th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4037 - acc: 0.7990 - val_loss: 1.4820 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 15th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4915 - acc: 0.7943 - val_loss: 1.4672 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4194 - acc: 0.7998 - val_loss: 1.4300 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 15th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4297 - acc: 0.7986 - val_loss: 1.3785 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4238 - acc: 0.8023 - val_loss: 1.4955 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 15th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4176 - acc: 0.7969 - val_loss: 1.4651 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 15th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4722 - acc: 0.7955 - val_loss: 1.5139 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5054 - acc: 0.7879 - val_loss: 1.9254 - val_acc: 0.7344\n",
      "[INFO] Training model: epoch 15th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4831 - acc: 0.7955 - val_loss: 1.5362 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4240 - acc: 0.8000 - val_loss: 1.2546 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 15th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4399 - acc: 0.7928 - val_loss: 1.3455 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 15th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5015 - acc: 0.7895 - val_loss: 1.4094 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 15th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4048 - acc: 0.7996 - val_loss: 1.4639 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 15th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4492 - acc: 0.7939 - val_loss: 1.4018 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 15th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4192 - acc: 0.8006 - val_loss: 1.5381 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 15th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3773 - acc: 0.8057 - val_loss: 1.3024 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 15th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4423 - acc: 0.7947 - val_loss: 1.4860 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4661 - acc: 0.7896 - val_loss: 1.3652 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 15th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4467 - acc: 0.7934 - val_loss: 1.4760 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 15th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4459 - acc: 0.7941 - val_loss: 1.2885 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 15th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4589 - acc: 0.7938 - val_loss: 1.4388 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 15th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4191 - acc: 0.8045 - val_loss: 1.4810 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 15th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4455 - acc: 0.7977 - val_loss: 1.4306 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 15th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4120 - acc: 0.7977 - val_loss: 1.2876 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 15th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3571 - acc: 0.8043 - val_loss: 1.4153 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5099 - acc: 0.7932 - val_loss: 1.5634 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 15th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4687 - acc: 0.7943 - val_loss: 1.4311 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 15th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5001 - acc: 0.7865 - val_loss: 1.4266 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 15th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3978 - acc: 0.8012 - val_loss: 1.2848 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 15th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4359 - acc: 0.8010 - val_loss: 1.5052 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 15th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4573 - acc: 0.7945 - val_loss: 1.2922 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 15th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4606 - acc: 0.7938 - val_loss: 1.4661 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4242 - acc: 0.8000 - val_loss: 1.4165 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3904 - acc: 0.8039 - val_loss: 1.4425 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4634 - acc: 0.7939 - val_loss: 1.6141 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 15th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4724 - acc: 0.7941 - val_loss: 1.5020 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4141 - acc: 0.8002 - val_loss: 1.5453 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 15th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5100 - acc: 0.7918 - val_loss: 1.4423 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 15th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3110 - acc: 0.8125 - val_loss: 1.5576 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 15th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5183 - acc: 0.7914 - val_loss: 1.5845 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 15th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4917 - acc: 0.7900 - val_loss: 1.4185 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 15th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4147 - acc: 0.7979 - val_loss: 1.3181 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4306 - acc: 0.7957 - val_loss: 1.3111 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 15th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4485 - acc: 0.7922 - val_loss: 1.4938 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 15th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4367 - acc: 0.7996 - val_loss: 1.3902 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 15th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5320 - acc: 0.7900 - val_loss: 1.4349 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3649 - acc: 0.8045 - val_loss: 1.3770 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 15th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4295 - acc: 0.8006 - val_loss: 1.3564 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3863 - acc: 0.8039 - val_loss: 1.6023 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 15th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4009 - acc: 0.8027 - val_loss: 1.4801 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4509 - acc: 0.7973 - val_loss: 1.2820 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4173 - acc: 0.8020 - val_loss: 1.4127 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 15th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7939 - val_loss: 1.4826 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5431 - acc: 0.7859 - val_loss: 1.4068 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 15th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4423 - acc: 0.7967 - val_loss: 1.3217 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 15th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5225 - acc: 0.7873 - val_loss: 1.4406 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 15th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5271 - acc: 0.7896 - val_loss: 1.6617 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 15th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.7969 - val_loss: 1.6475 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 15th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4586 - acc: 0.7975 - val_loss: 1.5459 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3830 - acc: 0.8027 - val_loss: 1.2658 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 15th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4140 - acc: 0.7982 - val_loss: 1.4477 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 15th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4598 - acc: 0.7965 - val_loss: 1.3523 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 15th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4046 - acc: 0.8064 - val_loss: 1.3688 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 15th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4543 - acc: 0.7945 - val_loss: 1.3641 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 15th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4829 - acc: 0.7928 - val_loss: 1.3678 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 15th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4497 - acc: 0.7928 - val_loss: 1.5807 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 15th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4672 - acc: 0.7926 - val_loss: 1.4716 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 15th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4567 - acc: 0.7934 - val_loss: 1.4830 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 15th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4184 - acc: 0.8004 - val_loss: 1.4723 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 15th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4826 - acc: 0.7975 - val_loss: 1.6151 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 15th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3710 - acc: 0.8021 - val_loss: 1.2524 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 15th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5048 - acc: 0.7910 - val_loss: 1.3003 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5657 - acc: 0.7834 - val_loss: 1.2287 - val_acc: 0.8281\n",
      "[INFO] Training model: epoch 15th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5110 - acc: 0.7908 - val_loss: 1.2722 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4246 - acc: 0.7955 - val_loss: 1.4865 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3833 - acc: 0.8084 - val_loss: 1.3848 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3957 - acc: 0.8039 - val_loss: 1.2826 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 15th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5164 - acc: 0.7857 - val_loss: 1.5313 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 15th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4534 - acc: 0.7934 - val_loss: 1.5125 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 15th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3617 - acc: 0.8066 - val_loss: 1.3965 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 15th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5309 - acc: 0.7881 - val_loss: 1.4237 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 15th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4853 - acc: 0.7932 - val_loss: 1.5519 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 15th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4029 - acc: 0.8010 - val_loss: 1.4562 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 15th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4175 - acc: 0.7988 - val_loss: 1.4230 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4033 - acc: 0.8008 - val_loss: 1.5140 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 15th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3746 - acc: 0.8039 - val_loss: 1.4757 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 15th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3764 - acc: 0.8082 - val_loss: 1.2276 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 15th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4200 - acc: 0.8012 - val_loss: 1.4753 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3836 - acc: 0.8057 - val_loss: 1.4062 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 15th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4880 - acc: 0.7908 - val_loss: 1.3010 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 15th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4697 - acc: 0.7908 - val_loss: 1.2856 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 15th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5014 - acc: 0.7857 - val_loss: 1.4895 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 15th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3940 - acc: 0.8023 - val_loss: 1.4304 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3798 - acc: 0.8039 - val_loss: 1.3979 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 15th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4325 - acc: 0.7971 - val_loss: 1.3474 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 15th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4132 - acc: 0.8047 - val_loss: 1.3481 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 15th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5218 - acc: 0.7936 - val_loss: 1.5090 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4794 - acc: 0.7986 - val_loss: 1.4001 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 15th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4221 - acc: 0.8025 - val_loss: 1.3320 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 15th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4692 - acc: 0.7900 - val_loss: 1.3480 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 15th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3243 - acc: 0.8104 - val_loss: 1.2595 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 15th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4622 - acc: 0.7928 - val_loss: 1.4247 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 15th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5151 - acc: 0.7914 - val_loss: 1.3753 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 15th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4701 - acc: 0.7904 - val_loss: 1.3392 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 15th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3648 - acc: 0.8096 - val_loss: 1.3357 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 15th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4231 - acc: 0.8027 - val_loss: 1.5974 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 15th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4512 - acc: 0.7998 - val_loss: 1.6855 - val_acc: 0.7563\n",
      "[INFO] Training model: epoch 15th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5161 - acc: 0.7908 - val_loss: 1.4399 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5016 - acc: 0.7924 - val_loss: 1.2620 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4747 - acc: 0.7938 - val_loss: 1.2990 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 15th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5121 - acc: 0.7891 - val_loss: 1.3348 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 15th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4642 - acc: 0.7979 - val_loss: 1.6062 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 15th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4435 - acc: 0.7930 - val_loss: 1.3627 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 15th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3760 - acc: 0.8043 - val_loss: 1.5273 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4319 - acc: 0.7988 - val_loss: 1.5309 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 15th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4635 - acc: 0.7959 - val_loss: 1.4841 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 15th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4178 - acc: 0.7988 - val_loss: 1.4798 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 15th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3758 - acc: 0.8061 - val_loss: 1.3960 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 15th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.8057 - val_loss: 1.5205 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7902 - val_loss: 1.3614 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 15th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4889 - acc: 0.7910 - val_loss: 1.2491 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 15th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4574 - acc: 0.8008 - val_loss: 1.4330 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 15th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4372 - acc: 0.7959 - val_loss: 1.6618 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 15th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4522 - acc: 0.7939 - val_loss: 1.4697 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 15th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4872 - acc: 0.7926 - val_loss: 1.4224 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 15th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4763 - acc: 0.7920 - val_loss: 1.4137 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 15th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5162 - acc: 0.7914 - val_loss: 1.4243 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 15th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5871 - acc: 0.7771 - val_loss: 1.1897 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 15th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4184 - acc: 0.8008 - val_loss: 1.5564 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4251 - acc: 0.7992 - val_loss: 1.2999 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 15th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4699 - acc: 0.7930 - val_loss: 1.3979 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 15th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3685 - acc: 0.8115 - val_loss: 1.4074 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 15th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4512 - acc: 0.7938 - val_loss: 1.5315 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 15th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4469 - acc: 0.7988 - val_loss: 1.4009 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 15th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4488 - acc: 0.8006 - val_loss: 1.4586 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 15th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4986 - acc: 0.7932 - val_loss: 1.3810 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 15th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4935 - acc: 0.7932 - val_loss: 1.4548 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 15th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5179 - acc: 0.7871 - val_loss: 1.4228 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 15th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4267 - acc: 0.8014 - val_loss: 1.5692 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 15th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5388 - acc: 0.7936 - val_loss: 1.2200 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 15th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4386 - acc: 0.7982 - val_loss: 1.4508 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 15th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4638 - acc: 0.7918 - val_loss: 1.3792 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 15th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5422 - acc: 0.7854 - val_loss: 1.3536 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 15th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4852 - acc: 0.7891 - val_loss: 1.5482 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4825 - acc: 0.7932 - val_loss: 1.6361 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 15th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3494 - acc: 0.8111 - val_loss: 1.3899 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 15th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4243 - acc: 0.8016 - val_loss: 1.5191 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.6461 - acc: 0.7836 - val_loss: 1.5813 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 15th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5231 - acc: 0.7893 - val_loss: 1.2987 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 15th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4213 - acc: 0.8020 - val_loss: 1.4072 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 15th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5339 - acc: 0.7814 - val_loss: 1.5188 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 15th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5056 - acc: 0.7904 - val_loss: 1.6508 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 15th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4708 - acc: 0.7926 - val_loss: 1.4334 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 15th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4513 - acc: 0.7984 - val_loss: 1.3575 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 15th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3600 - acc: 0.8055 - val_loss: 1.5420 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 15th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4890 - acc: 0.7936 - val_loss: 1.5430 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 15th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4179 - acc: 0.8023 - val_loss: 1.5751 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 15th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4444 - acc: 0.8000 - val_loss: 1.4978 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5480 - acc: 0.7859 - val_loss: 1.4744 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 15th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4816 - acc: 0.7971 - val_loss: 1.1499 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 15th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4980 - acc: 0.7922 - val_loss: 1.5581 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 15th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4532 - acc: 0.7938 - val_loss: 1.5551 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 15th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4678 - acc: 0.7980 - val_loss: 1.5114 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 15th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4234 - acc: 0.7994 - val_loss: 1.6153 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 15th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4164 - acc: 0.8020 - val_loss: 1.4799 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 15th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4164 - acc: 0.8027 - val_loss: 1.3513 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 15th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3933 - acc: 0.8000 - val_loss: 1.2722 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 15th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4752 - acc: 0.7936 - val_loss: 1.4108 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 15th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5233 - acc: 0.7898 - val_loss: 1.3814 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 15th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3858 - acc: 0.8029 - val_loss: 1.4400 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 15th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5011 - acc: 0.7873 - val_loss: 1.3746 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 15th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5032 - acc: 0.7943 - val_loss: 1.6308 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 16th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2637 - acc: 0.8193 - val_loss: 1.4207 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3819 - acc: 0.8021 - val_loss: 1.6082 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 16th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4316 - acc: 0.7912 - val_loss: 1.6702 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 16th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3471 - acc: 0.8092 - val_loss: 1.2822 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3903 - acc: 0.8037 - val_loss: 1.2245 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 16th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2726 - acc: 0.8098 - val_loss: 1.4617 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 16th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4493 - acc: 0.7924 - val_loss: 1.3781 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 16th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4152 - acc: 0.7957 - val_loss: 1.2711 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 16th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7908 - val_loss: 1.2638 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 16th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4338 - acc: 0.7967 - val_loss: 1.5058 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4517 - acc: 0.7982 - val_loss: 1.4151 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4280 - acc: 0.7986 - val_loss: 1.3592 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4467 - acc: 0.7930 - val_loss: 1.3189 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 16th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3525 - acc: 0.8025 - val_loss: 1.4508 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 16th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4900 - acc: 0.7926 - val_loss: 1.3320 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 16th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4494 - acc: 0.7910 - val_loss: 1.3187 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4461 - acc: 0.7922 - val_loss: 1.3038 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3810 - acc: 0.8027 - val_loss: 1.5103 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3801 - acc: 0.8027 - val_loss: 1.4942 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 16th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4146 - acc: 0.7980 - val_loss: 1.4775 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 16th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3344 - acc: 0.8080 - val_loss: 1.6228 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 16th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4456 - acc: 0.7918 - val_loss: 1.6132 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 16th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3269 - acc: 0.8098 - val_loss: 1.2892 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 16th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4516 - acc: 0.7949 - val_loss: 1.4428 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4638 - acc: 0.7918 - val_loss: 1.3797 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4100 - acc: 0.7980 - val_loss: 1.4101 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 16th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4843 - acc: 0.7938 - val_loss: 1.5077 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 16th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3562 - acc: 0.8016 - val_loss: 1.2701 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4746 - acc: 0.7906 - val_loss: 1.3193 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3670 - acc: 0.8010 - val_loss: 1.3524 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4691 - acc: 0.7988 - val_loss: 1.2830 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 16th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4372 - acc: 0.7969 - val_loss: 1.3729 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3931 - acc: 0.8027 - val_loss: 1.4309 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 16th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4784 - acc: 0.7938 - val_loss: 1.2529 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 16th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3944 - acc: 0.8033 - val_loss: 1.3439 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4461 - acc: 0.7949 - val_loss: 1.6078 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 16th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3460 - acc: 0.8066 - val_loss: 1.3804 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 16th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4338 - acc: 0.8029 - val_loss: 1.3922 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4423 - acc: 0.7955 - val_loss: 1.4536 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 16th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4428 - acc: 0.7930 - val_loss: 1.6147 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 16th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4664 - acc: 0.7957 - val_loss: 1.4451 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4772 - acc: 0.7938 - val_loss: 1.6345 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 16th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4718 - acc: 0.7920 - val_loss: 1.5513 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 16th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4253 - acc: 0.7988 - val_loss: 1.3379 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 16th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3906 - acc: 0.8016 - val_loss: 1.4222 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4487 - acc: 0.7979 - val_loss: 1.4233 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 16th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3517 - acc: 0.8049 - val_loss: 1.5228 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 16th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3813 - acc: 0.8021 - val_loss: 1.3918 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4163 - acc: 0.8018 - val_loss: 1.3766 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 16th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4402 - acc: 0.7953 - val_loss: 1.5739 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 16th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4105 - acc: 0.7945 - val_loss: 1.4729 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 16th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3555 - acc: 0.8064 - val_loss: 1.3501 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 16th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3915 - acc: 0.7969 - val_loss: 1.2691 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 16th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4347 - acc: 0.8002 - val_loss: 1.4622 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4148 - acc: 0.7994 - val_loss: 1.4090 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 16th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4511 - acc: 0.7910 - val_loss: 1.5425 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 16th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4341 - acc: 0.7924 - val_loss: 1.2830 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 16th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4225 - acc: 0.8010 - val_loss: 1.2901 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 16th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4213 - acc: 0.7971 - val_loss: 1.3974 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 16th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3779 - acc: 0.8027 - val_loss: 1.4697 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 16th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4421 - acc: 0.7928 - val_loss: 1.5014 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5108 - acc: 0.7887 - val_loss: 1.4216 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 16th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3977 - acc: 0.8018 - val_loss: 1.4607 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 16th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3687 - acc: 0.8033 - val_loss: 1.3486 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 16th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5019 - acc: 0.7895 - val_loss: 1.4198 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4072 - acc: 0.7973 - val_loss: 1.5156 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 16th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4828 - acc: 0.7877 - val_loss: 1.3270 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 16th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3600 - acc: 0.8043 - val_loss: 1.4164 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 16th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3670 - acc: 0.7982 - val_loss: 1.4342 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 16th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4526 - acc: 0.7973 - val_loss: 1.4885 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5373 - acc: 0.7846 - val_loss: 1.2643 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 16th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4841 - acc: 0.7887 - val_loss: 1.4231 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5848 - acc: 0.7793 - val_loss: 1.2608 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 16th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3803 - acc: 0.8064 - val_loss: 1.4300 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3813 - acc: 0.8031 - val_loss: 1.3891 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5294 - acc: 0.7812 - val_loss: 1.3976 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.8029 - val_loss: 1.5689 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 16th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3888 - acc: 0.7975 - val_loss: 1.5642 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 16th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7914 - val_loss: 1.4259 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 16th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4430 - acc: 0.7959 - val_loss: 1.2243 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 16th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4599 - acc: 0.7932 - val_loss: 1.4872 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4280 - acc: 0.7969 - val_loss: 1.5723 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 16th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5141 - acc: 0.7859 - val_loss: 1.6183 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 16th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4061 - acc: 0.8008 - val_loss: 1.5157 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4128 - acc: 0.8029 - val_loss: 1.3568 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 16th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4194 - acc: 0.7971 - val_loss: 1.3981 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3730 - acc: 0.8043 - val_loss: 1.6730 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 16th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3137 - acc: 0.8111 - val_loss: 1.3009 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 16th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4198 - acc: 0.8018 - val_loss: 1.5405 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 16th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4810 - acc: 0.7887 - val_loss: 1.5937 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 16th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4029 - acc: 0.7996 - val_loss: 1.4115 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4046 - acc: 0.8035 - val_loss: 1.2853 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 16th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4162 - acc: 0.7980 - val_loss: 1.3607 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3772 - acc: 0.8045 - val_loss: 1.4715 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 16th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4147 - acc: 0.7979 - val_loss: 1.5000 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4401 - acc: 0.7920 - val_loss: 1.4084 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4273 - acc: 0.7979 - val_loss: 1.4746 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 16th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4710 - acc: 0.7928 - val_loss: 1.7220 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 16th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4427 - acc: 0.7936 - val_loss: 1.3015 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 16th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4593 - acc: 0.7932 - val_loss: 1.5671 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 16th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3832 - acc: 0.8074 - val_loss: 1.4494 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 16th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4790 - acc: 0.7949 - val_loss: 1.4095 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 16th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4957 - acc: 0.7881 - val_loss: 1.3661 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4523 - acc: 0.7984 - val_loss: 1.3123 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4727 - acc: 0.7906 - val_loss: 1.5431 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3811 - acc: 0.8029 - val_loss: 1.2349 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 16th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5517 - acc: 0.7854 - val_loss: 1.3827 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 16th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4201 - acc: 0.7965 - val_loss: 1.5147 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 16th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.8021 - val_loss: 1.4944 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 16th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4290 - acc: 0.7945 - val_loss: 1.2905 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5102 - acc: 0.7879 - val_loss: 1.4560 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3291 - acc: 0.8133 - val_loss: 1.5100 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 16th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5434 - acc: 0.7842 - val_loss: 1.4095 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 16th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4340 - acc: 0.7943 - val_loss: 1.5018 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 16th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4072 - acc: 0.7992 - val_loss: 1.3014 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 16th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4185 - acc: 0.8000 - val_loss: 1.3970 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4030 - acc: 0.8035 - val_loss: 1.5028 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 16th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4006 - acc: 0.8031 - val_loss: 1.3465 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 16th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4323 - acc: 0.7986 - val_loss: 1.3047 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5213 - acc: 0.7869 - val_loss: 1.6585 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 16th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3942 - acc: 0.8039 - val_loss: 1.4819 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 16th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4739 - acc: 0.7936 - val_loss: 1.4375 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 16th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2914 - acc: 0.8150 - val_loss: 1.3044 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 16th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4347 - acc: 0.7980 - val_loss: 1.4716 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 16th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4013 - acc: 0.8020 - val_loss: 1.4160 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4594 - acc: 0.7949 - val_loss: 1.4418 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 16th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4219 - acc: 0.8016 - val_loss: 1.4700 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5042 - acc: 0.7902 - val_loss: 1.4448 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 16th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3920 - acc: 0.8018 - val_loss: 1.3761 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4441 - acc: 0.7959 - val_loss: 1.4828 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 16th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4486 - acc: 0.7996 - val_loss: 1.2838 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 16th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3236 - acc: 0.8129 - val_loss: 1.6631 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 16th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4297 - acc: 0.7939 - val_loss: 1.4683 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3954 - acc: 0.8010 - val_loss: 1.4652 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3788 - acc: 0.8027 - val_loss: 1.5795 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 16th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4449 - acc: 0.7930 - val_loss: 1.3709 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 16th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3786 - acc: 0.8041 - val_loss: 1.4203 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4795 - acc: 0.7912 - val_loss: 1.5802 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 16th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4673 - acc: 0.7934 - val_loss: 1.5120 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 16th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4316 - acc: 0.7986 - val_loss: 1.2736 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 16th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4527 - acc: 0.7988 - val_loss: 1.1950 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 16th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4120 - acc: 0.8010 - val_loss: 1.4067 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4344 - acc: 0.8000 - val_loss: 1.4463 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 16th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4328 - acc: 0.8000 - val_loss: 1.3809 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 16th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4037 - acc: 0.8020 - val_loss: 1.5321 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5040 - acc: 0.7891 - val_loss: 1.3800 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4811 - acc: 0.7916 - val_loss: 1.4680 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4002 - acc: 0.8063 - val_loss: 1.3881 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 16th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4624 - acc: 0.7926 - val_loss: 1.3855 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 16th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4597 - acc: 0.8004 - val_loss: 1.4089 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4086 - acc: 0.7965 - val_loss: 1.3614 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 16th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4661 - acc: 0.7955 - val_loss: 1.3836 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 16th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4262 - acc: 0.7973 - val_loss: 1.3922 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 16th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4109 - acc: 0.8045 - val_loss: 1.3351 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4869 - acc: 0.7936 - val_loss: 1.4324 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3631 - acc: 0.8090 - val_loss: 1.5112 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3398 - acc: 0.8059 - val_loss: 1.5875 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 16th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4739 - acc: 0.7951 - val_loss: 1.5679 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 16th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4288 - acc: 0.7965 - val_loss: 1.3719 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 16th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3970 - acc: 0.8012 - val_loss: 1.4106 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 16th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4405 - acc: 0.7979 - val_loss: 1.5496 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 16th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5084 - acc: 0.7900 - val_loss: 1.5094 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 16th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4493 - acc: 0.7945 - val_loss: 1.4480 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 16th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7908 - val_loss: 1.4344 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4810 - acc: 0.7918 - val_loss: 1.4842 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4762 - acc: 0.7930 - val_loss: 1.4262 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4267 - acc: 0.8006 - val_loss: 1.5943 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 16th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5405 - acc: 0.7879 - val_loss: 1.3190 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 16th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4309 - acc: 0.7982 - val_loss: 1.2876 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 16th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4089 - acc: 0.7975 - val_loss: 1.3208 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4949 - acc: 0.7881 - val_loss: 1.4326 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3851 - acc: 0.8020 - val_loss: 1.3164 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4577 - acc: 0.7984 - val_loss: 1.4254 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4525 - acc: 0.7977 - val_loss: 1.5433 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 16th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4583 - acc: 0.7949 - val_loss: 1.3310 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 16th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4206 - acc: 0.8021 - val_loss: 1.5389 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 16th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3172 - acc: 0.8043 - val_loss: 1.4431 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4375 - acc: 0.7980 - val_loss: 1.5395 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 16th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3602 - acc: 0.8076 - val_loss: 1.5164 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4157 - acc: 0.7951 - val_loss: 1.4751 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3860 - acc: 0.8033 - val_loss: 1.1921 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 16th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4316 - acc: 0.7979 - val_loss: 1.2275 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 16th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4924 - acc: 0.7857 - val_loss: 1.5555 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 16th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3985 - acc: 0.8037 - val_loss: 1.3775 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 16th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4954 - acc: 0.7902 - val_loss: 1.5616 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 16th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3935 - acc: 0.8014 - val_loss: 1.2078 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 16th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4690 - acc: 0.7955 - val_loss: 1.4137 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4415 - acc: 0.7953 - val_loss: 1.4884 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 16th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4462 - acc: 0.8000 - val_loss: 1.4397 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4814 - acc: 0.7883 - val_loss: 1.3361 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 16th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5330 - acc: 0.7850 - val_loss: 1.3699 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4135 - acc: 0.8037 - val_loss: 1.5399 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3955 - acc: 0.8004 - val_loss: 1.5413 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5418 - acc: 0.7854 - val_loss: 1.4457 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5149 - acc: 0.7922 - val_loss: 1.4631 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4678 - acc: 0.7936 - val_loss: 1.3036 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 16th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3902 - acc: 0.8043 - val_loss: 1.2579 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 16th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4063 - acc: 0.8008 - val_loss: 1.4496 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 16th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4858 - acc: 0.7863 - val_loss: 1.3946 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3699 - acc: 0.8092 - val_loss: 1.5223 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 16th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5241 - acc: 0.7902 - val_loss: 1.3821 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4228 - acc: 0.8004 - val_loss: 1.4205 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 16th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4727 - acc: 0.7975 - val_loss: 1.5684 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 16th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4005 - acc: 0.8016 - val_loss: 1.4699 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4693 - acc: 0.7945 - val_loss: 1.5144 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 16th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5037 - acc: 0.7926 - val_loss: 1.4759 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 16th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4786 - acc: 0.7949 - val_loss: 1.4097 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3547 - acc: 0.8051 - val_loss: 1.3916 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4458 - acc: 0.7963 - val_loss: 1.5842 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 16th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4627 - acc: 0.7939 - val_loss: 1.3730 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3924 - acc: 0.8057 - val_loss: 1.4510 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 16th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4963 - acc: 0.7939 - val_loss: 1.5111 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7928 - val_loss: 1.3885 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4266 - acc: 0.7996 - val_loss: 1.4284 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 16th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4386 - acc: 0.7984 - val_loss: 1.3976 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 16th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4336 - acc: 0.7973 - val_loss: 1.4884 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5799 - acc: 0.7760 - val_loss: 1.5012 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 16th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3690 - acc: 0.8027 - val_loss: 1.5108 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 16th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4978 - acc: 0.7912 - val_loss: 1.2647 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 16th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4678 - acc: 0.7881 - val_loss: 1.5445 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 16th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4887 - acc: 0.7893 - val_loss: 1.3506 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 16th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4299 - acc: 0.7984 - val_loss: 1.4542 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 16th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4346 - acc: 0.7984 - val_loss: 1.3924 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 16th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4425 - acc: 0.8008 - val_loss: 1.5764 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 16th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4025 - acc: 0.8029 - val_loss: 1.5877 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 16th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3806 - acc: 0.8035 - val_loss: 1.3530 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 16th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4327 - acc: 0.8000 - val_loss: 1.5947 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 16th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4953 - acc: 0.7902 - val_loss: 1.3998 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4170 - acc: 0.8000 - val_loss: 1.6169 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 16th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4065 - acc: 0.8043 - val_loss: 1.5397 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 16th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7926 - val_loss: 1.3376 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 16th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3278 - acc: 0.8113 - val_loss: 1.5904 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 16th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5490 - acc: 0.7877 - val_loss: 1.3603 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 16th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4869 - acc: 0.7914 - val_loss: 1.4811 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 16th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5010 - acc: 0.7879 - val_loss: 1.4738 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 16th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4724 - acc: 0.7979 - val_loss: 1.5290 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 16th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4612 - acc: 0.7973 - val_loss: 1.3941 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 16th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4227 - acc: 0.7951 - val_loss: 1.2733 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 16th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3765 - acc: 0.8063 - val_loss: 1.3992 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 16th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4946 - acc: 0.7938 - val_loss: 1.2206 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 16th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4424 - acc: 0.8000 - val_loss: 1.3993 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 16th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3731 - acc: 0.8104 - val_loss: 1.3612 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 16th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4176 - acc: 0.7988 - val_loss: 1.3844 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 16th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4827 - acc: 0.7918 - val_loss: 1.3423 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 16th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5416 - acc: 0.7850 - val_loss: 1.6041 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 16th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4283 - acc: 0.7967 - val_loss: 1.4947 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 16th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3647 - acc: 0.8066 - val_loss: 1.4431 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 16th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4698 - acc: 0.7967 - val_loss: 1.5275 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 16th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4314 - acc: 0.7955 - val_loss: 1.3376 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 16th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3222 - acc: 0.8105 - val_loss: 1.3508 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 17th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3657 - acc: 0.8086 - val_loss: 1.5270 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 17th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3546 - acc: 0.8049 - val_loss: 1.3945 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4257 - acc: 0.7996 - val_loss: 1.5782 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 17th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3846 - acc: 0.8033 - val_loss: 1.4793 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3121 - acc: 0.8086 - val_loss: 1.2725 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 17th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3994 - acc: 0.7988 - val_loss: 1.4651 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3933 - acc: 0.8025 - val_loss: 1.3035 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 17th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4059 - acc: 0.7980 - val_loss: 1.3650 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 17th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4337 - acc: 0.7914 - val_loss: 1.3574 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 17th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3488 - acc: 0.8047 - val_loss: 1.6905 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 17th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3497 - acc: 0.8002 - val_loss: 1.2918 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 17th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4188 - acc: 0.7982 - val_loss: 1.5083 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 17th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3833 - acc: 0.8020 - val_loss: 1.3176 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 17th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3824 - acc: 0.8010 - val_loss: 1.7443 - val_acc: 0.7594\n",
      "[INFO] Training model: epoch 17th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3316 - acc: 0.8094 - val_loss: 1.4722 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 17th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4161 - acc: 0.7959 - val_loss: 1.2471 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 17th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3708 - acc: 0.8035 - val_loss: 1.3606 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 17th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3927 - acc: 0.8012 - val_loss: 1.2270 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 17th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3963 - acc: 0.8037 - val_loss: 1.5170 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4155 - acc: 0.7973 - val_loss: 1.3362 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 17th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4890 - acc: 0.7912 - val_loss: 1.3143 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 17th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4507 - acc: 0.7893 - val_loss: 1.4271 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 17th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4072 - acc: 0.8008 - val_loss: 1.6330 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 17th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4298 - acc: 0.7967 - val_loss: 1.3027 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7842 - val_loss: 1.3497 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 17th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3893 - acc: 0.7967 - val_loss: 1.2157 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 17th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4141 - acc: 0.7973 - val_loss: 1.4791 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 17th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3324 - acc: 0.8072 - val_loss: 1.5726 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 17th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4170 - acc: 0.7992 - val_loss: 1.3057 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 17th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4114 - acc: 0.7980 - val_loss: 1.5558 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 17th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.8000 - val_loss: 1.4561 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4265 - acc: 0.7949 - val_loss: 1.4280 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 17th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3445 - acc: 0.8045 - val_loss: 1.4462 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 17th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3950 - acc: 0.8000 - val_loss: 1.4817 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3783 - acc: 0.8020 - val_loss: 1.3119 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4419 - acc: 0.7957 - val_loss: 1.4026 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 17th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4285 - acc: 0.7971 - val_loss: 1.3821 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 17th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3661 - acc: 0.8061 - val_loss: 1.4008 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 17th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3316 - acc: 0.8035 - val_loss: 1.2446 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 17th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4670 - acc: 0.7936 - val_loss: 1.5320 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3850 - acc: 0.8111 - val_loss: 1.7055 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 17th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3440 - acc: 0.8004 - val_loss: 1.3948 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4546 - acc: 0.7871 - val_loss: 1.4131 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 17th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4147 - acc: 0.7955 - val_loss: 1.4075 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 17th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4811 - acc: 0.7953 - val_loss: 1.3084 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 17th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4611 - acc: 0.7922 - val_loss: 1.5246 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 17th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4244 - acc: 0.7980 - val_loss: 1.4269 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3853 - acc: 0.8045 - val_loss: 1.5189 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 17th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4391 - acc: 0.7961 - val_loss: 1.3929 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 17th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3871 - acc: 0.8072 - val_loss: 1.4506 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 17th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4279 - acc: 0.8000 - val_loss: 1.4252 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4218 - acc: 0.8014 - val_loss: 1.4504 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 17th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4189 - acc: 0.7957 - val_loss: 1.5285 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4276 - acc: 0.8006 - val_loss: 1.4445 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4550 - acc: 0.7943 - val_loss: 1.2302 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 17th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3442 - acc: 0.8049 - val_loss: 1.4219 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 17th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5051 - acc: 0.7871 - val_loss: 1.3104 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4499 - acc: 0.7975 - val_loss: 1.4768 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4645 - acc: 0.7920 - val_loss: 1.4804 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3567 - acc: 0.8041 - val_loss: 1.2706 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 17th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4361 - acc: 0.7984 - val_loss: 1.3412 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 17th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3322 - acc: 0.8063 - val_loss: 1.7295 - val_acc: 0.7609\n",
      "[INFO] Training model: epoch 17th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4814 - acc: 0.7850 - val_loss: 1.4090 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 17th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3931 - acc: 0.7980 - val_loss: 1.2127 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 17th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5595 - acc: 0.7768 - val_loss: 1.3823 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 17th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4372 - acc: 0.7967 - val_loss: 1.4053 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4434 - acc: 0.7908 - val_loss: 1.6706 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 17th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2783 - acc: 0.8166 - val_loss: 1.2315 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 17th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4132 - acc: 0.8002 - val_loss: 1.4182 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3500 - acc: 0.8107 - val_loss: 1.2758 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 17th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4637 - acc: 0.7959 - val_loss: 1.2411 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 17th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5220 - acc: 0.7871 - val_loss: 1.6401 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 17th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7959 - val_loss: 1.5497 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 17th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3515 - acc: 0.8021 - val_loss: 1.3688 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 17th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3765 - acc: 0.8043 - val_loss: 1.3731 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 17th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3916 - acc: 0.8004 - val_loss: 1.5189 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 17th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3945 - acc: 0.8012 - val_loss: 1.6204 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 17th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4270 - acc: 0.7965 - val_loss: 1.4258 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 17th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3935 - acc: 0.8006 - val_loss: 1.3652 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 17th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4680 - acc: 0.7959 - val_loss: 1.2680 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 17th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3794 - acc: 0.7980 - val_loss: 1.5992 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 17th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4339 - acc: 0.7973 - val_loss: 1.5420 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 17th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5447 - acc: 0.7826 - val_loss: 1.4440 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3466 - acc: 0.8053 - val_loss: 1.5381 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 17th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3884 - acc: 0.7982 - val_loss: 1.5660 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 17th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4475 - acc: 0.7934 - val_loss: 1.3071 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4574 - acc: 0.7967 - val_loss: 1.6122 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 17th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5853 - acc: 0.7791 - val_loss: 1.3906 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 17th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4721 - acc: 0.7883 - val_loss: 1.4321 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 17th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5374 - acc: 0.7863 - val_loss: 1.2374 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 17th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4284 - acc: 0.8014 - val_loss: 1.2697 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 17th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4109 - acc: 0.7957 - val_loss: 1.4228 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 17th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4360 - acc: 0.7928 - val_loss: 1.5411 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 17th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4614 - acc: 0.7926 - val_loss: 1.2972 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 17th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4226 - acc: 0.7971 - val_loss: 1.4325 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 17th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4092 - acc: 0.8037 - val_loss: 1.4296 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4373 - acc: 0.7953 - val_loss: 1.3714 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 17th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4451 - acc: 0.8000 - val_loss: 1.7761 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 17th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3207 - acc: 0.8125 - val_loss: 1.4094 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3921 - acc: 0.7928 - val_loss: 1.3500 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 17th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3182 - acc: 0.8113 - val_loss: 1.4534 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 17th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3153 - acc: 0.8092 - val_loss: 1.4536 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 17th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3604 - acc: 0.8084 - val_loss: 1.4447 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 17th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3476 - acc: 0.8076 - val_loss: 1.3962 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4048 - acc: 0.7967 - val_loss: 1.3894 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 17th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4213 - acc: 0.7986 - val_loss: 1.4486 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5079 - acc: 0.7896 - val_loss: 1.4552 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3981 - acc: 0.8002 - val_loss: 1.3923 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 17th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3988 - acc: 0.8064 - val_loss: 1.3165 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 17th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3206 - acc: 0.8102 - val_loss: 1.5774 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 17th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3638 - acc: 0.8047 - val_loss: 1.5341 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 17th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3796 - acc: 0.8012 - val_loss: 1.5562 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 17th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4807 - acc: 0.7949 - val_loss: 1.3987 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4037 - acc: 0.7986 - val_loss: 1.3089 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 17th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4712 - acc: 0.7889 - val_loss: 1.4351 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 17th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4613 - acc: 0.7930 - val_loss: 1.4078 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 17th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3750 - acc: 0.8047 - val_loss: 1.6050 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 17th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4228 - acc: 0.7996 - val_loss: 1.3783 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4863 - acc: 0.7881 - val_loss: 1.6385 - val_acc: 0.7664\n",
      "[INFO] Training model: epoch 17th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4463 - acc: 0.7986 - val_loss: 1.4530 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 17th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3970 - acc: 0.7973 - val_loss: 1.3423 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 17th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5196 - acc: 0.7848 - val_loss: 1.4522 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 17th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4580 - acc: 0.7910 - val_loss: 1.2643 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 17th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5356 - acc: 0.7877 - val_loss: 1.2623 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 17th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4188 - acc: 0.7959 - val_loss: 1.4227 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 17th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4592 - acc: 0.7959 - val_loss: 1.2852 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 17th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3479 - acc: 0.8059 - val_loss: 1.5909 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 17th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3800 - acc: 0.8059 - val_loss: 1.4461 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 17th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3443 - acc: 0.8098 - val_loss: 1.4710 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 17th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3322 - acc: 0.8094 - val_loss: 1.3129 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 17th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4025 - acc: 0.8063 - val_loss: 1.3898 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 17th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4258 - acc: 0.8020 - val_loss: 1.4444 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4558 - acc: 0.7945 - val_loss: 1.3254 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 17th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4504 - acc: 0.7928 - val_loss: 1.4351 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 17th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5384 - acc: 0.7814 - val_loss: 1.4921 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 17th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5064 - acc: 0.7871 - val_loss: 1.5043 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3224 - acc: 0.8086 - val_loss: 1.5183 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 17th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4110 - acc: 0.7943 - val_loss: 1.6818 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 17th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3715 - acc: 0.8063 - val_loss: 1.2663 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 17th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3797 - acc: 0.8002 - val_loss: 1.6091 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 17th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3755 - acc: 0.8047 - val_loss: 1.2017 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 17th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4122 - acc: 0.8020 - val_loss: 1.3349 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 17th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3400 - acc: 0.8096 - val_loss: 1.3904 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 17th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4395 - acc: 0.7988 - val_loss: 1.3954 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 17th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3590 - acc: 0.8018 - val_loss: 1.3472 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 17th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5351 - acc: 0.7879 - val_loss: 1.3910 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4153 - acc: 0.7965 - val_loss: 1.2688 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 17th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.7945 - val_loss: 1.5866 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 17th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4956 - acc: 0.7885 - val_loss: 1.5737 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 17th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4502 - acc: 0.7955 - val_loss: 1.3993 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 17th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3872 - acc: 0.8025 - val_loss: 1.7325 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 17th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4656 - acc: 0.7955 - val_loss: 1.2710 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 17th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4408 - acc: 0.7910 - val_loss: 1.4612 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 17th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4084 - acc: 0.8037 - val_loss: 1.3408 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 17th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3875 - acc: 0.8016 - val_loss: 1.3698 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 17th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5307 - acc: 0.7871 - val_loss: 1.3680 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 17th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4691 - acc: 0.7943 - val_loss: 1.3064 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4969 - acc: 0.7896 - val_loss: 1.2961 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 17th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4421 - acc: 0.7938 - val_loss: 1.3783 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 17th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4047 - acc: 0.8000 - val_loss: 1.4394 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 17th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4631 - acc: 0.7936 - val_loss: 1.1723 - val_acc: 0.8391\n",
      "[INFO] Training model: epoch 17th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3469 - acc: 0.8102 - val_loss: 1.5389 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 17th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4544 - acc: 0.7908 - val_loss: 1.4891 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 17th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3408 - acc: 0.8080 - val_loss: 1.5444 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 17th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4053 - acc: 0.8027 - val_loss: 1.3836 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 17th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4694 - acc: 0.7914 - val_loss: 1.4032 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 17th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5050 - acc: 0.7912 - val_loss: 1.4535 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 17th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3248 - acc: 0.8143 - val_loss: 1.6145 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 17th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4324 - acc: 0.7979 - val_loss: 1.4542 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 17th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5634 - acc: 0.7822 - val_loss: 1.5926 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 17th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4095 - acc: 0.8029 - val_loss: 1.3951 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 17th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4132 - acc: 0.7986 - val_loss: 1.3257 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 17th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4173 - acc: 0.8000 - val_loss: 1.4391 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 17th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4109 - acc: 0.8002 - val_loss: 1.4733 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3946 - acc: 0.8018 - val_loss: 1.4155 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 17th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4264 - acc: 0.7982 - val_loss: 1.3158 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 17th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5155 - acc: 0.7938 - val_loss: 1.4820 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 17th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4700 - acc: 0.7941 - val_loss: 1.6728 - val_acc: 0.7617\n",
      "[INFO] Training model: epoch 17th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4399 - acc: 0.7980 - val_loss: 1.4311 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 17th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4207 - acc: 0.8010 - val_loss: 1.3754 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 17th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4382 - acc: 0.8027 - val_loss: 1.4107 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 17th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3834 - acc: 0.8061 - val_loss: 1.4268 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 17th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4203 - acc: 0.7990 - val_loss: 1.6072 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 17th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4507 - acc: 0.7916 - val_loss: 1.4932 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 17th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5039 - acc: 0.7916 - val_loss: 1.4289 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 17th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3827 - acc: 0.8029 - val_loss: 1.4782 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 17th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3842 - acc: 0.7971 - val_loss: 1.5865 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 17th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4194 - acc: 0.8012 - val_loss: 1.5450 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3710 - acc: 0.8041 - val_loss: 1.4897 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 17th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4612 - acc: 0.7977 - val_loss: 1.4082 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 17th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4009 - acc: 0.7955 - val_loss: 1.4636 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 17th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4667 - acc: 0.7922 - val_loss: 1.4339 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 17th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4557 - acc: 0.7949 - val_loss: 1.3166 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 17th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.8025 - val_loss: 1.3334 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 17th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3887 - acc: 0.8063 - val_loss: 1.4360 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 17th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4012 - acc: 0.8012 - val_loss: 1.5765 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 17th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4466 - acc: 0.7943 - val_loss: 1.3855 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 17th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2947 - acc: 0.8139 - val_loss: 1.3163 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 17th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3170 - acc: 0.8096 - val_loss: 1.2934 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 17th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4725 - acc: 0.7926 - val_loss: 1.3266 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 17th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4478 - acc: 0.7955 - val_loss: 1.4533 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7971 - val_loss: 1.4956 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 17th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4867 - acc: 0.7947 - val_loss: 1.4764 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3608 - acc: 0.8072 - val_loss: 1.4529 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 17th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4073 - acc: 0.8027 - val_loss: 1.3842 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 17th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4054 - acc: 0.8012 - val_loss: 1.2943 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 17th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4805 - acc: 0.7908 - val_loss: 1.4530 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 17th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3931 - acc: 0.8035 - val_loss: 1.5234 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 17th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4061 - acc: 0.7994 - val_loss: 1.4210 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 17th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3885 - acc: 0.8041 - val_loss: 1.4564 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 17th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5032 - acc: 0.7896 - val_loss: 1.3349 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 17th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4044 - acc: 0.8004 - val_loss: 1.3321 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 17th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4739 - acc: 0.7928 - val_loss: 1.3650 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 17th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4514 - acc: 0.7988 - val_loss: 1.2991 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 17th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4145 - acc: 0.8010 - val_loss: 1.4426 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 17th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4219 - acc: 0.7984 - val_loss: 1.2672 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 17th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4667 - acc: 0.7977 - val_loss: 1.3030 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 17th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4005 - acc: 0.7955 - val_loss: 1.3294 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 17th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3560 - acc: 0.8035 - val_loss: 1.4385 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 17th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4421 - acc: 0.7969 - val_loss: 1.6845 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 17th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4568 - acc: 0.7908 - val_loss: 1.4378 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 17th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4711 - acc: 0.7914 - val_loss: 1.3704 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 17th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3697 - acc: 0.8055 - val_loss: 1.3326 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 17th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3868 - acc: 0.8076 - val_loss: 1.2771 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 17th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4519 - acc: 0.7973 - val_loss: 1.5456 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 17th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3743 - acc: 0.8033 - val_loss: 1.5460 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 17th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4114 - acc: 0.8020 - val_loss: 1.4421 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 17th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4829 - acc: 0.7953 - val_loss: 1.5456 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 17th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4660 - acc: 0.7918 - val_loss: 1.3374 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 17th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3392 - acc: 0.8076 - val_loss: 1.4868 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 17th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4378 - acc: 0.7965 - val_loss: 1.4383 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 17th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4508 - acc: 0.7957 - val_loss: 1.5494 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 17th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4501 - acc: 0.7980 - val_loss: 1.2150 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 17th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4336 - acc: 0.7996 - val_loss: 1.6100 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 17th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3744 - acc: 0.8035 - val_loss: 1.4925 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4229 - acc: 0.8029 - val_loss: 1.4224 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 17th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4236 - acc: 0.7992 - val_loss: 1.3979 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 17th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4270 - acc: 0.8020 - val_loss: 1.5016 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 17th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4033 - acc: 0.8029 - val_loss: 1.4908 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4793 - acc: 0.7941 - val_loss: 1.4470 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 17th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3855 - acc: 0.8000 - val_loss: 1.3274 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 17th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4093 - acc: 0.8041 - val_loss: 1.3138 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 17th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4762 - acc: 0.7957 - val_loss: 1.4324 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 17th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3688 - acc: 0.8023 - val_loss: 1.2924 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 17th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5491 - acc: 0.7830 - val_loss: 1.5731 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 17th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4343 - acc: 0.7971 - val_loss: 1.2400 - val_acc: 0.8281\n",
      "[INFO] Training model: epoch 17th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4328 - acc: 0.7977 - val_loss: 1.3128 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 17th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4558 - acc: 0.7992 - val_loss: 1.5830 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 17th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5088 - acc: 0.7957 - val_loss: 1.5076 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 17th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4136 - acc: 0.7980 - val_loss: 1.5142 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 18th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4748 - acc: 0.7859 - val_loss: 1.1997 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 18th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3986 - acc: 0.8002 - val_loss: 1.1646 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 18th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3251 - acc: 0.8047 - val_loss: 1.2159 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 18th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4072 - acc: 0.7979 - val_loss: 1.4070 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2952 - acc: 0.8113 - val_loss: 1.3766 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 18th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3824 - acc: 0.8002 - val_loss: 1.3959 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 18th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4089 - acc: 0.7959 - val_loss: 1.5585 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 18th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3912 - acc: 0.7984 - val_loss: 1.2817 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 18th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3657 - acc: 0.8053 - val_loss: 1.3631 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 18th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4070 - acc: 0.7979 - val_loss: 1.3889 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4676 - acc: 0.7906 - val_loss: 1.4321 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3656 - acc: 0.8059 - val_loss: 1.3088 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 18th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3174 - acc: 0.8037 - val_loss: 1.3492 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3624 - acc: 0.8018 - val_loss: 1.2881 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 18th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4777 - acc: 0.7912 - val_loss: 1.4653 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 18th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3743 - acc: 0.8045 - val_loss: 1.4079 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4673 - acc: 0.7938 - val_loss: 1.2667 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 18th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4466 - acc: 0.7926 - val_loss: 1.2546 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 18th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4628 - acc: 0.7930 - val_loss: 1.5572 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3873 - acc: 0.8002 - val_loss: 1.5120 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 18th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3457 - acc: 0.8047 - val_loss: 1.3479 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4126 - acc: 0.8006 - val_loss: 1.5514 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 18th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4430 - acc: 0.7914 - val_loss: 1.4100 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 18th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3763 - acc: 0.8031 - val_loss: 1.3922 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3954 - acc: 0.8012 - val_loss: 1.3649 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3764 - acc: 0.8041 - val_loss: 1.3475 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3767 - acc: 0.8021 - val_loss: 1.2762 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 18th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4539 - acc: 0.7973 - val_loss: 1.5638 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 18th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3916 - acc: 0.7975 - val_loss: 1.1218 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 18th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3769 - acc: 0.8002 - val_loss: 1.3608 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 18th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3442 - acc: 0.8047 - val_loss: 1.3489 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 18th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3433 - acc: 0.8016 - val_loss: 1.4090 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4493 - acc: 0.7949 - val_loss: 1.4767 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 18th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3719 - acc: 0.8012 - val_loss: 1.5224 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 18th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3863 - acc: 0.7988 - val_loss: 1.3524 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 18th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3521 - acc: 0.8027 - val_loss: 1.4579 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 18th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3013 - acc: 0.8141 - val_loss: 1.4273 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 18th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3464 - acc: 0.8043 - val_loss: 1.3684 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7941 - val_loss: 1.4490 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4309 - acc: 0.7975 - val_loss: 1.4367 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4628 - acc: 0.7969 - val_loss: 1.4274 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4570 - acc: 0.7951 - val_loss: 1.4123 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 18th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3855 - acc: 0.8027 - val_loss: 1.3403 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 18th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4147 - acc: 0.8002 - val_loss: 1.1753 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 18th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3952 - acc: 0.8014 - val_loss: 1.3177 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 18th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3936 - acc: 0.7984 - val_loss: 1.3315 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 18th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3646 - acc: 0.8063 - val_loss: 1.4541 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 18th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3295 - acc: 0.8084 - val_loss: 1.2850 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 18th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3985 - acc: 0.8014 - val_loss: 1.4747 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 18th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4361 - acc: 0.8008 - val_loss: 1.4976 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 18th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4437 - acc: 0.7912 - val_loss: 1.4733 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 18th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3399 - acc: 0.8047 - val_loss: 1.4199 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3400 - acc: 0.8094 - val_loss: 1.5624 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 18th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4581 - acc: 0.7992 - val_loss: 1.2730 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 18th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3779 - acc: 0.7979 - val_loss: 1.4243 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4511 - acc: 0.7926 - val_loss: 1.4766 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 18th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4490 - acc: 0.7980 - val_loss: 1.4665 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 18th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3806 - acc: 0.7967 - val_loss: 1.2699 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 18th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3949 - acc: 0.7977 - val_loss: 1.3819 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3216 - acc: 0.8082 - val_loss: 1.4362 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3775 - acc: 0.8018 - val_loss: 1.4970 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 18th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4755 - acc: 0.7900 - val_loss: 1.5330 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 18th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4252 - acc: 0.8008 - val_loss: 1.4110 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 18th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4478 - acc: 0.7969 - val_loss: 1.4135 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 18th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4491 - acc: 0.7961 - val_loss: 1.2687 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 18th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4381 - acc: 0.7938 - val_loss: 1.6422 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 18th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4294 - acc: 0.7969 - val_loss: 1.4862 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 18th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3789 - acc: 0.8035 - val_loss: 1.5683 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 18th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3659 - acc: 0.8025 - val_loss: 1.4358 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3534 - acc: 0.8053 - val_loss: 1.2949 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 18th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3400 - acc: 0.8064 - val_loss: 1.5951 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 18th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4118 - acc: 0.7967 - val_loss: 1.0853 - val_acc: 0.8359\n",
      "[INFO] Training model: epoch 18th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5063 - acc: 0.7910 - val_loss: 1.4519 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 18th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3549 - acc: 0.8057 - val_loss: 1.2686 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 18th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4726 - acc: 0.7918 - val_loss: 1.3980 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 18th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5180 - acc: 0.7869 - val_loss: 1.3661 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 18th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3860 - acc: 0.8023 - val_loss: 1.5756 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 18th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4475 - acc: 0.7969 - val_loss: 1.3244 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 18th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2382 - acc: 0.8236 - val_loss: 1.4048 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 18th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3326 - acc: 0.8090 - val_loss: 1.3904 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 18th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4001 - acc: 0.7982 - val_loss: 1.3413 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 18th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4556 - acc: 0.7865 - val_loss: 1.5080 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 18th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3888 - acc: 0.7955 - val_loss: 1.3186 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 18th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3251 - acc: 0.8039 - val_loss: 1.4994 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 18th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5321 - acc: 0.7871 - val_loss: 1.4381 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 18th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4308 - acc: 0.8039 - val_loss: 1.3085 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 18th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4237 - acc: 0.7926 - val_loss: 1.3402 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 18th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3283 - acc: 0.8066 - val_loss: 1.3416 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 18th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4749 - acc: 0.7910 - val_loss: 1.3775 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3767 - acc: 0.7994 - val_loss: 1.6320 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 18th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3531 - acc: 0.8059 - val_loss: 1.2426 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 18th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3971 - acc: 0.8057 - val_loss: 1.3852 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 18th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4698 - acc: 0.7834 - val_loss: 1.3780 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 18th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3899 - acc: 0.8002 - val_loss: 1.2911 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 18th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4095 - acc: 0.7994 - val_loss: 1.5121 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 18th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4045 - acc: 0.8053 - val_loss: 1.2878 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 18th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4092 - acc: 0.7969 - val_loss: 1.5406 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 18th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3390 - acc: 0.8074 - val_loss: 1.3622 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 18th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3679 - acc: 0.8055 - val_loss: 1.4192 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 18th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4186 - acc: 0.7992 - val_loss: 1.4558 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 18th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4552 - acc: 0.7961 - val_loss: 1.5134 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4269 - acc: 0.7992 - val_loss: 1.4450 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3235 - acc: 0.8115 - val_loss: 1.3305 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 18th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3690 - acc: 0.8029 - val_loss: 1.6497 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 18th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4299 - acc: 0.8000 - val_loss: 1.2701 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 18th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4115 - acc: 0.7977 - val_loss: 1.4000 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4493 - acc: 0.7943 - val_loss: 1.2774 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 18th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3947 - acc: 0.8055 - val_loss: 1.5146 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4280 - acc: 0.7941 - val_loss: 1.4025 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 18th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4294 - acc: 0.7992 - val_loss: 1.4717 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 18th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5069 - acc: 0.7893 - val_loss: 1.5260 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4108 - acc: 0.7998 - val_loss: 1.5050 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 18th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4008 - acc: 0.8018 - val_loss: 1.3294 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 18th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4429 - acc: 0.7955 - val_loss: 1.3882 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 18th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4534 - acc: 0.7949 - val_loss: 1.4568 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4591 - acc: 0.7949 - val_loss: 1.3604 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 18th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4659 - acc: 0.7943 - val_loss: 1.4898 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 18th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3818 - acc: 0.8027 - val_loss: 1.3790 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 18th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4731 - acc: 0.7904 - val_loss: 1.7115 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 18th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3600 - acc: 0.8059 - val_loss: 1.3982 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 18th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4422 - acc: 0.7912 - val_loss: 1.4161 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4648 - acc: 0.7928 - val_loss: 1.2769 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 18th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4436 - acc: 0.7957 - val_loss: 1.3837 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 18th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3599 - acc: 0.8055 - val_loss: 1.5871 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5263 - acc: 0.7848 - val_loss: 1.3929 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 18th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3436 - acc: 0.8039 - val_loss: 1.4341 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3631 - acc: 0.8021 - val_loss: 1.1578 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 18th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3906 - acc: 0.7988 - val_loss: 1.4631 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4024 - acc: 0.8014 - val_loss: 1.5574 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 18th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4257 - acc: 0.7934 - val_loss: 1.5784 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 18th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4065 - acc: 0.7988 - val_loss: 1.5105 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 18th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4035 - acc: 0.8023 - val_loss: 1.4211 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5459 - acc: 0.7811 - val_loss: 1.3997 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 18th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4521 - acc: 0.7912 - val_loss: 1.4120 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4521 - acc: 0.7959 - val_loss: 1.6024 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 18th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4417 - acc: 0.7992 - val_loss: 1.4917 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4079 - acc: 0.8010 - val_loss: 1.4938 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 18th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4676 - acc: 0.7930 - val_loss: 1.2483 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 18th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4074 - acc: 0.7996 - val_loss: 1.3729 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 18th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4346 - acc: 0.7982 - val_loss: 1.3892 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3971 - acc: 0.8012 - val_loss: 1.3596 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3314 - acc: 0.8102 - val_loss: 1.5200 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4408 - acc: 0.7951 - val_loss: 1.4528 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 18th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4100 - acc: 0.8025 - val_loss: 1.4085 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3813 - acc: 0.8018 - val_loss: 1.3190 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 18th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4992 - acc: 0.7889 - val_loss: 1.2537 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 18th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3146 - acc: 0.8070 - val_loss: 1.4375 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4663 - acc: 0.7932 - val_loss: 1.3962 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 18th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3367 - acc: 0.8078 - val_loss: 1.4874 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3840 - acc: 0.7982 - val_loss: 1.3651 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4471 - acc: 0.7977 - val_loss: 1.6362 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 18th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4442 - acc: 0.7941 - val_loss: 1.4478 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4371 - acc: 0.7980 - val_loss: 1.4352 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 18th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4498 - acc: 0.7994 - val_loss: 1.3027 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 18th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3879 - acc: 0.7998 - val_loss: 1.2530 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 18th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3864 - acc: 0.8045 - val_loss: 1.5542 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5120 - acc: 0.7891 - val_loss: 1.4013 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 18th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4612 - acc: 0.7949 - val_loss: 1.4964 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 18th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3689 - acc: 0.8080 - val_loss: 1.4463 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3454 - acc: 0.8096 - val_loss: 1.4200 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 18th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4677 - acc: 0.7951 - val_loss: 1.5194 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 18th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4042 - acc: 0.7971 - val_loss: 1.4559 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3928 - acc: 0.7998 - val_loss: 1.4531 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 18th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4708 - acc: 0.7908 - val_loss: 1.6795 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 18th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3725 - acc: 0.8064 - val_loss: 1.3465 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4560 - acc: 0.7918 - val_loss: 1.3828 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4741 - acc: 0.7936 - val_loss: 1.4844 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 18th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4646 - acc: 0.7920 - val_loss: 1.3033 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 18th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4032 - acc: 0.7953 - val_loss: 1.5042 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 18th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5066 - acc: 0.7889 - val_loss: 1.3663 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4669 - acc: 0.7957 - val_loss: 1.2855 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 18th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4684 - acc: 0.7924 - val_loss: 1.5243 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 18th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3938 - acc: 0.8031 - val_loss: 1.4449 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 18th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3445 - acc: 0.8041 - val_loss: 1.4053 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3397 - acc: 0.8104 - val_loss: 1.1664 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 18th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4702 - acc: 0.7867 - val_loss: 1.4478 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 18th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3230 - acc: 0.8098 - val_loss: 1.5502 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 18th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4246 - acc: 0.7980 - val_loss: 1.2031 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 18th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5521 - acc: 0.7830 - val_loss: 1.4133 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 18th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3105 - acc: 0.8172 - val_loss: 1.3208 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3889 - acc: 0.8023 - val_loss: 1.4658 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 18th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4371 - acc: 0.7965 - val_loss: 1.5365 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 18th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3525 - acc: 0.8068 - val_loss: 1.3146 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 18th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3883 - acc: 0.8008 - val_loss: 1.4622 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4224 - acc: 0.7980 - val_loss: 1.4832 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4818 - acc: 0.7908 - val_loss: 1.6431 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 18th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3142 - acc: 0.8078 - val_loss: 1.5191 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 18th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4812 - acc: 0.7967 - val_loss: 1.4628 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 18th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4130 - acc: 0.7996 - val_loss: 1.3078 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 18th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4072 - acc: 0.8006 - val_loss: 1.3552 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 18th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3501 - acc: 0.8063 - val_loss: 1.5848 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 18th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4487 - acc: 0.7873 - val_loss: 1.4829 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 18th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4564 - acc: 0.7988 - val_loss: 1.3393 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 18th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4216 - acc: 0.7979 - val_loss: 1.3762 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4279 - acc: 0.7986 - val_loss: 1.4889 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3509 - acc: 0.8061 - val_loss: 1.4869 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4049 - acc: 0.8016 - val_loss: 1.3815 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4887 - acc: 0.7834 - val_loss: 1.3298 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 18th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4685 - acc: 0.7916 - val_loss: 1.4683 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 18th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4105 - acc: 0.7982 - val_loss: 1.4990 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 18th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4368 - acc: 0.8031 - val_loss: 1.4005 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 18th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4009 - acc: 0.7996 - val_loss: 1.3831 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 18th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4724 - acc: 0.7906 - val_loss: 1.4463 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 18th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3914 - acc: 0.7984 - val_loss: 1.3308 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 18th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3192 - acc: 0.8092 - val_loss: 1.5870 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 18th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4460 - acc: 0.7969 - val_loss: 1.4240 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 18th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5249 - acc: 0.7938 - val_loss: 1.3867 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 18th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3927 - acc: 0.8010 - val_loss: 1.4704 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4032 - acc: 0.8021 - val_loss: 1.3978 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4600 - acc: 0.7912 - val_loss: 1.5839 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 18th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3918 - acc: 0.8020 - val_loss: 1.5373 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 18th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4724 - acc: 0.7924 - val_loss: 1.3522 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 18th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4525 - acc: 0.7898 - val_loss: 1.6016 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 18th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.7996 - val_loss: 1.4825 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4367 - acc: 0.8000 - val_loss: 1.5337 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 18th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3944 - acc: 0.8020 - val_loss: 1.2291 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 18th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3902 - acc: 0.8020 - val_loss: 1.5803 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 18th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4383 - acc: 0.7941 - val_loss: 1.4477 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4103 - acc: 0.7986 - val_loss: 1.4844 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 18th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3713 - acc: 0.8088 - val_loss: 1.2311 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 18th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5165 - acc: 0.7912 - val_loss: 1.4391 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 18th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2955 - acc: 0.8113 - val_loss: 1.3315 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 18th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4597 - acc: 0.7916 - val_loss: 1.5516 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 18th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4292 - acc: 0.7961 - val_loss: 1.3265 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 18th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3751 - acc: 0.8086 - val_loss: 1.3719 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 18th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4506 - acc: 0.7959 - val_loss: 1.4556 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 18th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5074 - acc: 0.7889 - val_loss: 1.3504 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 18th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3366 - acc: 0.8107 - val_loss: 1.6152 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 18th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4079 - acc: 0.8082 - val_loss: 1.3487 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 18th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3624 - acc: 0.8047 - val_loss: 1.4252 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4100 - acc: 0.7988 - val_loss: 1.4601 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 18th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4353 - acc: 0.7967 - val_loss: 1.4519 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 18th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4508 - acc: 0.7928 - val_loss: 1.3999 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 18th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4739 - acc: 0.7889 - val_loss: 1.3043 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3802 - acc: 0.8008 - val_loss: 1.4815 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 18th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3560 - acc: 0.8102 - val_loss: 1.2748 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 18th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4053 - acc: 0.8014 - val_loss: 1.5202 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 18th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3548 - acc: 0.8047 - val_loss: 1.1694 - val_acc: 0.8359\n",
      "[INFO] Training model: epoch 18th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4539 - acc: 0.7922 - val_loss: 1.4899 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 18th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3520 - acc: 0.8027 - val_loss: 1.5360 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 18th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3259 - acc: 0.8104 - val_loss: 1.5547 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 18th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.4651 - acc: 0.7941 - val_loss: 1.0685 - val_acc: 0.8438\n",
      "[INFO] Training model: epoch 18th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4008 - acc: 0.8012 - val_loss: 1.4320 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 18th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3395 - acc: 0.8090 - val_loss: 1.4130 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 18th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3916 - acc: 0.8029 - val_loss: 1.4984 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 18th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3471 - acc: 0.8033 - val_loss: 1.3849 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 18th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4275 - acc: 0.7971 - val_loss: 1.5295 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 18th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5348 - acc: 0.7848 - val_loss: 1.4009 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 18th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3229 - acc: 0.8135 - val_loss: 1.3316 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 18th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3293 - acc: 0.8135 - val_loss: 1.3457 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.7996 - val_loss: 1.4751 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 19th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4683 - acc: 0.7891 - val_loss: 1.5259 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 19th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4368 - acc: 0.7920 - val_loss: 1.2866 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4038 - acc: 0.7953 - val_loss: 1.2120 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 19th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4544 - acc: 0.7910 - val_loss: 1.5218 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 19th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4123 - acc: 0.7984 - val_loss: 1.2960 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3341 - acc: 0.8025 - val_loss: 1.2396 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 19th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3732 - acc: 0.8014 - val_loss: 1.4875 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 19th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3591 - acc: 0.8018 - val_loss: 1.4701 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 19th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4156 - acc: 0.7990 - val_loss: 1.3954 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 19th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3374 - acc: 0.8084 - val_loss: 1.3328 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 19th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4199 - acc: 0.7912 - val_loss: 1.3666 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 19th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3456 - acc: 0.8014 - val_loss: 1.3551 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 19th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4039 - acc: 0.8000 - val_loss: 1.3293 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 19th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3252 - acc: 0.8080 - val_loss: 1.2764 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 19th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4353 - acc: 0.7914 - val_loss: 1.4504 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 19th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.8045 - val_loss: 1.1782 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 19th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3397 - acc: 0.8082 - val_loss: 1.3253 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4185 - acc: 0.7928 - val_loss: 1.4813 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3604 - acc: 0.8033 - val_loss: 1.1957 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 19th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3575 - acc: 0.8053 - val_loss: 1.2710 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 19th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3104 - acc: 0.8105 - val_loss: 1.3205 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 19th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5013 - acc: 0.7857 - val_loss: 1.4389 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4130 - acc: 0.7936 - val_loss: 1.3593 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3469 - acc: 0.8049 - val_loss: 1.2352 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 19th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4007 - acc: 0.7977 - val_loss: 1.5418 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 19th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4483 - acc: 0.7902 - val_loss: 1.5202 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 19th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3893 - acc: 0.8055 - val_loss: 1.3683 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4538 - acc: 0.7969 - val_loss: 1.3289 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3470 - acc: 0.8051 - val_loss: 1.2125 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 19th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3353 - acc: 0.8057 - val_loss: 1.2863 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 19th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3781 - acc: 0.8025 - val_loss: 1.2199 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 19th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3061 - acc: 0.8084 - val_loss: 1.5610 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 19th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3825 - acc: 0.7967 - val_loss: 1.3568 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3635 - acc: 0.7990 - val_loss: 1.3929 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 19th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4825 - acc: 0.7898 - val_loss: 1.4703 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 19th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3927 - acc: 0.8004 - val_loss: 1.5380 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 19th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3846 - acc: 0.7992 - val_loss: 1.2928 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 19th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3643 - acc: 0.8012 - val_loss: 1.4733 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 19th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4299 - acc: 0.7951 - val_loss: 1.1878 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 19th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3798 - acc: 0.8002 - val_loss: 1.4132 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4396 - acc: 0.7939 - val_loss: 1.6359 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 19th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3279 - acc: 0.8088 - val_loss: 1.2908 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 19th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3219 - acc: 0.8100 - val_loss: 1.3375 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4254 - acc: 0.7922 - val_loss: 1.4878 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 19th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3827 - acc: 0.7969 - val_loss: 1.5549 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 19th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4159 - acc: 0.7941 - val_loss: 1.3030 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 19th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3234 - acc: 0.8076 - val_loss: 1.2601 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 19th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4624 - acc: 0.7928 - val_loss: 1.3298 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3546 - acc: 0.8064 - val_loss: 1.4905 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 19th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3654 - acc: 0.8010 - val_loss: 1.3859 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 19th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4582 - acc: 0.7975 - val_loss: 1.2682 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 19th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3682 - acc: 0.8061 - val_loss: 1.4670 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 19th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4308 - acc: 0.7967 - val_loss: 1.4646 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 19th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3314 - acc: 0.8035 - val_loss: 1.3483 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3444 - acc: 0.8008 - val_loss: 1.4899 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 19th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4072 - acc: 0.7943 - val_loss: 1.2417 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 19th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4509 - acc: 0.7893 - val_loss: 1.2899 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4331 - acc: 0.7963 - val_loss: 1.3154 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 19th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3055 - acc: 0.8109 - val_loss: 1.5032 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 19th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3630 - acc: 0.8041 - val_loss: 1.4881 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3395 - acc: 0.8078 - val_loss: 1.1075 - val_acc: 0.8430\n",
      "[INFO] Training model: epoch 19th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3892 - acc: 0.7998 - val_loss: 1.3787 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4460 - acc: 0.7904 - val_loss: 1.4792 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4013 - acc: 0.7982 - val_loss: 1.5346 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4375 - acc: 0.7881 - val_loss: 1.3870 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3442 - acc: 0.7998 - val_loss: 1.5120 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 19th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3932 - acc: 0.7971 - val_loss: 1.5166 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 19th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4185 - acc: 0.7975 - val_loss: 1.3980 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 19th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4114 - acc: 0.7988 - val_loss: 1.2922 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 19th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3877 - acc: 0.7973 - val_loss: 1.3840 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3631 - acc: 0.8037 - val_loss: 1.3593 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3139 - acc: 0.8059 - val_loss: 1.4475 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 19th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3549 - acc: 0.8039 - val_loss: 1.1859 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 19th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4376 - acc: 0.7924 - val_loss: 1.4142 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3500 - acc: 0.8047 - val_loss: 1.2327 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 19th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2940 - acc: 0.8135 - val_loss: 1.2818 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 19th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3052 - acc: 0.8033 - val_loss: 1.5272 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 19th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4507 - acc: 0.7891 - val_loss: 1.3386 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 19th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4128 - acc: 0.7939 - val_loss: 1.5006 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 19th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4291 - acc: 0.7949 - val_loss: 1.3692 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 19th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3767 - acc: 0.8014 - val_loss: 1.4922 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 19th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3604 - acc: 0.8016 - val_loss: 1.5000 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 19th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3574 - acc: 0.8012 - val_loss: 1.3846 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 19th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.7973 - val_loss: 1.3616 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 19th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4347 - acc: 0.7965 - val_loss: 1.3707 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 19th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3376 - acc: 0.8084 - val_loss: 1.1411 - val_acc: 0.8336\n",
      "[INFO] Training model: epoch 19th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4369 - acc: 0.7936 - val_loss: 1.3880 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3826 - acc: 0.7971 - val_loss: 1.3068 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4536 - acc: 0.7900 - val_loss: 1.3500 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3691 - acc: 0.8045 - val_loss: 1.4208 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4405 - acc: 0.7926 - val_loss: 1.3469 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4261 - acc: 0.7977 - val_loss: 1.2833 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 19th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3792 - acc: 0.8064 - val_loss: 1.6256 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 19th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4123 - acc: 0.7955 - val_loss: 1.3794 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2956 - acc: 0.8100 - val_loss: 1.4667 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 19th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3339 - acc: 0.8084 - val_loss: 1.5862 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 19th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4514 - acc: 0.7945 - val_loss: 1.3589 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 19th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3540 - acc: 0.8082 - val_loss: 1.5397 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 19th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4490 - acc: 0.7924 - val_loss: 1.4294 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4258 - acc: 0.7965 - val_loss: 1.7584 - val_acc: 0.7523\n",
      "[INFO] Training model: epoch 19th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3089 - acc: 0.8123 - val_loss: 1.5377 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 19th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4015 - acc: 0.7943 - val_loss: 1.4278 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 19th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3860 - acc: 0.8051 - val_loss: 1.5271 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 19th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3916 - acc: 0.8041 - val_loss: 1.3021 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 19th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3638 - acc: 0.8057 - val_loss: 1.4172 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 19th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4665 - acc: 0.7930 - val_loss: 1.2863 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 19th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4337 - acc: 0.8000 - val_loss: 1.2749 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 19th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4113 - acc: 0.7984 - val_loss: 1.3382 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4045 - acc: 0.7947 - val_loss: 1.3226 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3557 - acc: 0.8078 - val_loss: 1.3448 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 19th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3777 - acc: 0.8039 - val_loss: 1.3999 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 19th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4071 - acc: 0.7979 - val_loss: 1.5834 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 19th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4068 - acc: 0.8008 - val_loss: 1.3883 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 19th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3518 - acc: 0.8080 - val_loss: 1.4396 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 19th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3819 - acc: 0.8021 - val_loss: 1.1936 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 19th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5230 - acc: 0.7836 - val_loss: 1.4090 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4136 - acc: 0.8010 - val_loss: 1.4657 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 19th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3893 - acc: 0.7988 - val_loss: 1.3081 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 19th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4459 - acc: 0.7990 - val_loss: 1.5023 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 19th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3795 - acc: 0.8016 - val_loss: 1.4251 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 19th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3849 - acc: 0.8021 - val_loss: 1.2685 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 19th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3725 - acc: 0.8035 - val_loss: 1.3044 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3503 - acc: 0.8068 - val_loss: 1.3177 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 19th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4811 - acc: 0.7920 - val_loss: 1.3643 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 19th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3885 - acc: 0.8031 - val_loss: 1.4079 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 19th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4073 - acc: 0.7977 - val_loss: 1.6467 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 19th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4144 - acc: 0.8018 - val_loss: 1.3901 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 19th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3437 - acc: 0.8070 - val_loss: 1.1914 - val_acc: 0.8297\n",
      "[INFO] Training model: epoch 19th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3553 - acc: 0.8047 - val_loss: 1.3337 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3881 - acc: 0.7996 - val_loss: 1.4596 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 19th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3379 - acc: 0.8129 - val_loss: 1.4189 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 19th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3830 - acc: 0.8037 - val_loss: 1.5327 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4396 - acc: 0.7930 - val_loss: 1.3607 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 19th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3370 - acc: 0.8102 - val_loss: 1.4955 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5108 - acc: 0.7801 - val_loss: 1.3027 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 19th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3824 - acc: 0.8021 - val_loss: 1.3776 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 19th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4492 - acc: 0.7957 - val_loss: 1.5800 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 19th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4382 - acc: 0.7926 - val_loss: 1.2758 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 19th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4128 - acc: 0.7951 - val_loss: 1.1828 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 19th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4626 - acc: 0.7936 - val_loss: 1.4168 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3488 - acc: 0.8072 - val_loss: 1.4389 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4241 - acc: 0.7975 - val_loss: 1.4649 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 19th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4708 - acc: 0.7924 - val_loss: 1.3377 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 19th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3416 - acc: 0.8104 - val_loss: 1.6438 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 19th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4683 - acc: 0.7920 - val_loss: 1.4304 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3544 - acc: 0.8043 - val_loss: 1.4320 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 19th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4449 - acc: 0.7980 - val_loss: 1.5243 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 19th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3519 - acc: 0.8096 - val_loss: 1.5569 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 19th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3712 - acc: 0.8051 - val_loss: 1.4118 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 19th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4227 - acc: 0.7951 - val_loss: 1.4076 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3391 - acc: 0.8088 - val_loss: 1.5320 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 19th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4085 - acc: 0.7959 - val_loss: 1.5052 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 19th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4806 - acc: 0.7904 - val_loss: 1.5961 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 19th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3887 - acc: 0.8043 - val_loss: 1.1587 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 19th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4507 - acc: 0.7934 - val_loss: 1.5414 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 19th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3516 - acc: 0.8074 - val_loss: 1.2052 - val_acc: 0.8297\n",
      "[INFO] Training model: epoch 19th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3782 - acc: 0.8037 - val_loss: 1.3472 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5222 - acc: 0.7863 - val_loss: 1.3722 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 19th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4315 - acc: 0.7971 - val_loss: 1.2574 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3631 - acc: 0.7992 - val_loss: 1.3868 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 19th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3929 - acc: 0.8021 - val_loss: 1.3331 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 19th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4815 - acc: 0.7881 - val_loss: 1.4499 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5184 - acc: 0.7828 - val_loss: 1.3558 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 19th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4159 - acc: 0.7988 - val_loss: 1.3659 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 19th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4735 - acc: 0.7924 - val_loss: 1.2881 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 19th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3455 - acc: 0.8092 - val_loss: 1.4769 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 19th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3786 - acc: 0.8047 - val_loss: 1.3224 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 19th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4834 - acc: 0.7879 - val_loss: 1.3179 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 19th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4156 - acc: 0.8047 - val_loss: 1.5255 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4930 - acc: 0.7854 - val_loss: 1.4855 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 19th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3840 - acc: 0.7941 - val_loss: 1.4456 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 19th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3881 - acc: 0.8033 - val_loss: 1.3435 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 19th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4803 - acc: 0.7926 - val_loss: 1.4603 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4833 - acc: 0.7889 - val_loss: 1.3859 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4523 - acc: 0.7969 - val_loss: 1.3514 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 19th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4108 - acc: 0.7936 - val_loss: 1.3478 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3978 - acc: 0.8000 - val_loss: 1.2357 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 19th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4573 - acc: 0.7918 - val_loss: 1.4320 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3335 - acc: 0.8092 - val_loss: 1.4316 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3852 - acc: 0.8031 - val_loss: 1.3764 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 19th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4030 - acc: 0.8025 - val_loss: 1.4401 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 19th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3029 - acc: 0.8137 - val_loss: 1.5005 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3712 - acc: 0.8063 - val_loss: 1.3667 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4471 - acc: 0.7969 - val_loss: 1.3151 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 19th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3832 - acc: 0.8059 - val_loss: 1.4442 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 19th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3753 - acc: 0.8037 - val_loss: 1.4811 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 19th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4254 - acc: 0.7951 - val_loss: 1.1516 - val_acc: 0.8422\n",
      "[INFO] Training model: epoch 19th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4282 - acc: 0.7996 - val_loss: 1.2851 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4753 - acc: 0.7941 - val_loss: 1.2921 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3969 - acc: 0.8002 - val_loss: 1.4555 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3957 - acc: 0.8082 - val_loss: 1.2871 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 19th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3158 - acc: 0.8113 - val_loss: 1.3900 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 19th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4367 - acc: 0.7977 - val_loss: 1.5908 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 19th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3878 - acc: 0.8021 - val_loss: 1.4624 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 19th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4427 - acc: 0.7963 - val_loss: 1.4631 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 19th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4488 - acc: 0.7957 - val_loss: 1.3342 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4443 - acc: 0.7988 - val_loss: 1.2553 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 19th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4706 - acc: 0.7941 - val_loss: 1.5136 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 19th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4136 - acc: 0.7979 - val_loss: 1.3518 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 19th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3235 - acc: 0.8051 - val_loss: 1.4394 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4640 - acc: 0.7947 - val_loss: 1.4797 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 19th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4112 - acc: 0.7980 - val_loss: 1.5590 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 19th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3002 - acc: 0.8090 - val_loss: 1.3785 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 19th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4506 - acc: 0.7922 - val_loss: 1.4323 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 19th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4123 - acc: 0.8010 - val_loss: 1.5544 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 19th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3557 - acc: 0.8102 - val_loss: 1.2645 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 19th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4122 - acc: 0.7984 - val_loss: 1.4065 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 19th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3760 - acc: 0.8016 - val_loss: 1.5722 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 19th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3545 - acc: 0.8043 - val_loss: 1.2528 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 19th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3720 - acc: 0.8049 - val_loss: 1.3889 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4006 - acc: 0.8021 - val_loss: 1.2558 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 19th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4194 - acc: 0.7975 - val_loss: 1.5590 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 19th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4962 - acc: 0.7936 - val_loss: 1.3991 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3978 - acc: 0.8018 - val_loss: 1.2303 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 19th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3829 - acc: 0.8020 - val_loss: 1.3427 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 19th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3805 - acc: 0.8012 - val_loss: 1.3631 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4386 - acc: 0.7951 - val_loss: 1.3940 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3949 - acc: 0.7998 - val_loss: 1.3080 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 19th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4436 - acc: 0.7975 - val_loss: 1.3953 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 19th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3875 - acc: 0.8006 - val_loss: 1.3579 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 19th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3529 - acc: 0.8035 - val_loss: 1.5214 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 19th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3941 - acc: 0.8023 - val_loss: 1.4005 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 19th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4834 - acc: 0.7898 - val_loss: 1.5205 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 19th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3928 - acc: 0.8014 - val_loss: 1.4513 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 19th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4057 - acc: 0.7979 - val_loss: 1.4045 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4118 - acc: 0.7957 - val_loss: 1.3835 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 19th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4572 - acc: 0.7969 - val_loss: 1.2484 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 19th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4406 - acc: 0.7930 - val_loss: 1.5176 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 19th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3855 - acc: 0.8000 - val_loss: 1.4207 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 19th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4379 - acc: 0.7988 - val_loss: 1.3796 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 19th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4445 - acc: 0.7934 - val_loss: 1.5764 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 19th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3870 - acc: 0.8072 - val_loss: 1.3879 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3329 - acc: 0.8166 - val_loss: 1.4971 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 19th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4120 - acc: 0.7928 - val_loss: 1.3760 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 19th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3725 - acc: 0.8006 - val_loss: 1.5119 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 19th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3679 - acc: 0.8049 - val_loss: 1.3908 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 19th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3755 - acc: 0.8045 - val_loss: 1.4342 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 19th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3913 - acc: 0.8020 - val_loss: 1.4322 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 19th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3743 - acc: 0.8041 - val_loss: 1.3939 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 19th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3531 - acc: 0.8100 - val_loss: 1.5516 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 19th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3709 - acc: 0.8051 - val_loss: 1.2861 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 19th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5207 - acc: 0.7830 - val_loss: 1.1959 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 19th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4300 - acc: 0.7984 - val_loss: 1.3508 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 19th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4013 - acc: 0.8031 - val_loss: 1.3486 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 19th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4238 - acc: 0.7988 - val_loss: 1.4592 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 19th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5094 - acc: 0.7865 - val_loss: 1.3728 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 19th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4885 - acc: 0.7910 - val_loss: 1.4216 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 19th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3550 - acc: 0.8070 - val_loss: 1.2495 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 19th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4483 - acc: 0.7992 - val_loss: 1.6233 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 20th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3134 - acc: 0.8094 - val_loss: 1.4526 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3533 - acc: 0.7990 - val_loss: 1.5521 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 20th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.7982 - val_loss: 1.4094 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 20th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3950 - acc: 0.7977 - val_loss: 1.3752 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5267 - acc: 0.7820 - val_loss: 1.3039 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 20th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5198 - acc: 0.7816 - val_loss: 1.3805 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 20th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3688 - acc: 0.8000 - val_loss: 1.2916 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3260 - acc: 0.8096 - val_loss: 1.4509 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 20th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3396 - acc: 0.8027 - val_loss: 1.3460 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4010 - acc: 0.7951 - val_loss: 1.3827 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3029 - acc: 0.8107 - val_loss: 1.2614 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 20th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3632 - acc: 0.8000 - val_loss: 1.5172 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 20th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3240 - acc: 0.8068 - val_loss: 1.3877 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 20th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4242 - acc: 0.7918 - val_loss: 1.2299 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 20th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3659 - acc: 0.8006 - val_loss: 1.3819 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 20th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4390 - acc: 0.7875 - val_loss: 1.2787 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 20th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4001 - acc: 0.7975 - val_loss: 1.3586 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4050 - acc: 0.8008 - val_loss: 1.3968 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 20th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3531 - acc: 0.8037 - val_loss: 1.4350 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4227 - acc: 0.7883 - val_loss: 1.2707 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3710 - acc: 0.8080 - val_loss: 1.3819 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 20th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3641 - acc: 0.8020 - val_loss: 1.3212 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 20th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3912 - acc: 0.7992 - val_loss: 1.2166 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 20th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4406 - acc: 0.7920 - val_loss: 1.3760 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 20th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3408 - acc: 0.8029 - val_loss: 1.4063 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4268 - acc: 0.7979 - val_loss: 1.3225 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4148 - acc: 0.7893 - val_loss: 1.3788 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3794 - acc: 0.7967 - val_loss: 1.3045 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3833 - acc: 0.7998 - val_loss: 1.4058 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 20th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3934 - acc: 0.7996 - val_loss: 1.5653 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 20th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3426 - acc: 0.8033 - val_loss: 1.1034 - val_acc: 0.8398\n",
      "[INFO] Training model: epoch 20th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4034 - acc: 0.7988 - val_loss: 1.2266 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 20th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4205 - acc: 0.7982 - val_loss: 1.4644 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 20th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3585 - acc: 0.7994 - val_loss: 1.5162 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 20th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3694 - acc: 0.8006 - val_loss: 1.3461 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3769 - acc: 0.8012 - val_loss: 1.4739 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 20th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3046 - acc: 0.8084 - val_loss: 1.2168 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 20th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3717 - acc: 0.8039 - val_loss: 1.3820 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3144 - acc: 0.8066 - val_loss: 1.3987 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 20th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4799 - acc: 0.7883 - val_loss: 1.3352 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3402 - acc: 0.8055 - val_loss: 1.4266 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3463 - acc: 0.8006 - val_loss: 1.3273 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 20th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3155 - acc: 0.8129 - val_loss: 1.3149 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4161 - acc: 0.7961 - val_loss: 1.3291 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 20th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3902 - acc: 0.8041 - val_loss: 1.3957 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 20th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4391 - acc: 0.7973 - val_loss: 1.3477 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 20th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.7980 - val_loss: 1.3287 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 20th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2361 - acc: 0.8160 - val_loss: 1.5068 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2887 - acc: 0.8080 - val_loss: 1.3285 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 20th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4671 - acc: 0.7906 - val_loss: 1.3053 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 20th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4123 - acc: 0.7984 - val_loss: 1.3072 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2642 - acc: 0.8094 - val_loss: 1.5510 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 20th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3525 - acc: 0.8031 - val_loss: 1.2424 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 20th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3966 - acc: 0.7982 - val_loss: 1.3118 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 20th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3308 - acc: 0.8076 - val_loss: 1.3456 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 20th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3351 - acc: 0.8064 - val_loss: 1.3981 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 20th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3647 - acc: 0.8053 - val_loss: 1.4950 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4102 - acc: 0.7969 - val_loss: 1.2650 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 20th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3558 - acc: 0.8035 - val_loss: 1.4006 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3683 - acc: 0.8037 - val_loss: 1.3839 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3576 - acc: 0.8031 - val_loss: 1.4242 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3507 - acc: 0.8061 - val_loss: 1.2868 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 20th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3398 - acc: 0.8082 - val_loss: 1.4706 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3511 - acc: 0.8041 - val_loss: 1.1921 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 20th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3348 - acc: 0.8018 - val_loss: 1.3480 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 20th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7949 - val_loss: 1.3792 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 20th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4245 - acc: 0.7984 - val_loss: 1.3095 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3826 - acc: 0.8043 - val_loss: 1.5007 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 20th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4460 - acc: 0.7926 - val_loss: 1.3214 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 20th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4539 - acc: 0.7947 - val_loss: 1.4377 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4024 - acc: 0.7973 - val_loss: 1.4859 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 20th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3558 - acc: 0.8043 - val_loss: 1.4520 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 20th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3914 - acc: 0.7990 - val_loss: 1.4468 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3621 - acc: 0.8045 - val_loss: 1.4479 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2909 - acc: 0.8178 - val_loss: 1.4853 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 20th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4078 - acc: 0.8002 - val_loss: 1.1511 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 20th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3578 - acc: 0.8023 - val_loss: 1.3334 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 20th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3697 - acc: 0.8039 - val_loss: 1.3766 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3841 - acc: 0.7947 - val_loss: 1.2830 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 20th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3539 - acc: 0.8029 - val_loss: 1.2673 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 20th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3990 - acc: 0.8020 - val_loss: 1.3073 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3895 - acc: 0.8045 - val_loss: 1.4198 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 20th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3312 - acc: 0.8072 - val_loss: 1.4286 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4987 - acc: 0.7865 - val_loss: 1.1291 - val_acc: 0.8336\n",
      "[INFO] Training model: epoch 20th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3642 - acc: 0.8049 - val_loss: 1.3181 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 20th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3392 - acc: 0.8070 - val_loss: 1.3270 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 20th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4035 - acc: 0.7943 - val_loss: 1.4820 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 20th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3434 - acc: 0.8006 - val_loss: 1.4775 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 20th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3352 - acc: 0.8053 - val_loss: 1.3155 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 20th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4127 - acc: 0.7930 - val_loss: 1.5801 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 20th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3011 - acc: 0.8053 - val_loss: 1.4184 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4467 - acc: 0.7904 - val_loss: 1.4215 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 20th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3448 - acc: 0.8049 - val_loss: 1.3919 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4558 - acc: 0.7854 - val_loss: 1.3127 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 20th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3412 - acc: 0.8074 - val_loss: 1.4964 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 20th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3639 - acc: 0.7988 - val_loss: 1.3414 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 20th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3491 - acc: 0.8053 - val_loss: 1.4561 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3971 - acc: 0.7982 - val_loss: 1.3737 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4918 - acc: 0.7887 - val_loss: 1.3994 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 20th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3449 - acc: 0.8031 - val_loss: 1.4364 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 20th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4204 - acc: 0.7957 - val_loss: 1.1660 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 20th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4211 - acc: 0.7932 - val_loss: 1.3442 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3791 - acc: 0.8014 - val_loss: 1.2989 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 20th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2535 - acc: 0.8227 - val_loss: 1.4348 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3689 - acc: 0.8025 - val_loss: 1.3499 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4617 - acc: 0.7883 - val_loss: 1.4085 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 20th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5414 - acc: 0.7828 - val_loss: 1.4241 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 20th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4573 - acc: 0.7934 - val_loss: 1.4572 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4232 - acc: 0.7961 - val_loss: 1.5367 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 20th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4770 - acc: 0.7889 - val_loss: 1.3713 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 20th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3393 - acc: 0.8041 - val_loss: 1.5334 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 20th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3416 - acc: 0.8021 - val_loss: 1.4069 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2968 - acc: 0.8129 - val_loss: 1.5114 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 20th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3751 - acc: 0.7988 - val_loss: 1.2171 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 20th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3789 - acc: 0.8041 - val_loss: 1.4304 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 20th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3091 - acc: 0.8082 - val_loss: 1.3613 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 20th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4405 - acc: 0.7887 - val_loss: 1.3293 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 20th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3734 - acc: 0.8037 - val_loss: 1.3770 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4047 - acc: 0.8004 - val_loss: 1.4602 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 20th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4280 - acc: 0.8000 - val_loss: 1.3106 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4007 - acc: 0.7998 - val_loss: 1.3643 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2807 - acc: 0.8135 - val_loss: 1.4692 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 20th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4417 - acc: 0.7941 - val_loss: 1.4104 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4696 - acc: 0.7922 - val_loss: 1.4946 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4347 - acc: 0.7973 - val_loss: 1.2745 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 20th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3428 - acc: 0.8076 - val_loss: 1.3962 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 20th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3744 - acc: 0.8021 - val_loss: 1.4574 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4437 - acc: 0.7920 - val_loss: 1.3251 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3439 - acc: 0.8059 - val_loss: 1.4512 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3875 - acc: 0.7998 - val_loss: 1.2837 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 20th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.8033 - val_loss: 1.3272 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 20th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4128 - acc: 0.7947 - val_loss: 1.3527 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3468 - acc: 0.8094 - val_loss: 1.4095 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 20th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4806 - acc: 0.7906 - val_loss: 1.3571 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3245 - acc: 0.8012 - val_loss: 1.3889 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3586 - acc: 0.8025 - val_loss: 1.2652 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 20th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3235 - acc: 0.8059 - val_loss: 1.3759 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3416 - acc: 0.8031 - val_loss: 1.2889 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 20th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3513 - acc: 0.8014 - val_loss: 1.5176 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 20th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3711 - acc: 0.8057 - val_loss: 1.3762 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4555 - acc: 0.7924 - val_loss: 1.4498 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 20th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3664 - acc: 0.8047 - val_loss: 1.5387 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 20th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3375 - acc: 0.8023 - val_loss: 1.3612 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3507 - acc: 0.7951 - val_loss: 1.4553 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3541 - acc: 0.8033 - val_loss: 1.3145 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 20th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5063 - acc: 0.7879 - val_loss: 1.2243 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 20th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4223 - acc: 0.7930 - val_loss: 1.4772 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 20th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4246 - acc: 0.7951 - val_loss: 1.4427 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3682 - acc: 0.8020 - val_loss: 1.4012 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4184 - acc: 0.7984 - val_loss: 1.3520 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 20th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4507 - acc: 0.7957 - val_loss: 1.3536 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4277 - acc: 0.7979 - val_loss: 1.4735 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 20th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4169 - acc: 0.7971 - val_loss: 1.4624 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 20th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4256 - acc: 0.7961 - val_loss: 1.3488 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 20th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5191 - acc: 0.7830 - val_loss: 1.1032 - val_acc: 0.8305\n",
      "[INFO] Training model: epoch 20th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3183 - acc: 0.8098 - val_loss: 1.3342 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3913 - acc: 0.8041 - val_loss: 1.2269 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 20th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4084 - acc: 0.7988 - val_loss: 1.2975 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 20th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4395 - acc: 0.7893 - val_loss: 1.2545 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4024 - acc: 0.8004 - val_loss: 1.4723 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 20th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3932 - acc: 0.8016 - val_loss: 1.4298 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3944 - acc: 0.7973 - val_loss: 1.0900 - val_acc: 0.8398\n",
      "[INFO] Training model: epoch 20th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3869 - acc: 0.8047 - val_loss: 1.2372 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 20th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4126 - acc: 0.7998 - val_loss: 1.3181 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 20th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3149 - acc: 0.8076 - val_loss: 1.4191 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 20th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3070 - acc: 0.8076 - val_loss: 1.4887 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 20th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4442 - acc: 0.7914 - val_loss: 1.3334 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3610 - acc: 0.8039 - val_loss: 1.4122 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3597 - acc: 0.8041 - val_loss: 1.3362 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3279 - acc: 0.8061 - val_loss: 1.2408 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 20th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3572 - acc: 0.8053 - val_loss: 1.2894 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 20th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4392 - acc: 0.7986 - val_loss: 1.4655 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3376 - acc: 0.8104 - val_loss: 1.3554 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 20th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3858 - acc: 0.8029 - val_loss: 1.4833 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 20th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4071 - acc: 0.8002 - val_loss: 1.2812 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 20th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4296 - acc: 0.7994 - val_loss: 1.3981 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 20th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4476 - acc: 0.7932 - val_loss: 1.6739 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 20th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3736 - acc: 0.8029 - val_loss: 1.4218 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4702 - acc: 0.7918 - val_loss: 1.4129 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4086 - acc: 0.8016 - val_loss: 1.5674 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 20th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4643 - acc: 0.7938 - val_loss: 1.2792 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4455 - acc: 0.7994 - val_loss: 1.3248 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3648 - acc: 0.8064 - val_loss: 1.6515 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 20th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3303 - acc: 0.8098 - val_loss: 1.3614 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 20th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3533 - acc: 0.8045 - val_loss: 1.4363 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 20th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3944 - acc: 0.8002 - val_loss: 1.4514 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3496 - acc: 0.8055 - val_loss: 1.4287 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 20th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5049 - acc: 0.7896 - val_loss: 1.4216 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 20th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3679 - acc: 0.7984 - val_loss: 1.3710 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3743 - acc: 0.8055 - val_loss: 1.5608 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 20th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3832 - acc: 0.8043 - val_loss: 1.4325 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3288 - acc: 0.8137 - val_loss: 1.3252 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 20th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3607 - acc: 0.8086 - val_loss: 1.4601 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 20th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4546 - acc: 0.7910 - val_loss: 1.3913 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 20th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4722 - acc: 0.7896 - val_loss: 1.3078 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 20th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3749 - acc: 0.8049 - val_loss: 1.3829 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 20th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4360 - acc: 0.7965 - val_loss: 1.5003 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4633 - acc: 0.7912 - val_loss: 1.4062 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 20th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3897 - acc: 0.8002 - val_loss: 1.2638 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 20th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4784 - acc: 0.7900 - val_loss: 1.4228 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 20th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3739 - acc: 0.8039 - val_loss: 1.4583 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3693 - acc: 0.8074 - val_loss: 1.4212 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 20th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4868 - acc: 0.7873 - val_loss: 1.3499 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 20th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4703 - acc: 0.7988 - val_loss: 1.5046 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 20th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4411 - acc: 0.7949 - val_loss: 1.3392 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 20th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3220 - acc: 0.8127 - val_loss: 1.5705 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 20th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3301 - acc: 0.8098 - val_loss: 1.3983 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 20th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3605 - acc: 0.7992 - val_loss: 1.4592 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 20th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3670 - acc: 0.8055 - val_loss: 1.3986 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 20th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4206 - acc: 0.8023 - val_loss: 1.1035 - val_acc: 0.8438\n",
      "[INFO] Training model: epoch 20th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3626 - acc: 0.8053 - val_loss: 1.3876 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 20th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4317 - acc: 0.7973 - val_loss: 1.6170 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 20th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3969 - acc: 0.7949 - val_loss: 1.3247 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4159 - acc: 0.7971 - val_loss: 1.2680 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 20th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4048 - acc: 0.8020 - val_loss: 1.3433 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 20th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3949 - acc: 0.7996 - val_loss: 1.4057 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 20th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3117 - acc: 0.8098 - val_loss: 1.2631 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 20th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3937 - acc: 0.7938 - val_loss: 1.5279 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 20th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3465 - acc: 0.8082 - val_loss: 1.4913 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 20th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4002 - acc: 0.8055 - val_loss: 1.4322 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4553 - acc: 0.7947 - val_loss: 1.4303 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4163 - acc: 0.8033 - val_loss: 1.5590 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 20th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4700 - acc: 0.7881 - val_loss: 1.4423 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 20th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4010 - acc: 0.7963 - val_loss: 1.5134 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 20th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4051 - acc: 0.8018 - val_loss: 1.5111 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 20th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3537 - acc: 0.8043 - val_loss: 1.4025 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 20th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5685 - acc: 0.7855 - val_loss: 1.3452 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 20th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4547 - acc: 0.7891 - val_loss: 1.4569 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 20th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4471 - acc: 0.7922 - val_loss: 1.3793 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 20th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4780 - acc: 0.7910 - val_loss: 1.5960 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 20th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2852 - acc: 0.8125 - val_loss: 1.3518 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 20th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4123 - acc: 0.7965 - val_loss: 1.4725 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 20th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3958 - acc: 0.8018 - val_loss: 1.4047 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 20th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3569 - acc: 0.8055 - val_loss: 1.4529 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 20th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3595 - acc: 0.8076 - val_loss: 1.3376 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 20th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4129 - acc: 0.8025 - val_loss: 1.2416 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 20th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4038 - acc: 0.8004 - val_loss: 1.2994 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 20th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3897 - acc: 0.7980 - val_loss: 1.2488 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 20th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3220 - acc: 0.8080 - val_loss: 1.1786 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 20th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3530 - acc: 0.8014 - val_loss: 1.4281 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4101 - acc: 0.8012 - val_loss: 1.5038 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 20th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3994 - acc: 0.7986 - val_loss: 1.4283 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 20th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4680 - acc: 0.7900 - val_loss: 1.1326 - val_acc: 0.8383\n",
      "[INFO] Training model: epoch 20th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4020 - acc: 0.7961 - val_loss: 1.3013 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 20th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4789 - acc: 0.7926 - val_loss: 1.2917 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 20th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3661 - acc: 0.8057 - val_loss: 1.3945 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 20th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3307 - acc: 0.8055 - val_loss: 1.4338 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 20th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4553 - acc: 0.7977 - val_loss: 1.4757 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 20th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4704 - acc: 0.7945 - val_loss: 1.2908 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 20th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3790 - acc: 0.8020 - val_loss: 1.2871 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3351 - acc: 0.8084 - val_loss: 1.3338 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 21th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.1823 - acc: 0.8203 - val_loss: 1.3727 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3398 - acc: 0.8021 - val_loss: 1.3133 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 21th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2965 - acc: 0.8080 - val_loss: 1.2934 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3997 - acc: 0.7979 - val_loss: 1.2611 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3902 - acc: 0.7992 - val_loss: 1.2541 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 21th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3632 - acc: 0.8004 - val_loss: 1.5409 - val_acc: 0.7727\n",
      "[INFO] Training model: epoch 21th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2986 - acc: 0.8096 - val_loss: 1.3331 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 21th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3682 - acc: 0.7979 - val_loss: 1.5355 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 21th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4084 - acc: 0.7943 - val_loss: 1.4678 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 21th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3589 - acc: 0.7957 - val_loss: 1.3504 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 21th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3260 - acc: 0.8078 - val_loss: 1.3614 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3108 - acc: 0.8092 - val_loss: 1.6371 - val_acc: 0.7609\n",
      "[INFO] Training model: epoch 21th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4178 - acc: 0.7975 - val_loss: 1.2999 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3007 - acc: 0.8084 - val_loss: 1.4362 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 21th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4088 - acc: 0.7965 - val_loss: 1.2968 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3111 - acc: 0.8068 - val_loss: 1.4216 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3722 - acc: 0.8033 - val_loss: 1.2953 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3671 - acc: 0.8008 - val_loss: 1.2718 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4003 - acc: 0.7926 - val_loss: 1.3616 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 21th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4347 - acc: 0.7949 - val_loss: 1.4331 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 21th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3536 - acc: 0.8041 - val_loss: 1.1901 - val_acc: 0.8367\n",
      "[INFO] Training model: epoch 21th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4096 - acc: 0.7951 - val_loss: 1.2918 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2905 - acc: 0.8082 - val_loss: 1.3544 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3785 - acc: 0.7980 - val_loss: 1.3874 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 21th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3695 - acc: 0.8008 - val_loss: 1.3557 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4219 - acc: 0.8000 - val_loss: 1.3200 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4447 - acc: 0.7895 - val_loss: 1.2074 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4639 - acc: 0.7893 - val_loss: 1.4762 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 21th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3697 - acc: 0.8016 - val_loss: 1.3065 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 21th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3469 - acc: 0.8029 - val_loss: 1.4045 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3125 - acc: 0.8045 - val_loss: 1.4257 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 21th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3438 - acc: 0.8090 - val_loss: 1.2159 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 21th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3688 - acc: 0.8045 - val_loss: 1.4248 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3657 - acc: 0.7967 - val_loss: 1.5587 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 21th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3494 - acc: 0.8004 - val_loss: 1.2080 - val_acc: 0.8352\n",
      "[INFO] Training model: epoch 21th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4154 - acc: 0.7941 - val_loss: 1.4198 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4062 - acc: 0.7992 - val_loss: 1.2345 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 21th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3875 - acc: 0.7982 - val_loss: 1.3312 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3170 - acc: 0.8080 - val_loss: 1.4082 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 21th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3068 - acc: 0.8027 - val_loss: 1.3904 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3533 - acc: 0.8021 - val_loss: 1.3632 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3933 - acc: 0.8020 - val_loss: 1.3769 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4627 - acc: 0.7893 - val_loss: 1.4083 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 21th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3562 - acc: 0.8020 - val_loss: 1.6293 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 21th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3430 - acc: 0.8043 - val_loss: 1.2354 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 21th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4057 - acc: 0.8002 - val_loss: 1.3910 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 21th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3589 - acc: 0.7982 - val_loss: 1.3553 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4260 - acc: 0.7926 - val_loss: 1.3365 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2730 - acc: 0.8129 - val_loss: 1.3181 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 21th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3689 - acc: 0.7992 - val_loss: 1.3317 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 21th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3106 - acc: 0.8066 - val_loss: 1.2707 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 21th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3315 - acc: 0.8076 - val_loss: 1.2685 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 21th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3102 - acc: 0.7998 - val_loss: 1.4309 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 21th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3367 - acc: 0.8053 - val_loss: 1.2445 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 21th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3695 - acc: 0.8004 - val_loss: 1.3398 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3562 - acc: 0.7986 - val_loss: 1.3970 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3419 - acc: 0.8035 - val_loss: 1.2173 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 21th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4613 - acc: 0.7920 - val_loss: 1.2878 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 21th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4638 - acc: 0.7846 - val_loss: 1.2925 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3669 - acc: 0.8078 - val_loss: 1.3552 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2470 - acc: 0.8172 - val_loss: 1.4687 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 21th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3761 - acc: 0.8020 - val_loss: 1.4271 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 21th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3332 - acc: 0.8006 - val_loss: 1.3745 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4530 - acc: 0.7896 - val_loss: 1.4351 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 21th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4324 - acc: 0.7900 - val_loss: 1.6281 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 21th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3365 - acc: 0.8066 - val_loss: 1.4218 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3434 - acc: 0.8049 - val_loss: 1.4076 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 21th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4005 - acc: 0.7961 - val_loss: 1.2982 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 21th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4202 - acc: 0.7973 - val_loss: 1.3858 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2787 - acc: 0.8160 - val_loss: 1.4525 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 21th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4307 - acc: 0.7924 - val_loss: 1.4516 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3600 - acc: 0.8033 - val_loss: 1.3632 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 21th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4054 - acc: 0.8014 - val_loss: 1.4491 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4510 - acc: 0.7885 - val_loss: 1.3440 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2668 - acc: 0.8135 - val_loss: 1.4116 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 21th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3717 - acc: 0.8080 - val_loss: 1.4079 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 21th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3794 - acc: 0.8035 - val_loss: 1.4035 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3648 - acc: 0.7953 - val_loss: 1.3418 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3725 - acc: 0.8078 - val_loss: 1.4142 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 21th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4061 - acc: 0.7998 - val_loss: 1.4703 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 21th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3362 - acc: 0.8016 - val_loss: 1.2197 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 21th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3696 - acc: 0.8031 - val_loss: 1.3264 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4386 - acc: 0.7984 - val_loss: 1.5607 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 21th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3932 - acc: 0.7939 - val_loss: 1.3769 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 21th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3878 - acc: 0.8016 - val_loss: 1.4570 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3165 - acc: 0.8039 - val_loss: 1.3865 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 21th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3687 - acc: 0.8041 - val_loss: 1.3457 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4192 - acc: 0.7949 - val_loss: 1.1683 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 21th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5045 - acc: 0.7854 - val_loss: 1.3795 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 21th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3459 - acc: 0.8078 - val_loss: 1.5064 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 21th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3739 - acc: 0.8039 - val_loss: 1.4060 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 21th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3846 - acc: 0.7975 - val_loss: 1.4163 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 21th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3538 - acc: 0.8020 - val_loss: 1.4683 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 21th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3881 - acc: 0.7992 - val_loss: 1.2216 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 21th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3294 - acc: 0.8094 - val_loss: 1.4656 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 21th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4017 - acc: 0.7961 - val_loss: 1.2460 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4140 - acc: 0.7977 - val_loss: 1.2820 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3210 - acc: 0.8070 - val_loss: 1.4784 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 21th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3180 - acc: 0.8139 - val_loss: 1.3913 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 21th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3786 - acc: 0.7998 - val_loss: 1.3063 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4121 - acc: 0.7988 - val_loss: 1.3761 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4704 - acc: 0.7877 - val_loss: 1.2886 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 21th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4293 - acc: 0.7939 - val_loss: 1.3825 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 21th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3482 - acc: 0.8018 - val_loss: 1.4855 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 21th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3669 - acc: 0.8066 - val_loss: 1.4982 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 21th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3296 - acc: 0.8109 - val_loss: 1.5085 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 21th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4403 - acc: 0.7959 - val_loss: 1.2140 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 21th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4907 - acc: 0.7938 - val_loss: 1.4714 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 21th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4276 - acc: 0.7922 - val_loss: 1.0832 - val_acc: 0.8344\n",
      "[INFO] Training model: epoch 21th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3445 - acc: 0.8074 - val_loss: 1.1880 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4151 - acc: 0.7945 - val_loss: 1.1602 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 21th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4629 - acc: 0.7896 - val_loss: 1.3475 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 21th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4354 - acc: 0.7912 - val_loss: 1.3467 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3183 - acc: 0.8064 - val_loss: 1.3406 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 21th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3856 - acc: 0.8029 - val_loss: 1.5012 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 21th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3872 - acc: 0.7998 - val_loss: 1.3437 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 21th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3731 - acc: 0.8031 - val_loss: 1.3942 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3854 - acc: 0.8027 - val_loss: 1.2933 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 21th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3821 - acc: 0.7998 - val_loss: 1.3956 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3449 - acc: 0.8035 - val_loss: 1.3599 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4029 - acc: 0.7988 - val_loss: 1.2507 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 21th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3131 - acc: 0.8094 - val_loss: 1.3975 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 21th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3979 - acc: 0.7990 - val_loss: 1.3716 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3392 - acc: 0.8090 - val_loss: 1.2511 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5106 - acc: 0.7883 - val_loss: 1.3411 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4022 - acc: 0.7941 - val_loss: 1.2853 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 21th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2824 - acc: 0.8115 - val_loss: 1.4877 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3790 - acc: 0.8041 - val_loss: 1.2688 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 21th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4098 - acc: 0.7969 - val_loss: 1.3703 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 21th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3638 - acc: 0.8010 - val_loss: 1.5864 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 21th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3885 - acc: 0.7957 - val_loss: 1.3358 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 21th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2469 - acc: 0.8154 - val_loss: 1.3624 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4039 - acc: 0.7959 - val_loss: 1.2643 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2988 - acc: 0.8102 - val_loss: 1.3755 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3063 - acc: 0.8105 - val_loss: 1.3340 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 21th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3833 - acc: 0.7982 - val_loss: 1.3965 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 21th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3397 - acc: 0.8074 - val_loss: 1.3697 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 21th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3284 - acc: 0.8059 - val_loss: 1.3872 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 21th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4356 - acc: 0.7969 - val_loss: 1.3297 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 21th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3929 - acc: 0.7949 - val_loss: 1.4058 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 21th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3359 - acc: 0.8059 - val_loss: 1.5405 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 21th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3800 - acc: 0.7980 - val_loss: 1.4670 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 21th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3729 - acc: 0.8037 - val_loss: 1.1791 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 21th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4760 - acc: 0.7900 - val_loss: 1.4076 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 21th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3262 - acc: 0.8045 - val_loss: 1.2842 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3155 - acc: 0.8131 - val_loss: 1.3384 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3502 - acc: 0.8109 - val_loss: 1.5555 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 21th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3536 - acc: 0.8033 - val_loss: 1.4604 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 21th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3422 - acc: 0.8068 - val_loss: 1.4189 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3516 - acc: 0.8064 - val_loss: 1.3854 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 21th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3281 - acc: 0.8059 - val_loss: 1.2422 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 21th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2802 - acc: 0.8143 - val_loss: 1.2977 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 21th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4149 - acc: 0.8027 - val_loss: 1.4527 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 21th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3760 - acc: 0.8023 - val_loss: 1.5270 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 21th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3762 - acc: 0.7996 - val_loss: 1.2823 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 21th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4950 - acc: 0.7865 - val_loss: 1.3232 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 21th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3882 - acc: 0.8000 - val_loss: 1.4695 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3393 - acc: 0.8055 - val_loss: 1.3372 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4180 - acc: 0.7990 - val_loss: 1.3346 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3907 - acc: 0.8014 - val_loss: 1.4586 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 21th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4172 - acc: 0.7977 - val_loss: 1.4808 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 21th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4227 - acc: 0.8000 - val_loss: 1.3060 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3885 - acc: 0.8018 - val_loss: 1.4272 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3712 - acc: 0.8002 - val_loss: 1.4401 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 21th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3919 - acc: 0.8045 - val_loss: 1.2573 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 21th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3703 - acc: 0.8039 - val_loss: 1.4779 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 21th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3686 - acc: 0.7965 - val_loss: 1.2276 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 21th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3866 - acc: 0.8031 - val_loss: 1.2639 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 21th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4446 - acc: 0.7930 - val_loss: 1.2172 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 21th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3764 - acc: 0.7980 - val_loss: 1.2958 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 21th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3069 - acc: 0.8117 - val_loss: 1.4685 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 21th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3392 - acc: 0.8098 - val_loss: 1.4634 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 21th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4017 - acc: 0.8008 - val_loss: 1.3814 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 21th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3534 - acc: 0.8094 - val_loss: 1.4700 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3886 - acc: 0.7996 - val_loss: 1.1893 - val_acc: 0.8352\n",
      "[INFO] Training model: epoch 21th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4019 - acc: 0.7980 - val_loss: 1.3297 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 21th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3575 - acc: 0.7996 - val_loss: 1.3749 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3255 - acc: 0.8102 - val_loss: 1.3486 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 21th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4050 - acc: 0.8031 - val_loss: 1.4925 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 21th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3066 - acc: 0.8098 - val_loss: 1.2546 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3485 - acc: 0.8039 - val_loss: 1.1935 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 21th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3971 - acc: 0.7984 - val_loss: 1.3629 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4149 - acc: 0.7959 - val_loss: 1.4628 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3645 - acc: 0.8010 - val_loss: 1.4297 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 21th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3944 - acc: 0.7986 - val_loss: 1.4438 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3542 - acc: 0.8045 - val_loss: 1.4641 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 21th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3636 - acc: 0.8049 - val_loss: 1.5575 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 21th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4271 - acc: 0.7959 - val_loss: 1.4793 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 21th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4356 - acc: 0.7994 - val_loss: 1.5157 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 21th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3751 - acc: 0.8012 - val_loss: 1.4111 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 21th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4001 - acc: 0.8008 - val_loss: 1.3990 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 21th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3346 - acc: 0.8061 - val_loss: 1.4939 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3887 - acc: 0.7988 - val_loss: 1.4207 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4039 - acc: 0.7967 - val_loss: 1.3309 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3620 - acc: 0.8014 - val_loss: 1.3533 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 21th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3509 - acc: 0.8066 - val_loss: 1.5730 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 21th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3871 - acc: 0.7992 - val_loss: 1.4705 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 21th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3513 - acc: 0.8055 - val_loss: 1.3575 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 21th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4466 - acc: 0.7893 - val_loss: 1.2491 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 21th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3966 - acc: 0.8006 - val_loss: 1.3788 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 21th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4032 - acc: 0.7984 - val_loss: 1.2631 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 21th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4412 - acc: 0.7939 - val_loss: 1.3647 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 21th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4415 - acc: 0.7990 - val_loss: 1.3780 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 21th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4394 - acc: 0.7910 - val_loss: 1.4168 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 21th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3785 - acc: 0.7967 - val_loss: 1.3955 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4073 - acc: 0.7990 - val_loss: 1.3729 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 21th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4420 - acc: 0.7943 - val_loss: 1.2272 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 21th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3253 - acc: 0.8094 - val_loss: 1.3742 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 21th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.8027 - val_loss: 1.5691 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 21th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3764 - acc: 0.8025 - val_loss: 1.4110 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4281 - acc: 0.7990 - val_loss: 1.4878 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 21th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3221 - acc: 0.8094 - val_loss: 1.2354 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 21th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4059 - acc: 0.7986 - val_loss: 1.5764 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 21th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3426 - acc: 0.8055 - val_loss: 1.4049 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 21th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4171 - acc: 0.7998 - val_loss: 1.4701 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 21th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2833 - acc: 0.8129 - val_loss: 1.5630 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 21th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4540 - acc: 0.7908 - val_loss: 1.2932 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 21th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3614 - acc: 0.8051 - val_loss: 1.4860 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 21th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4545 - acc: 0.7949 - val_loss: 1.2663 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 21th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3319 - acc: 0.8084 - val_loss: 1.3882 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 21th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4183 - acc: 0.7945 - val_loss: 1.3326 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 21th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3734 - acc: 0.8043 - val_loss: 1.2829 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 21th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4410 - acc: 0.7955 - val_loss: 1.4616 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 21th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3302 - acc: 0.8043 - val_loss: 1.3279 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 21th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4278 - acc: 0.7977 - val_loss: 1.3905 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 21th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4207 - acc: 0.7957 - val_loss: 1.3574 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 21th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3454 - acc: 0.8078 - val_loss: 1.4576 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 21th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3834 - acc: 0.8033 - val_loss: 1.2336 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 21th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4563 - acc: 0.7904 - val_loss: 1.4117 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 21th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4770 - acc: 0.7855 - val_loss: 1.4458 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 21th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4725 - acc: 0.7926 - val_loss: 1.5983 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 21th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3010 - acc: 0.8139 - val_loss: 1.3430 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3376 - acc: 0.8043 - val_loss: 1.2845 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 21th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4086 - acc: 0.8016 - val_loss: 1.2445 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 21th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3676 - acc: 0.8018 - val_loss: 1.3692 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 21th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4693 - acc: 0.7898 - val_loss: 1.6431 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 21th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4807 - acc: 0.7898 - val_loss: 1.3197 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 21th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3326 - acc: 0.8078 - val_loss: 1.3265 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 21th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3481 - acc: 0.8063 - val_loss: 1.2644 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 21th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4237 - acc: 0.8014 - val_loss: 1.3489 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 21th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4091 - acc: 0.8004 - val_loss: 1.4338 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 21th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4324 - acc: 0.8002 - val_loss: 1.5073 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 21th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3905 - acc: 0.8033 - val_loss: 1.2289 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 21th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2419 - acc: 0.8182 - val_loss: 1.2083 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 21th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4612 - acc: 0.7936 - val_loss: 1.5257 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 21th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3337 - acc: 0.8053 - val_loss: 1.4695 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 21th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3204 - acc: 0.8057 - val_loss: 1.3601 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 21th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4695 - acc: 0.7896 - val_loss: 1.2143 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 21th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3654 - acc: 0.8000 - val_loss: 1.3876 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 22th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3930 - acc: 0.7941 - val_loss: 1.2639 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 22th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3463 - acc: 0.8057 - val_loss: 1.4145 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 22th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2514 - acc: 0.8145 - val_loss: 1.3307 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3009 - acc: 0.8072 - val_loss: 1.2794 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 22th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.1988 - acc: 0.8232 - val_loss: 1.3376 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 22th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3324 - acc: 0.8057 - val_loss: 1.3795 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 22th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4248 - acc: 0.7934 - val_loss: 1.2745 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 22th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3457 - acc: 0.8039 - val_loss: 1.2243 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 22th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3914 - acc: 0.7967 - val_loss: 1.3178 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4010 - acc: 0.7982 - val_loss: 1.5482 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 22th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3440 - acc: 0.8043 - val_loss: 1.3141 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3573 - acc: 0.8016 - val_loss: 1.4169 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 22th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3577 - acc: 0.8061 - val_loss: 1.3381 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 22th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2985 - acc: 0.8084 - val_loss: 1.2903 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3045 - acc: 0.8102 - val_loss: 1.1783 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 22th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3892 - acc: 0.7955 - val_loss: 1.4770 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 22th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3110 - acc: 0.8051 - val_loss: 1.3751 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3977 - acc: 0.7930 - val_loss: 1.5091 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 22th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3812 - acc: 0.8012 - val_loss: 1.4429 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 22th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4527 - acc: 0.7877 - val_loss: 1.2605 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3804 - acc: 0.7986 - val_loss: 1.3133 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 22th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4267 - acc: 0.7975 - val_loss: 1.4343 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 22th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3695 - acc: 0.7990 - val_loss: 1.3187 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2671 - acc: 0.8187 - val_loss: 1.2838 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 22th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2749 - acc: 0.8092 - val_loss: 1.2409 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 22th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3595 - acc: 0.8064 - val_loss: 1.4529 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 22th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3297 - acc: 0.8049 - val_loss: 1.4717 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 22th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3754 - acc: 0.8008 - val_loss: 1.1387 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 22th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3590 - acc: 0.8035 - val_loss: 1.4398 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4147 - acc: 0.7928 - val_loss: 1.4263 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 22th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3543 - acc: 0.8012 - val_loss: 1.2807 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3625 - acc: 0.7953 - val_loss: 1.1518 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 22th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3224 - acc: 0.8025 - val_loss: 1.2407 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 22th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4071 - acc: 0.7906 - val_loss: 1.3535 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3114 - acc: 0.8063 - val_loss: 1.2003 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 22th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3386 - acc: 0.8029 - val_loss: 1.2806 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 22th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2798 - acc: 0.8143 - val_loss: 1.3086 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 22th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3327 - acc: 0.8090 - val_loss: 1.3700 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 22th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3617 - acc: 0.8004 - val_loss: 1.3262 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4049 - acc: 0.8008 - val_loss: 1.2295 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 22th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.7926 - val_loss: 1.3903 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 22th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3288 - acc: 0.8100 - val_loss: 1.2932 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 22th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3171 - acc: 0.8027 - val_loss: 1.4649 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 22th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3570 - acc: 0.7998 - val_loss: 1.2341 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 22th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3187 - acc: 0.8066 - val_loss: 1.3614 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3883 - acc: 0.7932 - val_loss: 1.4677 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 22th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3917 - acc: 0.7975 - val_loss: 1.4695 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 22th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3954 - acc: 0.7947 - val_loss: 1.6555 - val_acc: 0.7602\n",
      "[INFO] Training model: epoch 22th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4241 - acc: 0.7908 - val_loss: 1.4102 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4141 - acc: 0.7949 - val_loss: 1.3384 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2508 - acc: 0.8139 - val_loss: 1.2721 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 22th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3800 - acc: 0.7965 - val_loss: 1.4740 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3585 - acc: 0.8047 - val_loss: 1.3621 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3669 - acc: 0.8037 - val_loss: 1.3960 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 22th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3743 - acc: 0.7951 - val_loss: 1.2642 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 22th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4392 - acc: 0.7879 - val_loss: 1.4488 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3441 - acc: 0.8008 - val_loss: 1.4583 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 22th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3345 - acc: 0.8070 - val_loss: 1.5274 - val_acc: 0.7703\n",
      "[INFO] Training model: epoch 22th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3911 - acc: 0.8018 - val_loss: 1.4578 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 22th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3602 - acc: 0.8000 - val_loss: 1.5022 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3801 - acc: 0.8021 - val_loss: 1.4609 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4278 - acc: 0.7893 - val_loss: 1.5931 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 22th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2981 - acc: 0.8123 - val_loss: 1.1576 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 22th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3579 - acc: 0.8021 - val_loss: 1.2588 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 22th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3689 - acc: 0.8061 - val_loss: 1.2265 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 22th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3665 - acc: 0.8006 - val_loss: 1.2572 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 22th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3006 - acc: 0.8090 - val_loss: 1.2714 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 22th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3668 - acc: 0.8043 - val_loss: 1.3261 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 22th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3880 - acc: 0.8014 - val_loss: 1.3099 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 22th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3790 - acc: 0.8008 - val_loss: 1.4008 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3612 - acc: 0.8055 - val_loss: 1.2648 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 22th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4699 - acc: 0.7867 - val_loss: 1.2794 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2996 - acc: 0.8074 - val_loss: 1.4366 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 22th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4034 - acc: 0.7963 - val_loss: 1.2611 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 22th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3483 - acc: 0.7996 - val_loss: 1.2576 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 22th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3661 - acc: 0.8021 - val_loss: 1.3411 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 22th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3773 - acc: 0.8027 - val_loss: 1.3262 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 22th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3789 - acc: 0.8008 - val_loss: 1.4673 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3715 - acc: 0.7979 - val_loss: 1.3821 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 22th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2915 - acc: 0.8078 - val_loss: 1.2710 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 22th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3613 - acc: 0.8049 - val_loss: 1.2973 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 22th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2622 - acc: 0.8102 - val_loss: 1.5085 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 22th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4388 - acc: 0.7947 - val_loss: 1.4737 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4405 - acc: 0.7928 - val_loss: 1.1591 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 22th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4184 - acc: 0.7930 - val_loss: 1.4038 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3277 - acc: 0.8043 - val_loss: 1.4986 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 22th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3254 - acc: 0.8061 - val_loss: 1.2728 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 22th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4201 - acc: 0.7957 - val_loss: 1.4486 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 22th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2606 - acc: 0.8172 - val_loss: 1.2618 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3869 - acc: 0.7984 - val_loss: 1.3641 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4156 - acc: 0.7980 - val_loss: 1.2131 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 22th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4060 - acc: 0.7922 - val_loss: 1.3881 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2830 - acc: 0.8195 - val_loss: 1.3702 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 22th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3508 - acc: 0.8035 - val_loss: 1.3386 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3353 - acc: 0.8055 - val_loss: 1.2047 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 22th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3016 - acc: 0.8104 - val_loss: 1.3951 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 22th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3826 - acc: 0.8008 - val_loss: 1.3291 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3855 - acc: 0.7971 - val_loss: 1.5033 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 22th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4326 - acc: 0.7943 - val_loss: 1.3326 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4247 - acc: 0.7934 - val_loss: 1.4819 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2977 - acc: 0.8063 - val_loss: 1.3230 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3486 - acc: 0.8016 - val_loss: 1.3909 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 22th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2743 - acc: 0.8094 - val_loss: 1.1788 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 22th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2737 - acc: 0.8137 - val_loss: 1.3162 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 22th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4262 - acc: 0.7934 - val_loss: 1.3998 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 22th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3664 - acc: 0.8035 - val_loss: 1.2153 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 22th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3284 - acc: 0.8068 - val_loss: 1.1808 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 22th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3138 - acc: 0.8080 - val_loss: 1.1741 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 22th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3562 - acc: 0.8051 - val_loss: 1.2661 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 22th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3988 - acc: 0.7975 - val_loss: 1.4134 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 22th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4288 - acc: 0.7951 - val_loss: 1.4524 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 22th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3136 - acc: 0.8080 - val_loss: 1.5230 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 22th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3906 - acc: 0.8012 - val_loss: 1.3603 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2938 - acc: 0.8141 - val_loss: 1.3839 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4747 - acc: 0.7914 - val_loss: 1.2390 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 22th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3071 - acc: 0.8068 - val_loss: 1.4104 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 22th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3585 - acc: 0.8055 - val_loss: 1.4586 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 22th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3708 - acc: 0.8066 - val_loss: 1.4257 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 22th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3820 - acc: 0.8014 - val_loss: 1.4290 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 22th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3973 - acc: 0.7949 - val_loss: 1.2150 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 22th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3837 - acc: 0.8018 - val_loss: 1.5630 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 22th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3685 - acc: 0.8041 - val_loss: 1.2319 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 22th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4179 - acc: 0.7953 - val_loss: 1.4755 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 22th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3725 - acc: 0.7979 - val_loss: 1.2676 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3351 - acc: 0.8023 - val_loss: 1.5362 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 22th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3871 - acc: 0.8018 - val_loss: 1.4338 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3365 - acc: 0.8098 - val_loss: 1.3172 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 22th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4677 - acc: 0.7906 - val_loss: 1.2031 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 22th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2828 - acc: 0.8145 - val_loss: 1.4435 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2453 - acc: 0.8166 - val_loss: 1.4145 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2992 - acc: 0.8131 - val_loss: 1.3955 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3687 - acc: 0.8041 - val_loss: 1.2875 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3477 - acc: 0.8023 - val_loss: 1.4339 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3893 - acc: 0.7984 - val_loss: 1.3664 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 22th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4292 - acc: 0.7977 - val_loss: 1.4173 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4538 - acc: 0.7859 - val_loss: 1.5101 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 22th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3396 - acc: 0.8068 - val_loss: 1.3940 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 22th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4132 - acc: 0.7957 - val_loss: 1.4366 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 22th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3560 - acc: 0.8064 - val_loss: 1.4598 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3460 - acc: 0.8072 - val_loss: 1.3832 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 22th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4452 - acc: 0.7926 - val_loss: 1.3856 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 22th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3056 - acc: 0.8064 - val_loss: 1.3343 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4253 - acc: 0.7953 - val_loss: 1.3580 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3437 - acc: 0.8012 - val_loss: 1.4966 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 22th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3335 - acc: 0.8053 - val_loss: 1.4947 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4046 - acc: 0.7969 - val_loss: 1.3603 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2765 - acc: 0.8180 - val_loss: 1.4905 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4211 - acc: 0.7898 - val_loss: 1.4160 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 22th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3823 - acc: 0.7994 - val_loss: 1.2885 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 22th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3841 - acc: 0.7975 - val_loss: 1.5830 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 22th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3140 - acc: 0.8088 - val_loss: 1.2675 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 22th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4584 - acc: 0.7934 - val_loss: 1.3279 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 22th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3592 - acc: 0.8000 - val_loss: 1.3020 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3628 - acc: 0.8041 - val_loss: 1.4634 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 22th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3823 - acc: 0.8012 - val_loss: 1.3343 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4050 - acc: 0.7975 - val_loss: 1.4501 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3260 - acc: 0.8051 - val_loss: 1.2359 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 22th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3498 - acc: 0.8061 - val_loss: 1.1637 - val_acc: 0.8320\n",
      "[INFO] Training model: epoch 22th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4226 - acc: 0.8008 - val_loss: 1.3762 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 22th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3018 - acc: 0.8088 - val_loss: 1.5418 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3901 - acc: 0.8006 - val_loss: 1.4125 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 22th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3684 - acc: 0.8033 - val_loss: 1.4510 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 22th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3140 - acc: 0.8115 - val_loss: 1.2026 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 22th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3682 - acc: 0.8016 - val_loss: 1.3201 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 22th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3704 - acc: 0.8037 - val_loss: 1.5711 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 22th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3626 - acc: 0.8025 - val_loss: 1.5129 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3336 - acc: 0.8057 - val_loss: 1.2706 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 22th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4247 - acc: 0.7971 - val_loss: 1.2219 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 22th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3779 - acc: 0.8023 - val_loss: 1.4750 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4288 - acc: 0.7949 - val_loss: 1.3046 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 22th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3472 - acc: 0.8053 - val_loss: 1.1755 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 22th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4172 - acc: 0.7943 - val_loss: 1.3407 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 22th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3689 - acc: 0.8064 - val_loss: 1.4389 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 22th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3279 - acc: 0.8023 - val_loss: 1.3843 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4887 - acc: 0.7838 - val_loss: 1.2228 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 22th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4027 - acc: 0.7980 - val_loss: 1.2523 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 22th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3375 - acc: 0.8074 - val_loss: 1.4944 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4219 - acc: 0.7957 - val_loss: 1.4387 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2925 - acc: 0.8145 - val_loss: 1.5318 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4295 - acc: 0.7994 - val_loss: 1.3225 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3892 - acc: 0.8037 - val_loss: 1.1939 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 22th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3418 - acc: 0.8063 - val_loss: 1.6254 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 22th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3491 - acc: 0.8063 - val_loss: 1.4021 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 22th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4351 - acc: 0.7939 - val_loss: 1.2839 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 22th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3769 - acc: 0.7984 - val_loss: 1.2973 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4030 - acc: 0.7990 - val_loss: 1.4648 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 22th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4026 - acc: 0.8010 - val_loss: 1.2435 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 22th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3993 - acc: 0.7982 - val_loss: 1.3358 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 22th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3907 - acc: 0.7994 - val_loss: 1.2863 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 22th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3831 - acc: 0.7982 - val_loss: 1.3634 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 22th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3985 - acc: 0.7998 - val_loss: 1.4533 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 22th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3937 - acc: 0.7947 - val_loss: 1.3673 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 22th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3751 - acc: 0.8016 - val_loss: 1.3110 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 22th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4455 - acc: 0.7938 - val_loss: 1.4145 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 22th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3994 - acc: 0.8041 - val_loss: 1.3490 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 22th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3923 - acc: 0.8004 - val_loss: 1.4547 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 22th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4174 - acc: 0.7994 - val_loss: 1.4883 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 22th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3903 - acc: 0.7957 - val_loss: 1.6110 - val_acc: 0.7758\n",
      "[INFO] Training model: epoch 22th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.7975 - val_loss: 1.4345 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 22th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3066 - acc: 0.8127 - val_loss: 1.4159 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4389 - acc: 0.7949 - val_loss: 1.3774 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 22th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4435 - acc: 0.7930 - val_loss: 1.2623 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 22th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2680 - acc: 0.8158 - val_loss: 1.4247 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 22th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3499 - acc: 0.8092 - val_loss: 1.4468 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 22th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3981 - acc: 0.8008 - val_loss: 1.4374 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 22th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3331 - acc: 0.8076 - val_loss: 1.3615 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 22th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2771 - acc: 0.8123 - val_loss: 1.4252 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 22th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3168 - acc: 0.8076 - val_loss: 1.4280 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 22th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2971 - acc: 0.8117 - val_loss: 1.6364 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 22th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3990 - acc: 0.7947 - val_loss: 1.3455 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 22th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4286 - acc: 0.7965 - val_loss: 1.2984 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3968 - acc: 0.8006 - val_loss: 1.1455 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 22th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3286 - acc: 0.8064 - val_loss: 1.3055 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 22th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3455 - acc: 0.8055 - val_loss: 1.4865 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3734 - acc: 0.8057 - val_loss: 1.3141 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 22th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3542 - acc: 0.8002 - val_loss: 1.3682 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 22th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3760 - acc: 0.8027 - val_loss: 1.5993 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 22th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4344 - acc: 0.7969 - val_loss: 1.2910 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 22th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2910 - acc: 0.8133 - val_loss: 1.3390 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3562 - acc: 0.8068 - val_loss: 1.3154 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 22th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3352 - acc: 0.8107 - val_loss: 1.4027 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3911 - acc: 0.7979 - val_loss: 1.2949 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 22th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3269 - acc: 0.8102 - val_loss: 1.4738 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 22th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3581 - acc: 0.8025 - val_loss: 1.1962 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 22th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4136 - acc: 0.8008 - val_loss: 1.2583 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 22th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3230 - acc: 0.8102 - val_loss: 1.4751 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 22th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.4231 - acc: 0.7969 - val_loss: 1.3417 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 22th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4009 - acc: 0.8006 - val_loss: 1.4357 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3774 - acc: 0.8021 - val_loss: 1.5031 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4044 - acc: 0.7975 - val_loss: 1.3090 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4535 - acc: 0.7914 - val_loss: 1.3943 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 22th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4613 - acc: 0.7922 - val_loss: 1.2581 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3484 - acc: 0.8072 - val_loss: 1.2847 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3877 - acc: 0.7967 - val_loss: 1.4177 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 22th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3639 - acc: 0.8055 - val_loss: 1.3977 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 22th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3625 - acc: 0.8014 - val_loss: 1.4140 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 22th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4192 - acc: 0.8012 - val_loss: 1.2152 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 22th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4166 - acc: 0.7984 - val_loss: 1.4273 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 22th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3489 - acc: 0.7990 - val_loss: 1.1111 - val_acc: 0.8422\n",
      "[INFO] Training model: epoch 22th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3748 - acc: 0.8039 - val_loss: 1.4009 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3775 - acc: 0.7996 - val_loss: 1.3491 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 22th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4318 - acc: 0.7957 - val_loss: 1.2800 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 22th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3471 - acc: 0.8045 - val_loss: 1.4914 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 22th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4417 - acc: 0.7914 - val_loss: 1.3800 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 22th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2979 - acc: 0.8117 - val_loss: 1.2081 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 22th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3674 - acc: 0.8023 - val_loss: 1.3257 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 22th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3640 - acc: 0.8084 - val_loss: 1.4420 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 22th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3670 - acc: 0.8023 - val_loss: 1.3596 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 22th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4216 - acc: 0.7977 - val_loss: 1.4265 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 22th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4585 - acc: 0.7906 - val_loss: 1.3618 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 23th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3487 - acc: 0.8006 - val_loss: 1.2307 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 23th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2921 - acc: 0.8113 - val_loss: 1.2953 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3643 - acc: 0.7967 - val_loss: 1.3650 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 23th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3220 - acc: 0.8102 - val_loss: 1.5384 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 23th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3652 - acc: 0.7996 - val_loss: 1.3756 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4206 - acc: 0.7951 - val_loss: 1.3025 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3532 - acc: 0.7979 - val_loss: 1.4420 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 23th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3283 - acc: 0.7984 - val_loss: 1.3005 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 23th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3978 - acc: 0.7984 - val_loss: 1.2851 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4427 - acc: 0.7918 - val_loss: 1.2409 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 23th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2937 - acc: 0.8047 - val_loss: 1.3771 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 23th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2521 - acc: 0.8195 - val_loss: 1.5097 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 23th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3574 - acc: 0.7990 - val_loss: 1.2855 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3007 - acc: 0.8092 - val_loss: 1.2563 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 23th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3488 - acc: 0.8023 - val_loss: 1.3035 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3927 - acc: 0.7945 - val_loss: 1.2550 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 23th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3254 - acc: 0.8029 - val_loss: 1.4052 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 23th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3828 - acc: 0.7990 - val_loss: 1.3091 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 23th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3234 - acc: 0.8051 - val_loss: 1.3351 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3434 - acc: 0.7998 - val_loss: 1.4146 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 23th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4120 - acc: 0.7891 - val_loss: 1.5068 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 23th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4263 - acc: 0.7939 - val_loss: 1.2309 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 23th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3861 - acc: 0.8027 - val_loss: 1.3411 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 23th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4057 - acc: 0.7955 - val_loss: 1.2856 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3918 - acc: 0.7953 - val_loss: 1.3690 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2845 - acc: 0.8094 - val_loss: 1.1880 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 23th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3093 - acc: 0.8102 - val_loss: 1.3069 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 23th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3123 - acc: 0.8111 - val_loss: 1.3331 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2958 - acc: 0.8064 - val_loss: 1.3550 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 23th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3559 - acc: 0.8012 - val_loss: 1.3109 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3282 - acc: 0.8061 - val_loss: 1.3668 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3873 - acc: 0.7984 - val_loss: 1.4956 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 23th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2108 - acc: 0.8164 - val_loss: 1.2999 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 23th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3056 - acc: 0.8074 - val_loss: 1.1972 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 23th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2314 - acc: 0.8176 - val_loss: 1.2730 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 23th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4388 - acc: 0.7902 - val_loss: 1.3782 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3498 - acc: 0.7961 - val_loss: 1.2930 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 23th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2940 - acc: 0.8115 - val_loss: 1.3679 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3624 - acc: 0.8063 - val_loss: 1.1951 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 23th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3714 - acc: 0.8012 - val_loss: 1.2617 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 23th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.1827 - acc: 0.8232 - val_loss: 1.2772 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3331 - acc: 0.8041 - val_loss: 1.2965 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3727 - acc: 0.7957 - val_loss: 1.2718 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2500 - acc: 0.8119 - val_loss: 1.3893 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 23th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2768 - acc: 0.8102 - val_loss: 1.2976 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3268 - acc: 0.8023 - val_loss: 1.3095 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3925 - acc: 0.7924 - val_loss: 1.2906 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3632 - acc: 0.8051 - val_loss: 1.2208 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2495 - acc: 0.8131 - val_loss: 1.1524 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 23th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3124 - acc: 0.8041 - val_loss: 1.3499 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 23th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3210 - acc: 0.8094 - val_loss: 1.3588 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3293 - acc: 0.8008 - val_loss: 1.3177 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 23th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4331 - acc: 0.7926 - val_loss: 1.2611 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3638 - acc: 0.8014 - val_loss: 1.3446 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3938 - acc: 0.8021 - val_loss: 1.1312 - val_acc: 0.8359\n",
      "[INFO] Training model: epoch 23th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2605 - acc: 0.8113 - val_loss: 1.6597 - val_acc: 0.7586\n",
      "[INFO] Training model: epoch 23th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3058 - acc: 0.8008 - val_loss: 1.2573 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 23th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3489 - acc: 0.7969 - val_loss: 1.2180 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 23th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3841 - acc: 0.7980 - val_loss: 1.2046 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 23th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3498 - acc: 0.7988 - val_loss: 1.2996 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3672 - acc: 0.8008 - val_loss: 1.3792 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 23th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3458 - acc: 0.8023 - val_loss: 1.4056 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4294 - acc: 0.7936 - val_loss: 1.3341 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 23th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2792 - acc: 0.8121 - val_loss: 1.3689 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 23th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2902 - acc: 0.8121 - val_loss: 1.4030 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3712 - acc: 0.7980 - val_loss: 1.2269 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 23th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3455 - acc: 0.8010 - val_loss: 1.4485 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 23th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3158 - acc: 0.8094 - val_loss: 1.2449 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4399 - acc: 0.7883 - val_loss: 1.3526 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 23th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4011 - acc: 0.7955 - val_loss: 1.3080 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3478 - acc: 0.8063 - val_loss: 1.2773 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 23th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2594 - acc: 0.8148 - val_loss: 1.3849 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 23th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2384 - acc: 0.8178 - val_loss: 1.4649 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 23th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.5122 - acc: 0.7852 - val_loss: 1.4362 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4151 - acc: 0.7984 - val_loss: 1.1976 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3492 - acc: 0.8027 - val_loss: 1.2391 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 23th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4035 - acc: 0.7955 - val_loss: 1.3673 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 23th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3189 - acc: 0.8010 - val_loss: 1.3473 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3730 - acc: 0.8016 - val_loss: 1.3259 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3187 - acc: 0.8057 - val_loss: 1.4432 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3919 - acc: 0.7998 - val_loss: 1.3283 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3594 - acc: 0.8014 - val_loss: 1.2077 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4629 - acc: 0.7873 - val_loss: 1.3463 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3393 - acc: 0.8037 - val_loss: 1.1185 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 23th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3341 - acc: 0.8025 - val_loss: 1.2229 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 23th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3524 - acc: 0.8002 - val_loss: 1.4459 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 23th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3045 - acc: 0.8076 - val_loss: 1.4964 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 23th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4029 - acc: 0.7973 - val_loss: 1.4873 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 23th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3662 - acc: 0.7945 - val_loss: 1.2969 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 23th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3678 - acc: 0.8027 - val_loss: 1.3682 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 23th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4248 - acc: 0.7908 - val_loss: 1.3200 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 23th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3792 - acc: 0.7982 - val_loss: 1.3024 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 23th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3224 - acc: 0.8016 - val_loss: 1.5059 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 23th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3410 - acc: 0.8000 - val_loss: 1.3640 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 23th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3806 - acc: 0.7973 - val_loss: 1.1952 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 23th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3759 - acc: 0.8029 - val_loss: 1.2998 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3671 - acc: 0.8002 - val_loss: 1.5086 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 23th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3537 - acc: 0.8066 - val_loss: 1.3316 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3611 - acc: 0.7977 - val_loss: 1.3116 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 23th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3481 - acc: 0.8111 - val_loss: 1.3713 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 23th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3554 - acc: 0.8104 - val_loss: 1.3707 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 23th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3663 - acc: 0.8033 - val_loss: 1.4915 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 23th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3440 - acc: 0.8057 - val_loss: 1.2836 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 23th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3551 - acc: 0.8047 - val_loss: 1.5407 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 23th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4170 - acc: 0.7967 - val_loss: 1.2512 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 23th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3636 - acc: 0.8016 - val_loss: 1.1440 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 23th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3511 - acc: 0.8064 - val_loss: 1.4848 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 23th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.7971 - val_loss: 1.2684 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4515 - acc: 0.7861 - val_loss: 1.4017 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 23th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3994 - acc: 0.7994 - val_loss: 1.6158 - val_acc: 0.7641\n",
      "[INFO] Training model: epoch 23th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3264 - acc: 0.8082 - val_loss: 1.4277 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 23th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3373 - acc: 0.8053 - val_loss: 1.3728 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2652 - acc: 0.8113 - val_loss: 1.3582 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3963 - acc: 0.7967 - val_loss: 1.2735 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 23th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3667 - acc: 0.8053 - val_loss: 1.3367 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3383 - acc: 0.8109 - val_loss: 1.4350 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2975 - acc: 0.8082 - val_loss: 1.3108 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 23th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4064 - acc: 0.7979 - val_loss: 1.4125 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 23th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3401 - acc: 0.8041 - val_loss: 1.4063 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 23th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4026 - acc: 0.7912 - val_loss: 1.1629 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 23th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3706 - acc: 0.7953 - val_loss: 1.3558 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3405 - acc: 0.7992 - val_loss: 1.3886 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3453 - acc: 0.8014 - val_loss: 1.4804 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 23th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4695 - acc: 0.7865 - val_loss: 1.3685 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 23th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3715 - acc: 0.7990 - val_loss: 1.3010 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 23th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4185 - acc: 0.7912 - val_loss: 1.3921 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 23th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4174 - acc: 0.7934 - val_loss: 1.5005 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 23th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4077 - acc: 0.7998 - val_loss: 1.2181 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 23th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3319 - acc: 0.8086 - val_loss: 1.2962 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 23th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4104 - acc: 0.7943 - val_loss: 1.2364 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4195 - acc: 0.7920 - val_loss: 1.5236 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 23th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3555 - acc: 0.8035 - val_loss: 1.2941 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3032 - acc: 0.8066 - val_loss: 1.4549 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 23th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3436 - acc: 0.8000 - val_loss: 1.3996 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 23th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3964 - acc: 0.7959 - val_loss: 1.3096 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3552 - acc: 0.7990 - val_loss: 1.2723 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 23th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4100 - acc: 0.7988 - val_loss: 1.2682 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 23th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4076 - acc: 0.7930 - val_loss: 1.3275 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 23th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3317 - acc: 0.8082 - val_loss: 1.3313 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3603 - acc: 0.8031 - val_loss: 1.3671 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 23th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3979 - acc: 0.8008 - val_loss: 1.5132 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 23th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3179 - acc: 0.8092 - val_loss: 1.3540 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 23th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3923 - acc: 0.7979 - val_loss: 1.4017 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3856 - acc: 0.7965 - val_loss: 1.1923 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 23th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4372 - acc: 0.7945 - val_loss: 1.4132 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 23th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3756 - acc: 0.8031 - val_loss: 1.3294 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 23th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3396 - acc: 0.8072 - val_loss: 1.2291 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 23th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3895 - acc: 0.7957 - val_loss: 1.3964 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 23th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4340 - acc: 0.7928 - val_loss: 1.4153 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 23th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2792 - acc: 0.8102 - val_loss: 1.3105 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3897 - acc: 0.8008 - val_loss: 1.3182 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 23th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3581 - acc: 0.7992 - val_loss: 1.1717 - val_acc: 0.8320\n",
      "[INFO] Training model: epoch 23th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3393 - acc: 0.8010 - val_loss: 1.4277 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 23th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3962 - acc: 0.7975 - val_loss: 1.3089 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3622 - acc: 0.8049 - val_loss: 1.3564 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 23th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3031 - acc: 0.8113 - val_loss: 1.3814 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3676 - acc: 0.7951 - val_loss: 1.4143 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2988 - acc: 0.8105 - val_loss: 1.3068 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 23th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3716 - acc: 0.8006 - val_loss: 1.1537 - val_acc: 0.8359\n",
      "[INFO] Training model: epoch 23th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3164 - acc: 0.8137 - val_loss: 1.3429 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3083 - acc: 0.8023 - val_loss: 1.3248 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 23th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3697 - acc: 0.8039 - val_loss: 1.4147 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3995 - acc: 0.7982 - val_loss: 1.4116 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 23th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3640 - acc: 0.8016 - val_loss: 1.1808 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 23th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3969 - acc: 0.7988 - val_loss: 1.3710 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 23th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4035 - acc: 0.7977 - val_loss: 1.2014 - val_acc: 0.8320\n",
      "[INFO] Training model: epoch 23th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3612 - acc: 0.8057 - val_loss: 1.3768 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2880 - acc: 0.8072 - val_loss: 1.5814 - val_acc: 0.7734\n",
      "[INFO] Training model: epoch 23th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3721 - acc: 0.8002 - val_loss: 1.3730 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 23th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3695 - acc: 0.7994 - val_loss: 1.3010 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 23th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3846 - acc: 0.8016 - val_loss: 1.4172 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3803 - acc: 0.7992 - val_loss: 1.3724 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 23th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4400 - acc: 0.7906 - val_loss: 1.4780 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 23th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3013 - acc: 0.8084 - val_loss: 1.3605 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.7961 - val_loss: 1.3082 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 23th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3225 - acc: 0.8098 - val_loss: 1.5280 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 23th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3441 - acc: 0.8000 - val_loss: 1.1585 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 23th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3844 - acc: 0.7998 - val_loss: 1.2435 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 23th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4093 - acc: 0.7918 - val_loss: 1.3959 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 23th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3402 - acc: 0.8014 - val_loss: 1.4595 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 23th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3581 - acc: 0.8041 - val_loss: 1.3953 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 23th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2943 - acc: 0.8135 - val_loss: 1.5236 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 23th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3377 - acc: 0.8027 - val_loss: 1.3732 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3039 - acc: 0.8104 - val_loss: 1.4037 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4653 - acc: 0.7861 - val_loss: 1.3175 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 23th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3177 - acc: 0.8023 - val_loss: 1.3906 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 23th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3679 - acc: 0.8055 - val_loss: 1.3264 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 23th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4678 - acc: 0.7930 - val_loss: 1.1539 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 23th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2987 - acc: 0.8086 - val_loss: 1.3802 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3624 - acc: 0.8045 - val_loss: 1.5126 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 23th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3613 - acc: 0.8025 - val_loss: 1.2219 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 23th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2902 - acc: 0.8109 - val_loss: 1.5092 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 23th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3868 - acc: 0.7973 - val_loss: 1.5774 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 23th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3636 - acc: 0.8023 - val_loss: 1.4694 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 23th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2068 - acc: 0.8221 - val_loss: 1.4734 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 23th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3389 - acc: 0.8047 - val_loss: 1.4286 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3652 - acc: 0.8025 - val_loss: 1.3477 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 23th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3669 - acc: 0.8051 - val_loss: 1.4113 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 23th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3629 - acc: 0.8037 - val_loss: 1.4028 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4523 - acc: 0.7918 - val_loss: 1.4071 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4109 - acc: 0.7951 - val_loss: 1.1576 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 23th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4119 - acc: 0.7963 - val_loss: 1.3040 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 23th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3201 - acc: 0.8041 - val_loss: 1.2855 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 23th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3346 - acc: 0.8084 - val_loss: 1.4886 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 23th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2954 - acc: 0.8127 - val_loss: 1.3811 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 23th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3229 - acc: 0.8111 - val_loss: 1.5402 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 23th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4881 - acc: 0.7867 - val_loss: 1.2261 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 23th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3719 - acc: 0.8043 - val_loss: 1.4045 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 23th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4250 - acc: 0.7943 - val_loss: 1.2854 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 23th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3264 - acc: 0.8082 - val_loss: 1.3065 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 23th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4170 - acc: 0.7949 - val_loss: 1.3287 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 23th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3829 - acc: 0.8020 - val_loss: 1.5784 - val_acc: 0.7656\n",
      "[INFO] Training model: epoch 23th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4153 - acc: 0.7967 - val_loss: 1.4304 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 23th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3641 - acc: 0.8033 - val_loss: 1.4370 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 23th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3733 - acc: 0.8035 - val_loss: 1.2589 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 23th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4386 - acc: 0.7920 - val_loss: 1.4569 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 23th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4079 - acc: 0.8006 - val_loss: 1.3276 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 23th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3638 - acc: 0.8049 - val_loss: 1.3890 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 23th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4717 - acc: 0.7873 - val_loss: 1.2741 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4446 - acc: 0.7990 - val_loss: 1.2462 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 23th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4615 - acc: 0.7916 - val_loss: 1.3868 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2889 - acc: 0.8117 - val_loss: 1.3408 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 23th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3935 - acc: 0.8008 - val_loss: 1.3000 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 23th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4295 - acc: 0.7951 - val_loss: 1.2843 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 23th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3325 - acc: 0.8066 - val_loss: 1.3112 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 23th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2767 - acc: 0.8168 - val_loss: 1.4944 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 23th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3413 - acc: 0.8055 - val_loss: 1.4020 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 23th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.7979 - val_loss: 1.1711 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 23th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4090 - acc: 0.7979 - val_loss: 1.3072 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 23th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2816 - acc: 0.8145 - val_loss: 1.5126 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 23th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2990 - acc: 0.8084 - val_loss: 1.5493 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 23th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3319 - acc: 0.8035 - val_loss: 1.2880 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4437 - acc: 0.7916 - val_loss: 1.2911 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 23th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3046 - acc: 0.8100 - val_loss: 1.3020 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 23th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3108 - acc: 0.8002 - val_loss: 1.2691 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 23th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3567 - acc: 0.8055 - val_loss: 1.3742 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 23th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4206 - acc: 0.7936 - val_loss: 1.5962 - val_acc: 0.7742\n",
      "[INFO] Training model: epoch 23th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3365 - acc: 0.8061 - val_loss: 1.4174 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 23th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2902 - acc: 0.8150 - val_loss: 1.2730 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 23th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3403 - acc: 0.8082 - val_loss: 1.2045 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 23th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4444 - acc: 0.7951 - val_loss: 1.2372 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 23th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3405 - acc: 0.8055 - val_loss: 1.3828 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 23th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3374 - acc: 0.8051 - val_loss: 1.2954 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 23th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3377 - acc: 0.8098 - val_loss: 1.3600 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 23th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3674 - acc: 0.8049 - val_loss: 1.6314 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 23th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2555 - acc: 0.8170 - val_loss: 1.3400 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 23th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4068 - acc: 0.7936 - val_loss: 1.3235 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 23th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3399 - acc: 0.8094 - val_loss: 1.3462 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 23th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3875 - acc: 0.8006 - val_loss: 1.3589 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 23th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3670 - acc: 0.8006 - val_loss: 1.4029 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3591 - acc: 0.8004 - val_loss: 1.3808 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 24th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3274 - acc: 0.8055 - val_loss: 1.3716 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 24th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4415 - acc: 0.7928 - val_loss: 1.5109 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 24th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3913 - acc: 0.7947 - val_loss: 1.2859 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3591 - acc: 0.7963 - val_loss: 1.3563 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2497 - acc: 0.8137 - val_loss: 1.2839 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 24th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3958 - acc: 0.7947 - val_loss: 1.4856 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 24th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3738 - acc: 0.7922 - val_loss: 1.2921 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 24th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3055 - acc: 0.8049 - val_loss: 1.2686 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3360 - acc: 0.8041 - val_loss: 1.6039 - val_acc: 0.7680\n",
      "[INFO] Training model: epoch 24th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3737 - acc: 0.8014 - val_loss: 1.1979 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 24th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2811 - acc: 0.8104 - val_loss: 1.2799 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3460 - acc: 0.8025 - val_loss: 1.3529 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3360 - acc: 0.8045 - val_loss: 1.3802 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3256 - acc: 0.8063 - val_loss: 1.2450 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3229 - acc: 0.8080 - val_loss: 1.2647 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 24th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3094 - acc: 0.8080 - val_loss: 1.3026 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 24th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3295 - acc: 0.8061 - val_loss: 1.2491 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 24th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3100 - acc: 0.8057 - val_loss: 1.2010 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 24th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3853 - acc: 0.7979 - val_loss: 1.3320 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 24th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4162 - acc: 0.7926 - val_loss: 1.2407 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 24th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3826 - acc: 0.7988 - val_loss: 1.1559 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 24th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3115 - acc: 0.8057 - val_loss: 1.0746 - val_acc: 0.8336\n",
      "[INFO] Training model: epoch 24th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3320 - acc: 0.8021 - val_loss: 1.2383 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 24th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4028 - acc: 0.7992 - val_loss: 1.2073 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 24th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3204 - acc: 0.8037 - val_loss: 1.2332 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 24th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3876 - acc: 0.7887 - val_loss: 1.4579 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 24th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2780 - acc: 0.8090 - val_loss: 1.2110 - val_acc: 0.8320\n",
      "[INFO] Training model: epoch 24th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4064 - acc: 0.7963 - val_loss: 1.3322 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 24th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2699 - acc: 0.8129 - val_loss: 1.4520 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 24th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3286 - acc: 0.8070 - val_loss: 1.1533 - val_acc: 0.8297\n",
      "[INFO] Training model: epoch 24th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3376 - acc: 0.8090 - val_loss: 1.4789 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 24th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3973 - acc: 0.7988 - val_loss: 1.3870 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 24th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3629 - acc: 0.7977 - val_loss: 1.5449 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 24th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3156 - acc: 0.8023 - val_loss: 1.2303 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 24th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2109 - acc: 0.8184 - val_loss: 1.2335 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 24th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3755 - acc: 0.7953 - val_loss: 1.4262 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 24th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3461 - acc: 0.8018 - val_loss: 1.2249 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 24th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3324 - acc: 0.8072 - val_loss: 1.4115 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3105 - acc: 0.8102 - val_loss: 1.1479 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 24th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3206 - acc: 0.8047 - val_loss: 1.3263 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4937 - acc: 0.7818 - val_loss: 1.2545 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3681 - acc: 0.7992 - val_loss: 1.3526 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 24th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3437 - acc: 0.8031 - val_loss: 1.3540 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 24th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3268 - acc: 0.8063 - val_loss: 1.3575 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3897 - acc: 0.8010 - val_loss: 1.2778 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.8012 - val_loss: 1.3336 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3026 - acc: 0.8102 - val_loss: 1.1881 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 24th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3661 - acc: 0.7994 - val_loss: 1.4646 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 24th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3351 - acc: 0.8002 - val_loss: 1.3245 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 24th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3664 - acc: 0.8023 - val_loss: 1.3600 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4378 - acc: 0.7889 - val_loss: 1.4727 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 24th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3261 - acc: 0.8014 - val_loss: 1.5482 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 24th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2514 - acc: 0.8123 - val_loss: 1.3371 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 24th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3849 - acc: 0.7945 - val_loss: 1.3149 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 24th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3328 - acc: 0.8076 - val_loss: 1.1937 - val_acc: 0.8289\n",
      "[INFO] Training model: epoch 24th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3109 - acc: 0.8080 - val_loss: 1.2925 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3191 - acc: 0.7965 - val_loss: 1.3852 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2665 - acc: 0.8086 - val_loss: 1.3704 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 24th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3981 - acc: 0.8023 - val_loss: 1.3069 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3354 - acc: 0.8061 - val_loss: 1.3470 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3529 - acc: 0.8025 - val_loss: 1.4320 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 24th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4393 - acc: 0.7885 - val_loss: 1.2183 - val_acc: 0.8305\n",
      "[INFO] Training model: epoch 24th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2875 - acc: 0.8113 - val_loss: 1.1920 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3147 - acc: 0.8014 - val_loss: 1.2770 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 24th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3824 - acc: 0.7988 - val_loss: 1.1600 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 24th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4021 - acc: 0.7930 - val_loss: 1.2734 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 24th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3565 - acc: 0.8029 - val_loss: 1.3378 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 24th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3973 - acc: 0.7900 - val_loss: 1.3249 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2785 - acc: 0.8086 - val_loss: 1.4010 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 24th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3404 - acc: 0.8051 - val_loss: 1.3631 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 24th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3779 - acc: 0.7980 - val_loss: 1.4904 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 24th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2915 - acc: 0.8105 - val_loss: 1.2768 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 24th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3913 - acc: 0.7932 - val_loss: 1.4566 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 24th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3232 - acc: 0.8002 - val_loss: 1.3966 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 24th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3717 - acc: 0.7994 - val_loss: 1.2879 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3199 - acc: 0.8029 - val_loss: 1.3142 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3937 - acc: 0.7943 - val_loss: 1.1535 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 24th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2740 - acc: 0.8117 - val_loss: 1.3196 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 24th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2881 - acc: 0.8135 - val_loss: 1.3403 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3873 - acc: 0.7936 - val_loss: 1.3629 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 24th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2853 - acc: 0.8092 - val_loss: 1.1837 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 24th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3308 - acc: 0.8064 - val_loss: 1.4417 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 24th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3777 - acc: 0.7955 - val_loss: 1.2699 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 24th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3356 - acc: 0.8061 - val_loss: 1.3368 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3468 - acc: 0.8066 - val_loss: 1.3764 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 24th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3148 - acc: 0.8066 - val_loss: 1.3560 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 24th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3579 - acc: 0.8047 - val_loss: 1.3820 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 24th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4059 - acc: 0.7953 - val_loss: 1.2487 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 24th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3063 - acc: 0.8059 - val_loss: 1.1767 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 24th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2918 - acc: 0.8066 - val_loss: 1.3962 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 24th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3072 - acc: 0.8135 - val_loss: 1.3112 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3750 - acc: 0.7996 - val_loss: 1.2572 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3352 - acc: 0.8014 - val_loss: 1.2309 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 24th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3445 - acc: 0.8025 - val_loss: 1.4041 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2815 - acc: 0.8115 - val_loss: 1.5167 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 24th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3740 - acc: 0.7992 - val_loss: 1.4570 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 24th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3440 - acc: 0.7959 - val_loss: 1.3732 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3242 - acc: 0.8035 - val_loss: 1.3612 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3612 - acc: 0.8021 - val_loss: 1.4518 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 24th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4571 - acc: 0.7943 - val_loss: 1.4358 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 24th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2633 - acc: 0.8105 - val_loss: 1.2988 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4077 - acc: 0.7912 - val_loss: 1.3111 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 24th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3530 - acc: 0.8004 - val_loss: 1.3963 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 24th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3189 - acc: 0.8072 - val_loss: 1.4112 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3500 - acc: 0.7996 - val_loss: 1.3309 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3091 - acc: 0.8053 - val_loss: 1.2494 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 24th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4308 - acc: 0.7959 - val_loss: 1.3212 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 24th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4033 - acc: 0.7951 - val_loss: 1.3748 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2928 - acc: 0.8115 - val_loss: 1.3699 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 24th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3718 - acc: 0.8016 - val_loss: 1.2594 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 24th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2969 - acc: 0.8066 - val_loss: 1.2767 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3556 - acc: 0.8055 - val_loss: 1.2870 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 24th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2995 - acc: 0.8080 - val_loss: 1.3112 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3454 - acc: 0.8072 - val_loss: 1.2885 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3711 - acc: 0.7980 - val_loss: 1.5055 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 24th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2643 - acc: 0.8146 - val_loss: 1.2703 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3694 - acc: 0.8027 - val_loss: 1.2832 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3519 - acc: 0.8018 - val_loss: 1.4871 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 24th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4225 - acc: 0.7930 - val_loss: 1.4505 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 24th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3706 - acc: 0.8000 - val_loss: 1.3992 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 24th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2920 - acc: 0.8109 - val_loss: 1.3572 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 6s - loss: 1.3847 - acc: 0.7994 - val_loss: 1.0576 - val_acc: 0.8375\n",
      "[INFO] Training model: epoch 24th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4041 - acc: 0.7943 - val_loss: 1.1895 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 24th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3904 - acc: 0.7949 - val_loss: 1.2349 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 24th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3399 - acc: 0.8031 - val_loss: 1.5263 - val_acc: 0.7852\n",
      "[INFO] Training model: epoch 24th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3006 - acc: 0.8086 - val_loss: 1.4841 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 24th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2310 - acc: 0.8166 - val_loss: 1.3432 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3216 - acc: 0.8057 - val_loss: 1.3586 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3115 - acc: 0.8088 - val_loss: 1.1961 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 24th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3288 - acc: 0.8027 - val_loss: 1.3827 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 24th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2707 - acc: 0.8125 - val_loss: 1.4077 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 24th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3081 - acc: 0.8104 - val_loss: 1.2927 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3775 - acc: 0.8029 - val_loss: 1.3403 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4272 - acc: 0.7945 - val_loss: 1.1715 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 24th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4695 - acc: 0.7857 - val_loss: 1.2269 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 24th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3681 - acc: 0.8014 - val_loss: 1.3355 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3932 - acc: 0.8016 - val_loss: 1.2015 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 24th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2976 - acc: 0.8068 - val_loss: 1.3457 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 24th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3754 - acc: 0.7996 - val_loss: 1.5077 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 24th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3919 - acc: 0.8037 - val_loss: 1.4125 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4094 - acc: 0.7961 - val_loss: 1.3686 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 24th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3778 - acc: 0.7992 - val_loss: 1.4408 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 24th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3749 - acc: 0.8010 - val_loss: 1.3037 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3345 - acc: 0.8086 - val_loss: 1.2439 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3461 - acc: 0.8033 - val_loss: 1.2895 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 24th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3592 - acc: 0.7992 - val_loss: 1.2304 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 24th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4349 - acc: 0.7936 - val_loss: 1.4294 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 24th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3637 - acc: 0.8043 - val_loss: 1.2267 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4371 - acc: 0.7965 - val_loss: 1.2677 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4236 - acc: 0.7996 - val_loss: 1.3301 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 24th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3650 - acc: 0.7988 - val_loss: 1.4087 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3447 - acc: 0.8004 - val_loss: 1.2508 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3479 - acc: 0.8020 - val_loss: 1.3067 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4782 - acc: 0.7949 - val_loss: 1.2551 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 24th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4380 - acc: 0.7891 - val_loss: 1.2605 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 24th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4088 - acc: 0.7957 - val_loss: 1.4600 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4082 - acc: 0.7979 - val_loss: 1.3508 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 24th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3613 - acc: 0.8021 - val_loss: 1.3023 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2770 - acc: 0.8133 - val_loss: 1.3941 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 24th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4700 - acc: 0.7863 - val_loss: 1.2265 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 24th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3091 - acc: 0.8102 - val_loss: 1.3415 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4308 - acc: 0.7939 - val_loss: 1.5062 - val_acc: 0.7789\n",
      "[INFO] Training model: epoch 24th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3476 - acc: 0.8043 - val_loss: 1.3531 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 24th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3191 - acc: 0.8104 - val_loss: 1.3089 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 24th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3418 - acc: 0.8057 - val_loss: 1.2973 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 24th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3010 - acc: 0.8115 - val_loss: 1.3608 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 24th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3245 - acc: 0.8074 - val_loss: 1.3663 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3366 - acc: 0.8092 - val_loss: 1.2951 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3491 - acc: 0.8014 - val_loss: 1.3240 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 24th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.2843 - acc: 0.8150 - val_loss: 1.4226 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 24th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3382 - acc: 0.7988 - val_loss: 1.2868 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2728 - acc: 0.8107 - val_loss: 1.3509 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 24th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3490 - acc: 0.8076 - val_loss: 1.4962 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 24th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4008 - acc: 0.7967 - val_loss: 1.3044 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3457 - acc: 0.8088 - val_loss: 1.3950 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3366 - acc: 0.8119 - val_loss: 1.4354 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3474 - acc: 0.8010 - val_loss: 1.1563 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 24th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3657 - acc: 0.8012 - val_loss: 1.4435 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 24th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3575 - acc: 0.8006 - val_loss: 1.3290 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 24th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3735 - acc: 0.8021 - val_loss: 1.4479 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 24th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3348 - acc: 0.8053 - val_loss: 1.3208 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 24th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3969 - acc: 0.8002 - val_loss: 1.3517 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 24th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3028 - acc: 0.8084 - val_loss: 1.2066 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 24th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3284 - acc: 0.8049 - val_loss: 1.2880 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 24th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4035 - acc: 0.8035 - val_loss: 1.2315 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 24th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3652 - acc: 0.8014 - val_loss: 1.3500 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 24th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3093 - acc: 0.8096 - val_loss: 1.3987 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3315 - acc: 0.8055 - val_loss: 1.2435 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 24th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3285 - acc: 0.8080 - val_loss: 1.3874 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 24th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3100 - acc: 0.7977 - val_loss: 1.3581 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 24th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3208 - acc: 0.7996 - val_loss: 1.4803 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 24th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3935 - acc: 0.8012 - val_loss: 1.3981 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 24th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3716 - acc: 0.8039 - val_loss: 1.6240 - val_acc: 0.7688\n",
      "[INFO] Training model: epoch 24th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4694 - acc: 0.7885 - val_loss: 1.2685 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 24th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3927 - acc: 0.7992 - val_loss: 1.4724 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 24th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3819 - acc: 0.7971 - val_loss: 1.2404 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 24th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2689 - acc: 0.8113 - val_loss: 1.1835 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 24th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3581 - acc: 0.8068 - val_loss: 1.3838 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3024 - acc: 0.8145 - val_loss: 1.2730 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 24th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3298 - acc: 0.8057 - val_loss: 1.4419 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 24th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4091 - acc: 0.7965 - val_loss: 1.3547 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2982 - acc: 0.8088 - val_loss: 1.4687 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 24th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4112 - acc: 0.7967 - val_loss: 1.2527 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 24th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3368 - acc: 0.8041 - val_loss: 1.3734 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3236 - acc: 0.8078 - val_loss: 1.3764 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 24th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3998 - acc: 0.7977 - val_loss: 1.1534 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 24th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3001 - acc: 0.8105 - val_loss: 1.4324 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 24th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4273 - acc: 0.7898 - val_loss: 1.4330 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 24th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3398 - acc: 0.8037 - val_loss: 1.3093 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 24th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2607 - acc: 0.8170 - val_loss: 1.3959 - val_acc: 0.7992\n",
      "[INFO] Training model: epoch 24th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4279 - acc: 0.7961 - val_loss: 1.2197 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 24th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2379 - acc: 0.8178 - val_loss: 1.1307 - val_acc: 0.8305\n",
      "[INFO] Training model: epoch 24th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4517 - acc: 0.7957 - val_loss: 1.3542 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 24th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4071 - acc: 0.7959 - val_loss: 1.3326 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3935 - acc: 0.8016 - val_loss: 1.1366 - val_acc: 0.8359\n",
      "[INFO] Training model: epoch 24th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3767 - acc: 0.7992 - val_loss: 1.3033 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3361 - acc: 0.8039 - val_loss: 1.2888 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 24th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3662 - acc: 0.7992 - val_loss: 1.3855 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 24th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3713 - acc: 0.7936 - val_loss: 1.1639 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 24th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3588 - acc: 0.8037 - val_loss: 1.3123 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3955 - acc: 0.8027 - val_loss: 1.4768 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 24th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2874 - acc: 0.8105 - val_loss: 1.3744 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 24th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4430 - acc: 0.7912 - val_loss: 1.2676 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3505 - acc: 0.8018 - val_loss: 1.3488 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 24th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3741 - acc: 0.8031 - val_loss: 1.3576 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 24th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2809 - acc: 0.8137 - val_loss: 1.2576 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 24th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2975 - acc: 0.8082 - val_loss: 1.4269 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 24th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3301 - acc: 0.8070 - val_loss: 1.6331 - val_acc: 0.7711\n",
      "[INFO] Training model: epoch 24th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3591 - acc: 0.8021 - val_loss: 1.3473 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 24th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2982 - acc: 0.8059 - val_loss: 1.2666 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 24th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3704 - acc: 0.8023 - val_loss: 1.2258 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 24th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3750 - acc: 0.8053 - val_loss: 1.3052 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2648 - acc: 0.8121 - val_loss: 1.1375 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 24th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2804 - acc: 0.8121 - val_loss: 1.3773 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 24th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4795 - acc: 0.7863 - val_loss: 1.2657 - val_acc: 0.8203\n",
      "[INFO] Training model: epoch 24th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4118 - acc: 0.7965 - val_loss: 1.4245 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 24th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3977 - acc: 0.7967 - val_loss: 1.3462 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 24th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3253 - acc: 0.8104 - val_loss: 1.3877 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 24th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3836 - acc: 0.8002 - val_loss: 1.4581 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 24th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3470 - acc: 0.8080 - val_loss: 1.4161 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 24th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4144 - acc: 0.7955 - val_loss: 1.2434 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 24th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4000 - acc: 0.7957 - val_loss: 1.3921 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 24th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2043 - acc: 0.8211 - val_loss: 1.3813 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 24th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3138 - acc: 0.8133 - val_loss: 1.2565 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 24th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3122 - acc: 0.8045 - val_loss: 1.5087 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 24th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3438 - acc: 0.8031 - val_loss: 1.4917 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 24th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3586 - acc: 0.7980 - val_loss: 1.4017 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 24th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3646 - acc: 0.7994 - val_loss: 1.2413 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 24th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3288 - acc: 0.8049 - val_loss: 1.5894 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 25th 0/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3960 - acc: 0.8012 - val_loss: 1.2768 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 25th 200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2930 - acc: 0.8096 - val_loss: 1.2587 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 25th 400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2705 - acc: 0.8072 - val_loss: 1.2805 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 25th 600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2443 - acc: 0.8137 - val_loss: 1.2179 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 25th 800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3052 - acc: 0.8084 - val_loss: 1.2655 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 1000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3167 - acc: 0.8039 - val_loss: 1.4537 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 25th 1200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3600 - acc: 0.7998 - val_loss: 1.3400 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 1400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3137 - acc: 0.7977 - val_loss: 1.2108 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 1600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2607 - acc: 0.8143 - val_loss: 1.5795 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 25th 1800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3321 - acc: 0.8111 - val_loss: 1.3191 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 2000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3136 - acc: 0.8029 - val_loss: 1.4017 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 25th 2200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3206 - acc: 0.8055 - val_loss: 1.3483 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 25th 2400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.1843 - acc: 0.8213 - val_loss: 1.2603 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 25th 2600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2758 - acc: 0.8107 - val_loss: 1.4837 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 2800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2766 - acc: 0.8105 - val_loss: 1.2419 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 25th 3000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2005 - acc: 0.8172 - val_loss: 1.3226 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 25th 3200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4202 - acc: 0.7916 - val_loss: 1.4231 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 3400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3103 - acc: 0.8033 - val_loss: 1.3485 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 3600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3339 - acc: 0.8002 - val_loss: 1.3027 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 25th 3800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3181 - acc: 0.8059 - val_loss: 1.2793 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 25th 4000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3265 - acc: 0.7996 - val_loss: 1.4188 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 25th 4200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3105 - acc: 0.8057 - val_loss: 1.2670 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 25th 4400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3916 - acc: 0.7963 - val_loss: 1.1080 - val_acc: 0.8328\n",
      "[INFO] Training model: epoch 25th 4600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2095 - acc: 0.8160 - val_loss: 1.1937 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 25th 4800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3327 - acc: 0.8002 - val_loss: 1.3233 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 25th 5000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3042 - acc: 0.8059 - val_loss: 1.4184 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 25th 5200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3059 - acc: 0.8068 - val_loss: 1.3893 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 25th 5400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3983 - acc: 0.7947 - val_loss: 1.2437 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 25th 5600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2754 - acc: 0.8139 - val_loss: 1.1419 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 25th 5800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3692 - acc: 0.7963 - val_loss: 1.1924 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 25th 6000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2821 - acc: 0.8037 - val_loss: 1.4813 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 25th 6200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2509 - acc: 0.8135 - val_loss: 1.2599 - val_acc: 0.8180\n",
      "[INFO] Training model: epoch 25th 6400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3090 - acc: 0.8088 - val_loss: 1.2757 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 25th 6600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3524 - acc: 0.7949 - val_loss: 1.3194 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 25th 6800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2522 - acc: 0.8135 - val_loss: 1.4366 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 25th 7000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3511 - acc: 0.8037 - val_loss: 1.1706 - val_acc: 0.8250\n",
      "[INFO] Training model: epoch 25th 7200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3189 - acc: 0.8104 - val_loss: 1.2692 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 25th 7400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2804 - acc: 0.8068 - val_loss: 1.1591 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 25th 7600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3617 - acc: 0.8020 - val_loss: 1.3237 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 25th 7800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3556 - acc: 0.8027 - val_loss: 1.2930 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 8000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2733 - acc: 0.8094 - val_loss: 1.2822 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 25th 8200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3921 - acc: 0.7928 - val_loss: 1.4357 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 8400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3061 - acc: 0.8102 - val_loss: 1.2266 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 25th 8600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2604 - acc: 0.8131 - val_loss: 1.3645 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 25th 8800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2818 - acc: 0.8115 - val_loss: 1.3716 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 9000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3121 - acc: 0.8021 - val_loss: 1.2237 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 25th 9200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3573 - acc: 0.8025 - val_loss: 1.4604 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 9400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2861 - acc: 0.8105 - val_loss: 1.3834 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 25th 9600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3717 - acc: 0.7994 - val_loss: 1.3390 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 9800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3388 - acc: 0.8074 - val_loss: 1.3379 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 25th 10000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3289 - acc: 0.8094 - val_loss: 1.2576 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 25th 10200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2761 - acc: 0.8074 - val_loss: 1.4278 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 25th 10400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3420 - acc: 0.8035 - val_loss: 1.5010 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 25th 10600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3770 - acc: 0.7973 - val_loss: 1.3188 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 25th 10800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3762 - acc: 0.8018 - val_loss: 1.4250 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 11000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3462 - acc: 0.8045 - val_loss: 1.5779 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 25th 11200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3138 - acc: 0.8053 - val_loss: 1.2351 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 25th 11400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3672 - acc: 0.8014 - val_loss: 1.3337 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 25th 11600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2857 - acc: 0.8088 - val_loss: 1.1831 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 25th 11800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3503 - acc: 0.7994 - val_loss: 1.3238 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 25th 12000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3274 - acc: 0.8094 - val_loss: 1.3217 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 12200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3679 - acc: 0.8047 - val_loss: 1.3724 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 12400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3546 - acc: 0.8031 - val_loss: 1.3460 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 25th 12600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3222 - acc: 0.8055 - val_loss: 1.3209 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 25th 12800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3194 - acc: 0.8047 - val_loss: 1.5267 - val_acc: 0.7805\n",
      "[INFO] Training model: epoch 25th 13000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2824 - acc: 0.8070 - val_loss: 1.1686 - val_acc: 0.8227\n",
      "[INFO] Training model: epoch 25th 13200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3781 - acc: 0.8006 - val_loss: 1.1896 - val_acc: 0.8266\n",
      "[INFO] Training model: epoch 25th 13400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3144 - acc: 0.8035 - val_loss: 1.2739 - val_acc: 0.8070\n",
      "[INFO] Training model: epoch 25th 13600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3257 - acc: 0.7998 - val_loss: 1.3984 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 25th 13800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2831 - acc: 0.8123 - val_loss: 1.4185 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 25th 14000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3701 - acc: 0.7977 - val_loss: 1.1741 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 25th 14200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4295 - acc: 0.7926 - val_loss: 1.4126 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 25th 14400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3229 - acc: 0.8084 - val_loss: 1.3762 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 25th 14600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3110 - acc: 0.8080 - val_loss: 1.3535 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 14800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3216 - acc: 0.8064 - val_loss: 1.2037 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 25th 15000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4499 - acc: 0.7887 - val_loss: 1.5267 - val_acc: 0.7820\n",
      "[INFO] Training model: epoch 25th 15200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3055 - acc: 0.8074 - val_loss: 1.3760 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 15400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2999 - acc: 0.8055 - val_loss: 1.3716 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 25th 15600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3534 - acc: 0.8018 - val_loss: 1.2718 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 25th 15800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2472 - acc: 0.8127 - val_loss: 1.4493 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 25th 16000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3322 - acc: 0.8078 - val_loss: 1.3310 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 25th 16200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3289 - acc: 0.8027 - val_loss: 1.3057 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 25th 16400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2981 - acc: 0.8063 - val_loss: 1.3683 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 25th 16600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 5s - loss: 1.2509 - acc: 0.8146 - val_loss: 0.9070 - val_acc: 0.8687\n",
      "[INFO] Training model: epoch 25th 16800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3418 - acc: 0.8043 - val_loss: 1.3249 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 25th 17000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3342 - acc: 0.8039 - val_loss: 1.3652 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 25th 17200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3167 - acc: 0.8053 - val_loss: 1.2534 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 25th 17400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3067 - acc: 0.8082 - val_loss: 1.1728 - val_acc: 0.8305\n",
      "[INFO] Training model: epoch 25th 17600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2779 - acc: 0.8119 - val_loss: 1.4003 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 25th 17800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2981 - acc: 0.8105 - val_loss: 1.3842 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 25th 18000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3192 - acc: 0.8037 - val_loss: 1.4572 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 18200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3072 - acc: 0.8082 - val_loss: 1.2050 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 25th 18400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3248 - acc: 0.8090 - val_loss: 1.5127 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 25th 18600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2931 - acc: 0.8104 - val_loss: 1.3460 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 25th 18800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3501 - acc: 0.8092 - val_loss: 1.3865 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 25th 19000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2876 - acc: 0.8113 - val_loss: 1.1675 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 25th 19200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3807 - acc: 0.8039 - val_loss: 1.3084 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 25th 19400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3727 - acc: 0.8002 - val_loss: 1.3497 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 25th 19600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4048 - acc: 0.7949 - val_loss: 1.2445 - val_acc: 0.8164\n",
      "[INFO] Training model: epoch 25th 19800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3350 - acc: 0.8113 - val_loss: 1.2982 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 20000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3243 - acc: 0.8053 - val_loss: 1.0234 - val_acc: 0.8438\n",
      "[INFO] Training model: epoch 25th 20200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3144 - acc: 0.8039 - val_loss: 1.1992 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 25th 20400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4270 - acc: 0.7920 - val_loss: 1.3387 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 25th 20600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3600 - acc: 0.8023 - val_loss: 1.4798 - val_acc: 0.7773\n",
      "[INFO] Training model: epoch 25th 20800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3217 - acc: 0.8049 - val_loss: 1.4567 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 25th 21000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3073 - acc: 0.8135 - val_loss: 1.2233 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 25th 21200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3724 - acc: 0.7977 - val_loss: 1.3465 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 25th 21400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3732 - acc: 0.7971 - val_loss: 1.1629 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 21600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3328 - acc: 0.8082 - val_loss: 1.3496 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 21800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4114 - acc: 0.7930 - val_loss: 1.3982 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 25th 22000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3967 - acc: 0.7969 - val_loss: 1.4419 - val_acc: 0.7797\n",
      "[INFO] Training model: epoch 25th 22200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2344 - acc: 0.8209 - val_loss: 1.3634 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 25th 22400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3417 - acc: 0.8018 - val_loss: 1.4775 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 25th 22600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3586 - acc: 0.7980 - val_loss: 1.2848 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 25th 22800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3433 - acc: 0.8078 - val_loss: 1.2068 - val_acc: 0.8320\n",
      "[INFO] Training model: epoch 25th 23000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2929 - acc: 0.8076 - val_loss: 1.3445 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 25th 23200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3336 - acc: 0.8033 - val_loss: 1.2139 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 25th 23400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2521 - acc: 0.8123 - val_loss: 1.2679 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 25th 23600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3960 - acc: 0.7998 - val_loss: 1.3877 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 23800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.7945 - val_loss: 1.3779 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 25th 24000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3606 - acc: 0.8021 - val_loss: 1.3534 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 25th 24200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3683 - acc: 0.7965 - val_loss: 1.4926 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 25th 24400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3034 - acc: 0.8055 - val_loss: 1.2823 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 25th 24600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3734 - acc: 0.8045 - val_loss: 1.3086 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 24800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3025 - acc: 0.8086 - val_loss: 1.3223 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 25000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2547 - acc: 0.8139 - val_loss: 1.3318 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 25200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2873 - acc: 0.8104 - val_loss: 1.1803 - val_acc: 0.8281\n",
      "[INFO] Training model: epoch 25th 25400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3698 - acc: 0.8037 - val_loss: 1.2314 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 25th 25600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3669 - acc: 0.8021 - val_loss: 1.3625 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 25th 25800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3971 - acc: 0.7912 - val_loss: 1.3098 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 25th 26000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3025 - acc: 0.8096 - val_loss: 1.3673 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 25th 26200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.7992 - val_loss: 1.2673 - val_acc: 0.8133\n",
      "[INFO] Training model: epoch 25th 26400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3384 - acc: 0.8004 - val_loss: 1.2889 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 25th 26600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3365 - acc: 0.8006 - val_loss: 1.3328 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 25th 26800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3305 - acc: 0.8025 - val_loss: 1.3923 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 25th 27000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2695 - acc: 0.8135 - val_loss: 1.2663 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 25th 27200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2456 - acc: 0.8129 - val_loss: 1.3396 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 27400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2905 - acc: 0.8084 - val_loss: 1.1212 - val_acc: 0.8313\n",
      "[INFO] Training model: epoch 25th 27600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3535 - acc: 0.8063 - val_loss: 1.2652 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 25th 27800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3240 - acc: 0.8063 - val_loss: 1.2570 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 28000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3925 - acc: 0.8004 - val_loss: 1.4852 - val_acc: 0.7812\n",
      "[INFO] Training model: epoch 25th 28200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2854 - acc: 0.8139 - val_loss: 1.2969 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 25th 28400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.2872 - acc: 0.8129 - val_loss: 1.3089 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 28600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3280 - acc: 0.8027 - val_loss: 1.4373 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 25th 28800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4505 - acc: 0.7912 - val_loss: 1.4906 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 25th 29000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4030 - acc: 0.7947 - val_loss: 1.2530 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 25th 29200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4146 - acc: 0.7943 - val_loss: 1.4934 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 25th 29400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4133 - acc: 0.7939 - val_loss: 1.4524 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 29600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2814 - acc: 0.8113 - val_loss: 1.3025 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 29800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3152 - acc: 0.8107 - val_loss: 1.2202 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 25th 30000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2879 - acc: 0.8102 - val_loss: 1.4282 - val_acc: 0.7844\n",
      "[INFO] Training model: epoch 25th 30200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3490 - acc: 0.7996 - val_loss: 1.1482 - val_acc: 0.8336\n",
      "[INFO] Training model: epoch 25th 30400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2493 - acc: 0.8123 - val_loss: 1.3039 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 25th 30600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3320 - acc: 0.8053 - val_loss: 1.4509 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 25th 30800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2856 - acc: 0.8098 - val_loss: 1.5306 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 25th 31000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3848 - acc: 0.8016 - val_loss: 1.2550 - val_acc: 0.8234\n",
      "[INFO] Training model: epoch 25th 31200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3010 - acc: 0.8064 - val_loss: 1.2839 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 31400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4331 - acc: 0.7963 - val_loss: 1.2096 - val_acc: 0.8258\n",
      "[INFO] Training model: epoch 25th 31600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3900 - acc: 0.7959 - val_loss: 1.3515 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 25th 31800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3769 - acc: 0.8008 - val_loss: 1.2418 - val_acc: 0.8219\n",
      "[INFO] Training model: epoch 25th 32000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4249 - acc: 0.7982 - val_loss: 1.5208 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 25th 32200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3017 - acc: 0.8104 - val_loss: 1.3894 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 25th 32400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4007 - acc: 0.7980 - val_loss: 1.2475 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 32600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3737 - acc: 0.8023 - val_loss: 1.2627 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 32800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3373 - acc: 0.8039 - val_loss: 1.4083 - val_acc: 0.7961\n",
      "[INFO] Training model: epoch 25th 33000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2838 - acc: 0.8074 - val_loss: 1.4505 - val_acc: 0.7695\n",
      "[INFO] Training model: epoch 25th 33200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3927 - acc: 0.7969 - val_loss: 1.3170 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 25th 33400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4317 - acc: 0.7928 - val_loss: 1.3892 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 25th 33600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3806 - acc: 0.8021 - val_loss: 1.2398 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 25th 33800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4010 - acc: 0.7959 - val_loss: 1.3389 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 25th 34000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2933 - acc: 0.8133 - val_loss: 1.3799 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 34200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3482 - acc: 0.8051 - val_loss: 1.2358 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 25th 34400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3706 - acc: 0.8021 - val_loss: 1.2134 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 34600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3249 - acc: 0.8063 - val_loss: 1.3152 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 34800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3841 - acc: 0.7973 - val_loss: 1.2700 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 35000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3280 - acc: 0.8047 - val_loss: 1.3760 - val_acc: 0.8055\n",
      "[INFO] Training model: epoch 25th 35200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3196 - acc: 0.8072 - val_loss: 1.3918 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 25th 35400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3661 - acc: 0.7963 - val_loss: 1.2060 - val_acc: 0.8188\n",
      "[INFO] Training model: epoch 25th 35600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2802 - acc: 0.8119 - val_loss: 1.4802 - val_acc: 0.7859\n",
      "[INFO] Training model: epoch 25th 35800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2984 - acc: 0.8074 - val_loss: 1.2979 - val_acc: 0.8148\n",
      "[INFO] Training model: epoch 25th 36000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3610 - acc: 0.8061 - val_loss: 1.3453 - val_acc: 0.8102\n",
      "[INFO] Training model: epoch 25th 36200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3572 - acc: 0.7990 - val_loss: 1.3963 - val_acc: 0.7828\n",
      "[INFO] Training model: epoch 25th 36400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3837 - acc: 0.8070 - val_loss: 1.4408 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 25th 36600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3652 - acc: 0.7949 - val_loss: 1.4800 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 25th 36800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4205 - acc: 0.7953 - val_loss: 1.3404 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 37000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3181 - acc: 0.8035 - val_loss: 1.3718 - val_acc: 0.8078\n",
      "[INFO] Training model: epoch 25th 37200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3812 - acc: 0.7977 - val_loss: 1.2077 - val_acc: 0.8141\n",
      "[INFO] Training model: epoch 25th 37400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3390 - acc: 0.7998 - val_loss: 1.4839 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 25th 37600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3149 - acc: 0.8072 - val_loss: 1.3315 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 25th 37800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3713 - acc: 0.8023 - val_loss: 1.5455 - val_acc: 0.7719\n",
      "[INFO] Training model: epoch 25th 38000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3282 - acc: 0.8035 - val_loss: 1.2194 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 38200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3240 - acc: 0.8020 - val_loss: 1.3785 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 25th 38400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4151 - acc: 0.7936 - val_loss: 1.3848 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 25th 38600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3820 - acc: 0.8033 - val_loss: 1.2092 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 25th 38800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3263 - acc: 0.8055 - val_loss: 1.3163 - val_acc: 0.8094\n",
      "[INFO] Training model: epoch 25th 39000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.8004 - val_loss: 1.4798 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 25th 39200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4629 - acc: 0.7918 - val_loss: 1.2700 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 39400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3551 - acc: 0.8049 - val_loss: 1.2948 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 25th 39600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2822 - acc: 0.8117 - val_loss: 1.5434 - val_acc: 0.7922\n",
      "[INFO] Training model: epoch 25th 39800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3861 - acc: 0.7963 - val_loss: 1.2091 - val_acc: 0.8195\n",
      "[INFO] Training model: epoch 25th 40000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3870 - acc: 0.7988 - val_loss: 1.5072 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 40200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3909 - acc: 0.7988 - val_loss: 1.3428 - val_acc: 0.8086\n",
      "[INFO] Training model: epoch 25th 40400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3191 - acc: 0.8072 - val_loss: 1.3235 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 25th 40600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2956 - acc: 0.8070 - val_loss: 1.3851 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 25th 40800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4032 - acc: 0.7906 - val_loss: 1.4863 - val_acc: 0.7766\n",
      "[INFO] Training model: epoch 25th 41000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3292 - acc: 0.8061 - val_loss: 1.3572 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 41200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3761 - acc: 0.8039 - val_loss: 1.3424 - val_acc: 0.7906\n",
      "[INFO] Training model: epoch 25th 41400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3112 - acc: 0.8096 - val_loss: 1.2794 - val_acc: 0.8117\n",
      "[INFO] Training model: epoch 25th 41600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3854 - acc: 0.7988 - val_loss: 1.3968 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 25th 41800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3508 - acc: 0.8049 - val_loss: 1.4552 - val_acc: 0.7875\n",
      "[INFO] Training model: epoch 25th 42000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3335 - acc: 0.8063 - val_loss: 1.5009 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 25th 42200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3825 - acc: 0.7975 - val_loss: 1.4212 - val_acc: 0.7883\n",
      "[INFO] Training model: epoch 25th 42400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2655 - acc: 0.8187 - val_loss: 1.5574 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 25th 42600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3414 - acc: 0.7990 - val_loss: 1.3339 - val_acc: 0.8039\n",
      "[INFO] Training model: epoch 25th 42800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2830 - acc: 0.8074 - val_loss: 1.2355 - val_acc: 0.8156\n",
      "[INFO] Training model: epoch 25th 43000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3591 - acc: 0.8070 - val_loss: 1.4312 - val_acc: 0.7937\n",
      "[INFO] Training model: epoch 25th 43200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s - loss: 1.3931 - acc: 0.8010 - val_loss: 1.2693 - val_acc: 0.8211\n",
      "[INFO] Training model: epoch 25th 43400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4882 - acc: 0.7891 - val_loss: 1.4302 - val_acc: 0.8023\n",
      "[INFO] Training model: epoch 25th 43600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3050 - acc: 0.8105 - val_loss: 1.4634 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 25th 43800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3402 - acc: 0.8018 - val_loss: 1.1522 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 44000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3049 - acc: 0.8125 - val_loss: 1.2764 - val_acc: 0.8273\n",
      "[INFO] Training model: epoch 25th 44200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4361 - acc: 0.7973 - val_loss: 1.2958 - val_acc: 0.8062\n",
      "[INFO] Training model: epoch 25th 44400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2905 - acc: 0.8143 - val_loss: 1.4214 - val_acc: 0.7867\n",
      "[INFO] Training model: epoch 25th 44600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3632 - acc: 0.7996 - val_loss: 1.3727 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 25th 44800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3459 - acc: 0.8000 - val_loss: 1.5098 - val_acc: 0.7781\n",
      "[INFO] Training model: epoch 25th 45000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3596 - acc: 0.8006 - val_loss: 1.3961 - val_acc: 0.8000\n",
      "[INFO] Training model: epoch 25th 45200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4278 - acc: 0.7879 - val_loss: 1.5912 - val_acc: 0.7672\n",
      "[INFO] Training model: epoch 25th 45400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3899 - acc: 0.7953 - val_loss: 1.2381 - val_acc: 0.8242\n",
      "[INFO] Training model: epoch 25th 45600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3448 - acc: 0.8045 - val_loss: 1.2611 - val_acc: 0.8172\n",
      "[INFO] Training model: epoch 25th 45800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4298 - acc: 0.7973 - val_loss: 1.3868 - val_acc: 0.7898\n",
      "[INFO] Training model: epoch 25th 46000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3074 - acc: 0.8057 - val_loss: 1.4266 - val_acc: 0.7953\n",
      "[INFO] Training model: epoch 25th 46200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4049 - acc: 0.8000 - val_loss: 1.4928 - val_acc: 0.7750\n",
      "[INFO] Training model: epoch 25th 46400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3107 - acc: 0.8096 - val_loss: 1.3300 - val_acc: 0.8031\n",
      "[INFO] Training model: epoch 25th 46600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2966 - acc: 0.8098 - val_loss: 1.4184 - val_acc: 0.8008\n",
      "[INFO] Training model: epoch 25th 46800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4199 - acc: 0.7939 - val_loss: 1.3822 - val_acc: 0.7977\n",
      "[INFO] Training model: epoch 25th 47000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3392 - acc: 0.8061 - val_loss: 1.4050 - val_acc: 0.8047\n",
      "[INFO] Training model: epoch 25th 47200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4005 - acc: 0.7930 - val_loss: 1.2304 - val_acc: 0.8297\n",
      "[INFO] Training model: epoch 25th 47400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3849 - acc: 0.8029 - val_loss: 1.3873 - val_acc: 0.7891\n",
      "[INFO] Training model: epoch 25th 47600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3147 - acc: 0.8037 - val_loss: 1.4822 - val_acc: 0.7836\n",
      "[INFO] Training model: epoch 25th 47800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3232 - acc: 0.8047 - val_loss: 1.2933 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 48000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3560 - acc: 0.8018 - val_loss: 1.3445 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 48200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3828 - acc: 0.8055 - val_loss: 1.3110 - val_acc: 0.8109\n",
      "[INFO] Training model: epoch 25th 48400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3884 - acc: 0.8039 - val_loss: 1.3798 - val_acc: 0.7945\n",
      "[INFO] Training model: epoch 25th 48600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3262 - acc: 0.8092 - val_loss: 1.3811 - val_acc: 0.7930\n",
      "[INFO] Training model: epoch 25th 48800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4197 - acc: 0.7953 - val_loss: 1.4720 - val_acc: 0.7914\n",
      "[INFO] Training model: epoch 25th 49000/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.3977 - acc: 0.7973 - val_loss: 1.4325 - val_acc: 0.7984\n",
      "[INFO] Training model: epoch 25th 49200/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.2875 - acc: 0.8156 - val_loss: 1.4240 - val_acc: 0.7969\n",
      "[INFO] Training model: epoch 25th 49400/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4468 - acc: 0.7918 - val_loss: 1.3544 - val_acc: 0.8016\n",
      "[INFO] Training model: epoch 25th 49600/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4479 - acc: 0.7881 - val_loss: 1.2541 - val_acc: 0.8125\n",
      "[INFO] Training model: epoch 25th 49800/50000 samples\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 4s - loss: 1.4017 - acc: 0.7994 - val_loss: 1.3799 - val_acc: 0.8023\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "#tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "checkpoint = ModelCheckpoint('./weight/with_attention_weight_1.hdf5', save_weights_only=True,save_best_only=True,monitor='val_loss')\n",
    "#callbacks_list = [tensorboard, checkpoint]\n",
    "\n",
    "k_start = 1\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # Training 500 sequences at a time\n",
    "    for i in range(0, len(X), 200):\n",
    "        if i + 200 >= len(X):\n",
    "            i_end = len(X)\n",
    "        else:\n",
    "            i_end = i + 200\n",
    "        y_sequences = process_data(y[i:i_end], y_max_len, y_word_to_ix)\n",
    "\n",
    "        print('[INFO] Training model: epoch {}th {}/{} samples'.format(k, i, len(X)))\n",
    "        model.fit(X[i:i_end], y_sequences, batch_size=BATCH_SIZE, nb_epoch=1, validation_split=0.2, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using Rouge score¶\n",
    "Evaluate your model as before, using Rouge score. Ideally, your scores for the model with attention should be better than the model without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london share prices higher at midday\n",
      "london share prices lower at midday\n",
      "UNK to UNK UNK UNK\n",
      "world cup world cup cup\n",
      "a UNK UNK UNK open open\n",
      "UNK signs as as as\n",
      "stocks down in mexico brazil chile chile chile chile\n",
      "UNK UNK UNK to baby baby\n",
      "is UNK UNK UNK UNK UNK\n",
      "johnson 's for for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK for election\n",
      "UNK 's UNK olympic for for\n",
      "john 's has to\n",
      "UNK UNK UNK to to UNK\n",
      "UNK 's 's UNK\n",
      "san 's UNK UNK to\n",
      "UNK UNK to to for\n",
      "UNK coach UNK coach coach coach coach\n",
      "stocks of in in of of\n",
      "ac milan milan milan milan milan milan milan milan\n",
      "will to to to at at\n",
      "UNK 's UNK UNK for in in in\n",
      "indonesian of of of of of of UNK UNK\n",
      "some 's UNK UNK on\n",
      "court court UNK UNK UNK\n",
      "a the to a to to\n",
      "stocks to UNK UNK UNK UNK\n",
      "derby derby derby derby derby derby\n",
      "school school in in\n",
      "<unk> to UNK UNK UNK to\n",
      "UNK UNK he to\n",
      "UNK UNK UNK UNK\n",
      "clinton UNK UNK UNK on on on\n",
      "UNK 's to to to\n",
      "UNK UNK to to for in\n",
      "UNK UNK UNK UNK\n",
      "UNK named as as coach coach\n",
      "u.s. UNK to UNK to in\n",
      "at UNK ## ## at at at\n",
      "a UNK UNK UNK UNK\n",
      "spanish wins UNK UNK\n",
      "red red to to with\n",
      "former UNK UNK to in in in in in\n",
      "jackson jackson jackson jackson for\n",
      "UNK UNK wins UNK UNK\n",
      "knicks knicks knicks in\n",
      "UNK 's UNK UNK UNK UNK\n",
      "london share prices up up\n",
      "UNK beats to #-# in in in\n",
      "UNK cup cup cup cup cup cup cup\n",
      "# killed in in in in\n",
      "UNK UNK UNK UNK on UNK UNK UNK UNK\n",
      "the of of of of of of\n",
      "how UNK UNK UNK UNK UNK UNK UNK\n",
      "stocks stocks in mexico brazil chile chile chile chile\n",
      "<unk> <unk> UNK\n",
      "UNK wins to for\n",
      "UNK UNK in in in\n",
      "UNK wins UNK of\n",
      "UNK signs UNK UNK to on on on\n",
      "russian sign UNK UNK\n",
      "'s for\n",
      "baseball baseball to for\n",
      "<unk> UNK UNK in\n",
      "UNK UNK UNK UNK UNK to UNK UNK UNK UNK\n",
      "london share prices index at midday\n",
      "microsoft 's UNK UNK UNK UNK UNK UNK\n",
      "woods woods UNK woods at\n",
      "a UNK 's 's 's\n",
      "UNK UNK UNK UNK UNK in\n",
      "UNK named named new coach coach coach coach\n",
      "UNK UNK to to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "boeing 's UNK ### ### in UNK\n",
      "lewis 's for to to for\n",
      "to to for for\n",
      "man man charged in in\n",
      "toyota 's to to to to\n",
      "former 's UNK UNK\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "'s of UNK UNK UNK UNK UNK UNK UNK\n",
      "red red red UNK UNK to to\n",
      "strong hits hits central\n",
      "UNK UNK UNK to to\n",
      "us inflation rise rise in in\n",
      "toyota UNK to to to UNK\n",
      "after UNK UNK to\n",
      "former UNK UNK\n",
      "three beats UNK in in in\n",
      "canada wins olympic gold gold gold gold gold gold\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK wins woods woods woods\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "olympic to bid bid bid ####\n",
      "a UNK UNK UNK UNK UNK\n",
      "nasa space launch space space launch launch\n",
      "china 's of of UNK of of UNK UNK\n",
      "explosion explosion in pakistan pakistan pakistan\n",
      "of dies dies dies dies at\n",
      "greece 's UNK UNK\n",
      "former president president dies dies\n",
      "greece greece greece euro euro euro euro euro euro\n",
      "france france france france for in\n",
      "clinton for for for for for in\n",
      "a UNK UNK of UNK UNK UNK\n",
      "ucla wins pole 's\n",
      "no. ## ## ## ##\n",
      "UNK UNK UNK at at at\n",
      "# u.s. in iraqi iraqi in in in\n",
      "france to UNK in in world cup cup cup\n",
      "us us UNK to to to to\n",
      "olympic olympic olympic to to in in in in\n",
      "UNK to to for in\n",
      "us UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "withdraws withdraws withdraws from open\n",
      "stock to to to to\n",
      "schumacher withdraws to in season grand\n",
      "tokyo stocks rise dollar higher against against yen\n",
      "UNK UNK UNK to UNK UNK\n",
      "UNK president president UNK to UNK UNK\n",
      "UNK UNK UNK cup cup world cup cup\n",
      "UNK UNK to to to to\n",
      "UNK to to to to to\n",
      "new to to to to to\n",
      "bank bank bank bank interest interest interest interest\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "tokyo stocks higher dollar dollar against yen yen\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> 's UNK UNK\n",
      "the on on on on on on\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK of in\n",
      "UNK 's UNK UNK UNK UNK\n",
      "air air force force force crashes ;\n",
      "UNK UNK UNK to UNK\n",
      "# in in UNK\n",
      "us police UNK UNK for\n",
      "UNK UNK UNK to UNK\n",
      "jones jones to to to for\n",
      "london stock exchange index down\n",
      "# UNK in in in in\n",
      "to to UNK to to to to UNK UNK\n",
      "a UNK a UNK UNK UNK UNK\n",
      "UNK UNK to ## at\n",
      "UNK UNK UNK UNK UNK\n",
      "world to asian asian asian in\n",
      "a UNK for for for\n",
      "no. ## ## ##\n",
      "tokyo stocks rise dollar higher against yen\n",
      "for UNK UNK UNK UNK UNK\n",
      "london share prices lower at midday\n",
      "UNK named UNK england england england\n",
      "UNK 's UNK UNK minister\n",
      "on 's UNK in\n",
      "judge 's UNK UNK UNK UNK\n",
      "rangers beats to #-# #-# #-#\n",
      "former says says says says s s\n",
      "london stock exchange in in\n",
      "olympic olympic in in in in in\n",
      "obama to to to to\n",
      "UNK UNK UNK for for\n",
      "beijing to to to to to to to for for\n",
      "china china china china china china\n",
      "<unk> UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "us street stock in\n",
      "woods woods UNK woods UNK\n",
      "celtics beats UNK #\n",
      "mexico mexico UNK of UNK of of UNK UNK\n",
      "UNK UNK in in in\n",
      "england UNK UNK UNK UNK in in in in\n",
      "liverpool UNK to to chelsea chelsea chelsea\n",
      "world of of UNK of of of\n",
      "mexico 's in in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "u.s. says to to oil\n",
      "pope pope pope for for\n",
      "UNK UNK UNK to UNK UNK UNK\n",
      "UNK says to to after\n",
      "clinton clinton clinton to clinton UNK UNK UNK\n",
      "agassi\n",
      "british wins UNK from open\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "olympic u.s. u.s. UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK strike strike in\n",
      "england 's to england\n",
      "the 's for of of\n",
      "film 's 's 's for\n",
      "more 's to to in in\n",
      "bush bush bush bush bush\n",
      "UNK 's UNK for\n",
      "UNK UNK UNK UNK to\n",
      "UNK UNK at at at\n",
      "UNK UNK UNK to UNK\n",
      "UNK to to to in in in\n",
      "south africa to south UNK a in in with with with with with with with with with\n",
      "UNK UNK after after after after after after in\n",
      "london share ftse-### index up ##.## points\n",
      "clippers re-sign center UNK\n",
      "UNK UNK UNK UNK in in in UNK\n",
      "australia to to to in in\n",
      "former UNK of UNK UNK to UNK for\n",
      "UNK says he he at at\n",
      "juventus beats beats #-# #-# serie\n",
      "# UNK to to to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "UNK 's UNK at at at\n",
      "UNK UNK to to for\n",
      "UNK wins UNK in\n",
      "dollar rises rise $ dollar to to to\n",
      "british pm says says says on\n",
      "michael jackson jackson to for for\n",
      "obama 's obama UNK\n",
      "eu eu to eu eu eu eu\n",
      "the of the the\n",
      "UNK UNK UNK world world world\n",
      "UNK 's UNK UNK UNK\n",
      "france france france france in in in cup cup\n",
      "olympic to to to #### #### ####\n",
      "oil prices fall in UNK\n",
      "american of for UNK of games games games\n",
      "judge UNK UNK UNK baby\n",
      "'s UNK to UNK UNK\n",
      "france france france france france france\n",
      "london share prices higher at midday\n",
      "# UNK UNK on on on of of\n",
      "to 's UNK UNK UNK to to to to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK named UNK UNK UNK\n",
      "UNK world UNK UNK UNK UNK\n",
      "pope says says says s UNK UNK\n",
      "woods to to for in\n",
      "red to to to season season season season\n",
      "us UNK UNK UNK UNK UNK UNK\n",
      "UNK wins wins wins\n",
      "UNK UNK to to for for for\n",
      "jackson jackson jackson jackson to\n",
      "israeli workers in ## in in in\n",
      "england beats #-# #-# in friendly friendly\n",
      "UNK UNK UNK UNK\n",
      "italy beats england in in\n",
      "car car car car car car crash crash crash crash crash crash crash crash\n",
      "bomb bomb UNK UNK in in in\n",
      "man UNK in in in\n",
      "after open out french open open open open\n",
      "to to in in in\n",
      "london s ftse-### index up ##.## points points\n",
      "UNK UNK to for for\n",
      "UNK UNK UNK UNK\n",
      "south korea north UNK nuclear nuclear nuclear\n",
      "UNK wins to to #-#\n",
      "a new a a UNK UNK UNK\n",
      "former UNK UNK UNK UNK UNK\n",
      "bush president president president president president president president president\n",
      "after UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK world world world cup\n",
      "UNK UNK UNK UNK UNK at at\n",
      "in 's UNK UNK UNK UNK UNK UNK UNK\n",
      "former former former <unk> dies dies dies\n",
      "former UNK UNK UNK UNK to\n",
      "UNK wins world cup\n",
      "police police UNK to UNK UNK in\n",
      "UNK cup cup cup cup cup\n",
      "UNK 's UNK in\n",
      "UNK UNK to at title title title\n",
      "vietnam to to to UNK to UNK UNK\n",
      "baseball UNK to baseball for baseball\n",
      "michael 's back has for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "england and pakistan in\n",
      "UNK UNK UNK\n",
      "spanish UNK UNK for for for for\n",
      "former signs <unk> <unk> from from\n",
      "new UNK UNK UNK\n",
      "UNK UNK UNK to to the\n",
      "UNK 's UNK UNK\n",
      "'s to to to to\n",
      "jordan jordan UNK jordan for\n",
      "stocks rise in mexico brazil ; ; ; chile\n",
      "brazil brazil to to as as to to in\n",
      "moderate earthquake shakes turkey turkey\n",
      "UNK wants to to\n",
      "devils devils devils # #-#\n",
      "celtics sign sign forward forward\n",
      "williams 's UNK\n",
      "in 's of UNK the UNK UNK UNK UNK UNK\n",
      "yankees UNK as to yankees\n",
      "us UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "braves ## to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "red UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "giants sign to to\n",
      "UNK UNK UNK UNK\n",
      "dole 's UNK UNK UNK\n",
      "two UNK UNK UNK UNK in in in\n",
      "## ## ##\n",
      "no. UNK UNK to in\n",
      "french korea UNK UNK UNK UNK in\n",
      "UNK UNK UNK UNK in in\n",
      "clinton clinton clinton clinton clinton clinton\n",
      "bryant bryant to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "in in UNK UNK to to to to to to\n",
      "UNK UNK on on on\n",
      "## in in\n",
      "broncos UNK UNK to to to\n",
      "giants ## giants giants giants\n",
      "giants 's in in in\n",
      "UNK UNK to to\n",
      "a UNK UNK\n",
      "judge judge UNK UNK UNK UNK\n",
      "# in in in in\n",
      "UNK 's UNK UNK\n",
      "yankees cancer to to\n",
      "a 's and UNK for for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "judge 's and UNK UNK to\n",
      "mccain mccain mccain on on on\n",
      "stars 's UNK UNK\n",
      "<unk> UNK UNK UNK UNK in in in in in\n",
      "UNK gets UNK johnson\n",
      "dodgers ## for ##\n",
      "in a a a a a a\n",
      "london share prices lower\n",
      "london share prices lower at midday\n",
      "cowboys 's for for\n",
      "court 's UNK UNK UNK\n",
      "lakers 's to with\n",
      "stars 's for UNK UNK\n",
      "coach coach coach coach coach coach\n",
      "UNK # in #\n",
      "astros storm to to\n",
      "texas # in in\n",
      "UNK ## to UNK UNK\n",
      "UNK UNK is to to to UNK\n",
      "hong 's to for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "to to to open open\n",
      "roddick withdraws out french french french open open\n",
      "super to for for for\n",
      "to to UNK UNK UNK UNK UNK\n",
      "de UNK UNK as to as as of of\n",
      "england says to to to to to\n",
      "UNK UNK UNK UNK\n",
      "<unk> 's to UNK\n",
      "un of of of of of\n",
      "new UNK in new\n",
      "stars may on on to\n",
      "UNK 's 's to says UNK UNK\n",
      "mavericks UNK UNK to to to\n",
      "u.s. to UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to for UNK\n",
      "yankees beat to to\n",
      "space space space space space space to to\n",
      "the of of of\n",
      "woods woods a woods a a\n",
      "england and in in in in\n",
      "agassi agassi agassi to\n",
      "no. wins ## to\n",
      "list the the the the the\n",
      "no. ## UNK ##\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jets UNK UNK UNK UNK\n",
      "no. UNK to to\n",
      "UNK UNK UNK for\n",
      "UNK UNK on UNK\n",
      "UNK UNK UNK UNK on\n",
      "raiders raiders UNK for for\n",
      "the 's a a for for\n",
      "injured wins at at\n",
      "stars stars to on\n",
      "UNK UNK for for\n",
      "no. # to UNK\n",
      "hong UNK to to\n",
      "baseball hall hall hall hall\n",
      "UNK ## UNK UNK\n",
      "UNK UNK UNK to\n",
      "explosion explosion in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK wins UNK UNK\n",
      "england and first draw draw test test\n",
      "stocks to to for\n",
      "UNK 's UNK at at at\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK\n",
      "us 's UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "iraqi 's UNK UNK UNK UNK UNK UNK UNK\n",
      "spain spain spain spain in in spain\n",
      "UNK UNK UNK UNK\n",
      "UNK beats #-# #-# #-# #-# league\n",
      "to to UNK UNK\n",
      "us 's UNK to to to to to UNK\n",
      "'s to to UNK UNK\n",
      "a 's the UNK UNK UNK\n",
      "'s to to to in\n",
      "world cup world cup for\n",
      "UNK UNK UNK UNK for for for\n",
      "UNK signs signs signs UNK\n",
      "woman woman UNK UNK\n",
      "england to to to to in in\n",
      "UNK wins wins grand grand\n",
      "UNK UNK to to to in in in\n",
      "UNK named UNK as coach\n",
      "u.s. u.s. UNK UNK UNK UNK in in in UNK\n",
      "UNK de to tour tour tour france\n",
      "woods 's UNK UNK\n",
      "roddick roddick to to open open open open\n",
      "UNK UNK UNK UNK\n",
      "bush 's bush bush bush bush\n",
      "un and in the and and and and\n",
      "UNK UNK gets UNK UNK\n",
      "former UNK UNK UNK to\n",
      "UNK to UNK\n",
      "UNK UNK of to to for to of of\n",
      "canada 's central rates interest rates rates\n",
      "share prices close lower\n",
      "tyson 's for for for\n",
      "wheat futures prices on on\n",
      "former 's still in at at at for\n",
      "UNK UNK UNK $ $ $ $\n",
      "'s 's UNK\n",
      "bruins bruins UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "former president president UNK dies dies\n",
      "a UNK of a UNK\n",
      "tokyo stocks rise dollar higher against yen yen\n",
      "UNK UNK dies dies dies at at\n",
      "UNK UNK UNK to to UNK UNK\n",
      "dollar falls against yen yen yen yen\n",
      "in UNK UNK UNK UNK UNK UNK\n",
      "london s ftse-### index up points points points\n",
      "a UNK UNK UNK\n",
      "UNK signs signs UNK UNK UNK\n",
      "two train in in in in\n",
      "midfielder signs signs UNK UNK\n",
      "greece UNK UNK UNK UNK UNK\n",
      "barcelona UNK UNK to to to\n",
      "<unk> UNK UNK UNK UNK\n",
      "un of UNK on on on\n",
      "<unk> signs signs signs UNK\n",
      "olympic olympic to to to for for\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "germany to to to in in\n",
      "UNK 's UNK UNK on on on\n",
      "israeli UNK israeli israeli in gaza gaza gaza\n",
      "to to to to to to\n",
      "judge to UNK to UNK UNK\n",
      "no. ## UNK ## UNK\n",
      "UNK UNK UNK UNK to to to\n",
      "crude futures prices up\n",
      "UNK UNK UNK UNK\n",
      "to 's in in in ;\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "kings sign UNK UNK\n",
      "michael 's 's to 's\n",
      "UNK out out out out\n",
      "microsoft 's for for\n",
      "UNK UNK UNK to\n",
      "UNK UNK UNK UNK UNK UNK with UNK UNK UNK\n",
      "london share prices up at midday\n",
      "'s to to in to\n",
      "armstrong ends in in in after in\n",
      "UNK wins UNK UNK\n",
      "UNK UNK UNK to UNK\n",
      "in of of of of of UNK UNK\n",
      "chelsea signs signs signs chelsea\n",
      "brazilian signs signs signs\n",
      "UNK says says to to to to to\n",
      "to UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "nfl 's to to to to\n",
      "us to to to on\n",
      "olympic 's to for for at at at\n",
      "bush UNK UNK on UNK\n",
      "china to to open\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK to to after\n",
      "french signs UNK to from from from\n",
      "UNK UNK UNK to to\n",
      "a UNK UNK UNK for for\n",
      "UNK signs signs signs UNK UNK\n",
      "bush bush bush bush bush bush bush\n",
      "# killed killed in in in\n",
      "england to to to in in in in\n",
      "armstrong s to for in\n",
      "world wins at in in in\n",
      "u.s. us UNK UNK in in in in in\n",
      "UNK UNK city city UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK in in in\n",
      "angels for in\n",
      "sign sign sign UNK UNK\n",
      "ford ford ford UNK UNK UNK UNK\n",
      "mets mets mets mets\n",
      "#### UNK UNK UNK UNK UNK of of\n",
      "key UNK UNK UNK\n",
      "mets UNK to to\n",
      "judge UNK UNK UNK UNK UNK\n",
      "yankees # to yankees\n",
      "former UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "knicks UNK UNK UNK UNK\n",
      "UNK signs coach as coach coach\n",
      "the the the the the the\n",
      "## of of in UNK UNK UNK\n",
      "man s to to to\n",
      "UNK UNK UNK in in in in\n",
      "french french first french french\n",
      "russia russia to UNK UNK\n",
      "UNK UNK UNK UNK to\n",
      "world cup cup cup cup cup cup\n",
      "share prices close higher\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK in in UNK in\n",
      "of of of UNK UNK UNK UNK UNK\n",
      "in to to to to to to\n",
      "taiwan stock market lower\n",
      "taiwan stocks market lower\n",
      "taiwan stock market down\n",
      "taiwan stock market higher\n",
      "asian asian asian asian in in in\n",
      "taiwan stock market down\n",
      "on of for UNK UNK\n",
      "UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK opens opens in in\n",
      "# UNK UNK UNK\n",
      "dollar dollar against against yen low low low low\n",
      "UNK UNK UNK to to to UNK UNK UNK\n",
      "iraq iraq UNK UNK\n",
      "bush of UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK in UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "drug to UNK UNK UNK\n",
      "UNK UNK dies dies dies at\n",
      "to and and and and\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to in in\n",
      "UNK UNK UNK UNK UNK\n",
      "michael wants for for\n",
      "UNK UNK UNK UNK\n",
      "former says says says in to UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "obama to to #.# percent percent percent\n",
      "UNK UNK UNK in\n",
      "the 's in in to to in\n",
      "UNK 's UNK to to UNK UNK\n",
      "two UNK in in\n",
      "first first first UNK to in flu flu flu\n",
      "UNK UNK UNK UNK a\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "u.s. flu to to to flu flu\n",
      "stocks to to to to to to\n",
      "UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "to 's UNK UNK\n",
      "turkey turkey turkey turkey turkey turkey turkey turkey\n",
      "of UNK for UNK UNK\n",
      "more 's UNK UNK UNK UNK\n",
      "a of UNK UNK UNK\n",
      "bush 's UNK to bush bush bush\n",
      "michael jackson jackson jackson for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK to the\n",
      "israel of of the the the the the\n",
      "the 's UNK the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK a UNK\n",
      "bank 's to to UNK UNK UNK\n",
      "a the in the to\n",
      "the the a for for a for\n",
      "iraq UNK UNK UNK UNK UNK UNK UNK\n",
      "chinese chinese UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> UNK UNK\n",
      "u.s. stocks to to to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "first of of on on on\n",
      "clinton clinton UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK to UNK UNK UNK\n",
      "on of #\n",
      "in house to to to to to to\n",
      "in UNK UNK UNK UNK UNK\n",
      "when to in UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK to UNK UNK\n",
      "<unk> UNK to internet internet internet\n",
      "UNK UNK UNK UNK\n",
      "a UNK UNK the the the UNK\n",
      "to to to for to for for\n",
      "man UNK UNK UNK UNK\n",
      "to UNK UNK UNK UNK in UNK\n",
      "senate senate UNK UNK UNK\n",
      "venezuela UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "for UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK\n",
      "former king king in for\n",
      "the of on internet internet\n",
      "israeli s UNK UNK to to UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "the UNK UNK UNK UNK\n",
      "a 's UNK UNK UNK UNK UNK UNK\n",
      "obama says to to UNK on on on on on on\n",
      "in 's UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "us UNK to to to to to\n",
      "UNK UNK UNK UNK\n",
      "in UNK UNK a a a\n",
      "UNK UNK UNK UNK\n",
      "wall stocks shares down #.# percent\n",
      "UNK 's to for\n",
      "the to to to for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "bush mexico UNK UNK\n",
      "a UNK is UNK is but in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK a UNK UNK UNK\n",
      "when UNK UNK for for\n",
      "<unk> <unk> up <unk> <unk> <unk>\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stars UNK to UNK UNK in\n",
      "the UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "<unk> UNK the the\n",
      "UNK UNK UNK UNK\n",
      "euro hits in in in in in\n",
      "a of the the\n",
      "u.s. on UNK UNK UNK\n",
      "do to n't your your your\n",
      "UNK UNK UNK UNK\n",
      "to UNK UNK UNK UNK to UNK UNK\n",
      "UNK UNK # UNK in\n",
      "the the for a\n",
      "UNK UNK UNK to in UNK UNK UNK\n",
      "a UNK UNK the\n",
      "## 's 's to to to to to\n",
      "the UNK the the in the\n",
      "UNK 's UNK UNK UNK UNK in in\n",
      "bush 's UNK UNK\n",
      "#.## your to for for\n",
      "world to for the the the the the\n",
      "your your your your your your\n",
      "UNK UNK UNK UNK UNK to UNK UNK UNK UNK UNK\n",
      "house UNK UNK for for in\n",
      "russian UNK UNK UNK UNK UNK\n",
      "india 's 's to UNK UNK in in\n",
      "mccain mccain mccain mccain mccain\n",
      "<unk> <unk> <unk> UNK\n",
      "UNK UNK UNK to UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK of UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to of of\n",
      "UNK UNK UNK UNK\n",
      "when in in UNK\n",
      "chinese UNK UNK UNK in UNK in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK in UNK\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "the the the the the the\n",
      "to UNK UNK\n",
      "stocks to to to to\n",
      "more UNK UNK for for for\n",
      "senate senate senate UNK to\n",
      "obama obama obama obama obama obama obama\n",
      "new 's to to to in\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "surgery UNK UNK UNK UNK\n",
      "to to UNK\n",
      "<unk> UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to UNK for\n",
      "UNK UNK UNK UNK UNK UNK of of of\n",
      "stocks to to for for in\n",
      "bush bush bush bush\n",
      "UNK UNK to to to for for\n",
      "a UNK UNK UNK UNK UNK\n",
      "in UNK and UNK UNK to UNK in UNK\n",
      "paris UNK UNK UNK UNK to to UNK\n",
      "us UNK UNK UNK UNK UNK UNK\n",
      "the to the the UNK\n",
      "bush UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "us UNK to to UNK on on\n",
      "a UNK of UNK the UNK the the the the the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "microsoft UNK UNK UNK\n",
      "cowboys 's to to\n",
      "a a a UNK UNK\n",
      "bruins UNK UNK UNK\n",
      "for UNK 's UNK the the the\n",
      "to UNK UNK UNK\n",
      "a 's a a a UNK\n",
      "us urges to to to\n",
      "turkey to to ## ## ##\n",
      "UNK UNK UNK UNK UNK in\n",
      "microsoft UNK and to to UNK UNK\n",
      "u.s. UNK UNK in\n",
      "obama UNK UNK UNK UNK\n",
      "UNK UNK the UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK ### to to UNK\n",
      "california to UNK UNK\n",
      "UNK UNK UNK 's UNK\n",
      "knicks 's knicks but\n",
      "a UNK UNK UNK\n",
      "dodgers dodgers dodgers dodgers dodgers dodgers\n",
      "UNK wins UNK UNK\n",
      "cowboys 's UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK coach as as coach coach coach\n",
      "big UNK UNK in\n",
      "bruins bruins UNK UNK\n",
      "in UNK UNK to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "lakers UNK UNK to\n",
      "dodgers is a a dodgers dodgers dodgers dodgers\n",
      "judge 's out to to\n",
      "former ## ## ## ## ## ## ## ##\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "the UNK for UNK\n",
      "UNK UNK UNK in\n",
      "for UNK UNK UNK UNK UNK to UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "stars UNK to to of of of of of of of of of of\n",
      "a 's UNK UNK\n",
      "UNK 's UNK to in\n",
      "california to on on on on on\n",
      "UNK UNK women women in in in\n",
      "the UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK is the\n",
      "a UNK UNK UNK UNK\n",
      "a 's to\n",
      "after UNK still to to\n",
      "the UNK the the UNK\n",
      "china 's of UNK to in UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "jets season n't to in in in\n",
      "UNK UNK UNK in at\n",
      "johnson johnson UNK to to\n",
      "UNK UNK 's UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK in to in in\n",
      "the 's the the\n",
      "british wins UNK at\n",
      "us UNK UNK UNK UNK UNK UNK UNK\n",
      "to to to for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a of UNK UNK UNK UNK\n",
      "the your a a a the\n",
      "UNK UNK UNK UNK UNK in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK to to UNK\n",
      "<unk> UNK UNK UNK\n",
      "UNK UNK UNK in UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "italy UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK a UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "george 's UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "bush 's UNK UNK the the the UNK\n",
      "UNK UNK UNK UNK for for for\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "dodgers ## in to\n",
      "jones 's to to to the the\n",
      "UNK 's UNK UNK\n",
      "# 's UNK UNK UNK\n",
      "a UNK in in in in in\n",
      "UNK UNK UNK UNK UNK\n",
      "house house UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "new UNK UNK the UNK\n",
      "UNK UNK for for in in\n",
      "UNK is for for\n",
      "jets 's to to\n",
      "when UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "san to to to to to\n",
      "a UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a 's of UNK in in in in\n",
      "UNK UNK UNK UNK\n",
      "<unk> # to # UNK\n",
      "UNK 's UNK UNK UNK the\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK a a UNK UNK UNK UNK\n",
      "california UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to to to to UNK\n",
      "for 's UNK UNK for for for\n",
      "at UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a the of of of of of of\n",
      "no. ## UNK for\n",
      "UNK of UNK UNK\n",
      "the 's for for\n",
      "'s in in UNK\n",
      "'s to at in\n",
      "stars UNK UNK to in in\n",
      "in a UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK UNK for\n",
      "at of of of of\n",
      "stars # to #-#\n",
      "dodgers dodgers dodgers dodgers dodgers\n",
      "stocks UNK UNK UNK\n",
      "stock UNK UNK to to to UNK\n",
      "rangers is in in in in in\n",
      "UNK 's UNK a a\n",
      "no. UNK UNK ##\n",
      "obama UNK UNK UNK UNK UNK\n",
      "new UNK UNK UNK UNK UNK the the\n",
      "china UNK is the the the\n",
      "the cox news service service budget budget for\n",
      "celtics 's a UNK UNK\n",
      "clemens clemens UNK to UNK\n",
      "UNK UNK UNK for for\n",
      "UNK UNK UNK UNK UNK\n",
      "the UNK of UNK UNK UNK UNK\n",
      "a UNK of UNK UNK UNK UNK of\n",
      "UNK UNK UNK for\n",
      "UNK and to UNK\n",
      "broncos broncos UNK to broncos broncos\n",
      "in UNK UNK UNK UNK UNK\n",
      "UNK UNK to to to\n",
      "the the the the the\n",
      "stars UNK to to of of\n",
      "stars 's to in\n",
      "UNK UNK to to to\n",
      "## ## UNK ## UNK UNK\n",
      "UNK open play open open\n",
      "<unk> <unk> <unk> to UNK\n",
      "UNK UNK on UNK UNK\n",
      "stocks UNK UNK at UNK\n",
      "the UNK UNK UNK UNK UNK\n",
      "williams williams to for\n",
      "stock UNK in\n",
      "UNK 's UNK UNK UNK UNK\n",
      "<unk> UNK on UNK\n",
      "UNK 's UNK UNK UNK\n",
      "a a a a UNK\n",
      "<unk> UNK UNK UNK\n",
      "the the UNK UNK UNK the the of\n",
      "celtics 's UNK UNK UNK UNK\n",
      "michael 's for UNK UNK the\n",
      "mets UNK to to to to to to\n",
      "in UNK UNK of of UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "to to to for for in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK to to UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "russia 's UNK to to to\n",
      "former UNK UNK UNK from UNK UNK\n",
      "obama obama obama obama obama obama obama\n",
      "a UNK UNK a UNK UNK UNK\n",
      "to 's to to UNK\n",
      "<unk> <unk> UNK UNK UNK\n",
      "mavericks UNK to to to UNK\n",
      "king king UNK to for\n",
      "to 's UNK UNK UNK UNK in in\n",
      "UNK UNK to to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "for UNK UNK to to UNK\n",
      "the UNK UNK the UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "cowboys UNK UNK for for\n",
      "new UNK and to UNK to to UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "stars UNK to to to to to to to\n",
      "clinton clinton UNK UNK UNK\n",
      "stocks stocks fall as as\n",
      "the the for a a\n",
      "UNK UNK UNK UNK for\n",
      "a 's to in to\n",
      "UNK UNK to to to in in\n",
      "jordan 's n't to to\n",
      "woods woods UNK open at open\n",
      "the the UNK the the the\n",
      "angels is n't 's\n",
      "to 's is is UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "devils devils UNK UNK against\n",
      "stars UNK to to to to to\n",
      "for UNK of to to school school school UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "the UNK the the UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "UNK of of UNK UNK of of\n",
      "<unk> UNK UNK UNK UNK\n",
      "a 's the the UNK a\n",
      "UNK 's to to to\n",
      "the UNK UNK UNK\n",
      "no. 's in ## in in\n",
      "UNK 's to to UNK\n",
      "a UNK UNK city\n",
      "hong kong UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "lakers lakers in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK for\n",
      "UNK stock UNK UNK in in\n",
      "UNK UNK UNK in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "us says says says UNK to\n",
      "the UNK UNK to UNK UNK\n",
      "'s 's UNK UNK to UNK UNK\n",
      "clippers ## up to\n",
      "jordan 's for to for\n",
      "jets UNK UNK UNK UNK UNK UNK\n",
      "lakers 's lakers to to lakers\n",
      "UNK UNK to UNK to\n",
      "UNK UNK UNK UNK\n",
      "microsoft 's to UNK\n",
      "kings wings to to to\n",
      "to is is to UNK UNK UNK\n",
      "celtics celtics celtics celtics\n",
      "UNK UNK to UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK for\n",
      "<unk> UNK UNK to for for\n",
      "no. women to to\n",
      "UNK 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "a a a a a a\n",
      "judge UNK UNK to to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to to\n",
      "the 's to for\n",
      "UNK 's in in\n",
      "new UNK on on on\n",
      "toyota UNK for for for for\n",
      "a 's 's to to in in in in in\n",
      "UNK UNK to to to\n",
      "UNK coach coach as as as coach\n",
      "a UNK UNK UNK UNK\n",
      "## of in in in\n",
      "woods woods UNK woods tiger\n",
      "red sign sign to to\n",
      "UNK UNK n't to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK\n",
      "UNK UNK UNK UNK on on on on on\n",
      "new york UNK UNK UNK UNK\n",
      "clinton UNK UNK UNK\n",
      "new UNK in to\n",
      "stocks UNK UNK UNK\n",
      "new new new new new new the\n",
      "broncos 's UNK UNK UNK to to to\n",
      "for UNK to to UNK a the\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "patriots patriots patriots to patriots to\n",
      "in of of of UNK UNK UNK UNK UNK\n",
      "thailand 's for for of\n",
      "bush bush bush bush bush bush bush\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "bruins ## UNK ##\n",
      "a UNK UNK UNK UNK\n",
      "london 's in in at at\n",
      "wall street street UNK dies dies\n",
      "how in in in\n",
      "women # ## ## UNK\n",
      "jets jets in UNK\n",
      "UNK UNK UNK to to in in\n",
      "UNK UNK UNK UNK UNK\n",
      "this still for #### for\n",
      "san UNK to to to\n",
      "israeli of UNK UNK to to UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stars named name coach coach coach\n",
      "red wings to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "dodgers get UNK in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "after UNK UNK UNK in in in in\n",
      "UNK UNK UNK UNK\n",
      "new to to new for for for\n",
      "cowboys 's UNK UNK to\n",
      "after UNK UNK UNK UNK to to the\n",
      "internet internet internet internet internet internet\n",
      "UNK UNK UNK on on on on\n",
      "police police arrest UNK UNK UNK\n",
      "the 's UNK UNK for for\n",
      "toyota UNK UNK in UNK UNK UNK\n",
      "clinton UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "in UNK to UNK to UNK in in in in\n",
      "stock UNK to to to\n",
      "john 's to for\n",
      "rangers UNK to to to to\n",
      "the UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in\n",
      "a UNK to UNK UNK\n",
      "<unk> <unk> <unk> <unk>\n",
      "boeing 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to to\n",
      "a UNK UNK UNK UNK UNK\n",
      "red to to to to to\n",
      "UNK UNK to to to to to\n",
      "<unk> internet internet to internet internet\n",
      "UNK 's UNK to\n",
      "gordon 's UNK UNK UNK\n",
      "<unk> UNK to UNK\n",
      "un iraq iraq UNK to to iraq iraq iraq iraq\n",
      "at UNK of for UNK\n",
      "cowboys to to to\n",
      "yankees 's for but to\n",
      "google to for for for\n",
      "in the of of of\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "microsoft to to UNK\n",
      "johnson johnson johnson johnson to to to to\n",
      "the UNK UNK UNK UNK\n",
      "a 's 's to to in in\n",
      "for 's a a for for for\n",
      "UNK UNK UNK UNK\n",
      "us to UNK UNK to to to\n",
      "UNK <unk> <unk> <unk> <unk> UNK\n",
      "obama UNK UNK UNK UNK UNK UNK to to to\n",
      "former 's s UNK UNK UNK UNK\n",
      "UNK wins wins world cup cup\n",
      "UNK UNK to to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "giants UNK to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK to for\n",
      "no. ## to to to\n",
      "UNK UNK UNK in UNK\n",
      "UNK UNK to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "rockies 's to to a a\n",
      "jackson 's his 's\n",
      "no 's n't for for for\n",
      "some UNK UNK a for UNK\n",
      "no. ## to to to in in\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "a 's of of\n",
      "new UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK the UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK for UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> <unk> to to\n",
      "UNK 's UNK UNK UNK\n",
      "UNK UNK UNK to obama obama\n",
      "to UNK UNK to UNK UNK\n",
      "clinton clinton clinton to clinton to\n",
      "rangers 's UNK UNK UNK UNK\n",
      "UNK UNK and UNK UNK UNK a on on UNK UNK\n",
      "UNK UNK UNK\n",
      "a UNK UNK UNK UNK the the the\n",
      "UNK UNK UNK UNK UNK in UNK\n",
      "rangers UNK to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "a your a a a\n",
      "UNK UNK UNK UNK\n",
      "former UNK of ##\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK to\n",
      "stars stars to to to\n",
      "the UNK the the UNK\n",
      "UNK UNK UNK UNK\n",
      "senate senate senate UNK senate UNK\n",
      "mavericks # mavericks #\n",
      "us UNK to to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "former UNK UNK UNK UNK UNK in in in\n",
      "new UNK UNK UNK UNK UNK UNK on\n",
      "a 's to to for\n",
      "UNK UNK to UNK\n",
      "super says UNK to for\n",
      "stars beats #-# #-# in in\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to UNK UNK UNK UNK UNK\n",
      "los film the the the the\n",
      "new 's UNK for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "texas texas the the the the\n",
      "the 's news business for for\n",
      "cowboys cowboys UNK to\n",
      "UNK of UNK UNK UNK\n",
      "UNK UNK to UNK UNK\n",
      "stock UNK in UNK UNK UNK\n",
      "jets jets jets jets jets jets jets\n",
      "a 's UNK UNK UNK\n",
      "ucla 's to UNK UNK\n",
      "hall 's hall hall for\n",
      "jordan 's to jordan jordan\n",
      "a UNK of the of UNK UNK\n",
      "giants ## giants to\n",
      "u.s. stocks rise as UNK to UNK\n",
      "UNK beats to UNK UNK\n",
      "UNK UNK UNK for for for\n",
      "texas UNK UNK UNK texas texas texas\n",
      "yankees # to # #-#\n",
      "UNK UNK UNK UNK UNK\n",
      "celtics UNK UNK UNK UNK\n",
      "toyota to to for for for for for\n",
      "'s for to to\n",
      "john UNK to to to to\n",
      "in UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK is UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK to to UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "us of of in in in in\n",
      "UNK leaves UNK to to to to\n",
      "it 's UNK UNK a a\n",
      "some 's UNK to to to to to UNK\n",
      "stars UNK UNK UNK UNK\n",
      "baseball baseball baseball UNK\n",
      "UNK 's UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK germany\n",
      "magic sign to to on\n",
      "stars ## to to #-# #-#\n",
      "a UNK 's a UNK UNK\n",
      "texas texas in in in\n",
      "first UNK to to to to in in in in\n",
      "a UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK\n",
      "tyson tyson tyson tyson 's 's\n",
      "california of UNK UNK in\n",
      "yankees UNK to UNK to\n",
      "obama UNK to to\n",
      "us UNK UNK UNK UNK UNK UNK\n",
      "johnson johnson johnson johnson for for\n",
      "dodgers UNK dodgers for\n",
      "a UNK UNK UNK\n",
      "to to to UNK UNK\n",
      "<unk> 's UNK UNK\n",
      "UNK 's to in in\n",
      "advance UNK 's to UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK to UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "in UNK to UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "new york york new\n",
      "rangers 's to rangers\n",
      "after UNK UNK UNK\n",
      "UNK UNK star UNK UNK UNK UNK UNK\n",
      "yankees UNK yankees yankees\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> 's <unk> UNK UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK to of\n",
      "in 's state state state state state\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK in\n",
      "ucla beats to to\n",
      "the UNK UNK UNK UNK UNK UNK UNK\n",
      "california UNK UNK UNK\n",
      "the UNK and a UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "the UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "nasa to to to UNK\n",
      "at UNK ## ## ## at at\n",
      "armstrong armstrong tour tour tour tour tour tour de de\n",
      "UNK 's UNK UNK UNK\n",
      "in UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "a of UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK ## UNK\n",
      "microsoft UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK has to UNK\n",
      "for UNK UNK the the\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "the 's of the the the the\n",
      "UNK UNK of UNK\n",
      "a UNK UNK UNK\n",
      "UNK 's UNK win\n",
      "UNK wins UNK olympic to\n",
      "rangers UNK UNK UNK rangers rangers\n",
      "bruins beat UNK UNK\n",
      "clemens UNK to\n",
      "UNK UNK UNK UNK\n",
      "the #### for for\n",
      "UNK UNK UNK UNK\n",
      "ucla 's for for for for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "rangers UNK UNK UNK for for the\n",
      "UNK UNK UNK UNK UNK\n",
      "internet internet to on internet on internet internet internet internet\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "jones 's UNK UNK UNK\n",
      "the UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "in 's in UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to in in\n",
      "the 's to UNK\n",
      "the UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK UNK UNK\n",
      "in of in in in in in\n",
      "UNK 's for for\n",
      "south # in in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK of UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "giants is to to to to\n",
      "us sales sales rises in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK of\n",
      "in a of a a a the\n",
      "the UNK the the UNK\n",
      "johnson 's for UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK a a UNK\n",
      "the 's UNK UNK\n",
      "jordan jordan for to\n",
      "'s to for\n",
      "women women women to\n",
      "UNK UNK his UNK\n",
      "UNK of of UNK\n",
      "mets mets mets UNK mets\n",
      "UNK UNK UNK to UNK\n",
      "UNK UNK UNK UNK to in UNK UNK\n",
      "UNK UNK to in\n",
      "UNK UNK and with UNK\n",
      "in for UNK UNK UNK the the UNK UNK UNK\n",
      "china 's UNK UNK to of of of of of\n",
      "house UNK UNK UNK UNK UNK UNK\n",
      "revolution UNK to UNK\n",
      "fire UNK UNK to\n",
      "UNK UNK UNK UNK UNK\n",
      "the 's UNK the the of of\n",
      "cowboys UNK UNK in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "'s UNK to\n",
      "UNK UNK UNK UNK UNK\n",
      "mavericks # to #\n",
      "UNK UNK UNK UNK UNK\n",
      "a of a a a a a in in\n",
      "former 's UNK of to to UNK\n",
      "iraq iraq iraq UNK UNK UNK war\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK of\n",
      "bush 's UNK UNK\n",
      "wins wins UNK\n",
      "yankees ## to UNK\n",
      "dodgers UNK to to\n",
      "los angeles to ##\n",
      "new shares shares down percent percent percent percent\n",
      "mccain mccain mccain to\n",
      "UNK says UNK UNK UNK UNK\n",
      "some UNK UNK to a a in in\n",
      "some UNK UNK a a a in in\n",
      "UNK UNK UNK UNK in\n",
      "stars UNK UNK #-# in in\n",
      "yankees UNK a a #-#\n",
      "california of to to on\n",
      "bush bush UNK UNK UNK for\n",
      "celtics defense up for\n",
      "giants ## UNK UNK UNK\n",
      "UNK 's UNK to to to to\n",
      "miller 's UNK 's\n",
      "UNK 's his UNK\n",
      "UNK wins world women\n",
      "UNK 's UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in in\n",
      "a UNK in UNK UNK in in in\n",
      "a 's for UNK for for\n",
      "world UNK world UNK UNK at\n",
      "cowboys UNK UNK UNK for for UNK\n",
      "rangers beats rangers #-# in\n",
      "UNK UNK UNK UNK UNK\n",
      "brown 's UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "# UNK UNK UNK UNK UNK\n",
      "stocks stocks mixed as stocks stocks stocks\n",
      "UNK UNK UNK UNK\n",
      "yankees ## to in\n",
      "UNK UNK UNK UNK to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "clinton clinton UNK UNK UNK UNK UNK\n",
      "UNK UNK the the the the\n",
      "florida UNK to to\n",
      "los angeles angeles news\n",
      "olympic UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "mets sign UNK to to\n",
      "kings may to to to to\n",
      "kings sign kings to to\n",
      "a UNK UNK UNK UNK\n",
      "the 's to to to to\n",
      "UNK 's for for for\n",
      "the UNK the the the\n",
      "no UNK on to\n",
      "first UNK in in\n",
      "UNK UNK UNK UNK in\n",
      "a UNK UNK in UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "clinton clinton UNK on on on\n",
      "UNK wins UNK UNK\n",
      "stocks stocks UNK to to to\n",
      "says says to to in in in in in in in in in\n",
      "the to to UNK to to\n",
      "UNK UNK UNK UNK UNK\n",
      "jets 's UNK to UNK UNK\n",
      "wall UNK 's UNK of of\n",
      "angels ## to ##\n",
      "UNK 's on of of\n",
      "new UNK of on UNK UNK\n",
      "kings get to to\n",
      "the UNK UNK UNK UNK UNK\n",
      "in UNK 's UNK the the the UNK\n",
      "a UNK a UNK UNK UNK UNK\n",
      "UNK UNK to at at at\n",
      "UNK UNK for for\n",
      "dodgers is a to\n",
      "texas # in #\n",
      "UNK UNK UNK UNK in in\n",
      "american man wins UNK in in in in in in\n",
      "stars 's UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "new city of in for in\n",
      "for UNK to to to UNK to to\n",
      "to to to to to to\n",
      "brazil UNK UNK UNK UNK UNK UNK\n",
      "jets UNK UNK for\n",
      "us of a a for in in\n",
      "in 's UNK UNK for UNK\n",
      "nets UNK to UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> UNK of UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to to in\n",
      "jets 's UNK UNK UNK to to to of\n",
      "UNK 's UNK to\n",
      "the UNK UNK a\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "holiday to for UNK\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "'s to to for\n",
      "UNK UNK to of at the the the\n",
      "lakers lakers lakers lakers lakers lakers\n",
      "UNK UNK to UNK in\n",
      "in UNK UNK UNK UNK UNK UNK UNK to to\n",
      "UNK and at at at\n",
      "google 's on internet\n",
      "UNK 's UNK the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "treasury prices rise on stocks\n",
      "john 's to UNK UNK UNK\n",
      "<unk> <unk> UNK UNK UNK for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "gm to to to\n",
      "more UNK to for\n",
      "<unk> UNK UNK in UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "kings kings kings kings kings\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK\n",
      "in UNK UNK UNK UNK to to to to to\n",
      "rangers rangers rangers UNK in\n",
      "women women women UNK UNK women women\n",
      "UNK UNK UNK in\n",
      "in of of UNK UNK UNK in and\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "cowboys cowboys cowboys cowboys\n",
      "dodgers UNK dodgers dodgers\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "china UNK to to\n",
      "rangers rangers rangers rangers rangers rangers rangers\n",
      "awards UNK to awards awards awards awards awards awards\n",
      "talks 's 's to UNK\n",
      "UNK UNK to for for for\n",
      "stocks angeles to to\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "stocks stocks in early early trading\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK return\n",
      "UNK coach coach coach coach\n",
      "UNK UNK of to UNK UNK\n",
      "the UNK UNK UNK\n",
      "the 's for UNK UNK UNK\n",
      "UNK UNK UNK to #-#\n",
      "un of of of of of of of UNK\n",
      "senate senate new on on on on\n",
      "los UNK UNK to to to UNK\n",
      "a the a a a for\n",
      "some UNK UNK for for UNK UNK\n",
      "dodgers brown to to to\n",
      "UNK 's UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "roddick in in in in in\n",
      "broncos UNK UNK to to to to to\n",
      "a UNK UNK a UNK UNK UNK\n",
      "UNK UNK 's to\n",
      "senate s to UNK UNK\n",
      "broncos 's to UNK to\n",
      "UNK UNK to UNK\n",
      "UNK 's UNK UNK\n",
      "the the the the UNK\n",
      "in UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a UNK a a a a UNK UNK\n",
      "UNK UNK UNK UNK in in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "michael 's in in\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK\n",
      "knicks 's in UNK\n",
      "the UNK UNK UNK UNK the the the\n",
      "the UNK UNK UNK for a a\n",
      "u.s. UNK UNK for for a\n",
      "giants 's UNK UNK UNK for\n",
      "<unk> UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "angels fall down down\n",
      "los angeles daily news budget\n",
      "UNK UNK to for in\n",
      "the the the the the the the\n",
      "UNK UNK UNK UNK\n",
      "michael jackson jackson to UNK\n",
      "u.s. ### to to in in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "california UNK in in in in\n",
      "two UNK UNK in crash crash\n",
      "the UNK UNK UNK UNK\n",
      "in UNK UNK UNK in in in in\n",
      "the UNK 's UNK UNK\n",
      "UNK 's at at at\n",
      "lakers lakers lakers ##\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a of of of UNK in\n",
      "some UNK UNK on on on\n",
      "UNK UNK UNK to\n",
      "<unk> UNK UNK UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "stars ## to to\n",
      "the UNK UNK to\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "new UNK on on for in in\n",
      "to to to to to\n",
      "UNK UNK UNK UNK in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to UNK in in\n",
      "after UNK UNK for to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK as UNK\n",
      "knicks UNK UNK to to win win\n",
      "rangers beat rangers rangers rangers rangers rangers\n",
      "UNK 's UNK in\n",
      "dodgers get for news\n",
      "UNK UNK of UNK UNK UNK UNK UNK\n",
      "the a a a for for the\n",
      "UNK UNK 's UNK UNK\n",
      "UNK UNK to to in in\n",
      "UNK UNK <unk> UNK UNK UNK UNK UNK\n",
      "in of UNK UNK UNK UNK UNK\n",
      "new UNK UNK UNK UNK\n",
      "'s to for for\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "former UNK UNK UNK to to UNK UNK UNK UNK UNK\n",
      "baseball 's baseball UNK\n",
      "a UNK UNK UNK UNK\n",
      "UNK UNK on UNK\n",
      "gop 's gop for for for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "miller 's on with\n",
      "UNK 's UNK to UNK UNK UNK\n",
      "clemens UNK UNK to UNK UNK\n",
      "UNK UNK UNK in in UNK\n",
      "obama says to to to to in in in in in in\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK in\n",
      "woods woods for at at\n",
      "UNK UNK ## at at\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "UNK 's UNK to UNK\n",
      "world cup cup cup in in in cup\n",
      "for UNK UNK UNK the the the the the\n",
      "braves UNK for UNK\n",
      "braves ## ## ##\n",
      "mets # mets #\n",
      "<unk> <unk> in\n",
      "UNK 's to to\n",
      "UNK UNK to UNK\n",
      "a 's UNK UNK UNK\n",
      "<unk> UNK UNK\n",
      "UNK UNK UNK $ $ $ $\n",
      "UNK ## to ##\n",
      "more to for UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "south s to to to for for for UNK\n",
      "the 's to UNK\n",
      "UNK UNK UNK UNK\n",
      "a UNK UNK UNK of of of\n",
      "UNK says UNK to\n",
      "stars sign UNK to #-# #-#\n",
      "in UNK UNK UNK UNK UNK\n",
      "UNK 's UNK to\n",
      "UNK UNK UNK UNK UNK\n",
      "bush 's to UNK\n",
      "red is the for UNK\n",
      "some in UNK UNK UNK\n",
      "fall stocks 's UNK UNK\n",
      "UNK UNK UNK UNK UNK in\n",
      "mets UNK UNK UNK\n",
      "a 's UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "#### 's to to world world\n",
      "mets UNK mets to to to\n",
      "for UNK a UNK a a the the the\n",
      "a of of a UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "israel UNK UNK UNK UNK UNK UNK UNK\n",
      "texas texas to to to to to\n",
      "to to UNK UNK UNK UNK UNK\n",
      "for UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK at UNK UNK\n",
      "at UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK at\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK for for\n",
      "UNK UNK to to to for for for\n",
      "stars UNK to to to to to\n",
      "giants UNK UNK to UNK in to\n",
      "new UNK UNK to UNK UNK UNK\n",
      "UNK 's UNK to in in in in\n",
      "UNK UNK to to\n",
      "UNK UNK UNK UNK\n",
      "rangers UNK rangers rangers rangers\n",
      "for to to to to to to to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK to to\n",
      "UNK 's UNK\n",
      "johnson 's UNK of\n",
      "to of in in in in in\n",
      "iraq iraq iraq iraq iraq iraq iraq iraq iraq iraq iraq iraq\n",
      "a UNK UNK in in in\n",
      "judge judge in in UNK UNK\n",
      "<unk> UNK UNK UNK UNK UNK\n",
      "jones jones to UNK UNK\n",
      "johnson johnson johnson his UNK to\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "to in in in\n",
      "for UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK of the UNK UNK\n",
      "brazil to to to to to for UNK\n",
      "the UNK UNK in the UNK UNK\n",
      "UNK UNK and at and and\n",
      "german stock exchange end\n",
      "australian stocks close lower\n",
      "california UNK UNK UNK in\n",
      "## of of in in\n",
      "hong kong hong hong in\n",
      "russia russia sign UNK\n",
      "police police UNK in in\n",
      "brazil lead #-# #-# in\n",
      "<unk> UNK opens opens opens opens\n",
      "australian dollar closes higher\n",
      "chinext index opens higher higher\n",
      "south korea UNK UNK UNK to for for UNK\n",
      "chinext index opens lower lower\n",
      "chinext index opens lower wednesday\n",
      "dollar trades in mid-## yen in tokyo\n",
      "dollar rises to to yen in in\n",
      "dollar trades in lower ## yen in\n",
      "dollar trades in in yen in range\n",
      "oil futures fall fall\n",
      "dollar at at lower ### yen in tokyo\n",
      "the 's UNK UNK UNK a to\n",
      "UNK south south south africa\n",
      "kuala lumpur stocks close higher\n",
      "bulgarian stock market ends higher\n",
      "german stocks open mixed\n",
      "german stocks open lower\n",
      "german stocks open higher\n",
      "nikkei closes #.## pct higher\n",
      "dollar at at ## yen in tokyo\n",
      "UNK UNK minister in in\n",
      "shanghai stock market down down\n",
      "international conference opens opens opens opens opens\n",
      "china 's UNK UNK for in\n",
      "dollar opens opens opens in\n",
      "UNK UNK UNK in in\n",
      "new zealand stocks close lower\n",
      "crude prices fall on\n",
      "tokyo shares close higher higher higher\n",
      "london shares in in at in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "kuala lumpur stocks close lower\n",
      "china province to in\n",
      "u.s. to to on on on on on\n",
      "parliament parliament in in in\n",
      "world cup cup cup cup\n",
      "chinese chinese UNK for for UNK UNK\n",
      "sri lanka lanka in in in in in\n",
      "china in in in in in\n",
      "shanghai stock market market\n",
      "german stock exchange end mixed\n",
      "dollar at at lower ### yen in tokyo\n",
      "german stocks open lower\n",
      "new UNK prices in in\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar trades at lower yen in in tokyo\n",
      "australian stock market rises\n",
      "australian dollar closes lower\n",
      "UNK UNK new 's at\n",
      "<unk> 's new <unk> <unk>\n",
      "u.s. stocks fall lower on\n",
      "#### to host #### #### #### ####\n",
      "dollar at upper upper ### yen in tokyo\n",
      "german stocks open lower\n",
      "chinese shares down #.## pct in\n",
      "bulgarian stock market ends higher\n",
      "dollar at in upper ## yen in tokyo\n",
      "dollar at upper ## yen in tokyo\n",
      "first to first first first\n",
      "wall street stocks on on\n",
      "dollar hits against yen yen tokyo\n",
      "xinhua news news news\n",
      "crude futures futures sharply\n",
      "dollar at at lower yen yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar at upper upper yen yen in tokyo\n",
      "stocks shares end end stock\n",
      "# killed in in in in\n",
      "dollar trades lower ## yen in in\n",
      "s. korean shares close higher\n",
      "u.s. stocks trade mixed\n",
      "malaysia stocks stocks close higher\n",
      "bush 's president UNK UNK UNK UNK\n",
      "german stocks close ends\n",
      "court UNK\n",
      "bangladesh 's for elections elections\n",
      "china 's UNK china china china\n",
      "dollar at upper upper ## yen in\n",
      "dollar trades in lower ## yen in in\n",
      "dollar trades at lower ## yen in in\n",
      "dollar at lower ## yen in tokyo\n",
      "chinese shares down #.## pct in\n",
      "dollar falls to ## ## ## in\n",
      "dollar trades lower lower yen yen in\n",
      "china beats china #-# in soccer soccer\n",
      "china 's to UNK 's in\n",
      "new zealand zealand new on on on on\n",
      "australian defense minister to to\n",
      "australian dollar closes lower\n",
      "german stock exchange exchange higher\n",
      "chinese chinese chinese for for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "australian dollar closes lower\n",
      "international international international opens opens opens\n",
      "<unk> on opens opens opens in\n",
      "UNK chinese UNK UNK UNK UNK\n",
      "dollar rises to ### yen yen in\n",
      "## killed in in in in\n",
      "former UNK UNK UNK to to\n",
      "s. korean stocks close\n",
      "stocks stocks open lower\n",
      "u.s. stocks rise as as oil oil\n",
      "dollar at lower lower yen yen in\n",
      "dollar at lower ## yen in tokyo\n",
      "stocks close lower in mexico brazil\n",
      "dollar at lower ## yen in tokyo\n",
      "bulgarian stock market ends lower\n",
      "russia to to to to cooperation\n",
      "british soldier UNK in in in\n",
      "saudi drug saudi drug saudi saudi saudi\n",
      "wall street stocks rebound\n",
      "u.s. stocks stocks as as\n",
      "german stocks close lower lower\n",
      "australian stock market lower\n",
      "man dies dies in in in in\n",
      "UNK wins to to\n",
      "dollar at upper ## yen in tokyo\n",
      "chinext index opens lower\n",
      "dollar trades in ## ## in range\n",
      "chinese chinese chinese chinese in in\n",
      "australian 's UNK resigns in\n",
      "UNK UNK UNK UNK UNK\n",
      "strong earthquake hits UNK\n",
      "international UNK festival opens opens in\n",
      "UNK UNK UNK UNK\n",
      "UNK opens opens opens in in\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar falls to in ## yen in tokyo\n",
      "dollar at at lower ## yen in tokyo\n",
      "ronaldo says he to to to\n",
      "dollar trades in ## yen in\n",
      "brazil stocks lower lower\n",
      "china china UNK china china\n",
      "world world UNK UNK UNK\n",
      "australian dollar closes down\n",
      "brazil beats #-# #-# in friendly friendly\n",
      "australian dollar closes weaker\n",
      "australia to to to in in in in\n",
      "brazil beats world #-# in world cup\n",
      "kuala lumpur stocks close higher\n",
      "u.s. wins to UNK\n",
      "shenzhen stocks exchange down\n",
      "dollar at at lower yen yen in tokyo\n",
      "nikkei opens opens higher higher\n",
      "bulgarian stock market ends lower\n",
      "malaysia to malaysia in in in\n",
      "man man for in murder\n",
      "world to to to to be\n",
      "dollar at at lower ### yen in tokyo\n",
      "philippine stocks close higher\n",
      "un of in in in in\n",
      "chinese UNK UNK UNK UNK UNK UNK\n",
      "russia russia first of in\n",
      "china beats #-# #-# in friendly friendly friendly\n",
      "s. korean shares close higher\n",
      "chinext index opens higher\n",
      "chinext index opens lower lower\n",
      "chinese chinese UNK on\n",
      "china china UNK UNK UNK\n",
      "philippine stocks close lower\n",
      "u.s. stocks trade higher\n",
      "australia 's sign in\n",
      "former 's former president president\n",
      "china wins men 's title title\n",
      "germany wins germany germany team gold gold\n",
      "UNK wins women 's 's 's gold gold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jordan wants to to\n",
      "u.s. stocks mixed mixed mixed mixed\n",
      "dollar rises to ### ### yen in tokyo\n",
      "israel israel sign sign agreement agreement\n",
      "china reports rate #.# rate\n",
      "beijing 's UNK UNK UNK\n",
      "dollar at upper upper ## yen in tokyo\n",
      "german stocks open higher\n",
      "dollar at at lower ### yen in tokyo\n",
      "new zealand stocks close lower\n",
      "hong kong shares close close percent higher\n",
      "hong kong shares close #.## #.##\n",
      "hong kong shares prices close up percent\n",
      "shanghai shanghai UNK UNK ##\n",
      "bulgarian stock market ends lower\n",
      "u.s. stocks end mixed\n",
      "chinext index opens higher\n",
      "chinext index opens #.## pct lower\n",
      "us 's UNK in\n",
      "seminar opens opens opens in\n",
      "us UNK in to in to to\n",
      "hong kong shares close #.## #.## higher\n",
      "india india to to to in\n",
      "dollar rises in in yen in in\n",
      "china UNK UNK UNK\n",
      "minister elections elections elections elections\n",
      "jakarta stocks close lower\n",
      "shanghai b-share market down at close close\n",
      "dollar trades at yen yen in tokyo\n",
      "dollar rises to lower ### yen in tokyo\n",
      "stocks close lower in mexico brazil\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar rises to lower ### yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar at at yen yen in tokyo\n",
      "china 's first in in\n",
      "stocks close lower in mexico brazil\n",
      "dollar rises to ### yen yen in\n",
      "dollar trades upper ## yen in tokyo\n",
      "nikkei opens opens lower\n",
      "dollar at upper upper ## yen in tokyo\n",
      "hong kong stocks close #.##\n",
      "new zealand stocks to to new\n",
      "australian stock market down\n",
      "<unk> <unk> to <unk>\n",
      "sri lanka lanka to to UNK\n",
      "dollar at at upper yen yen in tokyo\n",
      "two UNK arrested in\n",
      "stocks mixed mixed early trading trading\n",
      "world beats #-# #-# in world cup qualifier\n",
      "malaysia foreign foreign to to in\n",
      "australian dollar closes lower\n",
      "jordan jordan jordan jordan\n",
      "china china china china china\n",
      "chinese shares close #.## percent higher\n",
      "dollar falls to lower ## yen in range\n",
      "dollar at at ## yen yen in\n",
      "australian dollar closes higher\n",
      "italy to to to to to in\n",
      "new zealand stocks in new\n",
      "canadian pm minister minister in\n",
      "eu to hold in in in\n",
      "UNK UNK UNK in in\n",
      "dollar at to upper ## yen in in\n",
      "UNK opens opens opens in\n",
      "hong kong stocks close hong\n",
      "nato UNK UNK in\n",
      "chinese opens opens opens opens in in\n",
      "australian dollar closes weaker\n",
      "australian stock market drops\n",
      "two UNK in in in in\n",
      "international trade UNK in in\n",
      "south s up up percent percent in\n",
      "romania beats world #-# in world cup qualifier\n",
      "helicopter helicopter crashes in\n",
      "UNK wins wins UNK\n",
      "dollar at at yen yen in tokyo\n",
      "UNK UNK women UNK in in in in\n",
      "spain beats play #-# friendly friendly friendly friendly\n",
      "south korea stocks index wins with with\n",
      "# beats #-# #-# #-# in\n",
      "german stocks open higher\n",
      "crude prices rise on on\n",
      "dollar rises to ### yen yen tokyo\n",
      "tokyo 's at down\n",
      "german stocks open higher\n",
      "s. korean stocks close\n",
      "stocks close close in mexico brazil\n",
      "german stocks close higher\n",
      "mexico to UNK UNK UNK\n",
      "chinese shares close #.## pct higher higher\n",
      "german stocks open mixed\n",
      "german stocks close up\n",
      "vietnam 's UNK UNK UNK UNK\n",
      "canada to bid bid bid ####\n",
      "french beats beats #-# #-# in french french\n",
      "# UNK in in in UNK\n",
      "dollar trades at lower ### yen in tokyo\n",
      "dollar rises in ### ### yen in tokyo\n",
      "china opens opens opens opens\n",
      "wall street stocks on on economic data\n",
      "dollar falls against in in in in\n",
      "dollar rises in lower ### yen in in tokyo\n",
      "UNK wins wins 's 's gold gold\n",
      "german stocks open lower\n",
      "crude futures rise on on\n",
      "dollar at at upper ### yen in tokyo\n",
      "stocks close lower in mexico brazil brazil\n",
      "dollar at upper upper yen yen in tokyo\n",
      "london stock stock market\n",
      "beijing to to to to to in\n",
      "dollar at at upper yen yen in tokyo\n",
      "germany beats germany #-# in cup\n",
      "german stock indexes end lower\n",
      "australian dollar rises rises\n",
      "taiwan stocks close down\n",
      "results of first of\n",
      "dollar trades in upper ## yen in tokyo\n",
      "new reports new on flu flu\n",
      "to to to to in in in\n",
      "german stocks open mixed mixed\n",
      "new zealand stocks close lower\n",
      "thailand to to to to in in in\n",
      "iraqi of in UNK in\n",
      "rubber futures close higher on higher volumes volumes\n",
      "china to to UNK UNK in in\n",
      "rubber futures close higher on higher volumes volumes\n",
      "UNK wins UNK 's\n",
      "UNK wins international in in in\n",
      "rubber futures close lower on smaller volumes\n",
      "more UNK UNK UNK UNK UNK UNK\n",
      "rubber futures close higher on smaller volumes\n",
      "UNK UNK UNK to\n",
      "# us soldiers killed in in in\n",
      "UNK wins wins wins title\n",
      "world cup squad cup\n",
      "rubber futures close higher on higher volumes\n",
      "australia names new new to\n",
      "gold 's in in hong kong\n",
      "hong kong markets closed for for\n",
      "thailand financial markets closed for\n",
      "indonesia financial markets closed for\n",
      "germany wins world cup cup world cup\n",
      "hong kong shares open #.## percent lower\n",
      "uganda and on in in\n",
      "UNK 's n't to in\n",
      "malaysian shares close #.## percent\n",
      "iran calls war war war war war iraq\n",
      "tiger UNK UNK UNK UNK UNK\n",
      "philippine financial markets closed\n",
      "UNK wins to in\n",
      "russia 's women 's cup cup\n",
      "obama obama obama to to to\n",
      "hong kong markets closed closed for for\n",
      "chinese 's UNK UNK UNK UNK UNK UNK of UNK\n",
      "malaysian shares close #.## percent higher\n",
      "german stocks opens in\n",
      "UNK named new new coach coach\n",
      "UNK named new england new new new\n",
      "UNK wins wins grand prix\n",
      "schumacher wins wins grand prix\n",
      "results presidential presidential elections\n",
      "oil prices higher higher asian\n",
      "australia stock markets closed for\n",
      "rubber futures lower lower on lower volumes\n",
      "knicks ## out of UNK\n",
      "hong kong hong UNK UNK UNK UNK\n",
      "podium 's women 's 's\n",
      "podium 's women 's 's 's\n",
      "## UNK in UNK in in\n",
      "rubber futures close higher on smaller volumes\n",
      "UNK UNK UNK UNK\n",
      "key of of\n",
      "indonesia financial markets closed for\n",
      "UNK of of UNK in in\n",
      "stocks prices fall lower\n",
      "UNK UNK to UNK UNK UNK\n",
      "dollar falls in in in in\n",
      "israeli israeli israeli israeli israeli israeli\n",
      "hong kong markets markets for for\n",
      "chinese scientists find in in UNK\n",
      "un chief chief un un un un talks talks talks\n",
      "tokyo stocks UNK UNK UNK UNK UNK UNK\n",
      "hong kong markets closed closed for\n",
      "hong kong markets markets for for\n",
      "us UNK UNK UNK UNK iraq iraq iraq\n",
      "russia 's UNK UNK\n",
      "canada ### ### record record\n",
      "UNK UNK UNK in in in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "rubber futures close lower on lower volumes\n",
      "canada to to for #### ####\n",
      "UNK 's UNK a for of of\n",
      "spurs wins first league in league\n",
      "UNK wins stage stage stage\n",
      "new 's the #### of of of\n",
      "german 's UNK in UNK UNK UNK UNK\n",
      "oil prices higher higher asian trade\n",
      "UNK UNK UNK UNK\n",
      "taiwan financial markets closed for\n",
      "skorean shares close #.## percent lower\n",
      "malaysian shares close #.## percent\n",
      "african cup cup cup\n",
      "us UNK UNK in in\n",
      "UNK UNK UNK UNK UNK to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK UNK\n",
      "<unk> signs UNK from from\n",
      "UNK UNK UNK UNK\n",
      "to to to to for\n",
      "serena williams williams UNK french UNK\n",
      "serena williams williams UNK UNK\n",
      "london share prices lower at midday\n",
      "china ### to to to to\n",
      "california of in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a of UNK UNK UNK\n",
      "london share prices higher at midday\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "UNK UNK UNK UNK $ $\n",
      "UNK wins wins world\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to to film to to to film film film film film\n",
      "UNK UNK UNK UNK\n",
      "former of former of dies at at\n",
      "# plane crashes plane plane plane\n",
      "UNK UNK he he\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "eu to to strike strike\n",
      "UNK UNK a to UNK\n",
      "asian stocks close close mostly lower\n",
      "united states states in in in world\n",
      "london 's to in\n",
      "european stocks close higher\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "swine swine swine swine swine swine flu\n",
      "stocks fall as as\n",
      "gore UNK UNK to to UNK UNK\n",
      "mexico mexico mexico mexico mexico mexico\n",
      "israeli says UNK UNK UNK UNK\n",
      "the 's on the\n",
      "texas UNK UNK ## in in in in in in\n",
      "armstrong de to tour tour tour tour de\n",
      "actor says says says UNK UNK UNK\n",
      "UNK signs UNK to to milan\n",
      "spurs to to to to\n",
      "a UNK UNK UNK UNK\n",
      "# die die dead in in\n",
      "UNK UNK to to to to\n",
      "UNK wins tour tour tour\n",
      "serena williams serena serena serena\n",
      "iraq 's UNK UNK UNK u.s. UNK iraq iraq\n",
      "former UNK UNK in in\n",
      "hong to to for # #\n",
      "UNK UNK UNK to UNK UNK UNK in in in in\n",
      "agassi 's for for at\n",
      "stocks street wall wall\n",
      "UNK UNK UNK UNK\n",
      "u.s. u.s. UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "india UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK\n",
      "magic sign sign free UNK UNK\n",
      "former 's in UNK UNK\n",
      "stocks prices in early trading\n",
      "a of in\n",
      "ucla 's UNK ##\n",
      "london share prices up at midday\n",
      "yankees to to play to\n",
      "no. ## no. ## ## ##\n",
      "UNK UNK UNK to UNK\n",
      "kings sign UNK coach\n",
      "a UNK UNK UNK UNK\n",
      "UNK UNK to to to\n",
      "to to to to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's he to the\n",
      "new of in in in in\n",
      "UNK UNK UNK to to to to to to\n",
      "UNK UNK UNK in\n",
      "women wins women women women women\n",
      "oil of of UNK UNK UNK\n",
      "to to to UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "magic sign sign forward <unk>\n",
      "man man of for UNK UNK UNK\n",
      "UNK UNK 's UNK UNK\n",
      "UNK of UNK UNK\n",
      "police police police UNK in\n",
      "UNK says UNK to to to to to UNK\n",
      "world cup cup cup cup\n",
      "england out for test for\n",
      "scientists UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "giants says he to to to to\n",
      "new UNK UNK UNK UNK\n",
      "UNK gets to for\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK president president president president president president\n",
      "woods woods woods woods ryder ryder\n",
      "UNK s UNK to UNK to to\n",
      "nasa to to to to\n",
      "australia to play to\n",
      "UNK wins wins win title title\n",
      "new UNK UNK UNK UNK UNK new new\n",
      "UNK UNK UNK for for\n",
      "UNK UNK UNK UNK UNK UNK the\n",
      "eu to to to to to to\n",
      "london s ftse-### index up at points points at\n",
      "london share ftse-### index up ##.# points points\n",
      "iran to to UNK iraq UNK iraq iraq iraq\n",
      "UNK of the the the\n",
      "us of of UNK UNK\n",
      "us man in in in in in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK to UNK for\n",
      "## injured ## in in\n",
      "internet to on internet internet\n",
      "giants giants to to to to to\n",
      "south 's of UNK dies dies at ##\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "wins wins wins pole gp gp\n",
      "eu to to to to to to to to\n",
      "UNK UNK UNK to as as coach\n",
      "ac to to UNK to to to UNK\n",
      "stock 's 's to UNK UNK\n",
      "beijing beijing beijing beijing for for for for\n",
      "to to to to UNK to\n",
      "to to to UNK UNK in in in in in\n",
      "# UNK UNK UNK\n",
      "stocks 's says UNK UNK UNK UNK UNK\n",
      "<unk> <unk> ## ## ## school school\n",
      "UNK named new coach coach\n",
      "in UNK to\n",
      "stocks prices up on\n",
      "u.s. stocks mixed on on on data\n",
      "to to to to UNK UNK\n",
      "microsoft to to to for for\n",
      "UNK says UNK to to to to\n",
      "spurs sign sign with with UNK UNK\n",
      "kings to to to\n",
      "UNK 's UNK UNK for for for\n",
      "UNK UNK UNK UNK to to\n",
      "boeing to to to to in\n",
      "man man man man UNK UNK\n",
      "london share prices up up\n",
      "UNK wins world cup\n",
      "london share prices lower\n",
      "iran iran iran UNK on on\n",
      "# UNK UNK UNK in in in in\n",
      "woman woman woman woman in in\n",
      "stocks s UNK ### $ $\n",
      "wall street a for for a\n",
      "pope pope in\n",
      "canadian 's minister parliament\n",
      "nasa to to for UNK UNK\n",
      "UNK UNK UNK UNK UNK the the\n",
      "UNK UNK out # in in\n",
      "lakers lakers lakers lakers\n",
      "UNK UNK UNK in\n",
      "braves # to #\n",
      "roddick to to to\n",
      "<unk> <unk> <unk> <unk> dies dies at ## ##\n",
      "UNK wins UNK french open open\n",
      "foreign foreign foreign in in in\n",
      "two shakes hits northern northern\n",
      "UNK to UNK UNK UNK\n",
      "indonesia to to to to to to to UNK\n",
      "man UNK on to to to to to\n",
      "UNK UNK to to UNK\n",
      "former UNK pleads UNK UNK UNK UNK\n",
      "chile to to UNK UNK UNK in\n",
      "# UNK UNK UNK in in in UNK UNK UNK\n",
      "s. korean stocks rise\n",
      "canada 's central interest interest interest\n",
      "woods 's in in in in\n",
      "UNK says he UNK\n",
      "## killed in dead in in in in\n",
      "a 's UNK UNK UNK UNK UNK\n",
      "UNK wins UNK UNK UNK UNK\n",
      "to to to to to UNK UNK UNK UNK\n",
      "'s 's 's he UNK UNK\n",
      "police police # with in in\n",
      "says 's he to to to to to\n",
      "in UNK UNK UNK with with in in in in in UNK\n",
      "UNK says to to to season season season season season\n",
      "russia UNK UNK UNK UNK UNK UNK\n",
      "UNK signs to to deal deal\n",
      "nato soldier killed in in\n",
      "UNK UNK new UNK UNK\n",
      "real UNK UNK to to to to madrid madrid\n",
      "agassi wins to in\n",
      "the UNK UNK UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> UNK at\n",
      "venezuela s s to to to to UNK UNK\n",
      "london s ftse-### index up ##.## points points\n",
      "for UNK and UNK to\n",
      "UNK UNK UNK UNK UNK of\n",
      "australian 's on UNK\n",
      "michael jackson UNK UNK UNK UNK in\n",
      "tokyo stocks open higher dollar\n",
      "UNK UNK of to on in in in\n",
      "woods woods woods woods woods woods\n",
      "on UNK to in\n",
      "jones jones jones in at\n",
      "french beats first french french\n",
      "london share prices index at midday\n",
      "share prices close lower\n",
      "mexico beats in #-# in in in\n",
      "spain to to for ####\n",
      "UNK UNK and baby baby baby\n",
      "UNK UNK UNK UNK UNK in\n",
      "UNK UNK UNK UNK to UNK in in in\n",
      "UNK UNK to of of england england\n",
      "spain UNK UNK UNK in in in\n",
      "knicks top first to\n",
      "UNK 's UNK 's\n",
      "a UNK UNK UNK the UNK UNK\n",
      "former UNK charged UNK with in\n",
      "UNK 's UNK for\n",
      "clippers ## to to\n",
      "former <unk> of dies dies dies dies at at\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "air in in in\n",
      "u.s. of of to to to to to to\n",
      "signs signs signs <unk>\n",
      "u.s. u.s. UNK UNK UNK iraq iraq iraq iraq iraq\n",
      "UNK cup ryder cup ryder cup\n",
      "UNK 's hall hall of of\n",
      "stars stars stars UNK stars stars stars\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "share prices close generally lower\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "iran says UNK UNK iraq iraq iraq iraq iraq\n",
      "a UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "key and in the at\n",
      "world cup cup cup to\n",
      "UNK UNK UNK UNK to in in\n",
      "stock to to to\n",
      "israel to sign sign deal\n",
      "ford s to to to to to for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stocks 's to to to UNK UNK UNK UNK\n",
      "us prices UNK on\n",
      "UNK to to to UNK\n",
      "wall street mostly higher\n",
      "former UNK to in in\n",
      "lakers 's for in\n",
      "no. UNK to to to\n",
      "big UNK in in\n",
      "UNK UNK UNK UNK\n",
      "love 's to in in\n",
      "olympic wins to in at at in\n",
      "chinese 's UNK UNK hong UNK UNK UNK UNK\n",
      "federer open open open open\n",
      "UNK 's to to to to to to to\n",
      "miller miller miller world for\n",
      "bush bush UNK UNK UNK\n",
      "world UNK UNK UNK UNK UNK UNK\n",
      "world to to to to to in\n",
      "gold prices rise as high to dollar\n",
      "police police ## ## in in\n",
      "UNK UNK to to to at at at season\n",
      "to to and UNK UNK to to to to UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "judge UNK says UNK to UNK UNK UNK\n",
      "brazil to for for for\n",
      "the UNK is the for for UNK UNK\n",
      "UNK UNK UNK to world world world cup\n",
      "to to to to to\n",
      "south korea korea to to to\n",
      "germany beats #-# #-# #-# world\n",
      "at at at UNK UNK UNK at\n",
      "israeli UNK UNK to to to to\n",
      "british higher higher higher on UNK\n",
      "fire fire fire fire fire fire fire fire fire fire fire\n",
      "stock stock in in ; ; ; ;\n",
      "texas man of UNK UNK UNK UNK UNK\n",
      "brazil president president for\n",
      "UNK 's UNK UNK UNK\n",
      "the UNK to to on on on on on\n",
      "london share prices lower at midday\n",
      "rangers UNK UNK UNK UNK UNK\n",
      "UNK UNK and and UNK UNK and\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "two killed killed killed in in\n",
      "UNK ## to ##\n",
      "bush president to to for\n",
      "spurs re-sign re-sign UNK\n",
      "bruins 's to hockey\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK could to a the the the the\n",
      "no. ## no. ## ## ##\n",
      "UNK UNK UNK UNK\n",
      "no. ## no. ##\n",
      "no. UNK to to UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "russia president president to to\n",
      "share prices close lower\n",
      "share prices close prices\n",
      "share prices close prices\n",
      "stocks prices lower dollar early\n",
      "UNK UNK UNK UNK UNK to UNK UNK UNK UNK\n",
      "explosion ship ship in in in in\n",
      "mexico prices in on\n",
      "wheat corn futures higher\n",
      "australia to to to UNK UNK\n",
      "south to UNK in africa\n",
      "stocks stocks in mexico mexico ; ; ; ;\n",
      "world leads world #-# in world cup cup\n",
      "# UNK in in\n",
      "woods woods to ryder ryder ryder ryder\n",
      "malaysia to sign sign cooperation\n",
      "eu UNK UNK UNK at in\n",
      "UNK UNK UNK UNK\n",
      "two injured killed injured in in\n",
      "stock ## to in\n",
      "UNK ## ## ##\n",
      "barcelona to to to to to\n",
      "UNK UNK school school to school school school\n",
      "a of as as as\n",
      "UNK UNK UNK UNK\n",
      "love wins UNK UNK UNK\n",
      "brazil stocks fall lower\n",
      "woman UNK UNK UNK in UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "bonds UNK to to to\n",
      "former UNK dies dies dies dies at\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "judge UNK UNK to UNK UNK UNK\n",
      "former president president UNK as as as president\n",
      "kings UNK to kings\n",
      "stock futures futures on to record\n",
      "red signs UNK UNK UNK UNK\n",
      "oil prices fall as prices\n",
      "french wins to french french french french french\n",
      "UNK to to to for for\n",
      "italy 's for UNK for after\n",
      "UNK and UNK cup UNK\n",
      "UNK school school school school school school school\n",
      "lakers lakers to to\n",
      "british pm new new\n",
      "lakers lakers lakers lakers lakers lakers\n",
      "stars stars stars #-#\n",
      "this is to UNK\n",
      "man UNK UNK for for in\n",
      "tokyo stocks open lower dollar against yen\n",
      "tokyo stocks down dollar dollar against yen yen\n",
      "former UNK <unk> <unk> dies\n",
      "tokyo stocks open higher\n",
      "a UNK of in UNK UNK UNK\n",
      "UNK united united united united united\n",
      "UNK wins wins in at\n",
      "magic re-sign re-sign UNK\n",
      "'s UNK UNK\n",
      "london share prices rise\n",
      "to s to UNK\n",
      "UNK UNK to to UNK\n",
      "midfielder signs signs striker UNK UNK\n",
      "wheat futures prices on on on on\n",
      "UNK UNK UNK UNK UNK\n",
      "tokyo stocks fall dollar dollar against yen\n",
      "beijing 's to in in in in\n",
      "woods woods woods woods woods woods\n",
      "for 's 's 's 's the\n",
      "<unk> wins world at world world world\n",
      "u.s. u.s. iraq iraq in iraq iraq iraq\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "to says he he to to he to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "john UNK UNK masters\n",
      "sign sign sign free <unk>\n",
      "michael says UNK in in in world world\n",
      "williams williams williams williams williams williams\n",
      "##ers ## ##ers for\n",
      "tokyo stocks rise dollar dollar up against yen\n",
      "for UNK UNK UNK UNK\n",
      "# injured in in in in\n",
      "in to to to to to in in\n",
      "iraq military military UNK UNK UNK\n",
      "three rates hits in in in ; ;\n",
      "UNK wins UNK #-# #-# in\n",
      "former UNK of of dies dies dies dies ##\n",
      "iran says says says minister minister minister to\n",
      "former UNK s to to to to to to of\n",
      "UNK UNK UNK UNK\n",
      "italy police to to for in in\n",
      "gold prices rise as UNK\n",
      "federer beats federer wimbledon\n",
      "wins wins wins at\n",
      "nasa space launch launch launch\n",
      "nasa space launch launch space shuttle\n",
      "a UNK UNK UNK\n",
      "google launches to <unk>\n",
      "former s former dies dies\n",
      "# of of for for UNK\n",
      "UNK signs contract contract\n",
      "two UNK in in in\n",
      "# court UNK UNK UNK UNK\n",
      "eu s UNK to to to for\n",
      "UNK UNK UNK for for for for\n",
      "the UNK a UNK\n",
      "<unk> <unk> <unk> <unk> <unk> <unk>\n",
      "strong earthquake hits southern\n",
      "UNK UNK to to open\n",
      "UNK UNK # UNK at in ;\n",
      "exchange to to UNK\n",
      "share prices close generally higher\n",
      "share prices close generally mixed\n",
      "UNK UNK UNK UNK UNK UNK of of\n",
      "<unk> UNK UNK UNK\n",
      "world world world UNK at world world\n",
      "when 's 's s s to on UNK\n",
      "russian company to to for UNK\n",
      "former olympic oldest oldest dies dies dies\n",
      "obama obama to to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> <unk> <unk> UNK\n",
      "a for for to in to to\n",
      "UNK to UNK UNK UNK for for\n",
      "greek UNK in in\n",
      "tropical storm UNK UNK UNK UNK UNK UNK UNK\n",
      "tropical UNK UNK in in\n",
      "oil prices prices $ $\n",
      "UNK to to to in in in\n",
      "share prices close generally lower\n",
      "tokyo stocks rise dollar higher against yen in\n",
      "UNK\n",
      "# ## ## ## ## ## ## ## ##\n",
      "nasa UNK launch on space UNK\n",
      "woods woods UNK at at\n",
      "somali ship ship ship ship ship\n",
      "to to to to to to at at\n",
      "# of of in in in\n",
      "to of of of UNK UNK UNK UNK UNK UNK\n",
      "UNK to to for in in\n",
      "no. UNK # ## ## in in\n",
      "the games UNK UNK\n",
      "cup 's for to\n",
      "when a in in in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "former cabinet new cabinet cabinet cabinet cabinet\n",
      "UNK UNK UNK UNK UNK\n",
      "french UNK UNK UNK for for for\n",
      "us says says UNK ban ban ban\n",
      "stars 's and for in in\n",
      "earthquake earthquake earthquake turkey ; ;\n",
      "chinese chinese chinese to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK\n",
      "england and test test in in\n",
      "for UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK for UNK\n",
      "england UNK UNK to cup cup\n",
      "UNK UNK UNK UNK UNK in UNK UNK\n",
      "no. # no. ## no. ## ##\n",
      "as 's 's to of\n",
      "UNK UNK UNK UNK UNK\n",
      "o'neal 's UNK UNK UNK\n",
      "braves ## ## ##\n",
      "UNK says he to to to to\n",
      "UNK cup to to UNK UNK\n",
      "british says says british british british british british british\n",
      "armstrong france france france france france tour tour france france france\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to UNK\n",
      "in UNK UNK to to UNK UNK UNK UNK UNK\n",
      "judge spears UNK UNK UNK UNK UNK UNK\n",
      "UNK withdraws withdraws from\n",
      "in UNK UNK UNK in in in in\n",
      "to to to to to on\n",
      "stocks 's in in in in in\n",
      "rangers rangers rangers rangers #-# rangers in\n",
      "no. ## in ##\n",
      "'s UNK as\n",
      "texas UNK in in\n",
      "u.s. stocks higher higher early trading\n",
      "UNK named UNK as as of of\n",
      "obama s UNK UNK\n",
      "gold prices fall as oil oil\n",
      "a 's UNK UNK UNK UNK\n",
      "u.s. UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK for for\n",
      "israeli prime minister minister minister for after after for for with with\n",
      "UNK UNK UNK UNK\n",
      "obama obama obama for\n",
      "UNK UNK UNK UNK UNK\n",
      "no. leads to to all-star in\n",
      "women to host for for world world world world\n",
      "of UNK dies dies dies at\n",
      "world world world UNK UNK\n",
      "UNK UNK UNK UNK to for of\n",
      "UNK UNK UNK UNK UNK UNK in UNK\n",
      "israel UNK UNK UNK on gaza gaza gaza\n",
      "UNK 's UNK to to to\n",
      "UNK wins wins wins\n",
      "federer federer federer for to\n",
      "jones UNK is UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "johnson 's for 's in\n",
      "armstrong wins wins title title title\n",
      "stocks rise as mexico mexico mexico mexico mexico\n",
      "england cup cup cup cup cup cup cup cup\n",
      "UNK UNK 's UNK UNK UNK UNK UNK\n",
      "UNK president UNK UNK on\n",
      "former singer singer singer singer to to in\n",
      "michael UNK to to to to to to\n",
      "jordan jordan UNK UNK\n",
      "chinese UNK UNK trial trial in in\n",
      "wall street stocks after\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "chelsea to to play in\n",
      "to to in for for\n",
      "share prices share prices\n",
      "UNK UNK UNK to to to to\n",
      "of leads in in\n",
      "stocks UNK to in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "on 's for for\n",
      "UNK UNK to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "spain beats to in in in cup cup\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "italy cup cup cup\n",
      "UNK UNK UNK to to\n",
      "world cup cup UNK UNK UNK\n",
      "arsenal signs UNK midfielder to\n",
      "UNK wins wins world cup cup cup cup\n",
      "the 's UNK UNK\n",
      "UNK wins wins cup cup\n",
      "world to to play in in in\n",
      "baseball 's to for UNK UNK\n",
      "london share ftse-### index up midday points\n",
      "UNK UNK UNK to to in\n",
      "stock 's for to for\n",
      "liverpool says he liverpool liverpool liverpool liverpool liverpool\n",
      "world cup cup cup cup\n",
      "former president president former dies dies\n",
      "london s ftse-### index up at points points\n",
      "UNK wins win title title\n",
      "UNK UNK UNK cup cup cup cup cup cup\n",
      "'s UNK UNK\n",
      "eu eu to to to to in in in\n",
      "UNK <unk> <unk> UNK UNK UNK UNK\n",
      "to 's to UNK at\n",
      "jones jones UNK to in\n",
      "american wins olympic UNK gold gold\n",
      "former in in to UNK in in\n",
      "kings sign to to\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to UNK UNK\n",
      "'s 's to to\n",
      "UNK 's UNK UNK\n",
      "thailand to to to to to in\n",
      "former UNK UNK UNK dies dies at ##\n",
      "world cup to cup cup cup cup cup\n",
      "UNK UNK he he he he to to UNK\n",
      "microsoft says says on on on\n",
      "UNK UNK UNK to\n",
      "us iran iran iran iran iran iran iran\n",
      "UNK wins wins wins\n",
      "u.s. dollar against UNK dollar UNK\n",
      "un chief to to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "indian stocks close down\n",
      "the UNK UNK UNK UNK UNK\n",
      "israel says says with to to for in\n",
      "stocks stocks fall fall as on on\n",
      "john UNK a a with with at at at\n",
      "new new new in in in in in\n",
      "rain north north north africa\n",
      "UNK UNK to to UNK\n",
      "UNK 's world cup cup\n",
      "british 's UNK at at\n",
      "UNK UNK UNK UNK\n",
      "chinese 's UNK in in in in\n",
      "the UNK UNK UNK\n",
      "UNK and in and\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "french named coach coach\n",
      "us UNK to to\n",
      "'s to to to to to to to to\n",
      "UNK UNK to UNK UNK\n",
      "bruins coach as coach\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK of UNK UNK in in in in in\n",
      "british pm pm cabinet cabinet cabinet cabinet cabinet\n",
      "coach names new coach\n",
      "france UNK UNK to to to to barcelona barcelona barcelona barcelona barcelona\n",
      "paris hilton of paris in in in in\n",
      "in UNK to UNK to UNK UNK\n",
      "stars stars to #-# #-# win #-# #-#\n",
      "china UNK UNK to to to\n",
      "woods wins\n",
      "real madrid deal deal with with\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "italy italy italy italy UNK UNK\n",
      "world music the\n",
      "paris of of in in in in\n",
      "UNK coach to as england england england\n",
      "liverpool liverpool UNK to UNK UNK UNK\n",
      "asian stocks close mixed in wall wall\n",
      "london share prices lower at midday midday\n",
      "UNK UNK UNK UNK in\n",
      "china wins men #-# at at at at\n",
      "world UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK to to\n",
      "UNK UNK UNK UNK UNK UNK in\n",
      "clinton clinton UNK obama obama obama obama\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "london shares ftse-### lower at midday points\n",
      "UNK wins world cup cup cup\n",
      "UNK 's to UNK for\n",
      "former UNK UNK will of of of\n",
      "results wins women results\n",
      "UNK UNK UNK UNK UNK to of\n",
      "mccain mccain mccain mccain in in in in\n",
      "british earthquake british in no no no\n",
      "explosion explosion in in in\n",
      "texas 's UNK UNK UNK UNK UNK UNK\n",
      "actor UNK has says\n",
      "former olympic former ## dies dies ##\n",
      "UNK UNK UNK president UNK\n",
      "UNK wins world world\n",
      "UNK UNK UNK UNK UNK in in\n",
      "british 's UNK ## at\n",
      "UNK cup france cup cup UNK\n",
      "UNK signs UNK to to UNK UNK\n",
      "chelsea signs UNK to UNK\n",
      "in of of UNK of\n",
      "gore UNK\n",
      "jones jones jones jones jones jones jones jones jones\n",
      "stocks still at with with\n",
      "bush bush bush bush bush bush\n",
      "a UNK UNK UNK to to\n",
      "michael UNK UNK to to to UNK UNK\n",
      "kong to to to UNK UNK UNK\n",
      "foreign stock exchange closed for for\n",
      "yankees to to to\n",
      "broncos broncos UNK to to broncos\n",
      "UNK of for for for for for for for\n",
      "no. ## texas ## ##\n",
      "UNK UNK UNK coach\n",
      "stocks stocks end end\n",
      "mets # mets #-#\n",
      "for 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK of the in\n",
      "UNK UNK to to to in\n",
      "for 's in in\n",
      "former court UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "wheat corn futures higher\n",
      "UNK 's UNK coach\n",
      "former UNK former to for in\n",
      "senate to to to to\n",
      "former s UNK to to to to to in in in\n",
      "san UNK 's to to\n",
      "UNK UNK to to UNK UNK UNK\n",
      "us soldier dies in in in\n",
      "iraqi iraqi iraqi iraqi iraqi iraqi UNK UNK UNK\n",
      "'s for at\n",
      "a UNK UNK UNK UNK\n",
      "cowboys smith smith cowboys to\n",
      "sign sign sign free free free free\n",
      "mets # mets #\n",
      "UNK UNK UNK UNK UNK\n",
      "no. ## UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "UNK to to to to to UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK to to #### #### at at at at\n",
      "devils and for to to the\n",
      "texas state UNK to\n",
      "u.s. UNK to to to to to to\n",
      "# army UNK in in UNK\n",
      "the the for the\n",
      "nasa to to UNK to UNK UNK\n",
      "clippers 's UNK coach coach\n",
      "# killed killed killed in in in\n",
      "rain and in africa africa africa\n",
      "france to to host host #### ####\n",
      "italy cup UNK cup cup\n",
      "russia to UNK to on\n",
      "UNK 's UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK to in\n",
      "michael jackson in in\n",
      "UNK UNK UNK UNK\n",
      "parliament parliament parliament parliament parliament\n",
      "earthquake earthquake shakes california california california no\n",
      "UNK wins wins wins\n",
      "to sign sign to to\n",
      "dollar rises against against in in\n",
      "in UNK UNK UNK UNK a a UNK UNK UNK UNK\n",
      "china 's UNK UNK UNK\n",
      "tyson tyson tyson to to to\n",
      "UNK UNK to to to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "tokyo stocks rise dollar dollar against against yen\n",
      "UNK ## for for\n",
      "democrats democrats UNK to to to to\n",
      "UNK wins UNK at\n",
      "celtics 's\n",
      "china 's to to china at china china\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "fire fire fire UNK in in\n",
      "UNK # UNK #-# #-# #-#\n",
      "celtics celtics celtics ###\n",
      "##ers for to\n",
      "UNK UNK to UNK\n",
      "no. ## ## ## ## ##\n",
      "to wants to to to to\n",
      "UNK UNK 's to to to on on on on\n",
      "UNK ## ## ## UNK\n",
      "no. UNK UNK to UNK\n",
      "red signs signs to UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK return return return return\n",
      "miller cup cup cup cup\n",
      "news 's as\n",
      "police police arrested in in\n",
      "UNK extends contract with\n",
      "a UNK of the UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK to to to to to\n",
      "williams UNK UNK williams williams williams\n",
      "UNK of in presidential in presidential\n",
      "davis 's to UNK\n",
      "UNK wants to to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "no. ## no. ## ## ## ##\n",
      "new UNK of UNK the the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in in\n",
      "european stocks close higher\n",
      "UNK 's 's UNK UNK UNK on on on on\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK 's he he\n",
      "UNK UNK UNK UNK UNK the the UNK\n",
      "UNK wins UNK at\n",
      "UNK UNK UNK to as coach UNK\n",
      "UNK UNK UNK UNK\n",
      "man s s s s s s s\n",
      "two kills kills in in\n",
      "UNK signs signs signs UNK UNK\n",
      "london share prices index up\n",
      "former kong hong UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "gold futures prices lower on lower\n",
      "UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK to to to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "tropical storm UNK UNK\n",
      "new UNK and the in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "baseball 's for in for\n",
      "england and for and for for\n",
      "sampras wins to UNK\n",
      "clinton to to UNK\n",
      "rangers ## to #\n",
      "at UNK UNK UNK in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "asian stock markets close mostly higher\n",
      "UNK UNK UNK UNK UNK\n",
      "microsoft microsoft to to on on\n",
      "results to first in\n",
      "UNK UNK UNK UNK\n",
      "in 's 's to to to to to to to\n",
      "us says says says says to to to to to to UNK UNK\n",
      "un to to to of in\n",
      "michael 's to in in in\n",
      "after UNK a has UNK to a UNK UNK UNK\n",
      "## UNK for on in in in\n",
      "of UNK UNK UNK UNK UNK dies UNK\n",
      "close signs signs midfielder\n",
      "UNK signs UNK UNK\n",
      "UNK signs signs signs UNK UNK UNK\n",
      "indian stocks close down down\n",
      "us iraq iraq iraq iraq iraq iraq iraq iraq iraq\n",
      "new to to to to to in in in in\n",
      "hong kong shares close hong\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK the of of of\n",
      "UNK UNK UNK UNK UNK\n",
      "house of in in\n",
      "johnson johnson is his his his for\n",
      "philippine 's 's 's\n",
      "UNK UNK UNK UNK UNK\n",
      "to to to to to to to to to\n",
      "woods wins to woods\n",
      "london share prices lower\n",
      "the news news news\n",
      "arsenal and out league league league league league league league league\n",
      "UNK to to UNK UNK\n",
      "germany UNK UNK to\n",
      "in 's of to to to to to to UNK\n",
      "'s to to in UNK\n",
      "federer beats to french french open open\n",
      "france beats UNK in in in\n",
      "UNK UNK UNK UNK UNK chinese\n",
      "'s for for\n",
      "stocks stocks mixed after\n",
      "UNK UNK UNK UNK of of of of\n",
      "coach fires coach as coach coach coach\n",
      "UNK 's UNK UNK\n",
      "u.s. to to in in in in\n",
      "israel says says military military military military\n",
      "UNK UNK UNK UNK UNK\n",
      "canada 's economy rate in\n",
      "mccain UNK UNK to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK in\n",
      "spain 's rate rate rate percent percent\n",
      "pope urges urges to to to on on\n",
      "judge s UNK UNK for\n",
      "UNK wins to UNK open\n",
      "<unk> signs signs signs <unk> <unk> <unk>\n",
      "germany and germany germany germany cup\n",
      "tokyo stocks rise dollar higher against yen\n",
      "un of of of of in\n",
      "us UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "man man man to to in in\n",
      "texas fire fire in in in in\n",
      "the UNK UNK the UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "stocks stocks in early trading\n",
      "michael 's UNK UNK\n",
      "clemens clemens to to to to\n",
      "UNK 's to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK at south\n",
      "UNK UNK UNK surgery surgery\n",
      "olympic UNK UNK to UNK UNK UNK\n",
      "UNK UNK UNK gold record record\n",
      "the UNK UNK UNK UNK\n",
      "spurs # to #-# #-#\n",
      "france cup UNK #-# in world cup cup\n",
      "fire fire in in in in in\n",
      "UNK UNK to to to to to to to\n",
      "UNK UNK to to to in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "liverpool signs signs UNK\n",
      "russian of of UNK to to to UNK UNK\n",
      "UNK withdraws from at\n",
      "wall UNK in in in\n",
      "two killed in in in\n",
      "tokyo stocks lower dollar dollar against yen trading trading\n",
      "woods UNK UNK the of the the the the\n",
      "UNK UNK UNK UNK UNK\n",
      "taiwan stock market lower\n",
      "shanghai stock exchange index at\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "us UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "u.s. and UNK UNK UNK UNK to UNK UNK\n",
      "UNK 's UNK to UNK for\n",
      "<unk> UNK UNK UNK\n",
      "the 's the UNK UNK\n",
      "in UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK\n",
      "in to for UNK\n",
      "<unk> of of UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK with UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "to to to to\n",
      "a UNK a UNK UNK\n",
      "california UNK UNK UNK UNK UNK\n",
      "some UNK UNK to UNK a UNK\n",
      "internet internet internet internet internet the\n",
      "a 's of the of\n",
      "UNK UNK UNK UNK UNK\n",
      "britney 's UNK to\n",
      "the 's for for for\n",
      "dole 's to UNK of of of of\n",
      "to to in in in in\n",
      "house house house to house\n",
      "UNK 's UNK UNK UNK for\n",
      "UNK UNK UNK UNK\n",
      "vietnam to UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK of UNK UNK UNK UNK UNK iraq\n",
      "<unk> UNK UNK the UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "the and in in in in in\n",
      "UNK UNK UNK UNK\n",
      "for UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "to to for for for\n",
      "u.s. u.s. u.s. to to mexico\n",
      "UNK UNK UNK UNK UNK\n",
      "film festival festival festival film festival\n",
      "u.s. in in in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "the UNK and the\n",
      "in UNK UNK UNK UNK UNK UNK\n",
      "in 's UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "the UNK UNK UNK\n",
      "a UNK of to to UNK UNK of UNK UNK\n",
      "UNK UNK UNK to to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "u.s. UNK to in to in in in\n",
      "george george UNK\n",
      "in 's UNK UNK UNK to to to\n",
      "to and UNK to to to to to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "rangers UNK in UNK\n",
      "<unk> UNK UNK UNK\n",
      "toyota 's to UNK UNK UNK UNK\n",
      "the of of UNK\n",
      "us us $ $ $ to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK the the UNK\n",
      "for the to to the UNK UNK UNK\n",
      "some to to to to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK on on UNK UNK UNK UNK\n",
      "canada 's 's to the to\n",
      "the the 's the UNK the\n",
      "former 's UNK UNK UNK\n",
      "a UNK a the for a UNK\n",
      "the 's UNK the the\n",
      "tropical storm UNK UNK UNK\n",
      "UNK UNK to UNK strike strike\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to to UNK\n",
      "UNK UNK UNK UNK in\n",
      "UNK chief chief as as UNK UNK\n",
      "UNK 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to to to to\n",
      "#.# UNK UNK UNK\n",
      "european 's UNK for for\n",
      "the UNK UNK UNK UNK the the UNK\n",
      "chinese UNK 's UNK for in\n",
      "UNK UNK UNK UNK UNK\n",
      "bush 's for on a for for\n",
      "house to for for\n",
      "to s to to in in in\n",
      "clinton 's UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "# u.s. in in in in in in\n",
      "<unk> <unk> UNK UNK\n",
      "california of of UNK UNK UNK UNK\n",
      "UNK UNK dies dies ##\n",
      "stocks stocks UNK on on UNK UNK\n",
      "us 's in in in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to UNK\n",
      "to UNK UNK UNK\n",
      "to for 's UNK\n",
      "stars UNK UNK UNK for for\n",
      "first to UNK to to to in in in in in\n",
      "the of of the\n",
      "bush bush bush bush bush\n",
      "UNK UNK UNK UNK\n",
      "the the a UNK UNK UNK the the\n",
      "south korea team UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK in\n",
      "UNK UNK UNK UNK\n",
      "<unk> UNK UNK ## ## to\n",
      "to to to to to to UNK UNK\n",
      "UNK UNK of UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "new new UNK UNK UNK the\n",
      "former 's UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "two UNK UNK in in\n",
      "obama UNK UNK UNK to to to in in\n",
      "UNK UNK UNK UNK\n",
      "a 's UNK UNK UNK UNK UNK\n",
      "us UNK $ UNK in in in in\n",
      "google UNK to to to to\n",
      "the the of of the the\n",
      "the UNK UNK UNK\n",
      "UNK to to for\n",
      "UNK UNK UNK UNK UNK\n",
      "bush 's UNK UNK UNK UNK\n",
      "a 's in in in in in\n",
      "iraq iraq iraq iraq iraq iraq iraq iraq\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK of UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "in UNK to to to UNK UNK\n",
      "UNK UNK and to to to in in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK with UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "# 's in UNK UNK women in\n",
      "in UNK UNK UNK UNK UNK UNK\n",
      "us UNK to to to\n",
      "gop 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "new UNK to to to in\n",
      "mexico mexico mexico UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK wins wins\n",
      "france france UNK for for\n",
      "UNK UNK UNK for UNK UNK\n",
      "for for a a to to in in in in\n",
      "UNK 's UNK UNK UNK UNK street UNK\n",
      "UNK UNK to to for to\n",
      "UNK 's UNK UNK UNK\n",
      "at UNK UNK the to\n",
      "new UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK for\n",
      "tokyo UNK to to\n",
      "texas UNK UNK to\n",
      "judge UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> to UNK UNK in in in\n",
      "to UNK UNK UNK\n",
      "in UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "a UNK to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "bank bank bank bank bank bank bank\n",
      "UNK of UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> to in in UNK\n",
      "new UNK UNK UNK UNK\n",
      "obama obama obama obama obama obama\n",
      "stars 's UNK\n",
      "microsoft UNK UNK UNK UNK UNK UNK\n",
      "sorenstam wins in of\n",
      "a UNK UNK UNK UNK\n",
      "stars 's in in\n",
      "stars stars gets red to to to\n",
      "the UNK UNK UNK UNK\n",
      "new UNK UNK UNK\n",
      "UNK to to presidential\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "time to to UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK for\n",
      "UNK UNK UNK UNK\n",
      "new UNK UNK UNK UNK\n",
      "'s UNK to to\n",
      "UNK UNK up UNK UNK\n",
      "<unk> <unk> UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "'s 's UNK UNK UNK UNK\n",
      "stars 's for for\n",
      "UNK UNK\n",
      "coach named named as coach coach coach coach\n",
      "the UNK UNK to\n",
      "rangers beats to to to\n",
      "<unk> UNK a a UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "texas ## texas in in\n",
      "british 's UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "kings ### up UNK\n",
      "the the the the the the the\n",
      "UNK 's his UNK\n",
      "<unk> UNK <unk> with UNK\n",
      "the UNK is the the the\n",
      "a UNK a UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "oil to UNK UNK on on\n",
      "european 's to to for for in\n",
      "UNK UNK to UNK UNK\n",
      "microsoft 's to #.# #.# #.# #.#\n",
      "super 's in in\n",
      "to to to UNK\n",
      "UNK 's UNK UNK UNK UNK UNK\n",
      "cowboys UNK to to to to\n",
      "new UNK 's in in UNK UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "baseball UNK he to to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK UNK\n",
      "mavericks 's to to as as\n",
      "UNK 's UNK UNK UNK\n",
      "UNK is for to for for for\n",
      "UNK UNK UNK UNK UNK in to\n",
      "more of to for for\n",
      "UNK UNK UNK UNK\n",
      "stock stock stock stock stock\n",
      "sampras UNK to to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK a a UNK\n",
      "<unk> 's UNK UNK\n",
      "angels UNK UNK UNK\n",
      "a UNK a a a to UNK the\n",
      "UNK 's UNK UNK UNK for of\n",
      "baseball 's UNK UNK to\n",
      "crude 's 's UNK but the UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "china to ## china china\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK defense UNK to for\n",
      "UNK 's UNK UNK UNK UNK\n",
      "shares 's UNK UNK UNK\n",
      "bank s to in in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "russian UNK UNK in on on on on\n",
      "lakers lakers lakers to\n",
      "mexico to UNK in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> 's UNK UNK UNK\n",
      "UNK UNK UNK in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK gets the to UNK\n",
      "UNK UNK UNK UNK\n",
      "world UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's 's to as\n",
      "broncos broncos broncos broncos to for for\n",
      "bush the of bush the the\n",
      "UNK coach coach coach\n",
      "UNK UNK UNK to to\n",
      "UNK UNK of 's 's 's\n",
      "a 's UNK UNK UNK the UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK for for\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK internet\n",
      "a a at the UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "jordan jordan jordan UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in\n",
      "after UNK UNK to to to us\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "stocks says says UNK UNK UNK UNK\n",
      "in UNK UNK to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "cowboys cowboys cowboys cowboys\n",
      "us UNK to to\n",
      "house to to in in\n",
      "a UNK UNK UNK\n",
      "jordan UNK for to for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "stars stars UNK the the the\n",
      "bruins angeles daily coach coach\n",
      "a UNK UNK to UNK UNK\n",
      "a 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "oil prices fall in\n",
      "UNK UNK UNK UNK UNK\n",
      "kings kings to to to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stars 's in UNK\n",
      "ford 's to for\n",
      "a 's a a the the the\n",
      "for 's UNK UNK UNK UNK the UNK\n",
      "UNK 's UNK UNK UNK UNK UNK\n",
      "former UNK UNK to to to to to to to\n",
      "to to a the the\n",
      "fire 's UNK to to to\n",
      "microsoft UNK to to\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "UNK fires coach coach coach\n",
      "UNK UNK UNK UNK\n",
      "UNK coach UNK UNK UNK UNK UNK UNK\n",
      "raiders 's UNK to to\n",
      "yankees UNK to UNK\n",
      "UNK UNK to for\n",
      "UNK UNK UNK UNK UNK\n",
      "u.s. to to to on in\n",
      "the UNK UNK UNK UNK UNK\n",
      "UNK named named as of\n",
      "UNK UNK UNK to\n",
      "UNK UNK UNK the the the the the\n",
      "wall street end to to to UNK\n",
      "UNK named as UNK UNK\n",
      "UNK UNK UNK UNK UNK the the the the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK the UNK\n",
      "UNK UNK UNK UNK UNK to UNK\n",
      "broncos UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "in of 's UNK UNK UNK UNK\n",
      "iraq UNK UNK to to in in to to\n",
      "UNK UNK UNK UNK\n",
      "UNK wins UNK for\n",
      "celtics 's for UNK for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "#### 's to of in\n",
      "in UNK of of UNK UNK UNK UNK\n",
      "armstrong to to to to in\n",
      "UNK UNK UNK UNK UNK of\n",
      "a UNK UNK UNK UNK UNK\n",
      "broncos UNK UNK to to to\n",
      "UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "angels beat angels in\n",
      "UNK 's to to to\n",
      "in UNK UNK UNK in in in in\n",
      "senate democrats to UNK UNK UNK\n",
      "UNK UNK UNK the\n",
      "UNK UNK UNK UNK UNK\n",
      "the the the the the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK UNK UNK UNK\n",
      "UNK <unk> UNK\n",
      "clinton UNK UNK UNK china\n",
      "UNK of UNK UNK\n",
      "internet 's on business\n",
      "dodgers UNK dodgers down\n",
      "in UNK UNK UNK\n",
      "michael UNK for UNK\n",
      "<unk> <unk> of of of UNK UNK\n",
      "dodgers UNK for for\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK UNK\n",
      "microsoft to to UNK UNK UNK UNK\n",
      "UNK 's UNK in\n",
      "UNK UNK UNK UNK UNK women\n",
      "stock stock stock stock stock stock stock\n",
      "<unk> UNK UNK\n",
      "new UNK UNK UNK new new\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "for in in of of of\n",
      "to to to to\n",
      "a UNK UNK UNK\n",
      "for UNK for to to\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "thailand 's to UNK for with UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "'s to to to to to to\n",
      "UNK UNK UNK UNK\n",
      "nato UNK UNK UNK in in\n",
      "a UNK for UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK in in UNK\n",
      "knicks 's to to\n",
      "to to to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stocks UNK to to\n",
      "UNK 's to to in\n",
      "UNK is to to\n",
      "UNK UNK UNK to to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "revolution UNK UNK UNK UNK\n",
      "UNK to to to to on\n",
      "UNK 's UNK UNK of of of\n",
      "UNK 's to tour tour\n",
      "former UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "a 's of of of of UNK\n",
      "us court UNK to to to UNK UNK\n",
      "<unk> to UNK UNK\n",
      "gordon 's a of\n",
      "new UNK UNK UNK UNK UNK UNK\n",
      "mets mets to to to to\n",
      "dodgers 's dodgers dodgers\n",
      "tax tax to tax tax tax tax\n",
      "UNK UNK to UNK\n",
      "UNK wins the the\n",
      "sri s to to UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "in of a UNK UNK UNK UNK\n",
      "to to to for for in in in\n",
      "UNK UNK UNK UNK UNK\n",
      "senate to to to\n",
      "stars stars to for\n",
      "in UNK to to to to to to to\n",
      "UNK UNK 's UNK\n",
      "the UNK to the\n",
      "new war UNK iraq iraq iraq iraq iraq\n",
      "south UNK in in in UNK\n",
      "UNK UNK UNK to\n",
      "the 's UNK UNK\n",
      "the UNK for for UNK\n",
      "chargers UNK UNK for\n",
      "us rates to for for\n",
      "giants UNK UNK UNK UNK\n",
      "UNK 's school in in school school\n",
      "spurs sign UNK with\n",
      "john UNK in in UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a 's UNK UNK the the the the UNK\n",
      "u.s. stocks to as as ; UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "super bowl a UNK UNK super the\n",
      "UNK UNK UNK to UNK\n",
      "mavericks\n",
      "u.s. stocks rise as record record ; UNK UNK UNK\n",
      "chinese chinese UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "texas UNK UNK to\n",
      "knicks 's in to in in\n",
      "UNK 's UNK UNK in UNK\n",
      "it UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "man UNK UNK UNK in to\n",
      "UNK UNK a a UNK\n",
      "UNK 's a UNK\n",
      "dolphins ## ## ##\n",
      "the for for for\n",
      "stars UNK UNK for UNK\n",
      "the UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in UNK\n",
      "stars 's to for of of\n",
      "new 's 's for UNK for\n",
      "UNK UNK UNK UNK UNK\n",
      "toyota 's to UNK to\n",
      "jets ## for super for\n",
      "jordan 's a a for\n",
      "texas UNK UNK to to to to to to\n",
      "jordan jordan jordan jordan jordan\n",
      "UNK UNK UNK to UNK\n",
      "red 's UNK as\n",
      "women women women women women women\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a 's is UNK UNK UNK UNK\n",
      "giants giants giants to giants giants\n",
      "no. ## ## ## ## ##\n",
      "UNK UNK to to UNK\n",
      "UNK 's UNK UNK\n",
      "UNK gets UNK to\n",
      "serena 's to UNK\n",
      "the 's UNK a in for the\n",
      "to to UNK UNK UNK to to to to UNK\n",
      "#### to to UNK\n",
      "new 's UNK UNK in in in\n",
      "china UNK and to to\n",
      "<unk> UNK UNK UNK UNK\n",
      "UNK 's in UNK\n",
      "<unk> UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK for UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "a 's UNK UNK UNK\n",
      "UNK UNK to to\n",
      "senate senate to to in in in\n",
      "stocks shares fall lower percent lower ; ;\n",
      "to 's 's UNK UNK UNK UNK\n",
      "<unk> UNK for UNK\n",
      "scientists UNK UNK to UNK UNK\n",
      "the UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> on for\n",
      "UNK UNK UNK in\n",
      "a UNK UNK UNK\n",
      "taiwan and UNK UNK UNK\n",
      "UNK UNK to for for the the\n",
      "UNK UNK UNK UNK for for\n",
      "UNK to to to to\n",
      "UNK 's UNK UNK UNK\n",
      "cowboys UNK to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "mavericks UNK to to to\n",
      "a the on UNK UNK\n",
      "the 's UNK UNK\n",
      "kong ## for UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "yankees 's in for for\n",
      "UNK UNK to UNK UNK UNK to\n",
      "a the to to to the the the the UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to to to in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the the on internet internet internet internet\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "gordon UNK UNK UNK\n",
      "UNK UNK UNK the\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK health health in in\n",
      "a of of UNK UNK UNK the UNK\n",
      "UNK to UNK UNK UNK UNK\n",
      "a 's a a a a UNK\n",
      "<unk> UNK for UNK UNK\n",
      "knicks 's a of the the\n",
      "in UNK UNK UNK UNK UNK UNK\n",
      "us UNK to to to to UNK\n",
      "UNK wins UNK of\n",
      "women 's UNK UNK\n",
      "UNK UNK for for for for for for\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "UNK UNK UNK UNK in in\n",
      "us ## ## ##\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "first 's for for in in\n",
      "a UNK UNK in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK\n",
      "treasury prices rise as as of\n",
      "no. 's to in\n",
      "the UNK the the to the\n",
      "house 's UNK to UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "new of of UNK to in in in\n",
      "UNK wins wins tour\n",
      "no. ## UNK ##\n",
      "us UNK UNK UNK UNK UNK\n",
      "a UNK UNK in UNK UNK\n",
      "UNK UNK UNK to to to to to to to\n",
      "UNK johnson his to\n",
      "giants giants giants giants UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "wall street wall as on of\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK to to to to\n",
      "UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "stars UNK UNK to to to to\n",
      "UNK UNK to to to\n",
      "in 's UNK UNK UNK the the UNK\n",
      "no. UNK ## to to to\n",
      "it 's UNK your UNK\n",
      "angels UNK a a\n",
      "UNK UNK in to to in in\n",
      "UNK 's UNK UNK in UNK\n",
      "for UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK s gold gold gold gold gold gold\n",
      "clinton UNK UNK UNK UNK the the\n",
      "UNK UNK to to on budget budget\n",
      "knicks ## in ##\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dole dole dole and in of\n",
      "UNK 's is his his his his\n",
      "UNK 's UNK to to\n",
      "jordan to to UNK UNK\n",
      "UNK wins UNK of of\n",
      "as 's UNK for to\n",
      "a 's of the the of UNK\n",
      "brown UNK 's 's UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "texas UNK UNK UNK UNK UNK\n",
      "the the UNK for the the the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK for for for\n",
      "UNK UNK to to for for for\n",
      "UNK 's UNK for\n",
      "UNK UNK UNK UNK UNK\n",
      "for UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK\n",
      "UNK UNK to as as UNK\n",
      "in UNK UNK UNK of UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK to to UNK for for\n",
      "no. ## UNK to to\n",
      "the UNK UNK UNK\n",
      "giants giants giants giants\n",
      "UNK UNK UNK in\n",
      "dodgers beat dodgers #\n",
      "the UNK UNK UNK UNK\n",
      "mets UNK UNK in in in\n",
      "a UNK of UNK a a a UNK UNK\n",
      "mickelson s for for is is the the the\n",
      "a UNK UNK UNK\n",
      "broncos 's to to to to the\n",
      "roddick withdraws to UNK\n",
      "federer federer federer federer federer\n",
      "<unk> 's UNK at UNK\n",
      "share 's for for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "broncos 's to to to to\n",
      "german 's UNK to UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "nfl bowl to to bowl\n",
      "obama for for for UNK UNK\n",
      "bonds get to to to in\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK the the the\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stars 's to to to to\n",
      "for 's for UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stars sign UNK UNK\n",
      "the UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "<unk> UNK UNK to UNK UNK UNK\n",
      "rangers UNK to to to to to\n",
      "baseball UNK to in game\n",
      "british 's UNK UNK UNK UNK UNK\n",
      "the UNK the the UNK UNK the\n",
      "cowboys to UNK UNK to\n",
      "williams williams to to UNK\n",
      "stocks 's UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK at\n",
      "cowboys UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "federer UNK UNK UNK\n",
      "UNK 's to in\n",
      "UNK UNK UNK UNK UNK\n",
      "it UNK 's for for for\n",
      "<unk> UNK <unk> <unk> <unk> UNK\n",
      "to to to to for\n",
      "a UNK UNK to in in in\n",
      "mets mets mets UNK for for\n",
      "china of of of\n",
      "UNK 's UNK UNK\n",
      "devils beats #-# #-# #-# #-# #-# #-#\n",
      "jones jones jones jones UNK UNK\n",
      "dodgers 's to to to\n",
      "texas UNK UNK UNK UNK\n",
      "UNK to to for in in in\n",
      "woods wins wins of\n",
      "UNK UNK UNK in in in\n",
      "the UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK for for\n",
      "UNK <unk> up UNK UNK\n",
      "UNK chief as UNK\n",
      "clinton UNK UNK to to to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK UNK\n",
      "angels UNK UNK to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK UNK in in\n",
      "UNK UNK UNK UNK\n",
      "a UNK in UNK UNK\n",
      "the 's to to n't to\n",
      "rangers UNK UNK UNK in in\n",
      "UNK UNK UNK UNK\n",
      "johnson johnson johnson johnson 's the\n",
      "for 's for for\n",
      "pct says he in in in\n",
      "cowboys cowboys UNK cowboys cowboys\n",
      "us to to to to to to\n",
      "u.s. states women women women women women\n",
      "toyota 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "# UNK for for\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK in in\n",
      "a 's for UNK\n",
      "UNK UNK for for\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "no. # no. no.\n",
      "a UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "armstrong 's to to in in\n",
      "UNK UNK UNK in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "microsoft to to to UNK to UNK UNK\n",
      "former 's UNK UNK UNK UNK UNK\n",
      "a 's the the the\n",
      "giants UNK in in in\n",
      "UNK ## to for\n",
      "u.s. stocks rise as as ; ; stocks\n",
      "in is is UNK but\n",
      "to UNK UNK UNK UNK UNK UNK UNK of of\n",
      "british wins wins\n",
      "england and england england in in in\n",
      "UNK UNK UNK UNK\n",
      "rangers UNK rangers rangers\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "cowboys cowboys UNK cowboys\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "some 's UNK to for for\n",
      "no. # UNK to in\n",
      "UNK 's UNK with\n",
      "the UNK of the UNK UNK\n",
      "the UNK a in in in\n",
      "former UNK <unk> <unk> <unk>\n",
      "of of of of of of\n",
      "UNK UNK of UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK a UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "new to UNK UNK UNK UNK\n",
      "world UNK UNK UNK UNK\n",
      "king king king new new\n",
      "UNK UNK UNK to UNK\n",
      "UNK to UNK UNK UNK for for for for\n",
      "mexico UNK UNK UNK UNK UNK\n",
      "more of in UNK\n",
      "vietnam 's UNK UNK UNK UNK\n",
      "UNK UNK to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "woods woods to woods woods\n",
      "UNK 's UNK in\n",
      "UNK 's UNK to for 's\n",
      "stocks UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "in UNK UNK city city in in\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK ## UNK UNK for\n",
      "gop gop UNK UNK UNK UNK\n",
      "kings kings kings kings kings kings\n",
      "stocks UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK\n",
      "in of UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "a the a the UNK the the the the the\n",
      "UNK 's UNK UNK\n",
      "a to to UNK UNK UNK UNK UNK\n",
      "woods woods woods woods woods\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "gore 's UNK UNK in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to in\n",
      "gore gore gore gore for for\n",
      "the UNK UNK UNK UNK UNK UNK\n",
      "pope UNK UNK to to to to\n",
      "the UNK UNK to on on\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "us UNK UNK UNK for\n",
      "UNK UNK UNK UNK\n",
      "in the to the the the the\n",
      "bonds UNK to UNK\n",
      "dodgers dodgers dodgers dodgers dodgers\n",
      "rangers rangers to to #-# in in #-# #-#\n",
      "<unk> UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK ## ## ## ## ##\n",
      "UNK UNK ## UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "when UNK UNK UNK in UNK\n",
      "internet to to to to to\n",
      "clinton UNK UNK UNK to UNK UNK\n",
      "clinton clinton clinton clinton clinton clinton\n",
      "johnson 's UNK UNK UNK\n",
      "a your a a a\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK of UNK UNK UNK UNK UNK\n",
      "UNK UNK for for for\n",
      "the the the site the the\n",
      "jets jets jets jets UNK\n",
      "moderate 's UNK\n",
      "UNK UNK UNK to\n",
      "no. ## to ## ## ##\n",
      "giants giants in in giants\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's for the\n",
      "a 's 's UNK UNK UNK UNK UNK\n",
      "rangers rangers to rangers rangers rangers rangers rangers\n",
      "bush bush UNK to\n",
      "'s UNK UNK UNK\n",
      "a UNK UNK UNK UNK a a to to to\n",
      "UNK UNK a a\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "rangers rangers rangers rangers rangers rangers\n",
      "UNK UNK to for\n",
      "new UNK UNK UNK UNK to UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK at at\n",
      "a UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "UNK 's UNK UNK\n",
      "california UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK but to UNK\n",
      "UNK <unk> UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "mets to to to to\n",
      "jordan 's for the\n",
      "a UNK UNK the UNK\n",
      "UNK UNK UNK UNK\n",
      "tiger says UNK his a\n",
      "california to UNK UNK UNK\n",
      "the 's to the\n",
      "UNK wins UNK UNK\n",
      "in to 's to to to\n",
      "texas state to UNK\n",
      "UNK UNK UNK in in in\n",
      "clinton clinton clinton clinton clinton clinton\n",
      "for the the the the the\n",
      "a the UNK UNK the UNK UNK\n",
      "# UNK in in\n",
      "UNK named named as to to\n",
      "UNK UNK UNK to UNK UNK UNK\n",
      "UNK UNK UNK to to UNK UNK\n",
      "new to to to to\n",
      "red sign sign sign to to\n",
      "the 's for UNK UNK\n",
      "raiders to to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK ## ## ## ## ##\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK for UNK\n",
      "the UNK the the the the\n",
      "UNK UNK UNK UNK in\n",
      "the the a a the\n",
      "scientists of in with in in\n",
      "the 's the the the\n",
      "in 's to to to to\n",
      "yankees and a UNK the the the\n",
      "UNK UNK for in\n",
      "us us us us UNK UNK UNK UNK\n",
      "at of UNK at UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK with UNK UNK\n",
      "stars UNK UNK UNK\n",
      "UNK UNK in UNK in\n",
      "the the to to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "no 's UNK to\n",
      "german s to to to to UNK\n",
      "UNK UNK UNK super super\n",
      "UNK UNK UNK UNK UNK\n",
      "shares 's to to\n",
      "new york on UNK UNK UNK\n",
      "at UNK dies dies dies dies at ##\n",
      "mccain UNK UNK to\n",
      "a UNK to UNK UNK UNK UNK\n",
      "a UNK a UNK UNK UNK UNK\n",
      "the 's 's to to UNK\n",
      "UNK internet internet internet internet internet internet\n",
      "UNK UNK to to UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "us UNK to to to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "angels 's UNK UNK\n",
      "a UNK a the UNK UNK\n",
      "UNK 's to to in in in\n",
      "devils 's UNK to in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "dodgers 's to dodgers\n",
      "clinton to to on for\n",
      "'s to in\n",
      "dodgers dodgers dodgers dodgers dodgers\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "giants giants giants giants giants giants\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "jordan 's to for\n",
      "it UNK UNK the UNK UNK UNK UNK\n",
      "UNK UNK a to in\n",
      "holiday UNK for UNK\n",
      "a the of the UNK\n",
      "rangers UNK to UNK\n",
      "jets 's for to the\n",
      "UNK UNK UNK UNK\n",
      "a 's a UNK UNK UNK\n",
      "UNK UNK UNK olympic UNK gold gold\n",
      "UNK wins UNK for at\n",
      "to 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK for for for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "yankees UNK UNK yankees\n",
      "bryant bryant UNK UNK\n",
      "bryant UNK UNK UNK UNK\n",
      "UNK UNK UNK in in\n",
      "in to 's the the the the the\n",
      "UNK UNK UNK in UNK\n",
      "UNK UNK UNK UNK\n",
      "brown UNK UNK on\n",
      "a UNK in in in\n",
      "china korea north north north\n",
      "the UNK names new as of of of of\n",
      "kenya wins marathon marathon marathon marathon marathon\n",
      "a 's UNK UNK UNK UNK UNK\n",
      "to to to to to to\n",
      "the UNK UNK UNK to UNK UNK\n",
      "star of on to\n",
      "broncos UNK to to to to to\n",
      "u.s. says UNK UNK in in in ;\n",
      "a of UNK UNK UNK UNK of of\n",
      "a 's to at\n",
      "stars is to to to to\n",
      "iraq president UNK UNK UNK UNK UNK\n",
      "wall street stocks on UNK street\n",
      "UNK UNK ## ## ##\n",
      "a UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stocks 's to to a a a a\n",
      "UNK UNK UNK UNK UNK\n",
      "microsoft 's is is up\n",
      "UNK beats to to\n",
      "stock to to to on\n",
      "<unk> UNK on to for\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "woods leads for at at\n",
      "is 's is for for\n",
      "new cox news service service budget budget for the\n",
      "UNK UNK UNK of\n",
      "a to UNK UNK UNK\n",
      "UNK 's UNK in in in in\n",
      "UNK UNK the UNK\n",
      "for for for for for UNK UNK\n",
      "UNK UNK to to\n",
      "yankees 's to to to\n",
      "a UNK UNK UNK UNK\n",
      "UNK is to for UNK\n",
      "the of of the the the\n",
      "world to to to to in in in\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK in in in in\n",
      "#### 's for UNK\n",
      "microsoft of of of of\n",
      "UNK UNK UNK UNK UNK be\n",
      "south UNK in in in\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK for in for\n",
      "hingis 's UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "tyson 's UNK to\n",
      "women 's women UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "to UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "web web UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK UNK UNK\n",
      "to to UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "clinton UNK UNK UNK\n",
      "more of UNK UNK UNK UNK\n",
      "UNK UNK 's UNK UNK on on\n",
      "in in in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stars UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "# killed in in baghdad\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> to to to UNK UNK\n",
      "'s to UNK UNK UNK\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "jones jones jones in at record\n",
      "# UNK UNK in in in in\n",
      "<unk> UNK <unk> UNK <unk> UNK UNK\n",
      "new UNK UNK new new\n",
      "a to for UNK UNK\n",
      "in UNK of of UNK UNK UNK on UNK UNK\n",
      "UNK UNK UNK to to to\n",
      "after says says n't but a a a of season\n",
      "texas texas texas texas texas texas\n",
      "microsoft 's home business\n",
      "johnson 's his his for\n",
      "UNK UNK UNK UNK UNK\n",
      "dodgers dodgers dodgers dodgers dodgers dodgers dodgers\n",
      "los angeles daily news budget\n",
      "bonds 's to to to\n",
      "UNK UNK UNK in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the the UNK UNK UNK\n",
      "mavericks UNK UNK UNK\n",
      "a 's n't 's a\n",
      "UNK UNK UNK UNK in\n",
      "jones jones jones jones jones\n",
      "some UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "internet to to for for\n",
      "mets UNK UNK to UNK\n",
      "gop UNK UNK UNK\n",
      "former UNK wife wife wife\n",
      "super 's for for\n",
      "in to UNK UNK UNK UNK UNK\n",
      "clemens clemens clemens UNK UNK\n",
      "a the the the the the the the the\n",
      "bush UNK to on on\n",
      "after 's UNK UNK UNK UNK\n",
      "england 's england england\n",
      "china 's to to to to in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "u.s. stocks rise as as earnings earnings\n",
      "UNK UNK UNK UNK UNK\n",
      "rangers UNK rangers UNK\n",
      "new kong UNK UNK UNK UNK UNK\n",
      "at UNK UNK UNK UNK\n",
      "UNK to in\n",
      "UNK UNK UNK UNK\n",
      "# UNK UNK for UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK a UNK UNK UNK\n",
      "UNK chief chief as\n",
      "ucla ucla to for for\n",
      "UNK wins wins wins\n",
      "south 's UNK UNK UNK UNK\n",
      "UNK UNK on on on to to\n",
      "after UNK UNK UNK UNK UNK\n",
      "'s to to for\n",
      "<unk> <unk> <unk> <unk> <unk> UNK <unk>\n",
      "UNK UNK UNK UNK UNK in in\n",
      "on to to on UNK in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK for\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "the cox news service spot news budget for thursday july ##\n",
      "in UNK UNK UNK UNK UNK UNK UNK\n",
      "wall street stocks on on on\n",
      "after UNK UNK UNK UNK of\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "michael 's n't to a a UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "women women women 's women women\n",
      "UNK UNK UNK in in in\n",
      "UNK 's to to\n",
      "red sox UNK UNK UNK UNK\n",
      "in UNK UNK in in in\n",
      "UNK 's UNK to to to of\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "north of UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "olympic UNK in UNK UNK\n",
      "in UNK UNK UNK\n",
      "cox news news news budget\n",
      "'s UNK to\n",
      "broncos UNK UNK UNK for the\n",
      "a a a a UNK\n",
      "texas UNK gets to UNK\n",
      "UNK 's UNK UNK\n",
      "UNK UNK UNK to\n",
      "bush 's UNK UNK bush bush bush\n",
      "johnson johnson UNK UNK UNK\n",
      "french of to france france in in in\n",
      "the the 's the UNK UNK\n",
      "the UNK UNK UNK UNK UNK\n",
      "on UNK UNK UNK UNK\n",
      "braves end to to #-#\n",
      "microsoft internet for for for for on\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to for in in\n",
      "UNK UNK UNK to for\n",
      "stars UNK UNK UNK UNK UNK UNK UNK\n",
      "bruins sign sign <unk> <unk>\n",
      "UNK UNK on UNK\n",
      "UNK UNK UNK the\n",
      "world world UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "giants giants giants giants giants\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK king over UNK UNK\n",
      "a to to new new new\n",
      "no. beats to to in\n",
      "mavericks ## mavericks #\n",
      "after UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK a the UNK\n",
      "UNK 's UNK UNK UNK\n",
      "UNK sox red UNK UNK\n",
      "texas UNK texas UNK UNK\n",
      "UNK UNK UNK to UNK UNK\n",
      "to UNK for for for\n",
      "UNK UNK UNK to to to to\n",
      "to UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "to UNK UNK UNK\n",
      "microsoft to to UNK UNK UNK\n",
      "obama obama obama obama obama obama obama\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "microsoft microsoft to to\n",
      "man 's UNK to UNK UNK UNK to to UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK\n",
      "in of for for for\n",
      "new on on UNK\n",
      "UNK UNK UNK for\n",
      "india india iran to to\n",
      "australian stock market closes\n",
      "UNK of in in in\n",
      "taiwan shares close close\n",
      "s. korean shares down\n",
      "south to to to #### #### #### ####\n",
      "china chinese to to to to to to in\n",
      "more UNK to in in\n",
      "dollar dollar against against dollar in\n",
      "vietnam president to UNK UNK\n",
      "foreign stock exchange exchange\n",
      "'s resigns minister resigns on resigns resigns\n",
      "UNK UNK UNK to to\n",
      "s. korean stocks close\n",
      "dollar at lower ## yen in tokyo\n",
      "dollar at upper ## yen in tokyo\n",
      "dollar trades lower ## ## yen in\n",
      "dollar trades lower ## ## yen range\n",
      "stocks close lower in mexico brazil\n",
      "china wins wins 's at at\n",
      "china 's first chinese chinese chinese\n",
      "military military in in\n",
      "china to first UNK to to to\n",
      "china UNK UNK china UNK UNK\n",
      "dollar rises to upper ## yen in tokyo\n",
      "dollar falls to lower ## ## in tokyo\n",
      "UNK UNK UNK UNK\n",
      "bulgarian stock market ends higher\n",
      "german stock indexes exchange rates\n",
      "dollar at lower ## yen in tokyo\n",
      "dollar at upper ## yen in tokyo\n",
      "german stocks open higher\n",
      "UNK UNK UNK UNK china\n",
      "hang seng china enterprises index down\n",
      "UNK UNK UNK UNK UNK UNK in in UNK UNK\n",
      "explosion killed in in\n",
      "china beats beats #-# in soccer soccer\n",
      "hong kong shares prices #.## #.## #.##\n",
      "german stock indexes rise rates\n",
      "new zealand stocks close higher\n",
      "helicopter crashes crashes crashes crashes crashes crashes\n",
      "crude prices rise on\n",
      "german stock indexes rise\n",
      "hong kong shares close #.## #.##\n",
      "boeing ### ### ### ### to\n",
      "results 's new in\n",
      "UNK UNK UNK to UNK in in\n",
      "australian dollar closes lower\n",
      "government UNK UNK on\n",
      "beijing of of opens in\n",
      "turkey reports flu flu flu flu flu flu\n",
      "<unk> <unk> opens opens in in in\n",
      "australian dollar closes slightly\n",
      "mavericks sign UNK UNK UNK\n",
      "dollar at upper ## yen in tokyo\n",
      "nikkei closes #.## pct higher\n",
      "dollar trades upper ## yen in in\n",
      "dollar trades upper ## ## in range\n",
      "dollar at at yen yen in tokyo\n",
      "tokyo stocks close higher\n",
      "key of new ####\n",
      "china urges to to to to\n",
      "australian stock market ends\n",
      "share shares close #.## percent lower\n",
      "UNK UNK australia in\n",
      "malaysia to to to to UNK\n",
      "dollar at at upper ### yen in tokyo\n",
      "malaysia tin market closes lower\n",
      "china to UNK UNK UNK UNK UNK\n",
      "dollar at lower ## yen in tokyo\n",
      "dollar at at ## yen in tokyo\n",
      "UNK beats UNK #-# in\n",
      "london stock market london down\n",
      "brazil beats china #-# in soccer\n",
      "quake quake hits in\n",
      "wall street opens higher on\n",
      "wall street trades higher on\n",
      "dollar at at yen yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar at at yen yen in tokyo\n",
      "dollar falls to upper ### yen in tokyo\n",
      "dollar trades in ## yen in tokyo\n",
      "dollar at at lower yen yen in\n",
      "<unk> <unk> UNK to to\n",
      "tokyo stocks close lower\n",
      "dollar at upper ## yen in tokyo\n",
      "stocks close lower in mexico brazil\n",
      "australian stock market closes\n",
      "israeli says says dies dies dies dies\n",
      "russia to to to to with with\n",
      "UNK 's first UNK UNK\n",
      "beijing opens first UNK UNK\n",
      "german stock indexes exchange\n",
      "german stocks open lower\n",
      "dollar falls in lower ## ## in in\n",
      "german stocks open mixed\n",
      "UNK to to international in\n",
      "wall street stocks as as on\n",
      "UNK UNK UNK to to to to\n",
      "chinese chinese chinese to to to to\n",
      "indian stocks open higher in\n",
      "hong hong in hong hong kong in in\n",
      "greece greece UNK greece greece greece greece\n",
      "germany 's rate rate rate rate\n",
      "australia stock up rises #.# percent\n",
      "australian prime minister leaves for\n",
      "china of UNK UNK in UNK\n",
      "international film festival opens opens in\n",
      "two injured in in in in\n",
      "chinese chinese exhibition opens in in\n",
      "UNK UNK UNK UNK UNK in\n",
      "police police UNK in in in\n",
      "israel israeli israeli gaza gaza gaza\n",
      "chinese chinese ### chinese chinese\n",
      "oil prices fall as as\n",
      "dollar at to upper ### yen in tokyo\n",
      "stocks 's down down\n",
      "crude prices rise above ##\n",
      "stocks close lower in mexico brazil\n",
      "dollar at at ## yen yen in tokyo\n",
      "canada of to in in\n",
      "dollar at upper ## yen in tokyo\n",
      "china condemns condemns of of of\n",
      "dollar at lower ## yen in tokyo\n",
      "dollar trades in lower ## ## in in\n",
      "two UNK dies in in in in in\n",
      "tokyo stocks open higher\n",
      "german stock end end mixed\n",
      "hang seng china enterprises index up\n",
      "chinext index opens lower\n",
      "dollar trades upper upper yen in in\n",
      "dollar rises to upper ## yen in in\n",
      "chinext index opens lower\n",
      "earthquake earthquake indonesia indonesia indonesia\n",
      "chinext index opens lower wednesday\n",
      "vietnam to UNK in\n",
      "israel to to UNK UNK UNK UNK UNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall street stocks fall\n",
      "UNK UNK UNK on on\n",
      "china 's to to to china china\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar at upper upper yen yen in tokyo\n",
      "dollar trades in yen yen in in tokyo\n",
      "london stocks market at at\n",
      "UNK UNK killed in in in\n",
      "tokyo stocks open lower\n",
      "dollar falls in in yen yen in\n",
      "stocks close higher in argentina argentina argentina\n",
      "stocks close higher in argentina argentina argentina\n",
      "chinext index opens lower lower\n",
      "wall street trades on on economic data data\n",
      "chinext index opens higher higher\n",
      "israel UNK UNK UNK UNK UNK\n",
      "dollar at upper ## yen in tokyo\n",
      "shanghai stock market in in\n",
      "india president to to with in in\n",
      "chinese chinese chinese UNK dies dies dies dies\n",
      "the UNK a UNK UNK\n",
      "s. signs sign sign agreement agreement\n",
      "china to to to ties ties ties\n",
      "hong kong stocks close lower\n",
      "dollar at lower ## yen in tokyo\n",
      "dollar at upper ## yen in tokyo\n",
      "president president arrives in in\n",
      "australian dollar in in\n",
      "russian russian plane russian UNK\n",
      "dollar at upper upper ### yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "u.s. senate senate to to to to\n",
      "hang seng china enterprises index up\n",
      "malaysia 's to to tour tour tour\n",
      "dollar at upper ## yen in tokyo\n",
      "dollar trades in upper ## yen in in\n",
      "philippine 's UNK UNK UNK\n",
      "china china sign cooperation cooperation cooperation\n",
      "to to to for for for for\n",
      "australian stock market slightly\n",
      "south president president UNK UNK president\n",
      "former chinese former <unk> <unk> dies\n",
      "beijing opens opens opens in beijing beijing\n",
      "UNK to to cup cup world cup\n",
      "china to to UNK\n",
      "u.s. stocks open higher\n",
      "australian UNK UNK UNK\n",
      "canada wins women 's team gold gold gold\n",
      "UNK wins men 's 's gold gold\n",
      "man 's in UNK UNK UNK of\n",
      "mexico in in in in in\n",
      "u.s. stocks open higher\n",
      "u.s. stocks trade higher\n",
      "beijing UNK on beijing beijing in beijing beijing\n",
      "european stock close close lower lower\n",
      "dollar trades in lower ## yen in\n",
      "south africa to to to to\n",
      "more of hits in in\n",
      "shanghai of of of held\n",
      "hong kong shares close higher higher higher\n",
      "australian dollar closes higher\n",
      "chinese UNK UNK UNK\n",
      "chinese premier meets meets UNK\n",
      "tokyo stocks open higher dollar against yen\n",
      "results wins men 's\n",
      "chinext index opens higher pct\n",
      "dollar trades lower ## ## in in\n",
      "chinext index opens lower\n",
      "chinext index opens lower\n",
      "chinext index opens higher\n",
      "australian dollar closes higher\n",
      "dollar at at lower ## in in\n",
      "dollar at at ## ## in in tokyo\n",
      "knicks sign <unk> <unk> UNK <unk>\n",
      "dollar trades in ## yen in in\n",
      "new zealand rates close lower\n",
      "chinese chinese UNK UNK UNK\n",
      "german stocks open lower\n",
      "dollar rises in upper ## yen in tokyo\n",
      "india in in in in in\n",
      "UNK UNK UNK in UNK in\n",
      "shanghai international opens opens shanghai shanghai shanghai\n",
      "shanghai to to to to in shanghai shanghai shanghai\n",
      "UNK of of in to in of UNK\n",
      "german stocks open mixed\n",
      "london stock market rises\n",
      "pope olympics beijing in beijing beijing beijing\n",
      "stocks close flat in central flat\n",
      "german stocks open lower\n",
      "bush UNK on in\n",
      "united sets to record record record record in in in\n",
      "more UNK ### in in in\n",
      "dollar at at yen yen in tokyo\n",
      "dollar at upper upper ### yen in tokyo\n",
      "dollar rises to ### ### yen in\n",
      "philippine stocks close higher\n",
      "dollar trades at lower ### yen in tokyo\n",
      "german stocks open lower\n",
      "bulgarian stock market ends higher\n",
      "bulgarian stock market ends lower\n",
      "dollar trades in lower yen yen in tokyo\n",
      "UNK UNK UNK UNK in in\n",
      "UNK UNK meets UNK UNK\n",
      "first of in in in\n",
      "beijing to to to in in in\n",
      "wall stock market mixed mixed\n",
      "world to to to to world world world\n",
      "brazil beats beats #-# in in cup\n",
      "UNK UNK UNK UNK of\n",
      "chinese chinese chinese dies dies dies\n",
      "film film opens opens opens\n",
      "new york on in new in\n",
      "dollar trades upper ## yen in tokyo\n",
      "new zealand stocks close higher\n",
      "hong kong shares close higher percent higher\n",
      "italy italy UNK UNK UNK UNK\n",
      "UNK 's UNK <unk>\n",
      "china reports first UNK flu flu flu flu\n",
      "german stocks open mixed\n",
      "chinese shares fall down on on on street street\n",
      "chinese shares close #.## percent higher\n",
      "shanghai 's UNK UNK\n",
      "international international opens opens in in\n",
      "stocks stocks market down\n",
      "australian stock market rises\n",
      "british wins wins grand prix prix\n",
      "kuala exchange rates close stock\n",
      "dollar down at lower ### yen in in\n",
      "german stocks open lower\n",
      "dollar falls at upper ### yen in tokyo\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar falls to lower ### yen in tokyo\n",
      "stocks close higher in mexico brazil\n",
      "stocks close higher in mexico brazil argentina\n",
      "brazil to to for for\n",
      "german stocks open higher\n",
      "world to host #### #### ####\n",
      "saudi beats to in in in in world cup\n",
      "crude futures futures sharply\n",
      "wall street stocks lower on data data\n",
      "german stocks open mixed\n",
      "u.s. stocks open lower\n",
      "chinese on on in in\n",
      "stocks close in in mexico argentina\n",
      "greek stocks close higher\n",
      "shanghai to host opens opens in shanghai\n",
      "shanghai b-share market down at close\n",
      "australian dollar australian UNK for UNK UNK\n",
      "crude prices prices on u.s. u.s.\n",
      "shanghai international international international\n",
      "tokyo stocks close higher\n",
      "former president meets UNK\n",
      "german stocks open higher\n",
      "UNK 's festival festival festival festival\n",
      "german stock indexes end\n",
      "tokyo stocks close lower\n",
      "tokyo stocks open lower dollar lower yen\n",
      "british olympic oldest dies dies dies at\n",
      "senate senate sign to\n",
      "german stocks close lower\n",
      "dollar at at yen yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "china 's first in in\n",
      "UNK UNK to in\n",
      "internet to to for internet\n",
      "malaysia stock market ends up\n",
      "UNK UNK UNK UNK UNK on on on on\n",
      "u.s. stocks open higher\n",
      "chinese chinese first chinese 's 's\n",
      "dollar down to upper ## yen in tokyo\n",
      "dollar at at ## yen in in\n",
      "chinese shares down #.## pct in in\n",
      "australian stock market drops\n",
      "crude to to to\n",
      "# killed killed killed in in in\n",
      "new zealand shares close flat\n",
      "sorenstam to to for\n",
      "chinese UNK UNK UNK UNK\n",
      "england 's new 's new new\n",
      "shanghai b-shares close #.# percent percent\n",
      "world 's UNK of in in in in in\n",
      "britain 's says says UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "new zealand shares close flat\n",
      "bush president UNK on\n",
      "UNK UNK UNK to UNK india\n",
      "new zealand shares close #.## percent\n",
      "rubber futures close lower on lower volumes\n",
      "australian stocks australia scores\n",
      "australian australia in scores\n",
      "UNK UNK UNK UNK\n",
      "gold opens opens in hong\n",
      "south korea korea to korea korea UNK UNK\n",
      "indian shares close #.## percent\n",
      "one 's on of\n",
      "red to host in in\n",
      "rubber futures close lower on bigger volumes\n",
      "bank bank england bank interest interest interest at at\n",
      "UNK UNK UNK to to UNK UNK\n",
      "taiwan stock market closed\n",
      "un chief chief chief chief on on\n",
      "us to to to to to\n",
      "germany wins gold 's team gold gold\n",
      "new zealand shares close #.## percent\n",
      "french UNK coach coach coach\n",
      "UNK wins UNK wins\n",
      "italy wins UNK wins\n",
      "<unk> UNK UNK news\n",
      "los of on on on\n",
      "thailand financial markets closed for\n",
      "foreign stocks close close close\n",
      "the UNK UNK UNK UNK\n",
      "china 's UNK UNK in in in in\n",
      "UNK UNK UNK UNK to to to in in\n",
      "iraq UNK UNK in in iraq\n",
      "podium wins men 's at\n",
      "new zealand stocks UNK UNK\n",
      "new zealand shares close #.## percent\n",
      "new zealand shares close #.## percent\n",
      "former UNK UNK UNK\n",
      "to to to to UNK UNK\n",
      "rubber futures close higher on higher volumes volumes\n",
      "sri UNK UNK UNK in\n",
      "UNK UNK UNK UNK UNK\n",
      "british british UNK british on new\n",
      "hong 's UNK UNK\n",
      "hong kong markets closed closed closed holiday\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "bush 's president bush\n",
      "new zealand stocks close higher percent\n",
      "former UNK UNK to to to\n",
      "spain king to to visit visit\n",
      "indian stocks close down on on ; ;\n",
      "spain confirms first case swine flu flu\n",
      "to to to for to to to to\n",
      "schumacher wins wins grand prix\n",
      "iraq 's UNK UNK in\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK wins world cup cup\n",
      "taiwan shares close #.# percent higher\n",
      "hong kong markets closed closed closed holiday\n",
      "UNK named as coach coach\n",
      "india markets markets closed\n",
      "malaysia financial markets closed\n",
      "philippine financial markets closed\n",
      "hong kong markets markets closed for\n",
      "south korea nuclear nuclear nuclear nuclear nuclear\n",
      "australia stock markets closed for\n",
      "indonesia financial markets closed for\n",
      "malaysia financial financial markets for for\n",
      "oil oil UNK on on on\n",
      "malaysia financial financial closed for\n",
      "key 's news news\n",
      "new zealand shares close flat\n",
      "mavericks UNK UNK to to UNK UNK\n",
      "UNK UNK UNK UNK dies dies at\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "taiwan shares close UNK on\n",
      "says says says he he he to\n",
      "hong kong shares rise #.## percent\n",
      "russia 's to UNK UNK\n",
      "south africa south zealand zealand\n",
      "cowboys sign cowboys #-#\n",
      "UNK UNK UNK on on on on on on\n",
      "city signs to from from\n",
      "UNK UNK UNK UNK UNK\n",
      "air UNK to to in\n",
      "north korea to to to to north korea korea korea korea korea\n",
      "u.s. stocks rise #.# prices in\n",
      "UNK UNK to to in in\n",
      "man man dies dies in of\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK UNK UNK UNK the\n",
      "presidential to presidential presidential presidential elections elections elections\n",
      "<unk> wins women women women marathon marathon\n",
      "UNK UNK UNK UNK\n",
      "agassi williams to to open open\n",
      "judge trial trial trial trial trial trial trial trial trial\n",
      "former UNK s to to to to to to in\n",
      "UNK UNK prices UNK in\n",
      "london share prices index at midday\n",
      "microsoft to to to to to UNK\n",
      "un to to on at world world at at\n",
      "armstrong armstrong to tour tour tour tour tour\n",
      "iraq iraq UNK UNK UNK in in in\n",
      "UNK wins UNK on at\n",
      "UNK wins UNK UNK UNK\n",
      "UNK says says to to\n",
      "french UNK dies dies dies at at ## ##\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "us 's sales ## in in\n",
      "un s chief to to to of of\n",
      "UNK to to for UNK\n",
      "u.s. u.s. UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> <unk> UNK\n",
      "to to to UNK UNK\n",
      "UNK to UNK UNK UNK UNK\n",
      "the 's to to to to\n",
      "UNK 's UNK to to win win win\n",
      "rangers rangers rangers rangers rangers rangers rangers rangers rangers\n",
      "fire fire at in in in\n",
      "cowboys sign sign UNK UNK UNK\n",
      "man man UNK UNK to UNK UNK to UNK\n",
      "UNK says he he UNK to\n",
      "united states states in in in world\n",
      "UNK wins for in\n",
      "<unk> to the the UNK\n",
      "UNK wins UNK UNK\n",
      "nasa space UNK for for launch\n",
      "UNK UNK to to to\n",
      "man dies dies dies at dies at\n",
      "obama to to to to to to\n",
      "roddick beats french french french french french french\n",
      "UNK president UNK UNK to\n",
      "## ## ## ## ## ## in\n",
      "dollar mixed in in trading\n",
      "UNK UNK UNK to to to to\n",
      "to to to to to to to\n",
      "european stock close close\n",
      "stocks stocks in in mexico\n",
      "UNK UNK UNK UNK UNK in in\n",
      "red wings to to to UNK\n",
      "u.s. on in for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "for UNK to to to in in\n",
      "iraq 's UNK UNK UNK UNK UNK with\n",
      "tyson tyson for to to\n",
      "obama to in in in in\n",
      "UNK UNK UNK UNK\n",
      "former UNK UNK UNK UNK dies dies at ## ##\n",
      "to s to to to to\n",
      "turkey to UNK UNK UNK UNK\n",
      "UNK UNK to UNK in in in in\n",
      "australian wins UNK at UNK\n",
      "johnson 's UNK UNK for\n",
      "euro and at at at at\n",
      "stars ## up #\n",
      "canada to to bid bid\n",
      "britney spears in to to\n",
      "john wants UNK UNK UNK\n",
      "no. ## ## ## ##\n",
      "UNK ## ## UNK\n",
      "jets jets in for\n",
      "red UNK UNK UNK for\n",
      "stocks prices lower in trading trading trading\n",
      "# UNK UNK in in\n",
      "jets UNK UNK UNK UNK\n",
      "stars UNK to to to to to to\n",
      "cubs # to to to\n",
      "UNK of of UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK in in\n",
      "house UNK to to in in in\n",
      "#### UNK for UNK\n",
      "agassi agassi UNK UNK\n",
      "bush to to to\n",
      "judge UNK UNK UNK\n",
      "no. ## ## ## ## ##\n",
      "giants sign n't ##\n",
      "super bowl UNK to to\n",
      "world cup downhill downhill downhill\n",
      "obama obama obama to to obama obama\n",
      "world cup cup cup cup cup\n",
      "chelsea signs new new\n",
      "two of in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to to to\n",
      "us inflation rate rate in\n",
      "pct hall to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK new\n",
      "UNK UNK UNK for for for for\n",
      "for for UNK UNK of of\n",
      "strong quake hits taiwan taiwan\n",
      "for to UNK UNK\n",
      "president president president president president\n",
      "germany 's to to for\n",
      "stocks stocks lower on ; ;\n",
      "spain UNK to to open open\n",
      "dollar dollar higher low yen yen in\n",
      "stocks stocks rise higher higher\n",
      "obama obama UNK UNK\n",
      "UNK signs to UNK UNK\n",
      "## UNK in in in UNK\n",
      "at of in in in in UNK\n",
      "clinton clinton UNK to to UNK\n",
      "the UNK to to\n",
      "UNK cup cup cup cup\n",
      "jordan jordan return jordan in\n",
      "UNK UNK UNK to to to to\n",
      "to for for for\n",
      "UNK wins world cup\n",
      "a UNK UNK for for for\n",
      "#### 's at at at\n",
      "UNK UNK UNK to\n",
      "england cup world world world\n",
      "indian markets markets closed for for\n",
      "UNK s england to to to to to with with\n",
      "england to sports coach\n",
      "UNK wins world cup cup\n",
      "bush 's president bush bush\n",
      "UNK UNK UNK UNK to in in\n",
      "first to to to to to to to in in in\n",
      "police police # in in in in\n",
      "UNK UNK UNK to UNK UNK\n",
      "stocks stocks in in trading\n",
      "UNK UNK UNK to UNK UNK\n",
      "raiders chargers chargers for\n",
      "williams williams to to UNK to\n",
      "UNK UNK to UNK\n",
      "'s to UNK\n",
      "<unk> <unk> UNK UNK\n",
      "giants 's n't n't\n",
      "in 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "dole brown in in in\n",
      "london share prices index at\n",
      "helicopter helicopter crashes crashes crashes crashes\n",
      "former president president UNK\n",
      "UNK UNK UNK UNK coach coach coach\n",
      "no. # UNK in in in\n",
      "bush UNK president president bush president\n",
      "eu 's UNK in in in in\n",
      "UNK UNK UNK from UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "czech pm minister minister minister in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "the on on on on\n",
      "UNK UNK UNK game in game game\n",
      "dolphins re-sign re-sign UNK UNK\n",
      "UNK UNK to to title title\n",
      "former 's UNK UNK\n",
      "man man shot dead in in\n",
      "in 's in in UNK UNK UNK in\n",
      "clinton clinton clinton to UNK\n",
      "malaysia is UNK UNK UNK\n",
      "indian markets markets closed for\n",
      "UNK UNK of to to to to to\n",
      "shanghai cabinet cabinet cabinet cabinet cabinet\n",
      "no. ## to ##\n",
      "woods masters masters masters masters\n",
      "gold futures higher higher higher\n",
      "UNK UNK to to in in\n",
      "real to to to league league league\n",
      "UNK UNK UNK on for\n",
      "china UNK UNK open open open open\n",
      "UNK signs UNK UNK UNK from\n",
      "of 's of of of of of\n",
      "german says says says says UNK\n",
      "UNK UNK UNK UNK UNK to UNK UNK UNK UNK UNK UNK\n",
      "UNK has UNK surgery\n",
      "us man UNK of UNK UNK UNK\n",
      "jury jury in trial trial trial trial\n",
      "UNK UNK olympic olympic olympic olympic\n",
      "UNK wins women 's at\n",
      "UNK UNK UNK\n",
      "UNK UNK UNK to to to for for for\n",
      "<unk> the UNK UNK\n",
      "wins to at\n",
      "china wins men 's UNK gold gold\n",
      "a for of a a a and the\n",
      "UNK UNK UNK in in\n",
      "fire UNK UNK to UNK UNK\n",
      "world cup cup cup cup cup cup cup cup\n",
      "beckham says to to up in in england england england\n",
      "brazil cup UNK cup in world world cup\n",
      "south africa president UNK UNK president president\n",
      "UNK UNK to european tour tour of in\n",
      "european s 's UNK for for for the\n",
      "the 's to to to the\n",
      "woods 's to at\n",
      "armstrong to to to in tour tour france\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "former UNK UNK UNK UNK UNK UNK\n",
      "south korea south in in\n",
      "south korea in in south\n",
      "dollar up gold gold in\n",
      "UNK UNK UNK UNK\n",
      "explosion explosion explosion explosion\n",
      "iraq says UNK UNK UNK iraq iraq iraq iraq\n",
      "UNK # UNK #\n",
      "the new UNK new UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK fires fires coach coach\n",
      "united to to to us in\n",
      "stocks stocks stock UNK after UNK\n",
      "obama to to UNK UNK\n",
      "UNK UNK the UNK\n",
      "tropical storm UNK UNK in\n",
      "arsenal beats #-# #-# #-# in\n",
      "of UNK in in in\n",
      "south says says says UNK UNK\n",
      "tiger wins to ryder ryder cup cup cup\n",
      "canada 's central interest interest interest\n",
      "us 's UNK to to UNK\n",
      "police police arrest arrest men\n",
      "malaysia 's he the as of of of of\n",
      "dollar beats to to to in in\n",
      "man 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in\n",
      "a UNK UNK UNK UNK\n",
      "baseball UNK UNK UNK\n",
      "UNK UNK UNK to to UNK of of\n",
      "share prices close mixed\n",
      "share prices close generally mixed\n",
      "UNK UNK of UNK UNK UNK UNK UNK\n",
      "share prices close generally lower\n",
      "brazilian to UNK UNK UNK UNK\n",
      "hong kong markets markets for for\n",
      "UNK UNK 's in\n",
      "earthquake earthquake hits northern\n",
      "UNK to to to UNK in in\n",
      "UNK UNK UNK at\n",
      "UNK UNK launch space space space\n",
      "roddick withdraws to to masters\n",
      "man to to to to to to to to\n",
      "israeli UNK UNK in in gaza\n",
      "jones jones jones 's UNK UNK\n",
      "new zealand minister to new\n",
      "judge judge UNK UNK to UNK UNK UNK UNK\n",
      "eu to first eu eu in in\n",
      "to 's in UNK UNK\n",
      "UNK at in in in\n",
      "nasa to to to UNK\n",
      "nasa UNK UNK UNK UNK\n",
      "iran to launch new # #\n",
      "city for for for for\n",
      "arsenal 's to in\n",
      "a UNK UNK UNK to for for for for\n",
      "UNK UNK UNK to to the UNK\n",
      "south korea korea to at at in\n",
      "UNK UNK in in to\n",
      "<unk> 's UNK to in\n",
      "canada of for UNK UNK\n",
      "brazil cup cup cup brazil brazil cup cup\n",
      "<unk> UNK ## ## UNK UNK\n",
      "hong kong hong kong UNK UNK UNK\n",
      "armstrong armstrong for in in\n",
      "world world world world UNK\n",
      "bush to new for for\n",
      "UNK wins UNK to in in\n",
      "los 's on in\n",
      "UNK UNK to to of of in\n",
      "UNK wins wins stage tour tour\n",
      "UNK wins UNK UNK\n",
      "stocks stocks lower early\n",
      "mexico mexico to #### #### world world #### ####\n",
      "UNK UNK UNK UNK UNK\n",
      "# killed in in in in\n",
      "UNK wins wins stage stage of of\n",
      "michael jackson jackson UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK dies dies dies\n",
      "dolphins ## to ##\n",
      "no. # ## ## ## ## ##\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "no. ## ## ## ##\n",
      "a UNK UNK UNK UNK UNK in\n",
      "# train in in in in in\n",
      "bruins bruins UNK #\n",
      "UNK UNK UNK UNK\n",
      "it UNK UNK UNK\n",
      "the UNK UNK the UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK says to to to to to\n",
      "UNK UNK UNK UNK\n",
      "police police arrest arrest in in\n",
      "moderate earthquake hits eastern\n",
      "jazz 's to his for to\n",
      "in of UNK UNK in in in in in\n",
      "UNK gets UNK UNK UNK\n",
      "jackson jackson jackson jackson jackson to\n",
      "ryder ryder ryder ryder ryder ryder ryder ryder ryder\n",
      "u.s. women women women women in in in\n",
      "sign sign sign sign\n",
      "london share prices close higher\n",
      "india UNK UNK in in in in\n",
      "gore party party party in\n",
      "us court UNK UNK UNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK awards to awards awards awards awards awards awards\n",
      "UNK UNK to at in at\n",
      "UNK UNK UNK on UNK\n",
      "UNK UNK UNK with\n",
      "UNK UNK UNK UNK UNK\n",
      "michael 's and for in in\n",
      "UNK UNK UNK UNK UNK\n",
      "stocks stocks lower lower on\n",
      "#### UNK UNK UNK UNK\n",
      "of 's UNK UNK UNK in in in\n",
      "at 's of of of at at at at at at\n",
      "still to for ####\n",
      "<unk> gets UNK UNK\n",
      "UNK wins wins UNK UNK\n",
      "reds moves to to to UNK\n",
      "woods woods to to in in\n",
      "braves # to ##\n",
      "in UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "dollar falls in lower yen yen in\n",
      "giants # to to to\n",
      "UNK 's UNK to\n",
      "a UNK UNK for\n",
      "## to ##\n",
      "stars UNK UNK to a UNK the the\n",
      "it of on a a a a a a\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "no. 's to at\n",
      "after UNK UNK UNK UNK UNK UNK UNK on on on\n",
      "new york are UNK to UNK UNK UNK UNK\n",
      "to to to to to to to in in\n",
      "mets mets mets to\n",
      "UNK to for of of at\n",
      "'s says UNK UNK UNK UNK UNK UNK UNK\n",
      "south africa to to to to cup cup\n",
      "UNK UNK UNK in UNK UNK\n",
      "san gop to to\n",
      "UNK UNK UNK UNK UNK\n",
      "to to to to to to in\n",
      "china to to to to #### ####\n",
      "tokyo stocks open higher dollar yen yen\n",
      "UNK 's his on\n",
      "UNK signs contract midfielder\n",
      "arsenal says UNK to chelsea arsenal\n",
      "for UNK wife wife wife to to a\n",
      "u.s. to to to to\n",
      "dollar trades in lower in in trading\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "UNK soccer soccer soccer in\n",
      "## UNK UNK UNK in in\n",
      "new named new zealand soccer\n",
      "olympic olympic olympic olympic olympic olympic for for\n",
      "UNK UNK UNK UNK\n",
      "u.s. to open open open open open\n",
      "nasa and to to with UNK in\n",
      "UNK UNK UNK UNK of of of\n",
      "red red to to for for for\n",
      "stocks stocks mixed as trading stocks\n",
      "the of of the UNK UNK\n",
      "israel to to to to to to\n",
      "UNK UNK UNK to the UNK UNK\n",
      "turkey beats turkey #-# in friendly friendly\n",
      "mets UNK mets UNK\n",
      "the 's 's to to the UNK\n",
      "UNK UNK french french french\n",
      "crude prices ## ## ## ##\n",
      "UNK cup cup for for in cup\n",
      "UNK union UNK with UNK union\n",
      "michael jackson jackson jackson jackson\n",
      "liverpool and to to in cup cup\n",
      "UNK UNK UNK UNK\n",
      "u.s. prices to on to on\n",
      "UNK 's UNK is of\n",
      "UNK UNK UNK UNK UNK\n",
      "# UNK UNK UNK UNK in in\n",
      "actor says says says UNK UNK\n",
      "UNK UNK of UNK\n",
      "czech says says to to to to to on on UNK\n",
      "u.s. to to to to to in\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "france UNK UNK france france france world cup\n",
      "to to to to\n",
      "ac milan milan to milan milan milan milan\n",
      "italy to contract contract contract UNK UNK UNK UNK UNK\n",
      "spain beats to to in in in euro euro euro\n",
      "UNK s UNK to to\n",
      "london share exchange index up\n",
      "obama obama obama on to on\n",
      "dollar dollar gold higher higher yen in\n",
      "stocks stocks as as of\n",
      "to to to to\n",
      "UNK wins UNK to\n",
      "british says for for for in in in\n",
      "nadal beats to to\n",
      "ac milan to to to in in in\n",
      "world to to sri sri sri sri lanka\n",
      "UNK UNK UNK to UNK UNK UNK UNK UNK\n",
      "UNK UNK gets to\n",
      "stocks leads UNK UNK\n",
      "to to to to to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK wins to UNK\n",
      "the 's to to of\n",
      "in UNK of of UNK UNK UNK UNK\n",
      "former pleads pleads guilty guilty guilty guilty to to\n",
      "stocks stocks as as as\n",
      "boeing 's to to to\n",
      "UNK wins wins wins marathon\n",
      "UNK to to UNK\n",
      "former king wife for for for for\n",
      "UNK wins UNK marathon marathon marathon marathon\n",
      "beckham to\n",
      "quake quake hits taiwan taiwan\n",
      "stocks stocks fall as earnings\n",
      "UNK UNK UNK UNK UNK to UNK on on\n",
      "tokyo stocks rise dollar higher against yen in trading trading\n",
      "after UNK UNK UNK UNK UNK UNK\n",
      "UNK wins UNK #-#\n",
      "a of of to in school in in\n",
      "UNK UNK of UNK UNK in in in\n",
      "UNK UNK UNK UNK\n",
      "bush UNK UNK UNK\n",
      "israeli israeli israeli israeli in in\n",
      "<unk> to for for\n",
      "UNK UNK UNK UNK in\n",
      "stars UNK UNK to of of of of of\n",
      "<unk> sign signs <unk> UNK\n",
      "UNK draws #-# #-# #-# #-# #-#\n",
      "UNK wins UNK UNK\n",
      "UNK UNK UNK to to to UNK UNK UNK UNK UNK\n",
      "england says he he to to england england\n",
      "UNK # UNK ##\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "obama UNK UNK obama obama obama obama\n",
      "ac milan to world world world world world\n",
      "french france france UNK UNK france\n",
      "UNK gets UNK to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK as as as as coach coach coach coach\n",
      "stocks close close on on on tax tax\n",
      "UNK UNK UNK UNK\n",
      "brazil brazil record record record record record record\n",
      "dollar falls in in in\n",
      "china to to UNK to for\n",
      "some of UNK UNK UNK UNK in in\n",
      "UNK UNK to UNK UNK\n",
      "former leads for\n",
      "UNK UNK to to to UNK on on\n",
      "cowboys 's to to to\n",
      "former UNK arrested arrested in in\n",
      "french UNK UNK UNK UNK dies at\n",
      "british says says says says in\n",
      "up and to UNK on UNK\n",
      "north korea nuclear korea korea korea\n",
      "moderate earthquake hits southern\n",
      "london share prices lower lower\n",
      "UNK 's UNK in UNK\n",
      "share prices close generally lower\n",
      "prices 's to in record\n",
      "microsoft UNK to for\n",
      "UNK UNK UNK UNK UNK to\n",
      "johnson wins UNK for for\n",
      "tyson 's to to to\n",
      "man UNK of UNK UNK\n",
      "eu UNK UNK UNK on\n",
      "UNK UNK UNK UNK UNK to to UNK UNK UNK UNK\n",
      "wins wins wins win title\n",
      "british soldier killed in in in\n",
      "king UNK UNK UNK\n",
      "australia to play for for in\n",
      "world wins world cup slalom slalom slalom\n",
      "israeli UNK israeli israeli UNK UNK UNK UNK\n",
      "china 's UNK to UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "woods leads at at open\n",
      "agassi ## ## ##\n",
      "federer beats to to\n",
      "UNK UNK at at at\n",
      "rangers 's rangers UNK\n",
      "toyota to to UNK UNK\n",
      "british wins to in\n",
      "bonds UNK to to to\n",
      "UNK to to for\n",
      "beckham says he he in in in in in\n",
      "UNK wins world cup cup cup\n",
      "devils beats to to game game game\n",
      "UNK UNK s to UNK UNK world in in in\n",
      "u.s. women women women women women women women women women\n",
      "'s in in in in\n",
      "no. wins to to to in\n",
      "UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK UNK UNK\n",
      "UNK to UNK UNK UNK\n",
      "us of on on to on on on on on on\n",
      "soccer soccer soccer soccer soccer soccer\n",
      "sri lanka lanka lanka lanka sri in in in\n",
      "real madrid UNK to as as UNK UNK\n",
      "UNK earnings earnings UNK earnings earnings\n",
      "former UNK UNK cancer cancer cancer cancer\n",
      "asian markets markets markets mostly up on markets markets markets\n",
      "italy united to to in in #### #### ####\n",
      "sorenstam sorenstam UNK UNK to to to\n",
      "UNK UNK to UNK UNK\n",
      "chelsea chelsea chelsea chelsea chelsea chelsea chelsea chelsea\n",
      "moderate quake hits southern ;\n",
      "<unk> <unk> <unk> <unk> <unk> <unk>\n",
      "'s 's #.## to to\n",
      "britney spears UNK to UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "us military says UNK UNK at in\n",
      "world world world world to be\n",
      "share prices close lower\n",
      "UNK UNK to on on on on\n",
      "UNK wins he win world\n",
      "UNK world world world world world world world\n",
      "london share prices higher at midday\n",
      "beijing to to to to to beijing beijing\n",
      "UNK to to to to in in\n",
      "dollar dollar falls against dollar in\n",
      "police police found in in in in\n",
      "of of of of at at at\n",
      "UNK 's UNK UNK UNK\n",
      "wall street stocks on on economic\n",
      "UNK 's to to to to to for\n",
      "UNK UNK UNK UNK UNK in UNK\n",
      "london share prices up up\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "federer federer federer federer federer\n",
      "UNK UNK UNK at\n",
      "sri lohan UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "striker signs signs striker UNK UNK UNK UNK\n",
      "UNK open open french french open open\n",
      "michael to to to UNK to to UNK UNK\n",
      "UNK UNK to for for for\n",
      "us says says says UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "stocks UNK UNK UNK UNK\n",
      "stocks UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "one UNK of in in in in in\n",
      "eu to to to to to to in in\n",
      "#### 's for on of title title title\n",
      "injured withdraws withdraws french in\n",
      "UNK UNK UNK in UNK in\n",
      "ac signs to to\n",
      "microsoft UNK to to for\n",
      "UNK to to brazil brazil brazil brazil brazil\n",
      "UNK UNK UNK UNK\n",
      "us military UNK UNK UNK iraq iraq\n",
      "UNK 's UNK UNK UNK\n",
      "UNK 's gold UNK to UNK UNK UNK UNK\n",
      "jones 's to for for the\n",
      "australian signs UNK UNK\n",
      "UNK UNK UNK as new new new\n",
      "UNK UNK UNK to to to\n",
      "UNK UNK UNK ##\n",
      "share prices lower lower lower\n",
      "UNK says says to to to to to to\n",
      "us to to to to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "toyota 's $ $ $ $ percent\n",
      "michael wins wins of of of\n",
      "UNK UNK UNK to\n",
      "the UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "moderate quake shakes turkey turkey\n",
      "rangers wins wins\n",
      "UNK 's UNK to UNK UNK UNK\n",
      "cowboys wins UNK of\n",
      "spurs ## spurs ##\n",
      "UNK wins UNK UNK open open\n",
      "<unk> to UNK UNK UNK\n",
      "strong of in baghdad baghdad\n",
      "england wins wins as of\n",
      "UNK UNK UNK UNK\n",
      "UNK wins to at in at at\n",
      "UNK 's to be\n",
      "tokyo stocks lower dollar dollar against yen yen\n",
      "of of of UNK at at\n",
      "UNK UNK UNK UNK UNK in in\n",
      "UNK 's UNK UNK UNK UNK UNK\n",
      "no. ## no. ## ##\n",
      "beats UNK to to game game\n",
      "stars 's UNK to to\n",
      "UNK UNK UNK UNK UNK\n",
      "spurs # to in # #\n",
      "mets # mets #\n",
      "british wants return return to\n",
      "UNK UNK UNK UNK UNK\n",
      "jordan 's he n't UNK\n",
      "<unk> UNK the UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "shanghai s UNK UNK UNK UNK UNK\n",
      "'s to UNK to to to UNK\n",
      "UNK wins UNK UNK\n",
      "a to to UNK UNK UNK\n",
      "britain to first to to in in in\n",
      "us UNK to to to\n",
      "UNK beats to UNK in in\n",
      "former UNK UNK of dies dies at at ## ##\n",
      "us UNK UNK UNK in in in\n",
      "canadian 's new UNK to\n",
      "UNK UNK to to UNK UNK\n",
      "china 's UNK #.# #.# in in\n",
      "rain wins out title\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "to UNK UNK UNK\n",
      "iraq to to to to\n",
      "share prices close generally lower\n",
      "british 's in to UNK UNK UNK UNK\n",
      "stocks UNK UNK to to to UNK\n",
      "UNK UNK UNK a UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "u.s. UNK UNK UNK open open\n",
      "for UNK UNK UNK UNK UNK UNK\n",
      "no. ## ## ## ##\n",
      "UNK 's UNK UNK for\n",
      "former <unk> <unk> of dies dies dies at at\n",
      "red sox to for UNK\n",
      "former UNK UNK UNK\n",
      "UNK gets for for\n",
      "UNK UNK UNK UNK\n",
      "united to to bid #### #### #### #### ####\n",
      "london share rise in\n",
      "in UNK 's UNK UNK UNK UNK UNK UNK\n",
      "rangers rangers to to\n",
      "UNK UNK UNK UNK dies at at\n",
      "britain 's says says # in in in\n",
      "<unk> signs UNK signs deal\n",
      "paris to to in in in\n",
      "UNK UNK UNK UNK\n",
      "UNK to to to UNK\n",
      "UNK leads for in in a a\n",
      "former king wife wife to to to to\n",
      "<unk> cup world cup cup\n",
      "los 's UNK at\n",
      "agassi agassi agassi in to\n",
      "new UNK new new\n",
      "UNK ## in #\n",
      "UNK UNK UNK UNK UNK\n",
      "world UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK for UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to UNK\n",
      "UNK UNK UNK surgery surgery\n",
      "former UNK UNK UNK UNK UNK UNK to to\n",
      "'s UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK to for in\n",
      "giants UNK to to\n",
      "woods UNK UNK woods at at\n",
      "stocks stocks in early trading\n",
      "venus williams UNK to at\n",
      "london share prices up at midday\n",
      "UNK UNK UNK UNK UNK\n",
      "dodgers UNK to to for in\n",
      "stocks mixed in early trading\n",
      "moderate earthquake hits southern\n",
      "celtics beat n't #-#\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "reds UNK to to to\n",
      "davis cup cup davis davis cup\n",
      "moderate quake shakes romania\n",
      "french french french french french french french\n",
      "UNK UNK UNK UNK ryder ryder\n",
      "UNK to to\n",
      "UNK UNK UNK in\n",
      "new UNK UNK to to to to\n",
      "mccain UNK UNK UNK\n",
      "bush bush bush bush presidential presidential presidential\n",
      "#### to for for at\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK UNK\n",
      "oil prices prices prices prices prices prices prices prices\n",
      "oil prices fall in ##\n",
      "UNK cup to cup season in in\n",
      "sorenstam wins UNK UNK\n",
      "# killed in in in in in\n",
      "UNK UNK UNK cup world world world cup cup\n",
      "germany beats world #-# #-# world cup cup\n",
      "UNK UNK UNK UNK UNK in in in\n",
      "UNK UNK UNK UNK 's\n",
      "world cup cup cup cup cup cup\n",
      "italy beats #-# #-# #-# world cup\n",
      "england and to on on on\n",
      "italy and to to cup cup cup cup cup cup cup\n",
      "british of UNK UNK UNK\n",
      "UNK named as coach coach\n",
      "UNK 's UNK UNK\n",
      "european cup cup cup cup cup cup cup\n",
      "stars of to to\n",
      "UNK UNK UNK UNK UNK\n",
      "share prices close higher\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "list UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK talks talks talks talks talks talks\n",
      "share prices close generally higher\n",
      "UNK UNK UNK UNK in in in in\n",
      "british 's in in in the in\n",
      "wins win with with\n",
      "UNK UNK new UNK of\n",
      "UNK UNK UNK UNK UNK\n",
      "police police UNK in for\n",
      "london share prices rise\n",
      "england cup cup cup cup cup cup\n",
      "wheat prices rise rise\n",
      "arsenal cup cup cup cup cup cup cup\n",
      "india india india india india pakistan\n",
      "man UNK in in in in\n",
      "south UNK in in\n",
      "to to UNK open UNK\n",
      "south 's UNK to in in in in in\n",
      "stars sign sign UNK UNK\n",
      "mccain mccain to to to\n",
      "tiger woods UNK UNK UNK\n",
      "czech signs UNK UNK UNK\n",
      "france s to france france france france france france\n",
      "<unk> UNK UNK to UNK in\n",
      "UNK president president president president president president\n",
      "german to to to to to\n",
      "tropical 's in in UNK UNK\n",
      "former UNK UNK UNK UNK UNK\n",
      "nicklaus 's to at at\n",
      "johnson 's UNK to to\n",
      "yankees is to UNK\n",
      "the 's up of the\n",
      "judge 's for for\n",
      "UNK 's for for\n",
      "UNK UNK to to\n",
      "cubs ## to to\n",
      "canada confirms ##th case of mad cow cow\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK wins wins wins wins title\n",
      "china 's to to to to\n",
      "china 's to to to to\n",
      "iraq s to to to to UNK UNK UNK\n",
      "to is is UNK UNK the the\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "# killed in in in in\n",
      "olympic champion champion in in in in in in\n",
      "united wins wins title title title title title\n",
      "UNK UNK to UNK UNK UNK of of\n",
      "<unk> UNK in in in\n",
      "south korea korea dies dies dies\n",
      "us s $ $ in in in in\n",
      "UNK UNK UNK UNK\n",
      "france signs UNK to to to\n",
      "canada 's to more to to in UNK UNK\n",
      "stocks stocks fall as as as of of\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK signs UNK with with with with\n",
      "oil iraq iraq in iraq on iraq iraq iraq\n",
      "israel to UNK on on on\n",
      "UNK UNK to to to\n",
      "israeli strike strike strike strike\n",
      "mexico police to to to\n",
      "UNK de tour tour tour tour tour france france france france\n",
      "UNK UNK UNK UNK to to for\n",
      "UNK to to to for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK to to for for for in\n",
      "UNK UNK to to at at\n",
      "braves 's for for for\n",
      "UNK UNK UNK UNK to UNK\n",
      "UNK wins UNK UNK in cup cup cup\n",
      "former UNK of of dies dies dies at at ##\n",
      "yankees UNK in UNK\n",
      "UNK UNK UNK to to to to\n",
      "mets mets mets to mets\n",
      "UNK 's up for\n",
      "mets UNK to UNK UNK #-#\n",
      "stocks to to for #\n",
      "john 's UNK 's the\n",
      "spurs # to #-# #-#\n",
      "## of of in UNK UNK UNK\n",
      "woods woods UNK UNK UNK\n",
      "UNK beats UNK #-# in\n",
      "UNK UNK UNK he he is\n",
      "stocks stocks in mexico brazil chile chile\n",
      "UNK to to to to to to to\n",
      "the UNK for UNK UNK\n",
      "UNK UNK to to to\n",
      "london share prices index up midday\n",
      "french french UNK french french french french\n",
      "former <unk> former former dies dies dies dies at at ##\n",
      "UNK UNK UNK UNK UNK in in in\n",
      "UNK UNK UNK for\n",
      "taiwan stock market down\n",
      "taiwan stocks market lower\n",
      "in UNK UNK UNK UNK\n",
      "taiwan shares prices #.# percent\n",
      "moderate president arrives in in\n",
      "shanghai stock market lower\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "u.s. u.s. and UNK and a a on on on on\n",
      "malaysia UNK UNK in in in in in\n",
      "man charged charged with with with with\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "for to to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "woods to to to in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK in\n",
      "california of of school school school\n",
      "for the UNK UNK UNK\n",
      "some of on UNK UNK on on UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "in 's of on on the the to\n",
      "in UNK UNK UNK UNK UNK UNK UNK\n",
      "mccain UNK to for\n",
      "a UNK UNK a to a to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "us UNK UNK UNK UNK UNK\n",
      "for UNK UNK UNK UNK UNK UNK\n",
      "us iraq iraq iraq iraq iraq iraq iraq iraq iraq iraq\n",
      "# UNK in in in UNK\n",
      "a 's UNK a UNK a UNK\n",
      "obama UNK UNK UNK UNK with with\n",
      "UNK UNK UNK UNK for for in\n",
      "chinese UNK UNK UNK for\n",
      "bush 's UNK to UNK UNK UNK\n",
      "for UNK UNK UNK UNK UNK UNK UNK\n",
      "of # ## ##\n",
      "UNK UNK to UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "australian 's UNK UNK\n",
      "UNK 's UNK 's\n",
      "a 's UNK UNK UNK UNK UNK\n",
      "the UNK UNK a for\n",
      "UNK UNK UNK at at\n",
      "for 's UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "## ## in in in\n",
      "UNK 's UNK UNK UNK\n",
      "the UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK UNK the\n",
      "clinton clinton to in in in in in\n",
      "obama UNK UNK to for\n",
      "the music on the the the\n",
      "UNK UNK UNK UNK\n",
      "for of UNK UNK UNK UNK UNK\n",
      "the UNK UNK for for for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "us UNK UNK UNK to to to\n",
      "UNK UNK UNK UNK\n",
      "senate court UNK UNK UNK UNK\n",
      "us says to UNK UNK UNK UNK UNK\n",
      "bush 's in for\n",
      "a UNK UNK UNK\n",
      "holiday your for UNK\n",
      "gold 's UNK UNK to UNK UNK to\n",
      "to to to to to to\n",
      "UNK of UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "bush 's president bush bush\n",
      "UNK UNK UNK UNK UNK\n",
      "u.s. UNK to to to to in\n",
      "UNK UNK UNK UNK\n",
      "'s 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "turkey 's for the\n",
      "UNK UNK UNK UNK UNK in in\n",
      "mccain mccain mccain mccain mccain\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK of UNK UNK UNK\n",
      "in of UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "china 's UNK china china china china\n",
      "<unk> UNK <unk> to\n",
      "UNK UNK UNK UNK UNK in in in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK dies dies dies dies\n",
      "mccain mccain to to\n",
      "UNK UNK UNK to to\n",
      "UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK to to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "microsoft 's UNK UNK\n",
      "california UNK UNK to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK for for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "a is for for a for\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "to 's UNK for\n",
      "us senate senate senate in for\n",
      "america america in in in in in\n",
      "a 's UNK UNK UNK\n",
      "<unk> UNK UNK <unk> UNK UNK UNK\n",
      "it 's n't the the\n",
      "world to to for for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "wall 's UNK to to for for\n",
      "a UNK UNK the UNK\n",
      "#### #### for for\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to on on on on\n",
      "us UNK UNK UNK on UNK\n",
      "iran says iran to to\n",
      "court court UNK UNK UNK UNK UNK\n",
      "american UNK 's the UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "for UNK UNK UNK UNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "us UNK UNK UNK for in\n",
      "the UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stock UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "pope pope john pope for\n",
      "yankees UNK for UNK\n",
      "a 's for a UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "former UNK UNK new UNK new UNK\n",
      "UNK UNK UNK UNK jordan in\n",
      "toyota UNK to to in in in\n",
      "the of the the the\n",
      "a UNK in in\n",
      "braves UNK in in in\n",
      "UNK 's UNK to to in in in\n",
      "UNK ## in ##\n",
      "dodgers 's to to\n",
      "after s UNK he he to to to in\n",
      "yankees ## to #\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK in in\n",
      "the the the UNK UNK\n",
      "UNK to UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK\n",
      "UNK UNK UNK to to the in UNK\n",
      "obama s UNK to to for for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK and UNK UNK for in in\n",
      "<unk> UNK UNK UNK UNK UNK UNK\n",
      "in to to to to to to to of\n",
      "UNK 's to to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "stars UNK to to to to to\n",
      "rangers beat rangers to #-# in\n",
      "new UNK and UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "red red to to\n",
      "the UNK UNK UNK UNK UNK\n",
      "UNK UNK of UNK UNK UNK UNK UNK UNK\n",
      "south UNK to south for for for\n",
      "UNK UNK UNK UNK in\n",
      "world UNK at at at at at in\n",
      "u.s. mixed mixed as as UNK UNK UNK UNK\n",
      "u.s. UNK says UNK UNK UNK UNK to to to to to\n",
      "a 's for for in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK UNK\n",
      "williams williams to to\n",
      "in UNK UNK UNK UNK UNK to to UNK\n",
      "texas UNK UNK UNK for\n",
      "the UNK to for for\n",
      "mets UNK UNK UNK for\n",
      "UNK UNK to to in in\n",
      "stocks prices fall on on\n",
      "UNK wins to at in\n",
      "UNK UNK to to\n",
      "in UNK UNK to\n",
      "woods open UNK of of\n",
      "stocks UNK in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "us to for for in\n",
      "cowboys 's n't for UNK\n",
      "UNK wins to to\n",
      "baseball baseball to to baseball\n",
      "UNK 's for for for\n",
      "UNK UNK UNK for for\n",
      "UNK UNK to to the\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to stars\n",
      "bucs 's for for\n",
      "UNK UNK UNK UNK UNK\n",
      "stocks to to to to UNK UNK\n",
      "UNK 's UNK of\n",
      "brown 's UNK UNK UNK\n",
      "in of of UNK UNK UNK UNK UNK\n",
      "'s 's UNK UNK to to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK 's UNK UNK UNK\n",
      "to 's of to UNK UNK UNK UNK\n",
      "to to UNK UNK to UNK UNK UNK\n",
      "UNK UNK 's UNK UNK UNK UNK\n",
      "clippers 's UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK\n",
      "super 's to in bowl\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a of UNK in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "bush UNK UNK for\n",
      "tokyo UNK UNK UNK dies dies ##\n",
      "UNK UNK to to in\n",
      "a UNK UNK UNK UNK a UNK UNK\n",
      "jets for for for for for for for\n",
      "a 's a the to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK in in in in in\n",
      "UNK UNK UNK to to to to UNK\n",
      "woods woods woods woods tiger woods\n",
      "to to to UNK UNK UNK UNK\n",
      "no. # texas ## ## ## ##\n",
      "UNK UNK UNK UNK in\n",
      "no. state to to to in in in to\n",
      "ucla gets his of\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "the 's UNK UNK UNK\n",
      "a of UNK UNK UNK\n",
      "microsoft 's to UNK\n",
      "stocks 's to to\n",
      "UNK UNK UNK on on in\n",
      "UNK UNK in in UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "the 's 's the the\n",
      "man UNK UNK UNK UNK UNK in\n",
      "online the to for the\n",
      "brazil brazil brazil brazil brazil brazil brazil brazil\n",
      "UNK UNK UNK the UNK the the\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "world 's world canada for\n",
      "UNK UNK of UNK UNK in in\n",
      "knicks 's to to to\n",
      "germany stocks close lower\n",
      "UNK named UNK\n",
      "the UNK UNK UNK UNK a UNK\n",
      "UNK UNK UNK UNK\n",
      "bush to new new\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "pct sign sign UNK UNK UNK\n",
      "'s 's UNK UNK UNK UNK\n",
      "angels to in to\n",
      "UNK UNK UNK UNK UNK in\n",
      "iraq iraq iraq iraq iraq iraq iraq iraq iraq iraq\n",
      "UNK UNK 's UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "tyson UNK to to to to to\n",
      "toyota to to UNK\n",
      "UNK <unk> <unk> <unk> <unk> dies\n",
      "a UNK UNK UNK a\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "no. ## no. ## ## ## ##\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK 's UNK UNK UNK\n",
      "UNK UNK 's in in\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK in in\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "UNK UNK UNK a UNK baby\n",
      "UNK wins UNK ## at\n",
      "spurs leads wins of to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "#### UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "jets UNK UNK to to\n",
      "for UNK UNK UNK of of of of\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to to\n",
      "UNK UNK UNK to UNK UNK\n",
      "bucs UNK to UNK to\n",
      "a UNK and and and and UNK\n",
      "kings kings kings kings\n",
      "jets bowl to to\n",
      "in UNK UNK UNK UNK UNK\n",
      "UNK of of UNK UNK for of of\n",
      "UNK UNK UNK UNK UNK\n",
      "#### of of news the\n",
      "kings will to to with in\n",
      "UNK 's UNK # #-#\n",
      "the UNK the the UNK\n",
      "california UNK UNK UNK UNK UNK\n",
      "microsoft microsoft microsoft to\n",
      "the of on UNK\n",
      "obama UNK UNK UNK to\n",
      "california UNK UNK in in in\n",
      "<unk> UNK to to\n",
      "giants to to to to to\n",
      "the UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "<unk> the to to the the to\n",
      "UNK still still in in in the\n",
      "cowboys 's n't to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "california UNK UNK UNK UNK UNK\n",
      "a UNK and UNK UNK UNK in in\n",
      "to to UNK UNK UNK for of\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> <unk>\n",
      "<unk> to UNK UNK\n",
      "judge says pleads guilty UNK UNK\n",
      "tyson 's to to to to to to\n",
      "us says says to on on on on UNK\n",
      "michael jackson jackson jackson\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "treasury prices in in in in\n",
      "UNK to to to UNK\n",
      "patriots beat patriots to\n",
      "revolution 's to UNK\n",
      "microsoft 's to UNK for\n",
      "spurs to to to to\n",
      "for 's to UNK UNK of of\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK the the the\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "mets UNK UNK UNK UNK\n",
      "some to to to to to\n",
      "<unk> UNK UNK UNK\n",
      "a UNK UNK UNK for wall\n",
      "to UNK UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "haiti says says UNK UNK UNK\n",
      "UNK UNK UNK UNK to to to\n",
      "new 's UNK to UNK UNK UNK UNK\n",
      "world world world UNK\n",
      "jordan 's for UNK\n",
      "rangers rangers rangers rangers rangers rangers\n",
      "says says says says says says says to\n",
      "UNK UNK to to\n",
      "the 's a the the the\n",
      "UNK 's to UNK\n",
      "in UNK a UNK UNK to UNK\n",
      "UNK UNK in in in in UNK\n",
      "and and UNK and UNK\n",
      "un un to to to on on on on\n",
      "bush bush bush bush UNK bush\n",
      "UNK UNK to to to to\n",
      "clinton gop gop in in UNK\n",
      "UNK 's UNK UNK\n",
      "UNK UNK UNK in UNK in\n",
      "u.s. stocks mixed as mixed mixed stocks stocks\n",
      "UNK UNK UNK to to to to to to\n",
      "# to #\n",
      "u.s. stocks fall as as ; rates\n",
      "angels UNK in in\n",
      "the cox news service spot news budget for thursday june ##\n",
      "jets jets jets jets to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the 's UNK UNK\n",
      "cowboys cowboys UNK UNK\n",
      "'s gets to\n",
      "UNK UNK to\n",
      "the to the UNK\n",
      "UNK UNK UNK UNK\n",
      "# UNK UNK for for in in\n",
      "UNK UNK of of UNK\n",
      "UNK 's UNK his his\n",
      "lakers lakers n't to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stocks UNK to to\n",
      "red wings red UNK\n",
      "in UNK 's UNK UNK\n",
      "senate to to to for for for\n",
      "microsoft 's to to UNK to\n",
      "house house UNK to the the the to\n",
      "UNK UNK UNK UNK\n",
      "'s 's to to to\n",
      "french wins french french french open open\n",
      "after UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "un 's on on on in\n",
      "UNK UNK to to\n",
      "mexico mexico mexico mexico mexico mexico mexico mexico mexico mexico\n",
      "cup cup cup cup cup cup cup\n",
      "us UNK UNK talks\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "yankees yankees to to\n",
      "lakers ## lakers ##\n",
      "<unk> UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "u.s. stocks up to UNK UNK UNK\n",
      "bruins bruins bruins UNK UNK\n",
      "stars gets UNK for\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK\n",
      "UNK ## UNK in\n",
      "man 's to with after in in in\n",
      "stars UNK and UNK UNK UNK UNK UNK\n",
      "in UNK to to to to UNK UNK UNK\n",
      "stars UNK UNK UNK to UNK stars\n",
      "ucla UNK UNK UNK UNK\n",
      "UNK UNK to to to\n",
      "UNK UNK UNK to UNK UNK\n",
      "mavericks wins UNK to\n",
      "first 's a to for of\n",
      "the UNK UNK UNK UNK\n",
      "celtics 's UNK news\n",
      "UNK UNK UNK UNK UNK in UNK UNK\n",
      "microsoft microsoft microsoft microsoft to for\n",
      "johnson 's to as to of\n",
      "obama obama obama in in\n",
      "the UNK UNK UNK\n",
      "wall street street UNK\n",
      "israel UNK UNK UNK UNK UNK\n",
      "UNK of school school in school school\n",
      "UNK 's n't in\n",
      "UNK UNK UNK UNK UNK\n",
      "former UNK UNK UNK UNK to of\n",
      "bush bush bush for\n",
      "san ## in in UNK UNK\n",
      "stars 's still to the the the\n",
      "the is a UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in\n",
      "for UNK UNK UNK for to\n",
      "UNK UNK to to tour tour tour\n",
      "the UNK is the UNK UNK UNK\n",
      "the UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stars UNK UNK UNK\n",
      "former <unk> <unk> <unk> to to to to <unk> <unk>\n",
      "patriots UNK to to UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "chinese king king for for\n",
      "'s 's UNK to UNK UNK\n",
      "'s 's 's\n",
      "'s to to super super\n",
      "dodgers is to to\n",
      "to to to to UNK\n",
      "UNK ## ## ## in\n",
      "u.s. women women women\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "# UNK a UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK for for UNK UNK UNK\n",
      "UNK 's UNK the to for\n",
      "UNK UNK in in in\n",
      "knicks UNK to to to to\n",
      "us man says to to UNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK to UNK UNK UNK\n",
      "no. ## UNK UNK\n",
      "in UNK UNK for for for\n",
      "dolphins re-sign re-sign <unk> <unk> <unk>\n",
      "chargers ## chargers ##\n",
      "UNK 's in to in in in\n",
      "former UNK UNK dies\n",
      "us UNK UNK UNK UNK UNK to to UNK UNK UNK\n",
      "no. ## ##\n",
      "mexico mexico UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to game to to game in\n",
      "the UNK UNK UNK\n",
      "texas 's gets UNK UNK\n",
      "in 's UNK UNK UNK in in in in\n",
      "the UNK to UNK to to on on on\n",
      "clemens clemens UNK to UNK\n",
      "stocks street stock UNK wall wall wall\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "cowboys cowboys UNK cowboys cowboys cowboys\n",
      "it 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "us UNK UNK in in in in in\n",
      "UNK UNK 's UNK UNK UNK UNK UNK UNK\n",
      "the of of of of of\n",
      "a 's a to a a in\n",
      "the UNK UNK prices\n",
      "UNK sign UNK UNK\n",
      "UNK 's for for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "bush 's to to in bush\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to to to to\n",
      "UNK wins to UNK\n",
      "UNK 's to to\n",
      "UNK UNK UNK to in\n",
      "UNK UNK UNK to in\n",
      "the UNK UNK UNK UNK UNK\n",
      "lakers angeles a a\n",
      "de de de to de de de\n",
      "UNK UNK UNK UNK\n",
      "broncos UNK to to to to to to\n",
      "no. # no. ## ## ##\n",
      "on UNK UNK on on on\n",
      "for UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "yankees sign to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "baseball 's for for for for\n",
      "UNK UNK UNK to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "bank 's bank bank bank in in\n",
      "stocks 's UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "king 's 's in in in\n",
      "in for UNK UNK UNK UNK UNK UNK UNK\n",
      "no 's UNK as as of\n",
      "UNK 's gets to\n",
      "u.s. stocks fall to to to to UNK UNK\n",
      "treasury prices mixed mixed mixed UNK\n",
      "UNK 's to UNK UNK\n",
      "the UNK to UNK a a UNK UNK UNK\n",
      "a 's 's UNK UNK UNK\n",
      "a to for a a a\n",
      "microsoft UNK UNK UNK\n",
      "UNK UNK UNK to to UNK UNK UNK\n",
      "rangers will rangers rangers in\n",
      "for UNK UNK UNK the UNK UNK\n",
      "patriots sign UNK UNK UNK\n",
      "UNK UNK to UNK to\n",
      "re-sign re-sign re-sign UNK\n",
      "UNK UNK UNK UNK\n",
      "<unk> 's UNK the\n",
      "stocks fall for for\n",
      "'s 's UNK UNK UNK UNK\n",
      "UNK UNK to to UNK UNK\n",
      "to to to to to\n",
      "UNK UNK UNK to to\n",
      "UNK to $ $ ### $ $ $ ### ###\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "celtics sign sign sign <unk> to to\n",
      "UNK UNK UNK UNK UNK\n",
      "man says says says says UNK UNK UNK\n",
      "UNK 's UNK for for for\n",
      "to UNK in in\n",
      "in UNK the the the the the the the the\n",
      "in of UNK UNK UNK UNK\n",
      "mavericks could to UNK UNK\n",
      "UNK UNK in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "a UNK the UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "on UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "'s 's to to UNK\n",
      "a UNK ## a UNK UNK UNK UNK\n",
      "<unk> UNK UNK <unk>\n",
      "to to to UNK to UNK UNK\n",
      "the 's for for\n",
      "UNK UNK to to in in\n",
      "jets UNK UNK UNK to for\n",
      "a hall hall hall hall hall hall hall hall\n",
      "toyota UNK UNK UNK UNK $ UNK UNK\n",
      "UNK UNK to to in in\n",
      "UNK 's UNK UNK\n",
      "us to to to on on on in\n",
      "us iran iran to to to to to to to\n",
      "dodgers beat dodgers for dodgers\n",
      "toyota UNK UNK UNK UNK in\n",
      "man UNK UNK to to to\n",
      "UNK UNK UNK UNK\n",
      "to to to UNK UNK\n",
      "mariners trade in in in in\n",
      "in UNK to UNK\n",
      "clinton UNK UNK to\n",
      "stars UNK UNK UNK\n",
      "internet on on for for\n",
      "<unk> <unk> <unk> <unk> <unk> <unk>\n",
      "braves 's to in\n",
      "UNK UNK UNK UNK\n",
      "a the the the\n",
      "UNK UNK UNK UNK\n",
      "a UNK 's UNK UNK UNK UNK UNK\n",
      "cowboys and to to UNK in UNK UNK\n",
      "us UNK UNK to UNK UNK UNK UNK UNK\n",
      "oil prices prices prices to to\n",
      "bush president president UNK\n",
      "mexico to to UNK UNK UNK in\n",
      "a UNK UNK UNK UNK for\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "house to UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "u.s. stocks fall to to in\n",
      "stars 's UNK UNK UNK UNK\n",
      "UNK UNK UNK in\n",
      "raiders UNK UNK to to\n",
      "taiwan central central central central\n",
      "british wins UNK UNK\n",
      "china 's his his\n",
      "UNK UNK UNK UNK\n",
      "u.s. stocks rise as as rise rise rise rise\n",
      "UNK UNK the UNK\n",
      "stocks 's to to UNK UNK\n",
      "tyson 's UNK\n",
      "the 's to ## ## in\n",
      "new 's new UNK new new\n",
      "in and UNK UNK UNK UNK UNK\n",
      "the UNK is UNK UNK a a\n",
      "on UNK UNK to UNK\n",
      "UNK wins wins de de\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "rangers beat rangers #\n",
      "UNK UNK to the\n",
      "UNK UNK UNK UNK\n",
      "johnson johnson johnson johnson UNK for\n",
      "giants brown UNK for\n",
      "internet 's up UNK\n",
      "for UNK 's UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "new UNK UNK UNK UNK UNK in in UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "u.s. beats UNK in in in in in in\n",
      "man s s UNK s to to to to to UNK\n",
      "bush s UNK to to to UNK UNK UNK\n",
      "UNK UNK UNK a a on in\n",
      "to 's 's and and and\n",
      "UNK UNK UNK to UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "australian UNK UNK UNK\n",
      "new UNK of UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK 's to to s the the the\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK the the\n",
      "more of on UNK of of of\n",
      "u.s. UNK UNK to to to\n",
      "china to to to to to\n",
      "a a a a a a a the\n",
      "a UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "raiders is for to for\n",
      "jones 's to to in in\n",
      "liverpool 's to to to to to\n",
      "court says says says to to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "texas UNK UNK in UNK in in\n",
      "for for UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to to UNK\n",
      "australian grand to grand grand\n",
      "stock UNK UNK UNK UNK UNK UNK\n",
      "former UNK and UNK UNK UNK\n",
      "UNK UNK to to UNK\n",
      "UNK UNK UNK the UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "the UNK UNK UNK UNK\n",
      "bruins UNK trade UNK\n",
      "in UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "for UNK a UNK a\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "a a for UNK UNK\n",
      "the the of the the the\n",
      "UNK to to to UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "jones sets up world world world world world\n",
      "UNK UNK UNK to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "baseball 's baseball baseball\n",
      "a UNK and UNK to to to in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a UNK of the of UNK\n",
      "UNK UNK UNK for in for\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "mexico mexico mexico mexico mexico mexico mexico mexico mexico mexico\n",
      "new york UNK UNK new UNK UNK\n",
      "red wings UNK UNK UNK\n",
      "the UNK UNK UNK UNK\n",
      "nasa to to to for to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "giants UNK to to to\n",
      "los the of of of of\n",
      "UNK to to UNK UNK\n",
      "new UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "## to for\n",
      "UNK 's in in #-#\n",
      "michael 's is is\n",
      "the UNK is the\n",
      "in UNK to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK 's UNK UNK\n",
      "mexican and UNK in in\n",
      "UNK UNK UNK to for\n",
      "UNK # for #\n",
      "in UNK of of UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "stars UNK UNK to\n",
      "<unk> UNK UNK UNK for\n",
      "devils and to ryder ryder cup ryder\n",
      "UNK 's for in UNK\n",
      "UNK your UNK UNK UNK\n",
      "a the UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "the the of the the the the\n",
      "wheat futures prices close on on futures\n",
      "UNK UNK UNK UNK UNK\n",
      "the 's UNK UNK\n",
      "the UNK UNK a the\n",
      "kings UNK to UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "lakers beat n't to #-#\n",
      "<unk> <unk> <unk> UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK to UNK UNK\n",
      "UNK UNK to to to\n",
      "no. UNK ### ###\n",
      "michael says says to to\n",
      "UNK UNK UNK UNK UNK\n",
      "baseball 's to be for\n",
      "UNK 's to to to to at\n",
      "for UNK for to in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "the 's for\n",
      "UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "former UNK s UNK to to to to to\n",
      "UNK UNK giants for giants\n",
      "the 's UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "of of of UNK UNK UNK\n",
      "to UNK UNK UNK\n",
      "johnson UNK UNK to to to\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK to to UNK UNK to\n",
      "to to UNK UNK\n",
      "us UNK to to to UNK\n",
      "in 's to to in a\n",
      "celtics ## celtics celtics\n",
      "'s to UNK\n",
      "the 's UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to to to to\n",
      "a UNK for UNK\n",
      "jordan 's UNK UNK\n",
      "man UNK to to to UNK UNK\n",
      "mets and n't to to to to in\n",
      "gore of in\n",
      "UNK 's UNK to UNK to\n",
      "UNK 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "angels is to to\n",
      "yankees UNK UNK to #-# to\n",
      "bush 's on on on on\n",
      "UNK UNK UNK UNK UNK\n",
      "a the UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "a of for for for in\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK for for\n",
      "dodgers dodgers dodgers dodgers dodgers\n",
      "UNK 's to to to\n",
      "UNK UNK UNK on UNK UNK\n",
      "u.s. sales sales in\n",
      "UNK UNK UNK UNK UNK\n",
      "tyson 's for to\n",
      "dodgers 's to to to to\n",
      "UNK gets gets to\n",
      "china UNK UNK to to in\n",
      "UNK UNK UNK UNK UNK\n",
      "bank bank bank bank to to\n",
      "us says says to to to to to to\n",
      "stars 's in in\n",
      "some are end on on on on\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "us court on on on on\n",
      "china 's UNK to to to to UNK UNK\n",
      "no. # UNK to no. in\n",
      "UNK 's to UNK\n",
      "time 's for for\n",
      "UNK 's UNK UNK for for\n",
      "rangers # to #-# #-#\n",
      "UNK UNK UNK UNK in in UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "colombia s bank #.# #.# percent percent of of\n",
      "the UNK UNK for for for\n",
      "mexico to UNK UNK UNK of\n",
      "<unk> UNK to to to\n",
      "a 's UNK UNK of of of of of\n",
      "UNK to to UNK UNK\n",
      "jets jets to to to\n",
      "UNK UNK to be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK to UNK UNK\n",
      "no. ## # ## in in\n",
      "the UNK a the the the the\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "super 's for super super\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK of UNK the\n",
      "UNK UNK to UNK to to\n",
      "house UNK UNK UNK UNK\n",
      "south UNK in in in\n",
      "#### to to to\n",
      "a UNK UNK ## UNK\n",
      "a of of the\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK is the\n",
      "no. sets to to to in in in\n",
      "a film the the film film film\n",
      "in 's 's to to to to to to\n",
      "<unk> <unk> of to to UNK UNK UNK <unk>\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK his in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stars 's UNK to to UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "bruins UNK UNK to\n",
      "jets 's to to to to\n",
      "UNK UNK texas texas texas UNK\n",
      "says says he he he to on\n",
      "tyson 's n't 's to 's\n",
      "clinton to to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK 's UNK UNK to at at\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "dodgers dodgers dodgers dodgers dodgers\n",
      "u.s. UNK UNK to to\n",
      "venus williams UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "in UNK UNK UNK for for UNK UNK\n",
      "<unk> UNK for in\n",
      "UNK UNK up UNK\n",
      "a in UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "rangers UNK UNK UNK\n",
      "a 's are the the\n",
      "the is 's in in in\n",
      "UNK UNK UNK UNK in\n",
      "israel UNK UNK UNK in\n",
      "internet internet internet internet internet\n",
      "for 's to to to to\n",
      "celtics 's a UNK UNK\n",
      "jets of in in\n",
      "a UNK UNK UNK UNK UNK UNK the the\n",
      "for UNK UNK UNK UNK UNK UNK\n",
      "stocks stocks rise as on ; ; ; stocks\n",
      "stocks stocks up on on of\n",
      "baseball 's for for\n",
      "UNK president president UNK UNK\n",
      "the UNK UNK for for for UNK\n",
      "a a on to to to to\n",
      "UNK UNK UNK UNK in in\n",
      "texas UNK in in in in\n",
      "UNK UNK UNK UNK in in in\n",
      "bush 's UNK for for\n",
      "UNK UNK to UNK\n",
      "in UNK says in UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "woods woods UNK woods at\n",
      "UNK UNK UNK UNK for for for\n",
      "clinton clinton clinton to clinton\n",
      "a of the the\n",
      "UNK UNK UNK UNK UNK\n",
      "in UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "hong to UNK for\n",
      "the UNK UNK the UNK\n",
      "new york UNK UNK new in in\n",
      "some UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK to to UNK UNK\n",
      "angels beat to #\n",
      "UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "stars makes out out for in\n",
      "a a a the\n",
      "in UNK of in in in in in\n",
      "<unk> <unk> UNK UNK UNK\n",
      "UNK UNK to to\n",
      "texas UNK UNK UNK UNK UNK\n",
      "at UNK UNK UNK UNK UNK UNK\n",
      "angels is to from the\n",
      "to to to to to\n",
      "UNK 's UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK to on on UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "cowboys UNK for for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> <unk> <unk> <unk> <unk>\n",
      "UNK UNK UNK UNK UNK\n",
      "wall stock market market\n",
      "the UNK for the\n",
      "to UNK to to of\n",
      "clinton to UNK UNK UNK\n",
      "jets jets UNK to to\n",
      "the the the the the the the the the\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "bush bush bush bush bush bush bush bush\n",
      "in UNK UNK UNK UNK UNK of\n",
      "michael s to to to to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "judge UNK UNK UNK UNK UNK\n",
      "UNK UNK to to in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "a to UNK UNK UNK a a\n",
      "UNK UNK UNK to to\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "south korean markets in for\n",
      "cubs UNK to to for\n",
      "stocks fall to UNK\n",
      "this 's to UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK UNK\n",
      "<unk> UNK UNK UNK UNK\n",
      "judge UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK of of of\n",
      "in UNK UNK UNK UNK UNK in UNK\n",
      "UNK UNK davis davis davis\n",
      "UNK UNK a of the in in\n",
      "mariners UNK in in\n",
      "UNK UNK UNK to UNK\n",
      "china 's a of the 's\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "man man s man man man UNK in in in ; ;\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "no. ## ## ## ##\n",
      "UNK UNK to UNK UNK UNK\n",
      "a 's UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stocks stocks stock UNK UNK\n",
      "UNK president president president president\n",
      "UNK UNK UNK UNK\n",
      "bond 's in for for\n",
      "UNK sign to to\n",
      "UNK UNK UNK to\n",
      "two of in in in in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "stock UNK at at\n",
      "UNK to to to at at of\n",
      "brown brown brown to\n",
      "the UNK for for\n",
      "a UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK in\n",
      "UNK 's UNK UNK UNK UNK\n",
      "spurs UNK UNK to with\n",
      "UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "red red signs to UNK UNK\n",
      "clinton 's to to\n",
      "UNK of of UNK of of of\n",
      "the UNK UNK UNK UNK UNK the\n",
      "the the UNK to\n",
      "ucla 's to to a to\n",
      "UNK wins UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "stocks 's in UNK\n",
      "UNK UNK for at\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK\n",
      "after s to UNK to\n",
      "UNK UNK women women UNK\n",
      "a UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "davis UNK UNK UNK\n",
      "clinton UNK UNK to to to to to\n",
      "in UNK UNK for UNK for UNK\n",
      "UNK UNK of of UNK UNK\n",
      "ucla UNK to to\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "the UNK the UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK ## UNK ## UNK UNK\n",
      "<unk> UNK a UNK\n",
      "the UNK on on UNK\n",
      "the UNK on on on on on\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "australian 's 's to to\n",
      "UNK UNK UNK UNK UNK on on in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "pct 's UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK to UNK UNK UNK\n",
      "in the for the the\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "jordan jordan UNK jordan\n",
      "UNK 's his for\n",
      "home UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "shanghai is is\n",
      "UNK UNK UNK UNK\n",
      "the 's of the UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK to UNK\n",
      "bush bush bush bush bush bush bush bush\n",
      "germany and UNK for UNK world\n",
      "celtics celtics celtics a UNK\n",
      "john UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK in\n",
      "ford 's on on to on\n",
      "new UNK UNK UNK in in in\n",
      "the 's news UNK\n",
      "UNK UNK to to to\n",
      "UNK 's of UNK UNK UNK UNK\n",
      "air to air UNK air\n",
      "woods woods UNK woods woods woods\n",
      "clemens clemens to UNK UNK\n",
      "the 's UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "former UNK UNK to to UNK\n",
      "the 's 's the the the the the the the the\n",
      "broncos UNK gets to to\n",
      "UNK UNK UNK UNK\n",
      "china 's UNK UNK\n",
      "a UNK UNK UNK UNK\n",
      "gop 's UNK for for\n",
      "a UNK the UNK\n",
      "tiger says to to\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "for UNK and UNK UNK a the\n",
      "UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "stars UNK UNK to to to to\n",
      "dodgers ## to #\n",
      "saudi says to to to to\n",
      "UNK UNK UNK UNK\n",
      "for to to to to to to to to\n",
      "UNK UNK UNK UNK UNK UNK UNK to UNK UNK\n",
      "german 's to for\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "a of of UNK UNK UNK UNK UNK\n",
      "the UNK the the UNK\n",
      "a UNK of of in in\n",
      "<unk> UNK in\n",
      "a 's UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "a UNK UNK to to\n",
      "clinton clinton UNK UNK UNK\n",
      "UNK UNK UNK to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "wheat futures futures prices\n",
      "UNK UNK to UNK UNK UNK\n",
      "two say UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "<unk> UNK UNK UNK UNK UNK\n",
      "a UNK UNK UNK\n",
      "yankees is in to\n",
      "ford in UNK\n",
      "UNK says says he he cup cup\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "braves UNK to to #-#\n",
      "kings kings UNK UNK UNK\n",
      "bruins 's for for\n",
      "rangers rangers rangers rangers #-# rangers rangers in\n",
      "stocks UNK UNK to UNK\n",
      "moderate 's to to\n",
      "UNK 's UNK UNK the UNK UNK\n",
      "stars UNK UNK UNK to to in in\n",
      "UNK UNK UNK UNK UNK\n",
      "george says says says UNK\n",
      "stock 's UNK UNK\n",
      "the cox news service spot news budget for thursday july ##\n",
      "the cox news service spot news budget for thursday june ##\n",
      "treasury prices rise to to dollar dollar\n",
      "china 's UNK UNK UNK\n",
      "the cox news service spot news budget for thursday june ##\n",
      "in UNK UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "the your a for UNK\n",
      "u.s. of in in in in UNK in\n",
      "us military military military UNK UNK\n",
      "the 's 's UNK UNK\n",
      "stocks is to UNK UNK\n",
      "jordan says for for\n",
      "UNK 's UNK UNK\n",
      "celtics 's for UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "to of of of in in in\n",
      "'s UNK UNK UNK\n",
      "UNK 's UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "in s UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK 's UNK for at\n",
      "a UNK for a UNK UNK\n",
      "angels 's to to\n",
      "jones jones jones 's the the\n",
      "rangers rangers to rangers #-# rangers rangers rangers\n",
      "ucla wins UNK to to\n",
      "british s party party party party\n",
      "u.s. stocks fall as as as ; ;\n",
      "u.s. stocks fall as as rates rates\n",
      "the 's 's to to a a in in in\n",
      "UNK UNK on UNK in\n",
      "u.s. UNK u.s. u.s. to to\n",
      "a UNK to UNK for\n",
      "johnson 's UNK UNK\n",
      "stars stars UNK UNK\n",
      "a UNK UNK UNK UNK UNK UNK\n",
      "a 's of the the the the the\n",
      "south african for for for for\n",
      "stars UNK to in in\n",
      "the UNK to to UNK the the the\n",
      "UNK UNK to to to in in\n",
      "a UNK a UNK to to to to to UNK UNK UNK\n",
      "mets UNK to to to to\n",
      "florida to in $\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "mavericks ## mavericks #\n",
      "the UNK the the the the\n",
      "internet to to for for\n",
      "gordon 's UNK UNK UNK UNK\n",
      "the to the UNK the the\n",
      "agassi agassi agassi in\n",
      "canada to to UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "un of of UNK to in in in\n",
      "UNK UNK UNK UNK\n",
      "in UNK UNK in UNK UNK\n",
      "obama UNK UNK in obama\n",
      "a the the UNK UNK UNK\n",
      "UNK UNK UNK the UNK UNK\n",
      "of 's 's in in in\n",
      "UNK 's UNK UNK UNK UNK\n",
      "UNK UNK UNK in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when 's 's UNK UNK\n",
      "a UNK of UNK\n",
      "more UNK aids aids to to in in\n",
      "a UNK a the UNK UNK\n",
      "UNK 's UNK UNK UNK UNK UNK UNK UNK\n",
      "no. ## ## ## ## ##\n",
      "iraq 's in UNK UNK UNK in\n",
      "UNK UNK <unk> UNK dies dies dies\n",
      "more of to to the the\n",
      "china to first first first shanghai in in\n",
      "hong 's to on on on\n",
      "china china to to to to to\n",
      "'s 's resigns resigns resigns resigns\n",
      "australian dollar down lower\n",
      "australian UNK UNK UNK in in\n",
      "australia to to to for for\n",
      "australian dollar UNK 's\n",
      "brazil to launch satellite satellite\n",
      "stocks markets markets for\n",
      "chinext index opens higher\n",
      "dollar at at ## ## yen in\n",
      "stocks close in mexico mexico brazil\n",
      "chinext index opens lower lower\n",
      "china to to to ties ties ties\n",
      "dollar at upper ## yen in tokyo\n",
      "u.s. stocks fall lower\n",
      "stocks close lower in mexico brazil\n",
      "tokyo stocks open higher higher\n",
      "chinese chinese chinese dies dies dies\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "beijing of of in in in\n",
      "new zealand stocks close lower\n",
      "UNK UNK UNK UNK UNK UNK to to\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "dollar at upper upper ## yen in tokyo\n",
      "dollar at upper ## yen in tokyo\n",
      "UNK of UNK UNK in in in\n",
      "dollar trades in yen yen yen\n",
      "s. korean stocks close\n",
      "former <unk> former <unk> <unk> <unk> at ##\n",
      "germany beats #-# #-# in\n",
      "dollar at upper ## yen in tokyo\n",
      "chinese shares down down on\n",
      "dollar at lower ## yen in tokyo\n",
      "british UNK UNK in in\n",
      "china to to to to to\n",
      "more UNK in in in shanghai\n",
      "UNK UNK in in in in\n",
      "chinese police UNK UNK UNK UNK\n",
      "UNK UNK to to\n",
      "thai s UNK UNK UNK UNK UNK\n",
      "german stock indexes exchange\n",
      "world world to UNK\n",
      "dollar falls at lower ### yen in tokyo\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "china to to to to to to to\n",
      "tokyo 's down down\n",
      "# people in in in\n",
      "german stocks exchange up\n",
      "former prime minister minister minister\n",
      "uganda 's for opens\n",
      "german stock indexes rise rates\n",
      "china to to in in china\n",
      "UNK UNK on on in in\n",
      "UNK wins wins stage italy\n",
      "shanghai UNK UNK UNK\n",
      "germany wins men 's UNK gold gold gold\n",
      "dollar wins UNK in in in in\n",
      "<unk> named new as coach coach\n",
      "hong kong stocks close higher\n",
      "spain to to to\n",
      "dollar at lower ## yen in tokyo\n",
      "tokyo stocks open higher\n",
      "UNK UNK leaves leaves\n",
      "UNK UNK UNK to to to\n",
      "UNK to in in in\n",
      "canada 's new ### record record in\n",
      "stocks close higher in mexico brazil\n",
      "results wins first UNK\n",
      "new UNK to to UNK\n",
      "UNK UNK UNK the\n",
      "u.s. stocks open higher\n",
      "xinhua news news news\n",
      "wall street trades mixed on\n",
      "stocks close higher in mexico argentina\n",
      "dollar rises at in yen in in\n",
      "beijing olympic olympic olympic olympic olympic\n",
      "nikkei closes #.## pct higher\n",
      "dollar at at lower ## yen in in\n",
      "s. korean stocks close\n",
      "dollar falls to lower ## yen in tokyo\n",
      "dollar at lower lower yen in tokyo\n",
      "u.s. stocks rise on oil oil\n",
      "hk opens opens in in\n",
      "german stocks close lower\n",
      "new zealand rates in new\n",
      "china UNK first UNK in china\n",
      "german stocks open lower\n",
      "dollar falls to upper ## yen in tokyo\n",
      "german stocks open mixed\n",
      "german stocks open higher\n",
      "china to to to to to to\n",
      "china to to UNK to to\n",
      "malaysia to to to to to\n",
      "UNK UNK in in in\n",
      "seminar on on opens opens in\n",
      "wall street stocks as on stocks\n",
      "thailand thailand in in\n",
      "prices prices prices in in\n",
      "open open open open\n",
      "strong quake hits southern\n",
      "australia to to to to\n",
      "chinese chinese chinese visits in\n",
      "chinese UNK UNK UNK UNK UNK UNK\n",
      "australia 's up up to in\n",
      "australian dollar closes lower\n",
      "<unk> on opens opens opens in\n",
      "china sign sign sign cooperation cooperation\n",
      "beijing to to on\n",
      "u.s. stocks fall lower on on news\n",
      "court court UNK UNK UNK UNK UNK\n",
      "internet launches new economic\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "jordan UNK UNK UNK UNK UNK\n",
      "u.s. stocks trade lower\n",
      "u.s. stocks open lower\n",
      "jakarta stocks close lower\n",
      "china UNK UNK UNK UNK\n",
      "hong kong shares prices #.## #.## #.##\n",
      "chinese UNK UNK UNK UNK UNK\n",
      "dollar trades in mid-## yen in tokyo\n",
      "bulgarian stock market ends higher\n",
      "bulgarian stock market ends lower\n",
      "bulgarian stock market ends higher\n",
      "dollar trades in lower ### yen in tokyo\n",
      "china province province china to\n",
      "school UNK UNK in in in\n",
      "nato nato nato nato nato nato nato nato nato\n",
      "drug denies UNK in in\n",
      "two us soldiers killed in in\n",
      "UNK UNK UNK UNK for UNK UNK\n",
      "nikkei index rises rises rises rises\n",
      "dollar trades upper ## yen in tokyo\n",
      "dollar at upper upper ## yen in tokyo\n",
      "new zealand finish lower lower\n",
      "UNK cup world cup cup\n",
      "china 's first opens in in china\n",
      "wall street stocks higher\n",
      "chinese premier meets meets meets\n",
      "UNK named named as as of of\n",
      "stock stock market markets lower\n",
      "dollar at at ## yen in tokyo\n",
      "german stocks open higher\n",
      "dollar trades in upper ## yen in tokyo\n",
      "dollar at lower ## yen in tokyo\n",
      "world to host host in in in\n",
      "chinext index opens higher higher\n",
      "china russia to to ties ties ties ties ties\n",
      "dollar trades in ## yen in tokyo\n",
      "dollar trades in upper ## yen in in\n",
      "dollar at lower lower yen in tokyo\n",
      "spain UNK UNK for for\n",
      "crude prices prices as u.s. u.s. u.s.\n",
      "hang seng china enterprises index up\n",
      "india india india india india india india india\n",
      "for and in in in in to to\n",
      "australian stock market drops\n",
      "china 's first UNK industry\n",
      "beijing opens opens opens opens\n",
      "internet to on on on\n",
      "international festival festival festival festival festival\n",
      "australian stock market closes\n",
      "malaysia signs sign sign sign UNK\n",
      "kuala lumpur stocks close lower\n",
      "new of new\n",
      "internet to to UNK UNK\n",
      "china UNK at in in\n",
      "hong kong hong kong kong hk\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "dollar at upper upper ## yen in tokyo\n",
      "dollar trades in yen yen in in in\n",
      "nikkei closes #.## pct higher\n",
      "dollar trades in upper ## yen in\n",
      "dollar trades in upper ## yen in in\n",
      "south africa first first for in UNK\n",
      "dollar falls to ## yen in tokyo\n",
      "dollar trades in lower ## yen in\n",
      "s. korean stocks close\n",
      "shanghai stocks close slightly\n",
      "key of UNK UNK\n",
      "u.s. stocks open mixed\n",
      "u.s. stocks open lower\n",
      "u.s. stocks open lower on\n",
      "oil prices rise above ## dollars\n",
      "chinese province to in in\n",
      "chinese chinese in in at at at at\n",
      "UNK president president to to to\n",
      "iraq president president in to\n",
      "australian stock market rises\n",
      "shanghai stock exchange down down\n",
      "UNK UNK UNK #.# #.# in #.#\n",
      "u.s. president arrives in in\n",
      "UNK UNK in in\n",
      "dollar trades in upper ## yen in tokyo\n",
      "mexico mexico mexico mexico mexico UNK\n",
      "dollar rises in upper ## yen in tokyo\n",
      "the of in of of in\n",
      "china to host opens opens in\n",
      "south korea new in south\n",
      "world UNK in UNK UNK\n",
      "taiwan shares close #.##\n",
      "UNK beats UNK #-# in friendly friendly\n",
      "new zealand new new new new in in\n",
      "moderate prices up in in\n",
      "germany beats #-# #-# in\n",
      "brazil to sign UNK UNK\n",
      "u.s. stocks trade higher\n",
      "dollar rises to ### yen yen in\n",
      "china china UNK UNK\n",
      "chinese 's festival opens opens in\n",
      "italy wins men men gold gold gold gold\n",
      "british stocks trade higher at midday\n",
      "oil prices fall below ## dollars\n",
      "s. african african in in in\n",
      "u.s. stocks open higher\n",
      "german stocks open higher\n",
      "UNK UNK opens opens opens in in\n",
      "malaysia tin market closes UNK\n",
      "wall street stocks on on earnings\n",
      "s. africa sign sign sign agreement agreement\n",
      "coach fires coach coach\n",
      "china 's new UNK UNK in\n",
      "taiwan shares close up up up\n",
      "china 's market market\n",
      "two killed crashes crashes in in ; ;\n",
      "dollar falls in lower ### yen in tokyo\n",
      "china china to to to ties ties ties\n",
      "dollar trades in upper yen yen in tokyo\n",
      "stocks close flat in central america\n",
      "gore 's UNK for for UNK\n",
      "chinese president meets in in\n",
      "UNK UNK of in in\n",
      "UNK to to in in in\n",
      "beijing to host host in\n",
      "china to to to to to UNK\n",
      "indian indian indian UNK UNK UNK UNK UNK\n",
      "world world #### ####\n",
      "india 's UNK UNK UNK\n",
      "dollar at at upper yen yen in tokyo\n",
      "shanghai UNK in in in in\n",
      "china to to UNK to UNK\n",
      "taiwan shares close down\n",
      "dollar trades in yen yen in tokyo\n",
      "dollar falls in lower ## yen in tokyo\n",
      "tokyo stocks end dollar higher against yen yen\n",
      "u.s. stocks trade flat on on\n",
      "dollar at upper upper ## yen in tokyo\n",
      "philippine stocks close lower\n",
      "jakarta stocks close lower\n",
      "key to for election in\n",
      "stocks close lower in mexico brazil\n",
      "dollar trades at ## yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "german stocks close higher\n",
      "UNK wins wins wins of of\n",
      "dollar at upper upper yen yen in tokyo\n",
      "london stock market opens higher\n",
      "china 's UNK to to to UNK\n",
      "UNK to to to to\n",
      "president president arrives in\n",
      "u.s. stocks fall on on of\n",
      "dollar at upper upper yen yen in tokyo\n",
      "UNK UNK to to to\n",
      "stocks close higher in mexico brazil\n",
      "dollar falls to ### yen yen in\n",
      "dollar at upper upper ## yen in tokyo\n",
      "shanghai to host to to\n",
      "china 's market market\n",
      "beijing 's opens on\n",
      "china 's market market\n",
      "# of in in in in in\n",
      "international international opens opens opens opens\n",
      "fire fire in in in\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar at upper upper ### yen in tokyo\n",
      "german stocks close lower\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beats beats china #-# in friendly friendly\n",
      "stars UNK UNK to for\n",
      "china 's UNK UNK UNK UNK\n",
      "dollar rises to upper ## yen in tokyo\n",
      "chinese shares close #.## percent higher\n",
      "german stock exchange ends slightly\n",
      "australian dollar closes lower\n",
      "australian dollar closes lower\n",
      "australian dollar closes higher\n",
      "bulgarian stock market lower lower\n",
      "dollar trades in upper ## yen in in\n",
      "UNK UNK to UNK UNK\n",
      "australian dollar at UNK in\n",
      "russia russia to to to\n",
      "turkey turkey urges on on war\n",
      "china 's UNK UNK in in\n",
      "german stocks open lower\n",
      "german stocks open mixed\n",
      "dollar at at yen yen in tokyo\n",
      "dollar at at ### yen yen in\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar rises at upper ### yen in tokyo\n",
      "dollar at at upper yen yen in tokyo\n",
      "dollar at at lower ### yen in tokyo\n",
      "dollar falls to lower ### yen in tokyo\n",
      "asian asian asian opens open open\n",
      "south african in in in\n",
      "german stocks open lower\n",
      "## killed in in in in\n",
      "UNK wins wins wins\n",
      "stocks close higher in argentina argentina argentina\n",
      "german stocks open higher\n",
      "german stocks open higher\n",
      "british UNK of UNK UNK UNK UNK UNK UNK\n",
      "china to host international in in\n",
      "china to to to to to to on\n",
      "u.s. stocks fall lower on prices\n",
      "german stocks open lower\n",
      "greek stocks close higher\n",
      "german stocks open lower\n",
      "australia to to to to to\n",
      "philippine arrested arrested UNK UNK UNK UNK\n",
      "uganda to to to in\n",
      "wall street stocks on on economic data data\n",
      "australia to to to to UNK\n",
      "london shares prices in at in\n",
      "malaysia stock market closes higher\n",
      "wall street stocks rise\n",
      "UNK UNK UNK to\n",
      "german stocks open lower\n",
      "german stock indexes end\n",
      "german stock indexes end higher\n",
      "german stock indexes end up\n",
      "british stocks trade lower at midday\n",
      "shanghai to new new new\n",
      "dollar dollar to yen yen in tokyo\n",
      "dollar at in lower yen yen in\n",
      "UNK 's opens opens in in\n",
      "shanghai opens opens opens in\n",
      "greece turkey sign sign UNK\n",
      "new zealand zealand UNK UNK\n",
      "judge fire UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "rubber futures close higher on higher volumes volumes\n",
      "russian president minister sign for\n",
      "french prime minister minister to in\n",
      "german wins germany in germany\n",
      "three shakes in in in\n",
      "kings kings kings kings\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "new zealand stocks close #.## percent\n",
      "woods wins to at at title\n",
      "man man man man in UNK\n",
      "rubber futures close higher on lower volumes volumes\n",
      "the and and and and and UNK\n",
      "french fires coach coach\n",
      "stocks stocks in early trading\n",
      "thailand financial markets closed for\n",
      "police police police police police UNK UNK on UNK UNK UNK\n",
      "oil prices fall in asian\n",
      "house to to UNK\n",
      "s. korean stocks in\n",
      "brown 's to on\n",
      "arsenal signs UNK in\n",
      "UNK wins women 's women women\n",
      "rubber futures close lower on bigger volumes\n",
      "canada wins women 's in\n",
      "south korean shares close #.## percent higher\n",
      "tyson 's on on\n",
      "former UNK dies dies dies dies\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "australia wins olympic 's team gold\n",
      "asian stock markets close higher higher\n",
      "woods woods woods woods woods woods\n",
      "UNK signs signs signs UNK\n",
      "UNK UNK UNK UNK\n",
      "red sign sign contract deal\n",
      "UNK signs UNK UNK\n",
      "india union UNK with to with with with with with\n",
      "schumacher wins wins grand prix\n",
      "new of of of cabinet\n",
      "podium games men 's games\n",
      "podium women women women women women women\n",
      "UNK 's UNK UNK in in in in\n",
      "australia beats ## in\n",
      "UNK wins wins #-# in\n",
      "turkey 's UNK UNK UNK UNK\n",
      "former former dies dies dies\n",
      "china 's closed closed for\n",
      "rubber futures close higher on higher volumes volumes\n",
      "key of UNK\n",
      "red wings to to UNK\n",
      "UNK prime minister minister in\n",
      "french shares #.## #.## #.##\n",
      "australia australia UNK UNK in in\n",
      "new zealand stocks close higher\n",
      "the of the of of\n",
      "england to play for in in\n",
      "indonesia financial markets closed for\n",
      "UNK UNK UNK UNK of of of\n",
      "south financial markets closed for\n",
      "italy italy in in in in in\n",
      "south south in south south\n",
      "asian asian markets mostly mostly lower\n",
      "UNK wins world 's cup cup cup cup\n",
      "beijing games to games olympic games games\n",
      "the UNK UNK the UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "indonesia financial markets closed\n",
      "hong kong markets markets for for for holiday\n",
      "to to to to to to in in in\n",
      "italy wins wins grand prix\n",
      "<unk> ## ## ##\n",
      "eu court to to to UNK\n",
      "indonesia financial markets closed\n",
      "french fires coach coach as\n",
      "african african for in in african\n",
      "results of in in\n",
      "UNK to to to to to at\n",
      "UNK wins UNK UNK\n",
      "UNK UNK UNK UNK UNK\n",
      "former pleads pleads pleads guilty guilty guilty\n",
      "for 's UNK UNK UNK to to to the UNK UNK UNK\n",
      "UNK wins australian australian australian australian\n",
      "to to of of of of of\n",
      "UNK UNK UNK UNK in in in\n",
      "devils beats to #-# UNK UNK\n",
      "cowboys to to UNK\n",
      "world world world world world world\n",
      "at of in in in in in\n",
      "the 's of s s s\n",
      "tokyo stocks end higher\n",
      "iran president president UNK\n",
      "tokyo stocks higher dollar higher against yen\n",
      "former of of dies dies dies dies dies dies\n",
      "in UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "former olympic former dies dies dies ## ##\n",
      "UNK s for for for for for\n",
      "ac milan says to to to to\n",
      "a UNK UNK UNK UNK UNK UNK UNK\n",
      "us UNK UNK to to UNK UNK\n",
      "tyson says says to in in in in\n",
      "us us sales #.# #.# in in in\n",
      "with 's to on on on on on UNK\n",
      "angels # to in in\n",
      "to UNK UNK UNK\n",
      "tokyo stocks open higher dollar\n",
      "jordan 's return to\n",
      "some on on on on on\n",
      "south korea to to to to iraq iraq iraq iraq\n",
      "u.s. u.s. in in in in\n",
      "former pleads pleads pleads guilty in in\n",
      "UNK 's UNK UNK\n",
      "colombia beats #-# #-# in friendly\n",
      "tokyo stocks open higher dollar against yen\n",
      "court UNK UNK court court UNK UNK UNK UNK UNK\n",
      "<unk> beats # to in in in\n",
      "of of league league league of\n",
      "tokyo stocks rise dollar dollar against yen yen\n",
      "UNK fires coach coach coach coach\n",
      "u.s. iraq iraq in UNK UNK in in\n",
      "olympic wins to to at at\n",
      "UNK president president president UNK UNK UNK\n",
      "sorenstam sorenstam to for in\n",
      "germany beats draw #-# #-# world\n",
      "time UNK UNK for for UNK\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "woman woman UNK UNK baby baby baby baby baby baby\n",
      "raiders UNK to for for for\n",
      "u.s. UNK UNK to to to to to to\n",
      "former says says wife wife wife after after after in\n",
      "tiger woods tiger to UNK\n",
      "wall street stocks lower\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK # to in in in ## ##\n",
      "to to to to UNK to to UNK UNK\n",
      "stars UNK UNK UNK UNK\n",
      "in 's in in in\n",
      "tokyo stocks open lower\n",
      "french king UNK UNK for for UNK UNK\n",
      "UNK of UNK UNK UNK in in in\n",
      "gore 's UNK to UNK UNK\n",
      "hong kong close higher\n",
      "shanghai on on on on on on on\n",
      "UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "woods wins UNK at\n",
      "ucla state to ## ##\n",
      "##ers 's on of\n",
      "moderate quake hits taiwan\n",
      "interest rates rates in in\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "tokyo stocks close lower dollar yen\n",
      "former UNK UNK UNK to to to\n",
      "woman of of UNK UNK school school school\n",
      "jordan jordan UNK UNK\n",
      "australian UNK UNK UNK UNK UNK\n",
      "a UNK to UNK\n",
      "team UNK UNK UNK to UNK\n",
      "broncos sign UNK UNK to to to\n",
      "UNK open open french open open\n",
      "the 's to to for\n",
      "UNK 's for for\n",
      "UNK 's UNK UNK UNK\n",
      "UNK UNK wins UNK race race race race race\n",
      "mickelson 's for\n",
      "to to to to to to\n",
      "UNK wins wins cup\n",
      "UNK UNK UNK UNK open open\n",
      "UNK UNK of UNK UNK UNK UNK\n",
      "mickelson # to to\n",
      "oil prices fall below ##\n",
      "turkey says UNK UNK UNK UNK UNK UNK UNK\n",
      "man 's to to UNK UNK UNK UNK\n",
      "UNK to to for\n",
      "UNK UNK UNK for for\n",
      "obama obama obama UNK obama to to\n",
      "man man in UNK in UNK UNK\n",
      "world cup cup cup cup\n",
      "to to to for for for\n",
      "UNK wins wins wins\n",
      "UNK UNK UNK UNK to UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK\n",
      "us UNK service on on on on\n",
      "stocks mixed in early trading\n",
      "for UNK UNK UNK for for\n",
      "first to to first to to to in\n",
      "california UNK UNK to UNK\n",
      "# of of in in in\n",
      "treasury prices UNK in as in in in\n",
      "treasury prices fall on on on economic\n",
      "UNK UNK to ### #,###\n",
      "stocks stocks higher higher higher\n",
      "england UNK UNK england UNK UNK UNK\n",
      "UNK UNK to to UNK\n",
      "oil prices rise ## ## ##\n",
      "china urges to to to to\n",
      "tropical storm UNK in in off off\n",
      "stocks prices rise in on stocks\n",
      "fire UNK fire in UNK UNK UNK\n",
      "u.s. to to to to in in\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK on in\n",
      "a of and the the\n",
      "world wins wins world cup cup cup cup\n",
      "mccain to to\n",
      "UNK UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK to\n",
      "manchester city to to to to manchester united united in\n",
      "vietnam to to to to to in in\n",
      "new york a a UNK UNK UNK UNK\n",
      "a UNK UNK UNK UNK UNK\n",
      "stocks prices in early trading\n",
      "UNK UNK UNK to to to\n",
      "UNK UNK UNK UNK UNK\n",
      "stars UNK UNK UNK UNK\n",
      "us us UNK UNK UNK in in UNK\n",
      "kings sign sign agent to to contract contract\n",
      "armstrong 's for for\n",
      "UNK UNK UNK to to to to\n",
      "UNK UNK UNK at at\n",
      "former UNK UNK UNK UNK UNK\n",
      "UNK of UNK UNK\n",
      "the the of UNK UNK UNK UNK\n",
      "UNK wins UNK in in\n",
      "UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n",
      "fire fire fire fire fire fire fire\n",
      "# plane crashes plane plane plane\n",
      "israeli police in at UNK UNK\n",
      "german german UNK UNK UNK\n",
      "london share prices higher at midday\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london stocks close lower\n",
      "jones 's for at\n",
      "results wins asian in at at\n",
      "moderate 's UNK to for for for\n",
      "china to to to to tour tour\n",
      "nasa space space space space space space\n",
      "south to to to in in in in in in\n",
      "ireland ## ## ##\n",
      "treasury rates rates in in in\n",
      "red sign sign sign to to\n",
      "UNK UNK awards awards awards awards awards awards\n",
      "baseball UNK to to to to\n",
      "UNK wins UNK of\n",
      "tyson jackson to to to in in\n",
      "dollar up in in\n",
      "a UNK of to UNK UNK UNK\n",
      "to UNK UNK\n",
      "tropical storm UNK in in in\n",
      "australia ## australia australia\n",
      "london s ftse-### index up at points points at\n",
      "russia france UNK UNK UNK UNK UNK UNK\n",
      "UNK UNK UNK UNK UNK UNK\n"
     ]
    }
   ],
   "source": [
    "#saved_weights = './weight/with_attention_weight_1.hdf5'\n",
    "#model.load_weights(saved_weights)\n",
    "\n",
    "X_test = load_test_data('data/test_article.txt', X_word_to_ix, MAX_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=X_max_len, dtype='int32', padding='post')\n",
    "\n",
    "sequences = []\n",
    "for i in range(0,len(X_test),1000):\n",
    "    predictions = np.argmax(model.predict(X_test[i:i+1000]), axis=2)\n",
    "    for prediction in predictions:\n",
    "        sequence = ' '.join([y_ix_to_word[index] for index in prediction if index > 0])\n",
    "        print(sequence)\n",
    "        sequences.append(sequence)\n",
    "        np.savetxt('test_Attention.txt', sequences, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_test = open('data/test_title.txt', \"r\")\n",
    "y_test = title_test.read().split('\\n')\n",
    "y_test = y_test[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test Title: 7000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.1695928341944434,\n",
       "  'p': 0.25254620181405896,\n",
       "  'r': 0.13989233479899885},\n",
       " 'rouge-2': {'f': 0.056502895152472123,\n",
       "  'p': 0.061305668934240366,\n",
       "  'r': 0.054509863152720293},\n",
       " 'rouge-l': {'f': 0.13872212286250798,\n",
       "  'p': 0.16121771190993878,\n",
       "  'r': 0.13714681898194941}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Length of test Title:',len(y_test), '\\n')\n",
    "#Rouge score\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "rouge_score = rouge.get_scores(sequences, y_test, avg=True)\n",
    "rouge_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity \n",
    "Even though we evaluate our models on ROUGE score, we don't train our neural networks to learn better ROUGE score for the fact that ROUGE score is a complicated nonconvex function. How does our model learn then? In information theory, Perplexity is a measure of how good a model is.\n",
    "\n",
    "Perplexity                     $$ = 2^{{-\\sum _{x}p(x)\\log _{2}p(x)}}$$ \n",
    "            \n",
    "Lower the perplexity, better the model. Justify why our model learns well with our loss function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does our model learn then?\n",
    "Rouge works by comparing matching sub-phrases in the predict summaries against sub-phrases in the ground truth reference summaries. We campare sub-phrases of one word and two words in the Rouge scores, even if they are not perfectly aligned. Rouge scores care more about words instead of sequence, and so the prediction of a model with high Rouge score may not be readable or interpretable. \n",
    "\n",
    "\n",
    "### Justify why our model learns well with our loss function?\n",
    "$$ entropy = {{-\\sum _{x}p(x)\\log _{2}p(x)}}$$ \n",
    "$$ Perplexity = 2^{entropy}$$ \n",
    "From the perplexity function and entropy function given above, we can see that the smaller the entropy, the smaller the perplexity. Smaller entropy implies a better model, and so smaller perplexity implies a better model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "You will now plot the attention weights for a sentence and it's output. If a grid cell is white in the plot, it means that during summary, the word on x-axis corresponds to the word on y-axis. You are provided with a Visualizer class for helping you out. Make sure you install matplotlib using sudo pip3 install matplotlib and also install python3-tk using sudo apt-get install python3-tk\n",
    "\n",
    "source: https://github.com/datalogue/keras-attention/blob/master/visualize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Visualizes attention maps\n",
    "        \"\"\"\n",
    "        \n",
    "    def set_models(self, pred_model, proba_model):\n",
    "        \"\"\"\n",
    "            Sets the models to use\n",
    "            :param pred_model: the prediction model\n",
    "            :param proba_model: the model that outputs the activation maps\n",
    "        \"\"\"\n",
    "        self.pred_model = pred_model\n",
    "        self.proba_model = proba_model\n",
    "\n",
    "    def attention_map(self, text, padded_data_vec, y_idx_to_word):\n",
    "        \"\"\"\n",
    "            Displays the attention weights graph\n",
    "            param: input sentence\n",
    "            param: padded_data_vector for prediction\n",
    "            param: idx2word dictionary for titles\n",
    "        \"\"\"\n",
    "        input_length = len(text.split())\n",
    "        \n",
    "        # get the output sequence\n",
    "        prediction = np.argmax(pred_model.predict(padded_data_vec), axis=2)[0]\n",
    "        text_ = text.split()\n",
    "        valids = [y_idx_to_word[index] for index in prediction if index > 0]\n",
    "        sequence = ' '.join(valids)\n",
    "        predicted_text = sequence.split()\n",
    "        output_length = len(predicted_text)\n",
    "        #get the weights\n",
    "        activation_map = np.squeeze(self.proba_model.predict(padded_data_vec))[\n",
    "            0:output_length, 0:input_length]\n",
    "        \n",
    "        plt.clf()\n",
    "        f = plt.figure(figsize=(8, 8.5))\n",
    "        ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "        # add image\n",
    "        i = ax.imshow(activation_map, interpolation='nearest', cmap='gray')\n",
    "        #i = ax.imshow(np.log(activation_map), interpolation='nearest', cmap='gray')\n",
    "\n",
    "        # add colorbar\n",
    "        cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "        cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "        cbar.ax.set_xlabel('Probability', labelpad=2)\n",
    "\n",
    "        # add labels\n",
    "        ax.set_yticks(range(output_length))\n",
    "        ax.set_yticklabels(predicted_text[:output_length])\n",
    "        \n",
    "        ax.set_xticks(range(input_length))\n",
    "        ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "        \n",
    "        ax.set_xlabel('Input Sequence')\n",
    "        ax.set_ylabel('Output Sequence')\n",
    "\n",
    "        # add grid and legend\n",
    "        ax.grid()\n",
    "        \n",
    "        f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_UniLSTMwithAttention_True(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers, return_probabilities = True):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Creating encoder network\n",
    "    model.add(Embedding(X_vocab_len, hidden_size, input_length=X_max_len, mask_zero=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(RepeatVector(y_max_len))\n",
    "\n",
    "    # Creating decoder network, Attention Decoder\n",
    "    model.add(AttentionDecoder(hidden_size, y_vocab_len))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can initialize Visualizer class as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = Visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizer has two methods.\n",
    "- set_models \n",
    "- attention_map\n",
    "\n",
    "The set_models takes in prediction model and probability model as inputs. In *create_UniLSTMwithAttention*, the model with *return_probabilities = False* which you already used in the training is the prediction model. For initializing probability model, call *create_UniLSTMwithAttention* with *return_probabilities = True* and initialize the weights with weights of prediction model. Now you can call set_models in this manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = model\n",
    "prob_model = create_UniLSTMwithAttention_True(X_vocab_len, X_max_len, y_vocab_len, y_max_len, HIDDEN_DIM, LAYER_NUM, return_probabilities = True)\n",
    "#prob_model.load_weights(saved_weights)\n",
    "idx2word = y_ix_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention_map creates the weights map for you. You need to give a sample sentence, a test_data_vector on which we call call model.predict and your output idx2word dictionary. You can call it as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.set_models(pred_model,prob_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above Visualizer to visualize attention weights for 15 sentences, as instructed in the Analysis section of the accompanying HW document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 GOOD \n",
    "99  \n",
    "I: a huge explosion has rocked pakistan ‘s main northwest city of peshawar .  \n",
    "G: huge explosion rocks paksitan s peshawar  \n",
    "A-: voice changed UNK UNK UNK  \n",
    "A+: explosion explosion in pakistan pakistan pakistan   \n",
    "Analysis: Uni LSTM with Attention model predicts much better than Uni LSTM without Attention, though there are some repetitions in the prediction. The semantic meaning of A+ is clear. This article is not about the market field, and Uni LSTM without Attention model cannot capture any information in the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4089  \n",
    "I: germany ‘s stocks opened mixed on monday at the frankfurt stock exchange .  \n",
    "G: german stocks open mixed  \n",
    "A-: german stocks open mixed  \n",
    "A+: german stocks open mixed  \n",
    "Analysis: Both Uni LSTM with Attention model and Uni LSTM without Attention predict well in the topic of stock market because there is a lot of articles in stock market and in about the same format in both articles and true titles. In this article, both predictions are perfectly well.  \n",
    "\n",
    "4282  \n",
    "I: tokyo stocks closed higher wednesday for the second straight trading day .  \n",
    "G: tokyo stocks end higher  \n",
    "A-:  tokyo stocks close higher  \n",
    "A+:  tokyo stocks close higher  \n",
    "Analysis: Both Uni LSTM with Attention model and Uni LSTM without Attention predict well in the topic of stock market because there is a lot of articles in stock market and in about the same format in both articles and true titles. Both predictions paraphrase from the article, and use ‘close’ instead of ‘end’.  \n",
    "\n",
    "6718  \n",
    "I: germany ‘s stocks opened higher wednesday on the frankfurt stock exchange .  \n",
    "G: german stocks open higher  \n",
    "A-: german stocks open higher  \n",
    "A+: german stocks open higher  \n",
    "Analysis: Both Uni LSTM with Attention model and Uni LSTM without Attention predict well in the topic of stock market because there is a lot of articles in stock market and in about the same format in both articles and true titles. In this article, both predictions are perfectly well, and Uni LSTM with Attention model is much faster and easier.  \n",
    "\n",
    "6719  \n",
    "I: germany ‘s stocks opened higher on monday on the frankfurt stock exchange .  \n",
    "G: german stocks open higher  \n",
    "A-: german stocks open higher  \n",
    "A+: german stocks open higher  \n",
    "Analysis: Both Uni LSTM with Attention model and Uni LSTM without Attention predict well in the topic of stock market because there is a lot of articles in stock market and in about the same format in both articles and true titles. In this article, both predictions are perfectly well, capture all information, including country name (German), trend (higher), and time (open).  \n",
    "\n",
    "### 5 BAD\n",
    "\n",
    "2454  \n",
    "I: shaquille o'neal conceded it felt different wearing a miami heat uniform .  \n",
    "G: shaq bests yao but rockets beat heat ##-## in nba exhibition  \n",
    "A-: UNK ‘s to to to in in in in in  \n",
    "A+: UNK ## ## ##  \n",
    "Analysis: Both models do not capture any information in the prediction titles. Information in the true title is not paraphrased or generalized from the article, which makes prediction hard.  \n",
    "\n",
    "2679  \n",
    "I: france has been chosen to host football 's european championship in #### .  \n",
    "G: france wins right to host football s euro ####  \n",
    "A-: flight padres to to to to world in   \n",
    "A+: france france france france france in in france  \n",
    "Analysis: Prediction of Uni LSTM without Attention Model does not make any sense. Prediction of Uni LSTM with Attention Model only captures the country name ‘france’ and repeated a lot of times. More data in sports are need to train a better model.  \n",
    "\n",
    "5818  \n",
    "I: < unk > < unk >, caterer and former restaurateur, cooks <unk> sicilian food .  \n",
    "G: < unk > sicilian vegetable dish a natural over < unk >   \n",
    "A-: UNK UNK UNK UNK UNK  \n",
    "A+: < unk > < unk > < unk > < unk > < unk > < unk >  \n",
    "\n",
    "\n",
    "6912  \n",
    "I: another beauty battle is moving to las vegas, at least for the time being .  \n",
    "G: miss usa pageant heading to las vegas also home to rival miss america  \n",
    "A-: UNK UNK UNK   \n",
    "A+: to to to to to to  \n",
    "\n",
    "6999  \n",
    "I: one is a banana billionaire who hobnobs with the kennedys and rockefellers .  \n",
    "G: banana baron faces off against chavez friend for ecuadorean presidency  \n",
    "A-: in a of a a the the the the  \n",
    "A+: UNK UNK UNK UNK UNK UNK  \n",
    "\n",
    "### 5 RANDOM\n",
    "\n",
    "102   \n",
    "I: former swiss president ernst brugger has died , it was announced monday .    \n",
    "G: former swiss president ernst \\*<unk\\*> dies at ##  \n",
    "A-: former president president president president dies dies  \n",
    "A+: former president president dies dies  \n",
    "\n",
    "1924\n",
    "I: more than ### us military engineers <unk> to the al-qaeda terror network .  \n",
    "G: us military engineers arrive in philippines hostage island  \n",
    "A-: a ‘s of of to to to of of UNK  \n",
    "A+: us of of UNK UNK of UNK  \n",
    "\n",
    "2008\n",
    "I: fresh heavy rains caused dozens of road accidents in california thursday .    \n",
    "G: california cleans up from deadly storm braces for more rain  \n",
    "A-: broke ‘s to to to in  \n",
    "A+: to to to with  \n",
    "\n",
    "3573  \n",
    "I: for the rangers , it has come down to calculators and historic anomalies .  \n",
    "G: rangers could duck kos with closer  \n",
    "A-: ranger ‘s to for for rangers  \n",
    "A+: next UNK to to to to  \n",
    "\n",
    "5740  \n",
    "I: what do you say about a < unk > who dies ? you pledge to celebrate his life .  \n",
    "G: thousands celebrate the life of a famed crocodile hunter  \n",
    "A-: UNK ‘s making to to to to to to to of  \n",
    "A+: < unk > UNK UNK UNK  \n",
    "\n",
    "\n",
    "*Example sentence summaries.  \n",
    "I is the input, G is the true headline,  \n",
    "A- is predict title with UniLSTM model without Attention,   \n",
    "and A+ is predict title by UniLSTM model with Attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb05469d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb05469438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'a huge explosion has rocked pakistan \\'s main northwest city of peshawar .'\n",
    "test_data_vector = X_test[99:100,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb0394bf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb03942470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfect\n",
    "text = 'germany \\'s stocks opened mixed on monday at the frankfurt stock exchange .'\n",
    "test_data_vector = X_test[4089:4090,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d33f36208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAGsCAYAAABNZ9S2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XecXGXZ//HPN5sekhBKAggSRAgQQLoiSAkSkY6ggBQFBQRU0AcL6POIBRXFApZHwZ/SfGiKoiBIRyxIMzQhlNASDJ0kJKRtrt8f171mWJPskD0zs5t836/XvPbMmZn7XLNz5sx17nYUEZiZmZn1aXUAZmZm1jM4KTAzMzPASYGZmZkVTgrMzMwMcFJgZmZmhZMCMzMzA5wUmJmZWeGkwMzMzAAnBWZmZlb0bXUAzbbKKqvE6NGjKylr5syZDBkypNvlzJ07t4Jo0pw5cxgwYEC3y5kyZUoF0aQVVliBV199tZKyBg4cWEk5AAMGDGDOnDndLqdfv34VRJPa2tpob2/vdjmSKogm9enThwULFnS7nCpnT63q/wTVff+q2p8Apk+fXkk5ACNGjODll1/udjmrr756BdGkiKhkH33ppZcqiCZVeZwaPnx4JeVIqux78/jjj78QEat29bzlLikYPXo0d955ZyVl3Xzzzey0007dLmfy5MndD6Z48MEH2XDDDbtdzsknn1xBNGncuHHceOONlZQ1ZsyYSsoBWHfddXnssce6XU6VB8vhw4czbdq0bpfTv3//CqJJQ4YMYebMmd0uZ968eRVEk6r6PwE89dRTlZQzZswYJk6cWElZ119/fSXlABx22GFccMEF3S7nlFNOqSCaNH/+fPr27f7Pz8UXX1xBNKnK49T48eMrKWfw4MHMmjWrkrIOO+ywJ+t5npsPzMzMDHBSYGZmZoWTAjMzMwOcFJiZmVnhpMDMzMwAJwVmZmZWOCkwMzMzwEmBmZmZFU4KzMzMDHBSYGZmZoWTAjMzMwOcFJiZmVnhpMDMzMyAJiYFklaUdFwXz9lJ0pXNisnMzMwWamZNwYrAEpMCMzMza51mJgXfBNaVNEHSt8vtfkn3STqw85MlbS3pH5LWlfSIpFXL+j6SHpW0qqTRkm6UdK+kGyS9uYnvx8zMbJmiiGjOhqTRwJURsbGk/YGPAbsBqwB3AG8HxgAnAV8HfgDsFxFPSfoSMC0ivi9pPHBMROwv6ffAryLiPElHAntHxL6L2PbRwNEAo0aN2vLiiy+u5D29+uqrrLDCCt0uZ968eRVEk2bPns3AgQO7Xc7kyZMriCYNGzaM6dOnV1JWFe+tw4ABA5gzZ063y+nXr18F0aS2tjba29u7XU6fPtXl+3369GHBggXdLqfKY01V/yeAuXPnVlJOVfsTUNn3BWDllVfmxRdf7HY5q6++egXRpIhAUrfLeemllyqIJg0dOpQZM2ZUUtawYcMqKaeq7x7A/vvvf1dEbNXV8/pWsrU3bnvgoohoB56VdAuwNTAd2BA4GxgfEc+U5/8cuAL4PnAk8IuyflvgfWX5AuBbi9pYRJxdymSrrbaKnXbaqZI3cfPNN1NFWVX+AD/44INsuOGG3S7n/PPPryCaNG7cOG688cZKyhozZkwl5QCsu+66PPbYY90up8qD5fDhw5k2bVq3y+nfv38F0aQhQ4Ywc+bMbpdTZfJb1f8J4KmnnqqknDFjxjBx4sRKyrr++usrKQfgsMMO44ILLuh2OaecckoF0aT58+fTt2/3f36qOq5Atcep8ePHV1LO4MGDmTVrViVl1asnjj74FzAb2LxjRUQ8TSYP44BtgKtbFJuZmdkyq5lJwQxgaFm+FThQUlvpK7ADcHt57BVgD+Abknaqef3PgAuBy0oNA8BfgYPK8iGlXDMzM1sKTUsKIuJF4C+S7ier/e8F7gFuBD4bEVNrnvsssCfwI0lvL6t/B6zAwqYDgE8AR0i6FzgMOKHhb8TMzGwZ1dQ+BRHxwU6rPtPp8ZuBm8vyU8DYmoffBtwTEQ/VPP9JYFwjYjUzM1vetKqj4Rsi6fPAsWQTgZmZmTVAT+xo+B8i4psRsXZE/LnVsZiZmS2rekVSYGZmZo3npMDMzMwAJwVmZmZWOCkwMzMzwEmBmZmZFU4KzMzMDHBSYGZmZkVdSYGktSW9uywPkjS0q9eYmZlZ79JlUiDpKOBXwE/LqjWB3zYyKDMzM2u+emoKjge2A6YDRMQjwMhGBmVmZmbNV09SMCci5nbckdQXiMaFZGZmZq1QzwWRbpF0CjBI0q7AccDvGxtW48ydO5ennnqqR5UVUV2OFRG0t7dXUk6VqirvlVdeqaQcgPb29krK22233SqIJj333HOMHj262+VMnTq16yfVqb29nREjRnS7nKFDq+uKNGPGDNZdd91Kynr00UcrKWfBggXMnTu36yfWoaqYAObMmVNJeZMmTaogmjRq1KhKjp1V/b+h2s9vzpw5lZQzcODAysqqVz01BZ8HngfuA44B/gB8sZFBmZmZWfPVU1MwCPh5RJwDIKmtrJvVyMDMzMysueqpKbiBTAI6DAKub0w4ZmZm1ir1JAUDI+LVjjtleXDjQjIzM7NWqCcpmClpi447krYEXmtcSGZmZtYK9fQpOBG4TNIzgIDVgAMbGpWZmZk1XZdJQUTcIWkDYExZNTEi5jU2LDMzM2u2emoKALYGRpfnbyGJiDi/YVGZmZlZ03WZFEi6AFgXmAB0zIoTgJMCMzOzZUg9NQVbARtF1VPcmZmZWY9Sz+iD+8nOhWZmZrYMq6emYBXgn5JuB/49CXNE7N2wqMzMzKzp6kkKTm10EGZmZtZ69QxJvEXS2sB6EXG9pMFAW+NDMzMzs2bqsk+BpKOAXwE/LaveBPx2aTYm6cSSVCzNa0+VdNLSvNbMzMy6Vk9Hw+OB7YDpABHxCDByKbd3Ir5ugpmZWY9UT1IwJyLmdtyR1Jecp2CJJA2RdJWkeyTdL+lLwBrATZJuKs85WNJ95fHTa167m6S7y2tvWETZR0m6WtIgSZ+U9E9J90q6uJ43bWZmZv+pno6Gt0g6BRgkaVfgOOD3dbxuN+CZiNgDQNJw4Ahg54h4QdIawOnAlsDLwLWS9gX+ApwD7BARj0taqbZQSR8HdgX2jYg5kj4PrFOWV6znTZuZmdl/UldzEknqA3wEGE9eEOmPwM+6msxI0vrAtcAlwJURcaukJ4CtSlKwD7B/RBxenv8RYCxwE3BQRBzSqbxTgfcBT5MJwbyy/hrgVbKfw29rL/Nc89qjgaMBRo4cueUFF1ywxPdcr9mzZzNw4MBKyqpKVTFNmTKlgmjSsGHDmD59eiVl9evXr5JyAAYPHsysWbO6Xc5KK63U9ZPqNH/+fPr2rXf28cWbN6/nXZ6kra26/snt7e2VlTdt2rRKyhk0aBCvvVbNBWRffPHFSsoBWG211Zg6dWq3y1l99dUriCb17duX+fPnd7ucGTNmVBBNGj58eGX7wrBhwyopp62tjfb29q6fWIf3v//9d0XEVl09r57RBwvIM/dz3kgAEfFwueTy7sDXFtUMsBTuAzYD1gQeL+v2AHYA9gK+IGmTiHjd3hYRZwNnA2y66aaxwQYbVBAKPPTQQ1RRVpWTRU6cOJExY8Z0/cQunH9+dbNY77LLLtxwQxUffx7gqrLZZpsxYcKEbpdz0EEHVRBNeu655xg5cmm77CxUxY9Ah6p+gIcOHVpBNGnGjBmVlffXv/61knLGjh3LAw88UElZP//5zyspB+CUU07h61//erfL+eIXv1hBNGnUqFE8++yz3S7nz3/+cwXRpPHjx3PttddWUtauu+5aSTlVJir1qmf0weOSJnW+1fG6NYBZEXEh8G1gC2AG0PFNvh3YUdIqktqAg4FbgNuAHSStU8qpPQ37B3AM8DtJa5RajLUi4ibgc8BwYIX63rqZmZnVqvfaBx0GAu8H6qkv3QT4tqQFwDzgWGBb4BpJz0TEzqU/wE1ks8RVEXEF/Lu6//Lyo/8c2YcAgIj4cxmaeBXZpHFh6a8g4KyIeKWO2MzMzKyTepoPOjdufV/SXcD/dPG6P5L9D2rdCfyg5jkXARct4rVXA1d3WnfqYsrefsnvwMzMzOpRz6WTt6i524esOeh+TygzMzPrUer5cf9OzfJ84AngAw2JxszMzFqmnuaDnZsRiJmZmbVWPc0Hn17S4xHx3erCMTMzs1apd/TB1sDvyv29yOGEjzQqKDMzM2u+epKCNYEtImIG/Htmwasi4tBGBmZmZmbNVc8FkUYBc2vuzy3rzMzMbBlST03B+cDtkn5T7u8LnNe4kMzMzKwV6hl9cJqkq4F3lVVHRMQ/GhuWmZmZNVs9zQcAg4HpEXEmMLnjugRmZma27KjngkhfIi82dHJZ1Q+4sJFBmZmZWfPVU1OwH7A3MBMgIp5h4ZUOzczMbBlRT1IwNyICCABJQxobkpmZmbVCPaMPLpX0U2BFSUcBRwLnNDasxmlvb+eVV6q5unJVZQ0bNqyCaBbKHK57VlhhhQoiSW1tbZWVN3fu3K6fVKeIqKS8UaOqG6H78ssvV1Le1KlTK4imWkOHVlfBOHPmzMrKW7BgQSXlVFnWtGnTKikHYP78+ZWUN3v27AqiSQsWLKikPEkVRLOwrKrKGzBgQCXl9OnTp7Ky6lXP6IMzJO0KTAfWB/4nIq5reGRmZmbWVHVdAjkirpN0N7AD8FJjQzIzM7NWWGyfAklXStq4LK8O3E82HVwg6cQmxWdmZmZNsqSOhutExP1l+QjguojYC3g7mRyYmZnZMmRJScG8muVdgD8AlAsjVdczx8zMzHqEJfUpeFrSJ4DJwBbANQCSBpETGJmZmdkyZEk1BR8BxgIfBg6MiI6xd+8AftHguMzMzKzJFltTEBHPAR9bxPqbgJsaGZSZmZk1X70XRDIzM7NlnJMCMzMzA+q7SuJ29awzMzOz3q2emoIf1LnOzMzMerHFdjSUtC3wTmBVSZ+ueWgY0NbowMzMzKy5ljRPQX9ghfKc2suRTQcOaGRQZmZm1nxLGpJ4C3CLpHMj4skmxmRmZmYtUM9VEs+VFJ1XRsS4qoKQdCrwakScUVWZZmZm9sbUkxScVLM8ENgfmN+YcMzMzKxVukwKIuKuTqv+Iun27mxU0uFkshHAvcBjNY9tBvwEGFzWHxkRL0v6JDnD4nzgnxFxkKQh5EiIjcnrMZwaEVd0JzYzM7PllSL+o2Xg9U+QVqq52wfYEjgrIsYs1QalscBvgHdGxAul/E9Smg8k3Qt8IiJukfQVYFhEnCjpGfJyznMkrRgRr0j6OpkgXChpReB2YPOImNlpm0cDRwOMHDlyy3PPPXdpQv8P8+bNo1+/7l8bqq2tusEcs2fPZuDAgd0uZ+rUqRVEk4YMGcLMmTO7fmIdJFVSDlQX12qrrVZBNKmqz2/WrFkVRFOtKr4rHebPn0/fvvVUdHbt5ZdfrqScQYMG8dprr1VS1rPPPltJOQBvetObmDJlSiXlVKV///7MnTu32+VUuZ8PGzaM6dOnV1LW8OHDKymnT58+LFhQzUWJ999//7siYquunlfPt+ou8oxe5Fn64+TFkpbWOOCyiHgBICJe6jjQSxoOrFg6OQKcB1xWlu8Ffinpt8Bvy7rxwN6SOpo4BgJvBh6s3WBEnA2cDTB27NioaueeMmVKJV+UYcOGVRBNevjhh1l//fW7Xc7ll19eQTTpne98J3/9618rKat///6VlAOw9dZbc8cdd3S7nM985jMVRJMeeughNthgg26Xc88991QQTWpvb68kca0yeZo6dWpl5f3pT3+qpJxNNtmE++67r5KyzjzzzErKATjttNP4whe+0O1yvvrVr1YQTVprrbV4+umnu13OXXd1rsheeuPHj+faa6+tpKw99tijknIGDx7c9AS/nuaDdZoRSB32AHYA9gK+IGkTMlHZPyImtjQyMzOzZUA90xwPlPRpSZdL+rWkEyV1p37zRuD9klYu5f+7eSIipgEvS3pXWXUYOSyyD7BWuULj54Dh5BwKfwQ+oVLVIGnzbsRlZma2XKun+eB8YAYLpzb+IHAB8P6l2WBEPCDpNPLHvh34B/BEzVM+BPxE0mBgEnAEOYPihaV5QWSfhlckfRX4PnBvSRweB/ZcmrjMzMyWd/UkBRtHxEY192+S9M/ubDQiziP7CyzqsQnAOxbx0PaLeO5rwDHdicXMzMxSPRdEulvSv3+kJb0duLNxIZmZmVkr1FNTsCXwV0lPlftvBiZKug+IiNi0YdGZmZlZ09STFOzW8CjMzMys5epJCr4WEYfVrpB0Qed1ZmZm1rvV06dgbO0dSX3JJgUzMzNbhiw2KZB0sqQZwKaSpkuaUe4/C/j6AmZmZsuYxSYFEfGNiBgKfDsihkXE0HJbOSJObmKMZmZm1gT19Cm4WtIOnVdGRDUThpuZmVmPUE9SUHu1l4HANuRFksY1JCIzMzNriXouiLRX7X1Ja5FTC5uZmdkypJ7RB51NBjasOhAzMzNrrS5rCiT9AIhytw+wGXB3I4MyMzOz5qunT0HtdQ7mAxdFxF8aFI+ZmZm1SD1JwSXAW8vyoxExu4HxNNyCBQuYM2dOJWVFRCVlRUTXT2pyeYMHD64gktSnT5/Kyps3b14l5XRYVv9X8+fPryCaasvr169fBZEkSZWW19PMnl3dYTYiKilvwYIFFURTbXltbW0VRFJ9eYMGDaqknD59+lRWVt3bXNwDkvpK+hbZh+A84HzgaUnfkrTsfhvNzMyWU0vqaPhtYCVgnYjYMiK2ANYFVgTOaEZwZmZm1jxLSgr2BI6KiBkdKyJiOnAssHujAzMzM7PmWlJSELGIBteIaGfhaAQzMzNbRiwpKfinpMM7r5R0KPBQ40IyMzOzVljS6IPjgcslHUlOawywFTAI2K/RgZmZmVlzLTYpiIgpwNsljQPGltV/iIgbmhKZmZmZNVU91z64EbixCbGYmZlZCy3NtQ/MzMxsGeSkwMzMzAAnBWZmZlY4KTAzMzPASYGZmZkVTgrMzMwMaGBSIGm0pPsXsf4rkt7dxWtPlXRSo2IzMzOz/9TlPAVVi4j/afQ2JLWVazSYmZlZnRrdfNAm6RxJD0i6VtIgSedKOgBA0u6SHpJ0l6SzJF1Z89qNJN0saZKkT3aslHSopNslTZD0U0ltZf2rkr4j6R5g2wa/LzMzs2WOFnEhxGoKlkYDjwJbRcQESZcCvwPeDVxZbo8AO0TE45IuAoZGxJ6STgXGAzsDQ4GJwGrAW4FvAe+LiHmSfgzcFhHnSwrgwIi4dBGxHA0cDTBy5Mgtf/GLX1TyHufPn0/fvt2vbKmijA6zZ89m4MCB3S7nueeeqyCaNHjwYGbNmlVJWVXur0OGDGHmzJndLmeNNdaoIJo0a9YsBg8e3O1yZsyY0fWTmmzAgAGVlTVv3jz69etXSVkvvfRSJeUMGjSI1157rZKypk6dWkk5AGuuuSaTJ0+upJyq9O/fn7lz53a7nKqOKwDDhg1j+vTplZQ1YsSISsqp0n777XdXRGzV1fMa3XzweERMKMt3AaNrHtsAmBQRj5f7F1F+uIurImIOMEfSc8AoYBdgS+AOSZAXZ+r49WoHfr2oICLibOBsgA033DBWXXXVbr6t9Pzzz1NFWausskoF0aRHHnmE9dZbr9vlXHPNNRVEk7bYYgvuvvvuSsqaN29eJeUAbLPNNtx+++3dLufUU0/tfjDFhAkT2Gyzzbpdzq233lpBNNWq8kdl8uTJlZV3yy23VFLOJptswn333VdJWaeffnol5QCcccYZnHRS97toVRnT2muvzZNPPtntcu69994Kokm77LILN9xQzaV99tuvmmsGtrW10d7e3JbwRicFc2qW28kf8aV9bV9AwHkRcfIinj/b/QjMzMyWXiuHJE4E3lKaGQAOrOM1NwAHSBoJIGklSWs3JjwzM7PlS9NHH3SIiNckHQdcI2kmcEcdr/mnpC8C10rqA8wDjge6Xw9lZma2nGtYUhARTwAb19w/YxFPuykiNlB2EPgRcGd57qmdyqot5xLgkkVsb4VKAjczM1tOtXpGw6MkTQAeAIYDP21xPGZmZsutljUfAETE94DvtTIGMzMzS62uKTAzM7MewkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrFBEtDqGppL0PNVdankV4IWKyqqKY6pfT4zLMdXHMdWvJ8blmOpTZUxrR8SqXT1puUsKqiTpzojYqtVx1HJM9euJcTmm+jim+vXEuBxTfVoRk5sPzMzMDHBSYGZmZoWTgu45u9UBLIJjql9PjMsx1ccx1a8nxuWY6tP0mNynwMzMzADXFJiZmVnhpMDMrIkkqdUxmC2OkwIzsyaQ9GaAiAgnBtZTOSmwlpG0paRxktpaHcuiSNpE0mqtjqOVan+8JPl4sZQkrQycKemz0HMSA0n9a5aHtjKWnqgnfEbN5i95RXryztPpwN63lbF08g7ga8D2PSWujv+VpE2A84GBrY3ojZH0Vknrl+Vu7ZOSFKUnsqSPAadUEGK3Le599fCkZQZwJrCNpGOg9YlBScb3l7SbpM2BL0ka0qp4apX9+C0t3P5GkJ9Rq2JolZ78Jeo1Og6eksZLOlvStyXt0fFYT4itLB8NnCqpT4sPRn0AIuJHwG3AF4CdWxVPrfI5vhO4EPhWRDwhqV+r4+qK0kDgS8Cu0P0DWs1+szNwAHBWd+Psrk778yGSDpb0IYCIWNDa6BYvIuYCawCvAEf1hMQgItqB24GfAX8AzomIma1KrmoS8ncAlwHnSHpTi+I4V9Jxzd52T+CkoALli70jcAbwF+AR4DxJB7c606w5gH4KOBL4Ze3BsxUHpI7tly/dm4H5wE9KU0JP2Cf/CawMHAoQEfN6SFyLFWk2cA5waEdtQXeVco4GBgPzyrqWJZQ1+/OJwFHkvnOKpA+2KqZ6SPoI8EXgUuC3wK6SPgEtrzF4EXgYmA5sXta15JjVcWIFfBf4HjAUOE3S2o3edu3/v+xjXwdWKI/16O9+1ZarN9tg6wOXRcR5EXE2sB/w35LGtCKYTk0Gg4BtyTPI6ZIOBa6QtE6rDkiSNiR/bI6PiN3Jg8BXgXHNjqe2yUDSFsBrwBhgI0lnQiYyPfXgIGmspF0kjYqIPwF/AkaWx+rur1FqG173HiPiYeDnwBTgcEnDe0C193Bg64jYCVgPmAhcUvbznmok8MWIuBb4IXABcICkj0Pzqqk7HRdWBmZExDjgA8BnJR1XPt/1JY1uRkwdcZV97yDg4og4n2xe7E+eMDS0xqC8520ljSir7gMOlrR1q2ugVNPvoxl65EGuN5H0dkkrATOBrTvWR8StwC1AS3aomjOqPcuqPsCtwPeB0eQZwncltTXjgLSIH5HJZI3Km0q8PwQmAP8HvLPR8dQqB4R9yLPsDwMXA2uRZ07jJZ1TntdTq6f3JZPQyyVtBQwDPiWpT6kirteQmlqcoyR9RdJ3yCTjAmAT4AOSVmxmDdgikrE2YEj5XLYCDizv88Dy/ltqMQlTO/B5SUMj4hXgz+QxY8eaH6JGxzWSbAZC0m5kk8EESe+LiHuAE4ETJP2A/LxXakZc8O+argXA/cBQScPK/WOAscCnGrXtms/rUOBXkr5M1hJ8m0yE+7YqCS5NgudKGtC0jUaEb924Af8P+H9l+W9kW/TKwLvIHXyTJsezPrBTWV4R+EPNYwcBo8ryOOAiYFATYlLN8mhg3bL8v8DxwJrl/vvJA9UaTf6frQFcDwwBPg78teb/tCLwBLBR7fto8T7XMRPpOsCImvVHAaeTidWLwHs7//+XUObeNfvxh4A7gfcCvyr/m2HAbsC5ZOLU9P9F+QwGlOUTgeeB9cv9w4F7O/alVn82ZflA4CRgXfJH5mvl/9nx4/wrYNUmxvahcrz6OHAtsDGwT/m/faA8ZyzwA+DdTdyP3wZsCawKbAH8nqzVHAFsCFxeYjyuym3XbH/NmvUbAIeU7V0GPAj07/zZNnmfGtLU7bXiTfbmW+cdgzzT/QkwuNz/PfAL4O/Ank2ObSDwZbI2YNvyI3clsHqng9XngH8AmzY5vv8C/kjWoHwF2A74dTlQnV9iWrcFn+na5TM8nuwT8tayfufyt2+r97uaWPuUv3uQVZw/Bv5Y8/iI8n7OB75XZ5krkz/8G5R95f/Is++Ox38GXF2WD6AkTE14r5sDnyzLxwEPlB+z/YG3lv3pMbID5N3A2FZ/PjWxH0ImVheV2/tLzN8GriM72L6tyTENAD5SPs/f1azfs3z3Du+0jzXsR7BmG+8GppZj5p3AmmTyeRHZ92Ji2S8/ChxZ0bZrj4V7kCcBpwOfBVYq69cG3kOe6P2w1ftTU/eTVgfQG29kT/n3AmuV+78EPl3z+CBgZFluSnZZ8yVbD/hv4FvlAH4mJdOtie1kYOMm/892r/lhORO4piyvDuwIHAus1+SYBtUs/7T8wGxS7u9SDpRvbfX+VuJZoWb5nWRCsA5wGDAXuKfT89vKAe3NdZQ9FLiGbDa5pPzIfqp23yoH6bYmvl+RZ4t/BL5R4lqRrA35MVlb0R/Yhjy7XLvVn1FN7LuSTS7Dyv2Pl5j3Lff70eSzv7LdjtqvA8kaucOBgWXdvuRZ8RqNPGZ1+s5tQnbO3q7c/3SJYe2y/27EwiThPmCjCra/KvDBsrw5WZu7LvAj4A6yv8dqNc9fG/h+q/eppu4nrQ6gt9w6DohlJz2QPMO9gKzG3KkcBNZqUWy1me+qZFXvl8pB/l9kJvx7srryl804uHc+sAA7kG12p5YDfUeV3JZN/D+tQnZQgzxD6PgRXIFMAs4s9z9GjkBoak3PEuIeUvavQ8v99YFNy4/PbWSidyswoeY1W5J9NlaucxufAV4tf9cmz8oPAFYDDi4HzOFNer8jgTFl+RvksLnLax4/jEziPkY5s2vx51P7/etb/l8vUmo5yvrjyBqYfTp/N5oRW9lnrgdOKPcPJ5sJDmVhYtDQpozy/TuBrM1qK9+1CeXY0HFScyLZqXXzmtdcTwW1mmSieQhZK/GRsh+tR57g3UXWmPyGbNZcrbx/+FHxAAAgAElEQVTmYDJRGdbq/axZtx4xYUxPJml1coedImlV8sf17cDV5JnLd8jqrS3J6sGna8dSN0PHtiQdT/Yb2JmFbb8zyDPeq8gvRXu8sc5nb1inseS7kmesbeQZ03PAbhERyglxPiBpX7IXdMP+Z8q5Bo4CRklaD/gkOT/CR8mD9cfJZpe9yAP78RFxU7M/y0WJHDv+LeCrkqZFxO9Lx6cjgPMi4jVJF5G9x98eEX8n29t3iYgX69zMpeR+8iPgKbLm5iTyDHId4IiImFbxW1uc4cAPJU0mE5QzyY6Tn4yIsyLigtLxamOyA1/LdNrXVwXmR8RFkuYDh0h6KSIujIgfS5oL/L3Zx4by/ToGmAa8T1LfiPiOpAXkCU2bpPPJRKYhSg/614DfkcNb1yR/mP+X/M49BDwXEd8vHUuHl/hfkLRn5HDbbin/918qZyndhExIniO/+0dGxD2SDiBPElYmmzX+BewVEdO7u/1eo9VZSU++kT9knyOrVjs6w91EVqe21TxnFHlGcydN6Li3mFj3p1ObPHlA/SJ5RvCOFsR0ItnLenS5/yWyPfXD5Ox499LEdmDyQPBlsg/Dt2vW/5g8WK3d6n1uETF3nOltUuKeCOxT1n2WHNP9MeAGYMMKtrcl8CiZXA4ka52a1hmuJo4zyLHzx5b77yXbmE+oeU6POXsja1j+SJ5VHk+OitiHPPP8aJNjWYGFfZxWJGuTNiebLXYkE8Djy+NH0uDO0GTNwHeB7cv9r5B9eMaW/etXwDeB1Tu9rvIaFbKfwC3ldgOZLP0N+Dw5euzvNLlptafdPCRxCSLPqC8hd5rvKCdyuTMiFpTHiIj2iHg2Ik4mDwhNGV60CCsBZ0fEY5IGljOYJ8kx5pOBx5sZjKQdyKq38ZGzAr6V/OKfQ7ZbrgK8PyIeaEIsHcOJHiTby58H3lZiJCKOK+t+UYYA9RgREZLeQ/64/InsOPo1Se8lR7q8TPbX+GFEPAjdm1woIu4iE8wfkbUD0yPi+W6+jaXR0fHzaEkHRsTV5DwWH1TOs0H0kLM3STuR/7N9yNqoDYHtyR+dXwHvljSsGcPaJK1I1vAMLtubS9YQTo+IeWSHzHuAIyQdGRE/j4j7GhzWCOAF8rPbiDxJmULW0r2ZrPHaBPhM7Zj8KL/iVSlDMv+bTDR3JD+b1cgTlQPImsMzIuL+Krfb27j5YDE6qgXLD9rZZHXqucDmpWpwZeBJstbga+REG9s0M7ZOq6cD/yXp6oh4ojzvKODeiDi9WTHVxNZxINhFOdvjTmQisG1EXFrG0Dd83H9NXBuQCcHnyFqdzwK7SVoQEX+OiI9IGhsVVFM2wNvIg9V5ysmI/kJ2JD0hIr4qqV/krIsd+2y3DqaR1ag7ktW9LRERjwKPSnqFnNXuFbLmYi75/ltmEd+/gcCzZd/5s6SZ5Nn438rf30XEjGbEFhGvlOPVQGC/iLhc0u/Ik5qPR8RkSQ+Q1fc7SLopIhp6whARkyR1dOg7hawp+AHZv+DD5EiZg8lOvXMbGMo88jdvlXL/Z2Qt4Zrksf3/IuKlntBk2EquKViEmh+SMWUylJnkGe4VwCTyzPsq8szztrIDPUUOYXum0fF17LCS9pN0svI6C4+QX67/Uc7MdQiZyDS8HbjTl2gt5YRIVwBPkx17boiIrcjq1W073kaz4lJO4PQFsir1NLJz0XfIKXL3r6kxaHitRT06zihLfxbIXvZ7wL9rr24l2zp/ImkUpV29ygNZRNwfEY9VVV434vg9mcCdQY6a+Vijf8SWpFMfgj0lrUGeHLwgaSdJAyPiH2Tv/hERMa9ZCYEWXlPkGXLeiUNLf4KLyCaEGyT9F5kcX0buVw2/MqKk3clpgyeTNZqfIScHO4v8of4IsCAi7m5kHBHxMpmk7SRp41Jz8isy0bw2Il4qz1tuEwJY2F5pRc0PyV7kD0dHk8D3ySFru5EdDU+IiKdrX9PkOD9JVrtdSVbHv0a2369CHhBeBb7UhKrB2piOJXszTyIv/PLp8sWjdOD5CjmhzpMNjmNARMwpy28hey8fQCYi7yB7GZ8MPEv2ezgvIh5qZEz16pTIHExWBT9LVnFOiYjDJb2drKb+bkT8s4XhNk2p+o0WNWX8h7Kvf5w8HkwlE5dVyR+YJ8jPbVxHrV0T4unYb0aUHz8kHU6OqrmCTFL2JBPjv5MjVv6X7J8yuYFx9SOnMP9DRPxB0liyY+EYsjnxeXKEzCONiqFTPGuSfXC2IUfUHED2r7i+GdvvFaIHdGzoCTegX83yaDKT3rLcP5IcArU5+cX/OrBFC2MVcB7wlnJ/QzL7PrHcH1z7fhoYx5Ca5V3JjoPrkR2IziJrUwaSncQeoAkdeMhOn5+kjOsnqyyvrnl8DXIo6R+poGNeg97Du8r/a8uadcPIYbC/Iy9gs2+r41xeb2X//js1HVPJTnx7s7Bjb9P3LbI26fdk34vxZd1hZNX4B1g49HBbsrapKZMnUTPra7m/Mzk/wC+omX+jif+nocB4cl6EHVu9P/W0m5sPAEl9yaFx75C0MZlJDifbmoiIn5Nt9p+JPFP5cjS4qqtTfCPLmRKl0xksnMiFyA5mj5Gdm4iIWVHO0BsY0/pkx6BNyqr55Mx6j5A/WieTneC2jOwk9u5oTgeeOeQP/lBJm0dWgQ9UzmdOZNXqXcAzZCe24eohFzrSwosXbU8e3B+X9DFJvyZnJ9yfrB0aFxG/bUbHNVtkx83ZwKSIeFKpf/m+/TkivkZO/PRgk2PckZyV7/PkZE6fk/SRiLiA7KC6L2WYHzkM78DI6x1UHUdH09ebtfBicKcDc0rtJmTNysPA6RHxatUxdCUiZkTEtRHx3Yi4pdnb7+l6xMGw1SJiPnlm9huymvZCcr7tDUp1F+QZ2sulvXxOk0NcD7hI0jdYeEnP04DhpRqzgySt0KSYRpBNFXspr3j4DNmGOT6yHXUmmSisBhAR/2p0QKXD3SsRMZE8OB5RPr9PA+tJuqA0Cx1NDi1dCZgXrb8KWsePTsdFT64kqzevJ89qfgz0Lx0hX4xS3RvltMcap1MfglVLdfhTwFslnRJprqQjga+UxK4pcyfU/ACvTO4vB5PTrq9GJpX7q4wwAE6KiGcBIuKxaFDfp4gISXuTx8/vKC+u1EbO6/IeSdeTx9Jzo4c02dnrefTBQo+QZ9ujyKraK8hx9SdLeo5sj/tMNHjin1oqPfQj4i+SJpJzve8dETMkPU5+0T5fOhqOJqfvbGjmXRPT30syMJqc4fGHZE/isyV9szx9Y7IfQUMprzw3I7IH/s7kZ3g1eeXAfcmhYZ8iZ1McR3Z+HEQOiRoEzGp0jEtSDqTjgcMk3U7+6OxDNs9MlfQ28uyvobU/9p9qEoLjyer5SeREO+8DrpG0DpkQ70EO4WxaQlCz3+xA9nmaS37fdo+IZyW9D3iXpOui9H9qQlzbk9+z95DfvzPImpUfkN/FTYFXI2JiK/piWdfc0bCG8nrsW5IdcD4TEddI6hhL+7uIuLNZO3KnM5RjyR+6geSY9CMj4s7y2EDyjH1uRDzX6Lhq4vsYOczwIrIN/FWy38W6wAfL037c6CYDSYPJyaXOIsdfX0EetJ8oMa1FJnu/7YhFOa78LOCwRlShvlGl6vfH5EQqp5JJwTFkx8jtyZEvn47siW9NJukgsknxULJzXFtEHKwc+XEImaxdW2qomhnXDmTyeGXk7JvDyc7GXyMnMjsH+Hg0qbOxpDeRHZ7XI2sSv0zWyv2E7FD4qegBI1psyZwULELp+X0meZ2A7YFPRIuGq0k6huzo+L7IqZa/QE6Usi/Z83mtiPjvJse0N9l8sUdEPFV6wx9A/gifGw0eXbCIePYjmwteAj4fOc7+EHLa6T5kT+eJZG/9acqplx+NFg5t61CqgI8mZxGcTiak+0XE0+UsdAQ5S2ZLx+YvTzol5CuQndKeJE8YDiD3+3mS1mnmPlSaLttr7v+OrCVYr/R1otQafp2sNfhGRFze4Jj6RMSCkmhfSHbGfpmcR+P+iPh5qWU5DDjESUHP5+aDRYiIKyW9SI6fPb2FCcEgsuf+/wDzSoLQl2wLP4tsOzymBaGtAVxUEoK+pSlhAXnWdICkHzaz30VE/EbSq+QY5PFkjcEl5OVqNyWrfH8dZe7+iLiuWbF1pVQBv0w2v8wG3hMRz5W+D28FfhSNndDFanRKCI4j+3nMJnvw3x4R7y6PHQWsK+nUaMKEV8qZ/g6UdBU5mdX2EbF3aW76f+TIByLiqrKufzmJaEjNZum/M68kBNuQQzAPr0lOHgQO6oibrOlyQtALOClYjIj4m6Q7ImJ+q9q+Ii908weyyvJpslp8EjlJ0YXAC1Em3GiyJ4F9Jf26psp0DbKm4LwWdMQkIq6TdAQ5+93kyIvSXEp2cvp7NGkcdFdq2oLfRjZLXVtue5H/1xnlIPsN4HNOCJqrJiE4huwjs1/5cR0NbCTpzWT/omPIPjxNmQGzdGYMsu/T8+QJCxGxjaS/S7o0Ij5Q1j1f87pGJAQdo7UmkTUSPySbDfcCbixPu4kcprkP8K2I+GvVcVhjuPmghyt9BjYBHoucgvMQsoPc7hHRkmloJQ0j50XoS045O5ycsvSgiJjUiphqYtudHKd9VkSc18pYOqupat2VbO/9J9nnYW/yoLor2RFyBnBmRFzhzljNV2roLiKbcu4imwzeRCYJN5F9e77crBrEmv1mDfKaFJsB29WOIJB0Dzm51e5NimkzsjPvHLKT5WCyP8w1EfGDmucNjIjZ3o97DycFvYRyLP0R5Ax8Bze6A18d8axOngXsTU6l/I2IuLeVMXUofR6+CbwbmBqtH3I4JHKIJsprMJxKNkv9Q9K3yergYyMvZjWKHCa53M/B3kqSjianCZ9Mzmo6ibyE9Knk5zO/yfHsS46GOoDsbHwseRy4R9LKEfGipG0i4vYmxTOErOEaSU49fYOk3chj1G0R8b3yPO/DvYyTgl6i9LI/kPzCNXVilCUpbYb0tGpuSatGD5gSV9JQ4Gzg8oi4TDmJ0vsoFzgqz/kGWUtwSLN7sNuiLaKG7oPkZGF7RERTh7CWs/LzgA907B+Sfgm8hexPcBqwS7NPFEqNyhZkjcpXy/59AjlKY9+ImNLMeKwa7lPQS0TELEnn9rSsu6clAx16QkJQiJx3/jBJz5Czu80HNpY0LiJujIiTlZPerNTKQG2h0lfgDkl9JH2EhTV0rZjTYg45xHAnSQeSQ4CfIXv5r00OrW16zWFpvvyLpFOAM5Wzwe5NDud2QtBLuabArMHKePJDyaGRJ5PXiPgvsh32xoj4YwvDsyXoCTV0ZVjkh8n5P84gOxy/i7w0+W9a3TwGIGlbsq/TxT1pdI+9cU4KzBpI0nvJ4aM/IMdwjyJrC+4mry0/ADgtIl5sWZC2RD2lXVx5jYW5krYmLyZ0QkTc0Oq4OpThyU3ta2HVc1Jg1kCSTgUeioiLSyfC95JnfF8ir7cxqqcMl7SerTQxbUbOfvn1iLiixSHZMsgXRDJrrAFk0wGRF6S5DRhCdg5rc0Jg9YqczfAhcujvFWU2TLNKOSkwq0jHQVrSdpI+IGk74LvAv8rQQ8gJXZ4CjouIl1sUqvVSETEzytTKPaFJw5Y9TgrMKlJmKtyHvGLdWuQc9B8o9zdRXjb2cuDS8GVjzawH8pBEs4qUCV12Jy9U9W5y5rtLy/DI3SStDRART/aUzmtmZrXc0dCsApI2JK92uDIwFdgWOCIiHlVeuW5KRExoZYxmZl1x84HZUurU0asfeTW9Z8lx7d8sCcGOZL8Cf9fMrMdzTYFZN0h6O7BZRPy0dCbsS166+QTgOvLKcZ+JiCtbGKaZWV2cFJgtJUn9gDPJIYcfA2aStQInA4+S0xZPi4g73IfAzHoDJwVmS0HSWmRzwVDgEuBh4DLg8+Slj4+MiKdbF6GZ2Rvndk6zN6hcHe4Ych76NYCPkBeoeRD4LbAROWmRmVmv4poCs6UgaTiwNTnl7G+AEcD3IuJBSW+OiKdaGqCZ2VJwUmDWDZLWB44lr2fwZERsI6mtTElrZtarOCkw66Zyed2xwKCI+FOr4zEzW1pOCswq5FEGZtabOSkwMzMzwKMPzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMBsmSTp1QaUOVrSBxfzWB9JZ0m6X9J9ku6QtE7VMZhZY/VtdQBm1muMJidp+r9FPHYgOeXzphGxQNKa5AWizKwXcU2B2TJM0k6Sbpb0K0kPSfqlJJXHnpD0rXJmf7ukt5b150o6oKaMjlqHbwLvkjRB0qc6bWp14F8RsQAgIiZHxMvl9eMl/U3S3ZIuk7RCWb9bienuUstwZVl/qqSTarZ/v6TRZfnQEusEST+V1NYRo6TTJN0j6TZJo8r6UZJ+U9bfI+mdSyrHbHnnpMBs2bc5cCJ5oaa3ANvVPDYtIjYBfgh8v4tyPg/cGhGbRcT3Oj12KbBX+ZH9jqTNASStAnwReHdEbAHcCXxa0kDgHGAvYEtgta7ehKQNyRqJ7SJiM6AdOKQ8PAS4LSLeBvwJOKqsPwu4pazfAnigi3LMlmtuPjBb9t0eEZMBJE0gmwH+XB67qOZv5x/6ukXEZEljgHHldoOk9wODyGTkL6WCoj/wN2AD4PGIeKTEdSFwdBeb2YVMIO4oZQ0CniuPzQWuLMt3AbuW5XHA4SXGdmCapMOWUI7Zcs1Jgdmyb07Ncjuv/97HIpbnU2oRJfUhf8i7FBFzgKuBqyU9C+wLXAtcFxEH1z5X0mZLKOrf2y8GdrwMOC8iTl7Ea+bVTC/d+T12tqRyzJZrbj4wW74dWPP3b2X5CfJMGmBvoF9ZngEMXVQhkraQtEZZ7gNsCjwJ3AZsV9NfYUi5suRDwGhJ65YiapOGJ8iqfiRtAXSMYrgBOEDSyPLYSpLW7uL93UBexRJJbeWS10tTjtlywUmB2fJthKR7gROAjs6D5wA7SroH2JaFowjuBdpLh73OHQ1HAr+XdH953nzghxHxPPBh4KKynb8BG0TEbLK54CpJd/P66vtfAytJegD4OPAwQET8k+yfcG0p6zqyg+OSnADsLOk+sllho6Usx2y54AsimS2nJD0BbBURL/SAWHYCToqIPVsdi9nyzDUFZmZmBrimwMzMzArXFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyucFJiZmRngpMDMzMwKJwVmZmYGOCkwMzOzwkmBmZmZAU4KzMzMrHBSYGZmZoCTAjMzMyv6tjoAWzJJsZj1S3rNG1rfiMe8rcaUVXUM3lbviM3balxZd9111x8jYrfFFriccVLQC0j6962R970tb8vb8raWw22tgv2bmw/MzMwMcFJgZmZmhZMCMzMzA5wUmJmZWeGkwMzMzAAnBWZmZlY4KTAzMzPASYGZmZkVTgrMzMwMcFJgZmZmhZMCMzMzA5wUmJmZWeGkwMzMzAAnBWZmZlY4KTAzMzPASYGZmZkVTgrMzMwMgL6tDsC69MeIWCUilua1qwAvVBxPs/X29+D4W8vxt1ZviL+nx9dUWsofG+sFJN0ZEVu1Oo7u6O3vwfG3luNvrd4e//LIzQdmZmYGOCkwMzOzwknBsu3sVgdQgd7+Hhx/azn+1urt8S933KfAzMzMANcUmJmZWeGkwMzMzAAnBS0jaTdJEyU9Kunzi3h8gKRLyuN/lzS65rGTy/qJkt7TVZmS1illPFrK7F/Wry3pBkn3SrpZ0po1rzld0v3ldmDNekk6TdJkSXMkPd/L4r9V0oRye1HSjF74Gewi6W5Jj0maJenJXhb/uBL/E5KmNen///GyLiStUrNeks4qj90raYuaxz4k6ZFy+1DN+i0l3SfpGUkv98L4T5P0tKTXFrWtnhy/pMGSrpL0kKQHJH2zc9zWTRHhW5NvQBvwGPAWoD9wD7BRp+ccB/ykLB8EXFKWNyrPHwCsU8ppW1KZwKXAQWX5J8CxZfky4ENleRxwQVneA7iOnNxqCHAHMKw8dgRwQc223tSb4u/0GbwK/Fcv/AweBsaWbf03cH5viZ88EXka2KBs6yzg6CbEvzkwGngCWKVmG7sDVwMC3gH8vaxfCZhU/o4oyyPKY7cD7yzbuhnYq5fF/w7ye7tgUdvqyfEDg4Gdy3P6A7cC7231MX1ZurmmoDW2AR6NiEkRMRe4GNin03P2Ac4ry78CdpGksv7iiJgTEY8Dj5byFllmec24UgalzH3L8kbAjWX5ppoYNgL+FBHzI2ImcC+wW3nsWOCKmm1N6WXxd9iJPKid0ws/gyAPoI8C84HJvSj+lYG55AH+UTKp2LeR8QNExD8i4gn+0z7A+ZFuA1aUtDrwHuC6iHgpIl4mE5zdymPDymfwKPBTYM/eEn8p6zbgzcCCZhyDqow/ImZFxE2lzLnA3cCaiyjXlpKTgtZ4E3m21GFyWbfI50TEfGAaeUBd3GsXt35l4JVSRudt3QO8ryzvBwyVtHJZv1upqlsF2BlYqzxv3fKaLSRdLWm9XhZ/h32ByRExfRHl9vT38FHg+8D2wGHAN3tR/C+QtQfvKts6oKxvZPxL8kbLelPN8tM1y70l/trXxRIe7+nxI2lFspbmhi62YW+Ak4Ll20nAjpL+AewITAHaI+Ja4A/AX4GLgL8B7eU1A4B5ZG3BOcDPmx10jaWJv8N2ZFVnqy3Ne/gUcFpZ/wvgu80OusYbij8igqyKPgLYG5jBf342ZkskqS+5X50VEZNaHc+yxElBa0zh9Weua5Z1i3xO+QIMB15cwmsXt/5Fskqub6f1RMQzEfG+iNgc+EJZ90r5e1pEbBYRu5LtfQ+X108mE4K1gN8Am/ay+Clnruvy+jOlXvEeJK0KvA24pWzrErJ9u1fEX9b/DTgS+Afwp7K+kfEvyRsta0rN8lo1y70l/trXqYtt9eT4zwYeiYjvd1G+vVGL6mjgW2NvZPXpJLKTTkeHnLGdnnM8r+/kc2lZHsvrO/lMIjv4LLZMst22tpPYcWV5FaBPWT4N+EpZbgNWLsubAvcDfcv9b5LV15NKXHf2pvjLuo+RnfN63WdQbi8AG5ZtfQ64vLfEX+6PrNnWX4DxjY6/pswneH1Htz14fUe328v6lYDHyb4PI8rySuWx28mapklkR8O9e1P8NcegBV1sq0fGD3wN+DVlv/Ot4t+nVgewvN7IXrcPk1XYXyjrvgLsXZYHkgfiR8tB6C01r/1Ced1EanreLqrMsv4tpYyOjl0DyvoDgEfKa35Ws34g8M9yuw3YrKasFYGrypf7NbLdr9fEXx6/mex01Vs/g/2A+8gD8CzgyV4W/7eBB8lap+ea9P//ZNnefOAZ4GdlvYAfleffB2xV85ojy7YfBY6oWb8VmeT8C3i5F8b/rVLWArIp8KXeEj9ZYxDk/jOh3D7a6uP5snTzNMdmZmYGuE+BmZmZFU4KzMzMDHBSYGZmZoWTArPlhKR25TUf7pd02f9v795BowqiMI7/Px/gA620EYSACgEDpkiENGJhComFhSIakYAIqawsLCLaphJEJI0Yoml8i1qKijZqRIOCqJU2KVJqSGxyLM5sXEI0b6PJ92v27ty5985usXt29s45ktZM8/jv0+zfLenABO0Nki6U7TZJF8t2u6RjVe2bpnM9M5s9BwVmS8dwZN6AOjLVcHv1zlKcZt4/EyKiLyJOTtDeFRE95Wkb4KDA7C9zUGC2ND0DtkqqKVXteshldpslHVZWAXwvqbP6IEnnS3W6RyWREpJOSHolqV/SrXEzEHsk9Un6JGlf6b9b0oPxA5J0TtKpMrvQAPSWmY0WSXer+jVLujP3b4mZOSgwW2JKdiUy0sAAAAG5SURBVLq95LpwgG3ApYjYTq5b7yQLINUDjZIqxY/WAn2l31PgbGm/HRGNEbGDXD9+vOpyNWShnBagS9KqycYXETfJpFitEVFPpkuurQQhZIrkhUyvbbZoOSgwWzpWS3pLfuF+BS6X9i+RFeoAGoEnETEYWQSnF9hV9o2SaZUBrpEFmQDqJD2T9A5oJTPeVVyPiNGI+EwmW6qd7qAjk6lcBY6WIjhNZBY8M5tjKybvYmaLxHD55T0mK+EyNMPzVTKfdQP7I6JfUhtZlnp8n989n6orwH1gBLgRvyo2mtkc8kyBmVV7SVY93CBpOXCY/KsA8vOisprgCPC8bK8DBiStJGcKqh2UtEzSFjJV8scpjuNbOS+QhZfI9LgdZIBgZvPAMwVmNiYiBiSdBh6TeekfRsS9snsI2Cmpg6xZcKi0nwFeAIPlcV3VKb+SgcZ6oD0iRsrsxGS6yXsQhoGmiBgm/8rYGBEfZvESzewPXPvAzP4LJZ/Bm4i4PGlnM5sRBwVm9s+T9JqcqWiOiB8LPR6zxcpBgZmZmQG+0dDMzMwKBwVmZmYGOCgwMzOzwkGBmZmZAQ4KzMzMrPgJO5szqPIpQQsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d33f258d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfect\n",
    "text = 'tokyo stocks closed higher wednesday for the second straight trading day .'\n",
    "test_data_vector = X_test[4282:4283,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb03807898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb037f4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfect\n",
    "text = 'germany \\'s stocks opened higher wednesday on the frankfurt stock exchange .'\n",
    "test_data_vector = X_test[6718:6719,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb037799e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb037e65f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfect\n",
    "text = 'germany \\'s stocks opened higher on monday on the frankfurt stock exchange .'\n",
    "test_data_vector = X_test[6719:6720,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d31cf9cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d3756d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'shaquille o\\'neal conceded it felt different wearing a miami heat uniform .'\n",
    "test_data_vector = X_test[2454:2455,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d3765ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d37670c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'france has been chosen to host football \\'s european championship in #### .'\n",
    "test_data_vector = X_test[2679:2680,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb036639e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb0364aa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = '<unk> <unk> , caterer and former restaurateur , cooks <unk> sicilian food .'\n",
    "test_data_vector = X_test[5818:5819,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb036d8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb036c50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'another beauty battle is moving to las vegas, at least for the time being .'\n",
    "test_data_vector = X_test[6912:6913,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb036ecf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb036e97f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'one is a banana billionaire who hobnobs with the kennedys and rockefellers .'\n",
    "test_data_vector = X_test[6999:7000,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb0543d320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb05426898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'former swiss president ernst brugger has died , it was announced monday .'\n",
    "test_data_vector = X_test[102:103,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d373fb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d311eee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'more than ### us military engineers <unk> to the al-qaeda terror network .'\n",
    "test_data_vector = X_test[1924:1925,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d37363fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d37374a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'fresh heavy rains caused dozens of road accidents in california thursday .'\n",
    "test_data_vector = X_test[2008:2009,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d32654fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d31125da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'for the rangers , it has come down to calculators and historic anomalies .'\n",
    "test_data_vector = X_test[3573:3574,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d314f00f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAGWCAYAAAAdeHvNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcVMW5//HPA8MwgIgCCioKbuBCRBGXRE1wR417osYtRuOauCXeezXb1fyu0ZjELRqjXhMTTeKSmHjjEjV6zTVxR0VwX0BFEXEXREB4fn881dLOmWG6eqanmeH7fr3mNd2nT52qPn2W59SpOmXujoiIiEi5HvUugIiIiCx9FCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoa6l2Aeho4cKCvvvrqWWk++ugjmpqastK88sorWfOX9O/fnw8++KDi+ddYY42q8pk7dy59+vTJSvP4449n5zN06FBef/31rDS55QIYOHAgb7/9dlaaAQMGZOcD0Lt3b+bNm5eVZtGiRdn59OnTh7lz52alWXnllbPzmTdvHr17985KM3ny5Ox8VlllFWbMmJGdbsUVV8xOk7sfAfTokX/t1K9fP+bMmZOVpmfPntn5VLMtfPzxx9n5LLfccsyePTs7Xa9evbLTVPOdqtmP+vbty4cffpiVJnd/gFgHCxYsyE6X+zs1NTXx0UcfZefz+uuvv+nuK7U13zIdIKy++urcdtttWWmmTJnC6NGjs9Icf/zxWfOX7LLLLtx6660Vz3/xxRdXlc/jjz/ORhttlJUmN7ACOOWUUzjttNOy0qy//vrZ+RxxxBFcccUVWWl233337HwARo4cybPPPpuVJvcABbDRRhtlB2XVbHdPPfVU9jqvZlv49re/zSmnnJKdbscdd8xOs/POO2fv59UEpuPHj+fuu+/OSlNNwLPpppsyceLErDQzZ87MzmfHHXfkjjvuyE43bNiw7DRjxoxh0qRJWWmq2Y+22GILHnjggaw0a621VnY+q622Gq+++mp2ulmzZmXNP3r0aKZMmZKdz9lnn/1SJfPpFoOIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpKDLBAhmNsLM8p8IISIiItkqChDMbLiZ7ZBe9zGz/tVkZmaNZtavmrRLWGY/M8t/tqeIiIi0qs0AwcyOBP4IXJomDQP+kpOJma1vZj8DngFGpmnTzGxwej3OzO5Or083s1+Z2d1m9qKZndDC8tYys0fNbLO0vGfN7Kdmlv9cXhERESkwd1/yDGaPAZsDD7j7JmnaZHf/TBvp+gH7AUekSb8GrnP3D9Ln04Bx7v6mmY0Dfuru483sdGAnYFugPxFUDAVWA24C9gWuAQ5z90lpWf2B/YGvAQ5ckfIqjJxiZkcBRwEMGTJk06uvvnqJ37+5agY2evnll7PmLxkwYADvvfdexfMv7YM1VfN88mqeiT948GDefPPNrDQrrLBCdj7Q/QZrqmYwsmq2hWHDhjF9+vTsdNWMXZC7H0F1gzVVMyhUQ0P+cDjVDDhUzcBByy+/PO+//352usbGxuw0nTVYUzUDalXzfRobG5k/f352utzBmqpZbwAHH3zwRHcf19Z8lWyd89x9vpkBYGYNxEm4LTOAx4Gvu/vTFcxf7mZ3nwfMM7M3gCFp+krAjcA+7v5kaeYUdPw38N+pFuEK4AJg+eYLdvfLgMsAxowZ47kDL1UzWNOll17a9kwtWJoHa9ptt92y8znrrLOyB2v6zGeWGIe2SIM1hc4arGmnnXbKzuenP/1pVYM17bffftlpNFiTBmsq0WBNeSoJk/9hZt8B+pjZjsD1wF8rSPcl4FXgBjP7gZkNb/b5x2X5N79kKb8kW8jiQOY94GVg6+aZpUaM/wn8GXgl5S8iIiJVqCRAOBWYBUwGjgZuAb7XViJ3v93d9we2IU7sN5rZ381sRJplGrBper1vheWdD+wNHGpmB8IngcHfiXYR7wJbufv+7n57hcsUERGRZiq5xdAH+JW7Xw5gZj3TtIrqd9z9LaK6/wIz25yoEQA4A7jCzP4fcHelBXb3OWb2ReAOM5sNPAp8x90frHQZIiIismSVBAh3AjsAs9P7PsDtwOdyMys/ibv7PaQeDc3mOb3Z+/Ib/qPTtHeBzcqmv5JbFhEREWldJbcYmty9FByQXvetXZFERESk3ioJEOaY2djSGzPbFMjvVyEiIiJdRiW3GE4Crjez1wAjnkmwf01LJSIiInXVZoDg7g+Z2XrAqDTpGXfPf+qGiIiIdBmVPsZrM2BEmn+smeHuv61ZqURERKSu2gwQzOwqYG3gMRZ3UXRAAYKIiEg3VUkNwjhgA29r0IYuqFevXgwdOjQrzdNPP52dZrPNNmt7phb069cvK+0111xTVT5Dhw7NTrveeutl59PU1JSdbvPNN8/Op1+/ftnpFi5c2PZMLXD37LRTp07NzmfUqFHZ6XLHBYBYD7npRo4s9FZuU1NTU1XpBg0alJ2moaEhO90qq6ySnU/v3r1Ze+21s9KstNJKVeUzatSotmcsU3pUfo5qjo8Aq6++elV55aZ7++23s/NpaGjIXufV/Ea9evWqKt3f//73rPnXXnvt7EdU56ikF8MUomGiiIiILCMqqUEYDDxpZg9SNkaCu+9Rs1KJiIhIXVUSIJxe60KIiIjI0qWSbo7/SCMxruvufzezvkDP2hdNRERE6qXNNghmdiTwR+DSNGk1YuREERER6aYqaaT4DWAr4H0Ad38OWLmWhRIREZH6qiRAmOfu80tvzKyBeA6CiIiIdFOVBAj/MLPvAH3MbEfgeuCvtS2WiIiI1FMlAcKpwCxgMnA0cAvwvVoWSkREROqrkl4Mi4DL05+IiIgsAyrpxTDVzF5s/lerApnZCDOb0mza6WZ2ipldaWavmlnvNH2wmU1rKZ2ZHWlmE81sxVqVVUREpLuqdCyGkibgy8DA2hSnIguBw4FLWpvBzA4Bjge2c/d3OqtgIiIi3UWbNQju/lbZ36vufj6wWyeUrTXnAyen3hQFZrYf0W5iJ3d/s1NLJiIi0k1YW4M0mtnYsrc9iBqFY919TE0KZDYCuMndR5dNOx2YDYwGbgJ2Be4helM87O4jUrrJwFxgE3d/tZXlHwUcBTBkyJBNc0cxnD17Nsstt1xWmpkzZ2bNX9LY2Mj8+fPbnjGpZsQ2iJHHFixYkJXmzTfzY6+VVlqJWbNmZaXJXdcQoznOmTMnK01DQyWVaUVNTU189NFHWWly5wcYMGAA7733XlaaVVddNTuf+fPn09jYmJXmhRdeyM5n5ZVX5o033shO179//+w01WwPvXr1ys6nd+/ezJs3r+0Zy1Sz3TU0NPDxxx9npcktF0Dfvn358MMPs9Plbj9Q3TGomhFYq/mNevfunZ1Pjx49WLRoUXa63BEqV1hhBd59993sfI488siJ7j6urfkq2Tp/Vvb6Y2AasF92iSrXWsRSPv0s4Ebg5mbzzALeJsp3XosLcb8MuAxg3LhxPn78+KzC3X333eSmOeecc7LmLxk+fDgvvfRSxfM3NTVVlc/QoUN5/fXXs9JcccUV2fkcffTRXHrppW3PWGarrbbKzmfLLbfk/vvvz0ozePDg7Hwghr1++umns9Lkzg8wYcIE/va3v2WlOeOMM7Lzeemllxg+fHhWmhNPPDE7nxNOOIELL7wwO93222+fnaaa7aGa4Z7XWWcdnn/++aw01QwJPGjQIN56662sNM8++2x2PmPHjuWRRx7JTrfmmmtmpxkyZEj2hVQ1wz2PHDkye12stdZa2flUE5QC3HDDDVnz77PPPtlpclTSi2HbmuXesreA5g0LBwJTS2/c/Tkze4xioPIhqXbBzN5w99/VtKQiIiLdVJsBgpl9a0mfu/u5HVcccPfZZjbDzLZz97vMbCAwAbgAKA9WzqRYg4C7v2FmE4C7zexNd7+tI8snIiKyLKjkQUnjgGOJQZpWA44BxgL9018tHAp8P9US3AWc4e6futHp7k8ALdZ/uftUYA/gV2a2eY3KKCIi0m1V0gZhGDDW3T+ATxoM3uzuB9eqUO7+JJ+uLShNP6zZ+33KXk8jGjGW3k8iAhoRERHJVEkNwhCgvCn9/DRNREREuqlKahB+CzxoZn9O7/cCflO7IomIiEi9VdKL4UwzuxXYJk36mrs/WttiiYiISD1VcosBoC/wvrtfAEw3s/yOriIiItJlVDJY038C/wGclib1Aq6uZaFERESkviqpQdib6DI4B8DdX6N23RtFRERkKVBJgDDfY8AGBzCzfrUtkoiIiNRbJb0YrjOzS4EVzOxIYqjly2tbrO6l2kGUctNOnz69qjwGDRqUnbaagYB69eqVnS53XACIwWJy01UzKE1J7u/72muvZeexYMGC7HS5A/oAuHt2utVWy3/cSK9evapKV83gXT179sxOV82gUD179sxON3DgwOx8GhoastOtscYa2fk0NjZWla6tAQA7Kl1nbd/VHr+rSTdjxoys+RcsWJCdJkclvRh+amY7Au8DI4EfuPsdNSuRiIiI1F1FY426+x1m9gjweWK0RBEREenGWm2DYGY3mdno9HoVYApxe+EqMzupk8onIiIidbCkRopruvuU9PprwB3uvjuwBREoiIiISDe1pABhQdnr7YFbANKgTYtqWSgRERGpryW1QXjFzI4HphPDO/8NwMz6EA9LEhERkW5qSTUIRwAbAocB+7v7u2n6lsCva1wuERERqaNWaxDc/Q3gmBam/y/wv7UslIiIiNRXpYM1iYiIyDJkqQsQzGyEmU1pNu10MzvFzK40s1fNrHeaPtjMprWUzsyONLOJZrZip34BERGRbqCS0Ry3qmRaJ1pIG90szewQ4HhgZ3d/p1NKJSIi0o1UUoPw8wqndZbzgZPNrMX2E2a2H3AqsJO7v9mpJRMREekmrLUBMszss8DngJOA88o+Wh7Y293H1KRAZiOAm9x9dNm004HZwGjgJmBX4B7gr8DD7j4ipZsMzAU2cfdXW1n+UcBRAEOGDNn0mmuuySrf7Nmzswd+mTlzZtb8JY2NjcyfP7/i+asZvASgT58+zJ07NytNNYMbrbjiirzzTl6FTjWD5vTu3Zt58+ZlpVm0qLpHezQ1NfHRRx9lpfnggw+y8xk0aBBvvfVWVppqBtpZsGABvXrl9WJ+5ZVXsvMZOHAgb7+d/9T2fv3yB5OtZvvOXQelNAsWLGh7xnbmY2bZAxvllguq+z7Vqiavao531eyvTU1N2fn06NGjqmNK7rli8ODBvPlm/nXwcccdN9Hdx7U135Keg9AILJfmKT9Kvw98KbtElWttyy+ffhZwI3Bzs3lmEWNF7Meng5rFC3G/DLgMYNy4cT5+/Piswt19993kpvnJT36SNX/JGmuswcsvv1zx/LNmzaoqnzFjxjBp0qSsNJMnT87OZ5999uGGG27ISpO7riFGgHzppZey0lQ7muOoUaN45plnstLceeed2fkccsghXHXVVVlpLrnkkux8pk+fzrBhw7LSVLN9H3DAAeQG5wDjxrV5TCuoZvuuZrTSVVddNXvEzWpHRc09mVYzgmg13wfi5Jhr6NChvP7661lpqjnerb/++jz11FNZaUaNGpWdT9++fas6plx22WVZ8x911FHZaXIsqZvjP4B/mNmV7p53tG2ft4DmDQsHAlPLyvacmT1GBALlPiTVLpjZG+7+u5qWVEREpJuqZDTHK82scFXv7tvVoDy4+2wzm2Fm27n7XWY2EJgAXABsWzbrmRRrEHD3N8xsAnC3mb3p7rfVopwiIiLdWSUBwillr5uAfYHqbnZX7lDgYjM7N70/w91fMLNPZnD3J9IQ1GObJ3b3qWa2B3CLme3t7g/WuLwiIiLdSpsBgrtPbDbpX2ZW0xOuuz/Jp2sLStMPa/Z+n7LX04hGjKX3k4DValZIERGRbqzNACFV8Zf0ADYFBtSsRCIiIlJ3ldximEj0IDDi1sJUYiAnERER6aYqucWwZmcURERERJYeldxiaAKOA7YmahLuAX7p7nlPmxAREZEuo5JbDL8FPmDx45UPBK4CvlyrQomIiEh9VRIgjHb3Dcre/6+ZPVmrAomIiEj9VfJMzEfMbMvSGzPbAni4dkUSERGRequkBmFT4F4zKw0KsAbwjJlNBtzdN6pZ6TrBwoULa54md6CYkkWLFmWlzRnYqXk+uWlXXLH507Db1tDQkJ2us/LJHdypxMzo2bNnVprcQZcgBqapJl1nGDx4cHaahoaGqtI1NjZmpzGz7HQNDZUcGov55Kar5vtUk27QoEHZeTQ0NFSVbsaMGdlp3D17EKXc+SGOdbnpqjlHuHtV6WbPnp01/8KFC7PT5Khka55Qs9xFRERkqVRJgPBf7n5I+QQzu6r5NBEREek+KmmDsGH5GzNrIG47iIiISDfVaoBgZqeZ2QfARmb2vpl9kN7PBG7stBKKiIhIp2s1QHD3s9y9P/ATd1/e3funv0HuflonllFEREQ6WSVtEG41s883n+ju/1eD8oiIiMhSoJIA4d/KXjcBmxMDOG1XkxKJiIhI3VUyWNPu5e/NbHXg/JqVSEREROqukl4MzU0H1u/ogoiIiMjSo5LRHH9OjOIIEVBsDDxSy0KJiIhIfVVSg/Aw0eZgInAf8B/ufnCtCmRmI8xsSrNpp5vZKWZ2pZm9ama90/TBZjatpXRmdqSZTTSz/Gf1ioiILOMqaaR4LbBOev28u+c/ALtjLQQOBy5pbQYzOwQ4HtjO3d/prIKJiIh0F0t6UFKDmZ1DtDn4DfBb4BUzO8fMenVWAVtwPnByeqJjgZntB5wK7OTub3ZqyURERLoJc/eWPzA7D+gPnOzuH6RpywM/Bea6+4k1KZDZCOAmdx9dNu10YDYwGrgJ2BW4B/gr8LC7j0jpJgNzgU3c/dVWln8UcBTAkCFDNr3mmmuyyjd79myWW265rDTVjG4G0Lt376xRBj/++OOq8unXrx9z5szJSlNNXssvvzzvv/9+Vpr+/ftn59OzZ8/skdQWLFiQnQ/k/0YAb7/9dnY+K6+8Mm+88UZWmrXWWis7nwULFtCrV178X832PWDAAN57773sdE1NTVWlyR3BL3cdQIx+mLtfVJNPNRYtWpSdpkePHlWlq2ZfamxszB5Rtpp8+vbty4cffpiVpk+fPtn5VHMMgvx9aciQIcycOTM7n+OPP36iu49ra74l3WL4IjDSyyIId3/fzI4FngZqEiCwuEHkkqafRTzu+eZm88wC3gb2A85rcSHulwGXAYwbN8632WabrMLdc8895KY588wzs+YvWXfddXnuuecqnr+aEw/ApptuysSJE7PS5J6sAHbccUfuuOOOrDTjx4/PzmfgwIHZ6+L111/PzgfyfyOAP/zhD9n5fPOb3+Siiy7KSnPddddl5zN9+nSGDRuWlebXv/51dj4TJkzgb3/7W3a6kSNHZqfZYIMNePLJJ7PSDB06NDufag7Wueu6WrkXAFDdhQNUFzAOHz6cl156KSvNrFmzsvMZM2YMkyZNykozevTotmdqZrnllqtqGOYLLrgga/4TTzwxO02OJTVSdG+hesHdF9L6SbwjvAU0b1g4EPjkdoG7Pwc8RgQC5T4kaheOMbODalhGERGRbm1JAcKTZnZo84lmdjBRg1AT7j4bmGFm26X8BgITgH82m/VM4JQW0r+R5v+Rme1cq3KKiIh0Z0u6xfAN4AYzO5zo4ggwDugD7F3jch0KXGxm56b3Z7j7C2b2yQzu/oSZPQKMbZ7Y3aea2R7ALWa2t7s/WOPyioiIdCutBgipkd8W6Up+wzT5Fne/s9aFcvcngW1bmH5Ys/f7lL2eRjRiLL2fBKxWs0KKiIh0Y5WMxXAXcFcnlEVERESWEtWMxSAiIiLdnAIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRglYHa1oWmNksIO8B4DCYssc+11hn5aV8lv68lM/Sn5fyWfrzUj5huLuv1NZMy3SAUA0ze7iSUbC6Ul7KZ+nPS/ks/Xkpn6U/L+WTR7cYREREpEABgoiIiBQoQMh3WTfMS/ks/Xkpn6U/L+Wz9OelfDKoDYKIiIgUqAZBREREChQgiIiISIECBBHpdsysT73LINLVKUCQujEzbX/LODOzGixzAvBXM/uBmW3Y0ctfltTi91kWdJf1pgN0lcxsgJkNT69HmdlyHbTcFjeszjiZmlm/WueR8tnGzDZ290WdlN8KZrZyej3SzJo6YJnd8gq1Mw9sZmaeWkmb2eodtMxtgPOAK4GPga90xHIzy9Ap+1EtmVlvAF/KWrG3Z/ssT1vL7dzMepRt140dcbypF/ViqIKZ9QS2ATYG1gXWAvZ29486MI+DgDWBD4A/u/vLacOryUnVzNYH9gFudPcptcijLK+TiHV2EkAtAwUzawA+B3wB6A+sDHzD3ee0Y5nfBEYBs4Gz3f29jihrO8pjzQ/k1WwrzU7YOwEfArj7PzussC3nexywI3A48F57todU7hXd/Voz2wy4CtgaeLszAtLO3I9ayNvc3c1sK2A08BTwjLvPzFzOicAYYBXgh8BT7v5uhxc4U7PtcxtgFvCRu0/LTHsw0M/dL21p3+nA8p4AbAY0An909+trkU8tqQahCu6+kNj5dgW+DFxZCg6qjUzNbNXSVamZHQ8cTwQHw4E/mdk6NT7A9QfWAXZLB7laeph4hjjuvqhW0Xza+T8GXiZOQIcA17j7nGprZNLJ7MvA2cQJ7edmtm5HlTmjHJ+ss3RS6J9qsi4zs7HVbCtlB9DjgB8DewK/MrNvdVjBmzGzw4CvASe5+zvAgHYu8h7grvT6SeAZUnDQSbUjnbkffUraDnYHLk7lOBPYL+d7m9muxO/xQ2I//SoRXNe92rxs+zwFOAP4JvAjMxudkfZbxLH1H82m92xv+dL+NyS9PgLYA/g3oA/wpfYuvx4UIGRodlCeCVwO/A5Y38x2SNPdzBozl7sacBpwaAoSRgAnuvsF7v4t4I/A92tRrW1mG5pZH3d/kDiwrAHsZWZrdXA+W5ZONOmKdB5xEqpZNWbZcqcDvwKuB3Yws01LJ9BUw1ARM1seGAscAOwLPJo+urCzg4SyA9tQM9sc+B8iYDkAaHMQltaY2arAwcCX3f3fiCD422Z2YPtLvXgfstAIrA+cDvQxs5OB+8zse9Uu393nuvus9HoO0Bf4fXrvNQxGO2U/aqMM/YDdgR2Ax4F+xDb/yS2DFtI0mtkG6fXngZ2Av7r7NHf/PvAIcKqZ9a3X7YZmtwY2AbZ39+0AI67On1zC91uvFKilbXsX4PPADDPby8wuMrPl0kVfe8q4A/BLPn1O/TqxP/YCDjKzBjNboz35dDYFCBVqVkW1q5mNJXae04gNdWcz28TM9iSuHnIORK8BE4nbFQcBG5Ki9uRWYL67z+2Ar/IJM+tLRNOXpYPbw8BviIPMN0sHjg60r5ldYGbfJU7YZjW+P2dmWwDPAncApxLV5oeb2WqpmnKnSn8rd38f+AZxm2Jvd59AXGFtBhySGxi2V7qSugg4FrgUuImo2XoyYxnNjwEfAq8C7wO4+/PAfwAjO6C85dW55u7zgb8T7QXOJmrMjgUmWGrf05680st9gd+b2b5Qm2C0DvtRed7l2+484ve7EPhPYB93fx3Ymbjl0JI1gPPN7HfAicQxbVUzWw/A3S8DZhI1mZ2uPDBJx4p3gKlm9gPiFuzBKdjf2pq1AzOzXsRV/MwUBLwGvAv8EzgfGA+sDlxabeBoZj1SPnsB/wesbHGLZx2iluKz7r5Lqsk8gjj29KomrzbKUZtjj7vrL+OP2InuJ042txP3t/sC3weuIQ6uozKWV2oHcjhwS/r7EfAK8PX02UFEtemAGnyfdYmd5XLivhxE9d2fgREdsPwNifv1PYCexBX4ucTV91zgwA7+PtbCtP9K+a0GDCIOnncDLwJrV7nO7gE+A3wRuBZYoxO2vR5lr/unbXETYEiadiFwWJXLHgX0Sa8vA24v++zbaVph3VaZ17FpezuXqEFYBeidPtsW+BfRjqCj1lsf4CxglRr+NjXdj9rIexviRAmwH3GS3y+935oIkLdcQvqfEgHh0en95cD30rK+TAScK9fyO7RSribgu8BWRBX9ucCKaZ0+UraejyZOziuUpe2Z/jekY9Av0/7aFzgBWDN9PoEIsntWWcYV0v9hxLDLM8s+u5uoYe4DHAU8AaxXo/X0+9I+1KHL7uwfvSv/EVVTdxInup8Qkej/Adukz0cAw6pY7kHECWxj4OfECew84t75L4ApwIYd+D12Bv5f+g5rESftnwA3E1c99xKRb3vz2ZOoGbmSqHbdquyzjYgTxXXAQDro5FO2/M2Alcref4+odl0lvd+8dJCoYtm9iavqO9JOv0Enb4eHAls0m9afaJD3mQqXsQNxhUk6YL4IXAEcn6Zdk7b1i9K22SHfETgmLXcMEfReVPbZKcBkYKMarLMeNVhmp+xHreRdurD4LPAXYBFxhTqAOKneAfyWOLl/sY1lrUO0z3mUuKU0GDgsfY8ra/F7ZHzPcem7PV/6DYlbYBcAfwD+Pe3Xo1tJP4IIQP+buJU1uuyzk4hAI/v7EbXGw9N+0o+oiXkpHQ8OSvP0JS74rgRuq+VxghQsdfhy6/XDd4W/5gcV4iph9bTz3A0slw6gzwK7tiOfHwL/ll43pg332rTxjwAGd+B32gKYSlSJXZ92tJ2JK+ufESfs3TsgnzFEFdtg4GTgOSJI2KlsnhXSTr5SB+RXOmD2BJYnArczy9dd+r4vAsM7IL9eaVtYrRO2w3HAeWXvr6ZZIEBcIV2Vscxd04H3JOLKd1SadjHwH2mebYgakuxalrJ81qUsuCUCqxWJBmZ/I67wGtNvtgU1uMKq0W/SKftRG2XYJu1XnyUaFs5kcU3CKGC70nZCBQE4UR0/majFmUDUgHRYTU7G92q+L/+ZuP20U5reh7jldTxwXPk2Q9ToHpBeH5/293PTdvdr4AfptxuYtvuKAuoWytiQ/g9K62u99H4MMAk4pmzenkDfem+zVX0Db6MSAAAgAElEQVTPehegK/ylna2JxRHs94Fd0uvvENWXw9ux/L2Iq4DyA+lDRCO+5TvwewwnrnhOL5v278ANZe9L1XZVX9Gnk8K+RC3BjkQtwueIE9tNpQMnsCVxZbB6O7+Xlb0ulX8I8Kd0kFspTTuWCEjWqvc2lfn91iRua/0svb+RZlemaX2PquS3K9uOzyC6al6a3vcl2r5cBJwDNHZAuc9I+87ANO2cdND+c9l8RwPH1ns9Z3yvTtmPWsh3KHBG2ftDgAvL3n+OaIfw9XbksQtxRf4odQjWmu3LK7H4VsHWwHvA/un9eMpuKZSl2Y0I3E4nag3WTtvX94hbjZcTx+vPUP1thcHAtLJt+lTgadJtHCIwewg4ud7banv/1EixBWa2g5ntk16fQDQS/DnRmreBeADLf6TW1l8FfuHuL7Ujy7uJqqkDzWx7M/sisTNc6NEwrt1S95tjiSuOVc1sHQB3PwdY0cw+k97PSf+9ynz2IK6ennX3x4mq/DPd/V6i29TbRI0LpKsVd3+l6i/Gp1r0H0k0SLuY2EkPJRpnfdfMLiBqfk529xfbk19nc/epRGvosWb2/4htZZGZrWlmK6YeFPcTv22rv12z1uArENWk1wFHmNme7v4hcB8RrEI7uhya2TDgSOKqdhPgOxZPNTyX+P1fSPMdTrSluKuVRS1VOms/aiFfIxrHrm9mP06TXwVWMbM+Fs+9uJe4Sj7TzPaqJh93vxXYnrhaf7ojyp6Zf2lfPoU4md9uZhM8ej7tC1xpZhcSQezyLaS/mbjfv29a3AtEFf9UInj6IKWb4VX2XHD3N4naiXvNbEV3P5s4P1xqZlu4+11EQLK3xUPauuxTFfWgpBZY9AW+CfgWUcV/CRGJTiAaoZyZDmyrAX9x98kdkOeqxANW9iECkFPSCbZDWPTzvQFYSFzBPU1cJcxhcXVoe4IczGxjYmfcz92fNbMViQZQ2xK9Pf4TOMrd/2lmPavdQVvJ+0Ciz/HJxK2LU4gGQlcRDa1GAr/zTn54TbWa9ZppdPf5ZjaCaCy4A7F9Qpzk+wBf8gofZmNmG7j7kymgmku07P49cIS7X59aWTd4O3rNpIPiV4n1/h6wHnHVdSuxzZ1PNIxbmWgcV3HPi3rqjP2ojfx3IW7P/NPdzzKz36aPLiDWZaktwSjgyI4KUGqt2fZ+LLCvu+9gZncR3+tMd/+DxcOvtiNqoJ5dwvL2JAKME9z9mtRb5zCiVuJXnrrCtrPMuxCByjh3f8fi+TVfJbqo/yv1wPiwvfnUkwKEZlIkvsjMziBab//O3Y9OXZk2I042HwDf9+i60tH59yN+l9kdtLzVgOXc/ZnUB/dbxIFtKPF9ehE1FTd0QF7rE/f67iN2xC8QDS1HEY2lbkwRfoczs68Di9z9V+n9BkRwcpS7T69FnrXS7GB5JFEd+qS7/zIFCT8jAtXj0jyD3P2tCpf9WaJh1Y+INiK/IW6ZvUVUi+7t7jd2RPlTEL0fEcTcRrQmn0Y8Ve6p1DWrt7t/0J78OkNn7kdLKMMeRJuR14jbN7e6+3+Z2dnEvfCxRK3NCOJC41DvpMeZt0ez7b0H0WPhIeI7fJ64pfZD4gLj10TNQJsnLjPbjbid8KOyIGG5jqqVTXk0DxL+nWiguiMwr6sEaK2q172Npe2PxcFSD+IK9IdEX/2PgT3TZ43E1ds5dEDDuk74Tv2I3hB3EdVunyFqQz6bPh9Euv9f+v7tzG854urmXmLn3pC4/7cX0Ksj8iFONtZ8OcTVwVOk++bpd7yWjC6nS9sfcXJ9iBhP4CXgtDR9OPAY8OPSd61weY1Ed6x7idbbe6Tt40mi0dbWHbW+KPbMOYO4T38JcZthk3qv34zv0qn70RLKcBeweXq/OdGm59tl8yxPtCGYRJWN7+q8nk8Crk2vVyN6APRN7+9M33e5zGXuQnQZ/1INy70LUZNUapPQ6Q07a/bd6l2Ape2P1BWFiMQPJlpxv088WQ7iSqFPvcuZ8X2aiCuLa4nuT7PSSaddDQPbyLN0kt6MuF++fQcue62y10cTVwgnEEHdD9J3G5l+uwfohF4GHfjdyhtobU1UZe+c3o9K3+3U9H4NMp69QLR0P4MI2tYinrx4WNrOF1HW4K6DvktLPXP+krbBC+nAnjmd9Nt0+n7ULP/liZq5rdP7Un/+Z4Bz0rR+xIO86tYtsR3fb3fitlmpG3KvtK6/R7Ql+gtVNgQnruZr2jCZ6NL9KHFhUpMgsR5/FT9mdllQqn41s+bVr9sCD5nZfI/q1wV1LGYWjzEiHjGzo4j++z2Iq7phwCvl1XsdaKGZbUpUvX3H3e9s7wLTPe0m4EEz+ynxBL4jiDYGaxNV2PsS94ZPJ66Ij3D3V9ubd2cp/Q5l37UfsIeZPe5RtX0gcGvaDs/NXPwr6e83xLM1bgbed/cbzGwR0VC2Iz0CHGZmt7j7E8TT+g4CHiRa4ld0S2Rp0dn7UdltmpHE7Z/3iC6o3zOzb7v7E2b2LPGwtj+kMs5J8yz1mt1W6Ed0PRxP1MbMSLNdSdRE7gEc7lW27XD3O9pb3gryuNHM7vQucEsnh9ogJOl+6MpEQ6Mm4iSzLdG3eWtgA2CWuz9TrzJ2FItHHQ9396NqmEc/4ulrUzvi4FnWNmR9ourxbWKAn3vS56cBI939a6mRXQ93n9fe79HZzOwLxFXgQUQ18gFEq//r3H2mma1NtLWYWuXyxxC1Lv2J22TrdUzJC/msQDQahaga70M0ID20KwVtS1Kr/agsOPgicQV9F9F1+Fyia/AJxMnzSOCr7n5njQL9mjOz/kQDzz7ExdgooubpeTNrcPePzWwFXwpGk1wWqZsjn9QcfJfo1nUwMbjPQOLe7HpES9h/dvXgoKy7zQvAcKvB4E8l7j6ndBLrgODASpG5uz9FPHp1VaLFcMkNQM/UO2JBVwkOWugCNY1oBHsJcYvkz8TJ4atmtrK7v1BtcADg7pOIWwu/AN5NjR47XDqgX0xcDX6XOKmd3B2Cg1rtR6kRHSk4WJtolLcn0dNkMDHs8nnEIEBPEI8pv7OUpiPKUGtmNjIFwVgM+3418dTHTYmakPuIbpqjPDUCV3BQP6pB4JM+2xOIx8D+grj/NStVvx4B3O3Rn7bLSwe3LwJTvQt0+WtWFXk8cQ/9CeL+79+JQX5+DOxPXLGO9xg2uEsxs5Geum2Z2epEt9Am4ipxJ6Jr14868ruZWS93r/ntso7umbM06Oj9KPWSOBS4wt3fsHi2xeHEuBTfJWpenrMYYGyid8HucxaDLZ1GXIhNJXorHEAErKsRDRH/RfQQGUI88KnL3M7tjhQglOms6lfJZ2bHEUHAQcST3n5JPHjpMuB14rbDb9L97qVeWTVyL+LqcArwLXf/TbqSXJP4btOJE0XvrnhSkMqY2SrE7c27iGdEfEi0L1gX2DgFDdsTT+07rKvWxKSakQOJQP8Ndz8hTT+caHS8I9HGwz0eSCR1pFsMZTqr+lXymNnyRAvyA4hGSw8RJ9DdiG5nBlzcVYID+FSV8Ch3n0EEP981s4PcfVGqsXqUqEVYWcFB95Xutc8A9iae5X8C0WvhZ0Qt2bfNbG+iq+VFXS04KL+Nlrbry4lugeub2Q5p+q+IniGj3H2WgoOlg2oQWtFZ1a9SGTPrTbQHOd/dt00HnXeJsTB+0xWrr9NV05HADu4+x8y2I2pGLiC6sU0g7jPPrGMxpROk+/L9iYGsjiIeZnU70UX0ZOKxyve7+61dqUFis1uEBxIXpW8T7Q6+Q/RaeI54+NPZwBfc/bU6FVeaUTfHVig4WLq4+zwz+xBosHje/XBiNMCbulpwUOqRQTyF7yxf/Nz+u1LQsDdxT/ZbCg66r7LbTJ8jAsOJRKPORUQD3F5Em4SvN09TlwK3g8Xjkw8mBky6mRiJ8kqi3cWxxHffU8HB0kUBgnQlLxMPUzmX6MXw5Wr7RtdT6q65FnG/9bbSdDNbx2NQmg4fq0KWPik42JwYlvxr7n6/xeBP04lnLOwLDDWz75cuWLpKcGBmawLT3X2BxTgz2xKNOvcjGiM+mD77BTAf+LW7v1G/EktLdItBupTUqG8o8SyALnUvFj65H9tAPE3wXmKQpPWIxrEvAz8BXu4qJwJpHzPbkagJ+767/yht37sQT768CBji7o/Us4y5zGww8RyZWUQN2XyLh5v1Jp4AeoC7zzWzbxEB//PezR4w1F2okaJ0KekZB690xeAA0igzcTXYn6gFuZNoGDuJGOjqFQUHyw6Pp/ztAxxuZl9J28Z7xAPa5nS14CB5j2g/sQLRZRHiCaeHA3ul4GA/okfSPAUHSy/VIIh0MjMbRXTV/CMxJPUdavOybDOz3Ylt4XaiDcLV7v4/9S1VnmYNEnsRz+7YB3jC3S80s2uJoGEm8cTEr7v75LoVWNqkAEGkDlLXzY/Luy921QZo0jEshnP+ITHE/E9K3QO7wjbRLDgYSdR+vGpm44nRSB9394vNbCzRQ+dld3+5fiWWSihAEBFZSpjZTsQw8ye4+w31Lk8uMzuRGN79XaLx4cHADsCuRJuEs919fv1KKDnUBkFEZCnh7rcDXwMeq3dZKlH+ECQzm0AM27wDMBkYmm6d3U701lmeaHsjXYRqEEREJFuz2wojiFsH6wCjiaGbd0tdGT/n7veaWV89EbRrUQ2CiIhkKwsOjgV+Dowjuu9+3t13SsHB14DTzGx5BQddjx6UJCIiVUkNK48Bdnf3l81sIHCSmX2ZqEnYCzjI3d+vZzmlOgoQRESkWqsC16bgoMHdzzez94ERxIOR9nf3p+taQqmaAgQREanWS8BeZvYnd38mTXsfmOHut9axXNIB1EhRRESqkp7n8W/Exea/gAHAScQopM/Vs2zSfgoQRESkama2CrAnsAfxmOWz3P3x+pZKOoICBBERaTczawTQg5C6DwUIIiIiUqDnIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgkg3Zmaza7DMEWZ2YCuf9TCzC81siplNNrOHzGzNji6DiNSenqQoIrlGAAcCv2/hs/2Jx+9u5O6LzGwYMKcTyyYiHUQ1CCLLADMbb2Z3m9kfzexpM/udmVn6bJqZnZOu+B80s3XS9CvN7EtlyyjVRpwNbGNmj5nZyc2yWoV4zO4iAHef7u7vpPQ7mdl9ZvaImV1vZsul6RNSmR5JtQ83pemnm9kpZflPScMKY2YHp7I+ZmaXmlnPUhnN7Ewzm2Rm95vZkDR9iJn9OU2fZGafW9JyREQBgsiyZBPiMbgbAGsBW5V99p67fwa4CDi/jeWcCtzj7hu7+3nNPrsO2D2dcH9mZpsAmNlg4HvADu4+FngY+JaZNQGXA7sDmwJD2/oSZrY+UVOxlbtvDCwEDkof9wPud/cxwP8BR6bpFwL/SNPHAk+0sRyRZZ5uMYgsOx509+kAZvYYcavgn+mzP5T9b37Sr5i7TzezUcB26e/ONPRvHyIw+VequGgE7gPWA6aWnttvZlcDR7WRzfZEMPFQWlYf4I302XzgpvR6IrBjer0dcGgq40LgPTM7ZAnLEVnmKUAQWXbMK3u9kE/v/97C649JtYxm1oM4qbfJ3ecBtwK3mtlMYC/gduAOd/9K+bxmtvESFvVJ/klTKRnwG3c/rYU0C3zx42Gbf8fmlrQckWWebjGICERVe+n/fen1NOIKG2Ignl7p9QdA/5YWYmZjzWzV9LoHsBExJPD9wFZl7Rv6mdlI4GlghJmtnRZRHkBMI24HYGZjgVJviDuBL5nZyumzgWY2vI3vdydwbJq/p5kNqHI5IssMBQgiArCimT0OnAiUGh5eDnzBzCYBn2Vxb4THgYWpsV/zRoorA381sylpvo+Bi9x9FnAY8IeUz33Aeu7+EXFL4WYze4RPV/H/CRhoZk8A3wSeBXD3J4n2DLenZd1BNI5ckhOBbc1sMnHrYYMqlyOyzNBgTSLLODObBoxz9zeXgrKMB05x9y/WuywiyzrVIIiIiEiBahBERESkQDUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQoQREREpEABgoiIiBQoQBAREZECBQgiIiJSoABBREREChQgiIiISIECBBERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpUIAgIiIiBQ31LoBUxsx8CZ9lTa/FZ8qr7c+6armXxbyW5rIpr9ota+LEibe5+4RWEy5jFCB0IaWN2sw++WvP+45clvJSXspLeXWDvAYjn9AtBhERESlQgCAiIiIFChBERESkQAGCiIiIFChAEBERkQIFCCIiIlKgAEFEREQKFCCIiIhIgQIEERERKVCAICIiIgUKEERERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAoUIIiIiEiBAgQREREpaKh3AaRit7n7YAB3r3dZWjMYeLPehahAVyhnVygjdI1yqowdpyuUsz1lXNq/W6eypfhkI12MmT3s7uPqXY62dIVydoUyQtcop8rYcbpCObtCGbsK3WIQERGRAgUIIiIiUqAAQTrSZfUuQIW6Qjm7Qhmha5RTZew4XaGcXaGMXYLaIIiIiEiBahBERESkQAGCiIiIFLm7/rrpHzABeAZ4Hji1hc97A9emzx8ARpR9dlqa/gywc1vLBNZMy3g+LbMxTR8O3Ak8DtwNDCtL82NgGjAPeL20PGB74BHgMeBfwM1puS8Ab6XpjwF/6qQyTknlfK20TGC7VMYpwG+AvmXr8vU0/+PA2Dqvy/JyXgVcl5b7JPB+2bq8I7OM30zTHBhcNt2AC9NnjwNjyz77KvAc8Cowo2xdbgpMTu8vZPF2+SLwHjA1lW/FKtZlteV8FZgPzCxbl+XlvLjs956e1nlpXV5ZxzKeCbwCzObT+/eDwF9ZvK//uI6/9ydlbHYcmgksILbNx4Cvd+Lv/Vz6+2qa1pc47jwNPAGcXclxs7v91b0A+qvRDws9iRPqWkAjMAnYoNk8xwG/TK8PAK5NrzdI8/cmTlYvpOW1ukzixHNAev1L4Nj0+vqynW474Kr0ejfioP8CsCHwMHHw3QB4Flg/zXcN8Ex6fQnwXB3K2EicrB4HBqVlzgBGpvl+CFydlrkrcXC7FtgypanXutyQOBCXynkLcHdZmV9rx7rcBBhBBCXlB+JdgVuJA/KWwANp+sC0DgcTJ/yXgZXTMh9P81pKe1H63ucAv0/r8lTgvzuxnFOBjdPrKWkdPVhWzieAm1OaPwKP1WFdtlTGLYFViAChfP++Ang+vf428G4df+8DSmUsPw4BhwG30b7jULXlHEgEoC+m/32BbdM8jcA9wC5LOm52xz/dYui+NicOCC+6+3ziRLtns3n2JK5+IQ5y25uZpenXuPs8d59KRMqbt7bMlGa7tAzSMvdKrzcA7kqv/7esDBsQB47n3f0JYiefnD53YPk031jg/vT6IWBYJ5fx/4grx+dS/tsTV2KN7v5smu8OYOe0zD2Bn6T5HiAOhDfXaV1+BZhfVs5BxMEO4B/A4GrWJYC7P+ru0yjaE/ith/uBFcxslbR+7gDWJQLAW9M6uhkY6u73exxxf8vi7XJP4N/TfKX3nVHOScCz7l6qWZkMHAwsX1bOj4mrd4gr3nU7eV22VMY9U/lmlKUv7d+rs/j3bgJ6EdtGZ//e1wBrlpWxeTmfp8rjUHvK6e5vu/s7qcwT3P1Dd//ftMz5RC3csBbKW37c7HYUIHRfqxFXjyXT07QW53H3j4nq3EFLSNva9EHAu2kZzfOaBOyTXu8N9Dez0lX454HXzGwwsG1Zmb4O3GJm04E1gLPSZ4uIA9sU4AhgTieUcQJx9fJGKuPqRNVmLzMrPa3tS0D/lO9qwEtl6/IjYG6d1uUKQENZOdcmro4AFhJXYpOBY4h1W2kZl6Stbaf0vzT9I+K2SPn8A9I8Q9x9OrEuFxBBY852WW05Pyr7bDoRsK6dXpf0T38Q666R2C4PIW6D1aOMre7fwKpErcEgFtcwDKpxGVv6vZd4HCK27/7AjcCoNpbdkeVsdVlmtgKwO3F771PLanbc7HYUIEitnQJ8wcweBb5A3I9c6O63E1H5HsAfgPtYfJI6GdjV3YcRB7UfpOl/JU6+XyB20KM7oYy3EPdMt0tlXJjS3A6cZ2YPAh8QB+haq2ZdHlBWzkVl0x8h1uV4oor/5E4of3t1xjquxiVEFfp44EPgoLqWpuv6K3F7YDrRxmaHehYGwMwaiH3qQnd/sd7l6WwKELqvV4mr3ZJhaVqL86QdYQBx9dNa2tamv0VU2TU0m467v+bu+7j7JsB307R303w/Bx529x2Je4MfEwHBGHd/IM3zDPDZ9Pq9sjLeQVzV1bSM7n4mcCBxdWhEdekwYKK7b+PumxO3Id5L+b5KNCYslbMJ6FOndfmqu99XVs6XicZ0ECey5VN+9wK9U+1DJWVckra2ndL/0vQm4h5z+fyldTnTzIYR67IXEYjlbJfVlrOp7LNhxPp8gcVVzKSyfJBev5XK+CZxlTmqTmVsdf8mGtiukMo6A1iOxTUdnfl7t3occve3iAB8AHAB0X6hM37vJS3rMqLd0/ktLavZcbP7aa1xgv669h8xUueLRPV4qSHPhs3m+QafbmxzXXq9IZ9uHPQiUR3d6jKJBnTlDeuOS68HAz3S6zOBH6bXPYlGSy8CuxCNviYBGxEH2lLDuquBF9PrY8rKeAJxi6HWZRyUljmdCFb6pGVuk+bpTZwULkjL3I1opHgd0Rhqch3X5YbAymXlfAb4n/T+6LJ1uT9xP73iMpZtQ9P4dGOw3fh0Y7AH0/SBRDuJwSnNK8AQFreXKG+k+Iv0vX9CNFK8jmikeEXuumxHOacBY9LrKWldNm+keEsL2+WPgXfqVcaytLP59P79K+CF9PoUPt1IsbN/79J2Xmqk+I30e69COg4Rt9AmdeLvvWL6mwoMTJ/9F9FTqkclx83u+Ff3Auivhj9utNx9lrj6+W6a9kNgj/S6iTgZlbpBrVWW9rsp3TOk1rutLTNNXyst4/m0zN5p+peIBn7PEq3Qe5fl/SRxVTs3HUBKZbw27eCTiKvzW9JyX0vLmUQ00juvk8r4JNHd6aXSMomT1ywicDip2bqcmeadDIyr87q8N71/hjgxlMo4rWxd3g9cmlnGE9J3/zj9Lv+dphvRBfCF0vcvS3N42e/4etm6HEe08ZhB9GAorcvybo5/Jw7mueuy2nK+RgRNb5Sty8vLtoFLytblm8T28TjwP0SbmXqV8V+pPIvSMp9IZXyIxfvRg8BP6/h7n0N0sS2V8b/SunybqNl6iti/1+vE3/v59Pe1NG0YcUvrKRZ3X/16W8fN7vanRy2LiIhIgdogiIiISIECBBERESlQgCAiIiIFChBElkFmttDMHjOzKWZ2vZn1zUw/O3P+K83sSy1MH2dmF6bXh5nZRen1MWZ2aNn0VXPyE5H2U4Agsmya6+4bu/tooiX8MeUfWqj58cHdH3b3E1qY/kt3/216exjxJEAR6UQKEETkHmAdMxthZs+Y2W+JfvWrm9lXzGxyqmn4cXkiMzvPzJ4wszvNbKU07VvdfqQAAAIaSURBVEgze8jMJpnZn5rVTOxgZg+b2bNm9sU0/3gzu6l5gczsdDM7JdU6jAN+l2o8djOzv5TNt6OZ/bnjV4mIKEAQWYalJ8HtQvQNhxhc5xfuviEx/sGPicdMbwxsZmalgaP6EU9u3JAY+Ok/0/Qb3H0zdx9D9CE/oiy7EcRAO7sBvzSzprbK5+5/JEanPMjdNyb68q9XCkiArxEPARKRDqYAQWTZ1MfMHiNOvi8TTykEeMljtDuAzYjhoWd5DErzO2JQKIiH3FybXl8NbJ1ejzaze8xsMjEmwYZleV7n7ovc/TniIUjr5Rba48EtVwEHp0F0Pks8IU9EOlhD27OISDc0N12RfyKNWDun5dnbVHri2pXAXu4+ycwOIwYwaj5Pa+8r9WtiYJ+PgOt98ciXItKBVIMgIq15kBg9crCZ9QS+QtxOgDh2lHolHAj8M73uD8wws14URzX8spn1MLO1icdJP1NhOT5g8dDKuPtrxGN0v0cECyJSA6pBEJEWufsMMzuVeC6+ATe7+43p4znA5mb2PWIsgP3T9O8DDxDjVDxA2YmduJXxIDGK5DHu/lGqtWjLlUSbhbnAZ919LnG7YyV3f6odX1FElkBjMYhIl5Oel/Cou1/R5swiUhUFCCLSpZjZRKIGY0d3n1fv8oh0VwoQREREpECNFEVERKRAAYKIiIgUKEAQERGRAgUIIiIiUqAAQURERAr+P+1778jPpruFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d30e604a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'what do you say about a <unk> who dies ? you pledge to celebrate his life .'\n",
    "test_data_vector = X_test[5740:5741,:]\n",
    "viz.attention_map(text,test_data_vector,idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss how the attention weights show whether the system is working for these examples:\n",
    "X-axis of the graph of the graph is the input article, and Y-axis is the output predicted title. The graph shows the probability of words in Y-axis appear in the prediction when words in X-axis appear in the input article. White implies high probability and black implies low probability. For both good and bad examples, graphs have a lot of white squares which implies high co-occurrence probabilities between each pair of words. Attention weights is one way to make prediction but most output does not make seanse. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the problems that your system has the most trouble with. \n",
    "From the good prediction examples, we can see that the model predicts titles relatively well in the stock market field because there is a large portion of article data in the field of stock market. Most stock market articles and titles have the same format, and so after training the model, the prediction titles are great and some are even perfectly matched with the true titles. However, some predictions are totally opposite to the true titles in the semantic meaning or have wrong objects (like country, city, high or low, fund or stock, open or end). More data and more training are needed to improve the model. Comparing to market news, sports news is much harder to predict summary information because of lack of a clear format. Other daily news, like politic news, are more free in title and in the first sentence of the news, and are also hard to generate summary information. \n",
    "\n",
    "Also, the neural network mechanism tends to fill in details when details are missing. For example, ‘the jse all-share index dropped by #.## percent to ####.## on wednesday .” the attention model predicts ‘shenzhen stocks exchange down’. The true title is ‘jse ends lower wednesday’. JSE index represents the performance of South African companies and has nothing to relate with Shenzhen stocks. These errors happen most often when the number of decoding beams is small, since the model stops considering the decoding where the sentence ends early before outputting the made up details.\n",
    "\n",
    "Some mistakes in the predictions are obvious. A large part of the predictions with attention or without attention have the problem of repetition of words, like ‘n’t n’t n’t n’t n’t n’t n’t n’t n’t n’t n’t UNK UNK’, and ungrammaticality, like ‘markets malaysia malaysia in’. Predictions have a lot of proposition words, like ‘to’, ‘of’ and ‘in’, and sometimes only have proposition words in the prediction model which make the predictions have no meaning at all. Also, because of the restriction of vocabulary size, there are a lot of ‘UNK’ and ‘<unk>’ in the predictions, which make the predictions harder to understand. Syntactic problems are hard to see from these two models, since there are not enough meaningful words in the predictions. \n",
    "\n",
    "The rogue score of the attention model is low and is hard to improve under the limitation of memory and training speed. The rouge score of the attention model is not much higher than the rouge score of the model without attention. Looking into the prediction titles, the model with attention does not perform better than the model without the attention. \n",
    "\n",
    "Models use abstractive approach most of the time, and use lexical substitutions, generalizing, compressing to generate prediction titles. The length of titles are shorter than the length of articles, and title words are not directly from article words but semantically generalized from article. \n",
    "\n",
    "### Compare your different system outputs to reveal the pros and cons of each.\n",
    "Uni LSTM without attention model is fast to compile and train, and is easy to overfit. Can only generate good summary for articles have a specific format and have a lot of similar training data. Even with double vocabulary size, Uni LSTM without attention model cannot capture more information as expected. \n",
    "Training speed of Uni LSTM with attention model is much lower than without Attention when giving the same parameters. With smaller vocabulary size, batch size, number of layer and epochs, Uni LSTM with attention model predicts a little bit better than  Uni LSTM without attention model. If we have enough memory size, and take more time to train  Uni LSTM with attention model, predictions would get much better. \n",
    "\t\t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one of the problems that you identified and provide a proposal for what you would do to correct the problem. \n",
    "\n",
    "### Background / Problem Statement  \n",
    "News editors from different news categories do not use language in exactly the same way. Each branch of news have its own way to deliver the information. Think about the difference between markets news and political news, or scientific reports and sports news. There are big differences in the vocabulary, tone, formality of language, and style of content structured. Models perform best if they are trained and tested on the news in the same category. With enough training, the model will capture details, like politicians, organizations, and countries.  \n",
    "\n",
    "In the given dataset, news categories are mixed, including markets, education, politics, sports and more. The data is imbalanced. Most news are markets data and both models predict much better in market news than other news. Some predictions in political news are correct. Predictions in other fields are extremely bad, and usually give predictions with ‘UNK’ and some preposition words, which are unreadable at all. However, this also make sense because news in markets usually have the same format. The first sentence addresses information of country, date and trend directly and clearly. The title is a straightforward paraphrase of the first sentence. With the same format, the models learn well in markets mews.  \n",
    "\n",
    "### Object / Goal\n",
    "Both models built above do not perform very well. The accuracies on test data are about 16%. In order to improve the model in generating news title in field other than markets, the model need to learn more information about other fields. \n",
    "\n",
    "### Methodology\n",
    "The simplest way to improve the quality of the prediction titles is to train the model on more data, but at the same time we need to consider about the quality of the data. If new data is still unbalanced, the improvement of the model prediction would not be significant. I come up with 3 approaches to improve the model. \n",
    " \n",
    "First, to reduce the appearance of ‘#’ in the prediction of summary title, I will keep ‘#’ in the form of numbers in the input article and title, and keep ‘##.##’ in number with decimal places. This replacement distinguishes ‘#’ and will have relative lower probability between numbers and other words.  When using ‘#’, high frequency of ‘#’ makes it having high probability to occur with many words, which we don’t want in the prediction. Both model of Uni LSTM with and without Attention will have less predictions that only have ‘#’ in it, and will have predictions on stock price, date, time, and frequency.\n",
    "Second, I will add encoder and decoder pre-training. Our data only use the first sentence of news as the input. However, not every news has summary in the first sentence. Usually, more information is in the following two sentences, and sometimes the last sentence of the news gives the summary. Pre-training subsets of the model on full documents will utilize the rest of the text. Information capturing from the pre-training would be much more than information in the first sentence. \n",
    "\n",
    "Third, I will try Bi-Directional RNN and LSTM when building the attention model since more information would be available. Two models built above are both Uni-Directional, and compute the attention weight for the current input word given the current and previous words. Adding the information of the following words, the Bi-Directional model will make network easier to decide which values to assign the neurons. \n",
    "\n",
    "It is not guarantee that combining all  three approaches in the same model would give the best result, and more tests are need to get the best model. \n",
    "\n",
    "### Reference  \n",
    "Tilk, Ottokar & Alumäe, Tanel. (2017). Low-Resource Neural Headline Generation.    \n",
    "https://arxiv.org/pdf/1707.09769.pdf  \n",
    "\n",
    "Lopyrev, Konstantin. Generating News Headlines with Recurrent Neural Networks.  \n",
    "https://nlp.stanford.edu/courses/cs224n/2015/reports/1.pdf  \n",
    "\n",
    "https://www.elsevier.com/connect/new-open-access-resource-will-support-text-mining-and-natural-language-processing  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search on the Decoder\n",
    "resource: \n",
    "https://gist.github.com/nikitakit/6ab61a73b86c50ad88d409bac3c3d09f   \n",
    "\n",
    "https://github.com/ottokart/beam_search/blob/master/beam_search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = beam_search(model.initial_state_function, model.generate_function, X, y_ix_to_word['<S>'], y_ix_to_word['</S>'])\n",
    "\n",
    "for hypothesis in hypotheses:\n",
    "    generated_indices = hypothesis.to_sequence_of_values()\n",
    "    generated_tokens = [reverse_decoder_vocabulary[i] for i in generated_indices]\n",
    "    print(\" \".join(generated_tokens))\n",
    "    \n",
    "def beam_search(initial_state_function, generate_function, X, start_id, end_id, beam_width=4, num_hypotheses=1, max_length=50):\n",
    "\n",
    "    if isinstance(X, list) or X.ndim == 1:\n",
    "        X = np.array([X], dtype=np.int32).T\n",
    "    assert X.ndim == 2 and X.shape[1] == 1, \"X should be a column array with shape (input-sequence-length, 1)\"\n",
    "\n",
    "    next_fringe = [Node(parent=None, state=initial_state_function(X), value=start_id, cost=0.0, extras=None)]\n",
    "    hypotheses = []\n",
    "\n",
    "    for _ in range(max_length):\n",
    "\n",
    "        fringe = []\n",
    "        for n in next_fringe:\n",
    "            if n.value == end_id:\n",
    "                hypotheses.append(n)\n",
    "            else:\n",
    "                fringe.append(n)\n",
    "\n",
    "        if not fringe or len(hypotheses) >= num_hypotheses:\n",
    "            break\n",
    "\n",
    "        Y_tm1 = np.array([n.value for n in fringe], dtype=np.int32)\n",
    "        state_tm1 = np.array([n.state for n in fringe], dtype=np.float32)\n",
    "        state_t, p_t, extras_t = generate_function(X, Y_tm1, state_tm1)\n",
    "        Y_t = np.argsort(p_t, axis=1)[:,-beam_width:] # no point in taking more than fits in the beam\n",
    "\n",
    "        next_fringe = []\n",
    "        for Y_t_n, p_t_n, extras_t_n, state_t_n, n in zip(Y_t, p_t, extras_t, state_t, fringe):\n",
    "            Y_nll_t_n = -np.log(p_t_n[Y_t_n])\n",
    "\n",
    "            for y_t_n, y_nll_t_n in zip(Y_t_n, Y_nll_t_n):\n",
    "                n_new = Node(parent=n, state=state_t_n, value=y_t_n, cost=y_nll_t_n, extras=extras_t_n)\n",
    "                next_fringe.append(n_new)\n",
    "\n",
    "        next_fringe = sorted(next_fringe, key=lambda n: n.cum_cost)[:beam_width] # may move this into loop to save memory\n",
    "\n",
    "    hypotheses.sort(key=lambda n: n.cum_cost)\n",
    "    return hypotheses[:num_hypotheses]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
